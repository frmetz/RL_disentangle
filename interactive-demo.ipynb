{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7b88ab",
   "metadata": {},
   "source": [
    "# <center>Reinforcement Learning to Disentangle Multiqubit Quantum States<br>from Partial Observations</center>\n",
    "---\n",
    "### <center>*Interactive Demos*</center>\n",
    "\n",
    "This notebook demonstrates the disentangling abilities of our RL agents. We choose to show only the 4 and 5-qubit agents, because they produce short enough circuits for this presentation format. Because the agents policy is modeled with Transformer architecture, we decided to show the attention scores (from the 4 qubit agent only). In each Episode Step you can apply a single qubit or two-qubit rotation to the current state. This lets you explore the generalization capabilities of the Deep Reinforcement Learning framework. (Note that the rotations are not shown in the Quantum Circuit). The amplitudes of the state are also visible and modifiable trough text boxes (Click on `Set` button to modify). The policy of the agent is shown as bar chart. Below the policy (negative Y) we show for each action $(i,j)$ what the average reduction in entanglement\n",
    "\n",
    "$$\\Delta S_\\mathrm{avg} = \\frac{1}{L}\\sum_{i=1}^{i=L}{\\Delta S_\\mathrm{ent}(\\rho^{(i)})}$$\n",
    "\n",
    "would be if the agent were to take action $(i,j)$. Using this \n",
    "information, it can be seen that our agent is not greedy - there are examples where the taken action is not the one that minimizes $\\Delta S_\\mathrm{avg}$. You can also input your own states to the agent. See the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "from demo_impl import start_demo_4q, start_demo_5q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aec4e0-415b-4932-9b66-3891e3ab67ce",
   "metadata": {},
   "source": [
    "#### Use this cell to extend the dropdown menu with your custom inital states\n",
    "There are default initial states also, for example `|0>|Bell>|0>` stands for $|0_1\\rangle|\\mathrm{Bell_{23}}\\rangle|0_4\\rangle$, `|GHZ>|Bell>` for $\\mathrm{|GHZ_{123}\\rangle|Bell_{45}\\rangle}$, `|RRRR>|R>` for $\\mathrm{|R_{1234}\\rangle|R_5\\rangle}$ and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956ac2c-4bcb-4910-9f72-7a01e981d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States are normalized and converted to np.complex64 automatically\n",
    "# You can add both 4q and 5q states here - they will appear\n",
    "# in the correct corresponding demo below, respectively\n",
    "my_initial_states = {\n",
    "    \"My4qState\": np.random.randn(16) + 1j * np.random.randn(16),\n",
    "    \"My5qState\": np.random.randn(32) + 1j * np.random.randn(32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51609e8-d087-4d56-8e26-61c8de143b6a",
   "metadata": {},
   "source": [
    "### Demo with 4-qubit agent\n",
    "\n",
    "- The Quantum Circuit is show in top-left, the policy of the agent (positive Y) and average entanglement reductions $\\Delta S_\\mathrm{avg}$ for each step $(i,j)$ (negative Y) is show in bottom-left and attention scores are in right subfigure.\n",
    "\n",
    "- Use `Step` button to advance the episode step. The taken action is always the one with highest probability.\n",
    "- Use `Undo` button to remove the last applied gate (undo taken action).\n",
    "- Use `Reset` button to clear everything and go back to the selected state in the $\\mathrm{Initial\\ state}$ dropdown menu\n",
    "- Use `Set` to apply the modifications to the z-basis amplitudes.\n",
    "- Use **Single qubit rotation** to apply a rotation over qubit $i$ (selected again trough dropdown menu). You cannot \"chain\" rotations - you can only rotate around one axis per qubit $i$ (at current $\\mathrm{Episode\\ Step}$).\n",
    "- Use **Two-qubit rotation** to apply a rotation over qubits $(i,j)$. Again, you cannot apply a series of rotations in the current $\\mathrm{Episode\\ Step}$).\n",
    "- The entanglement of each qibit $S_\\mathrm{ent}(\\rho^{(i)})$ with the rest of the system is shown in the status box **Single qubit entanglements**. Whenever a qubit is disentangled, it's numeric value turns <mark style=\"background-color:lightgreen;\">green</mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f6f45-8c96-4cd4-8a3e-feda58c3332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_demo_4q(my_initial_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82839ff-848a-4a84-ac68-efc3bf25c93b",
   "metadata": {},
   "source": [
    "### Demo with 5-qubit agent\n",
    "- Instructions are the same as in the 4-qubit case. Here, attention scores are not show simply because they take too much space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48dc4d-0c8b-47ee-a338-33df3d31e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_demo_5q(my_initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d9a77-372d-4477-babb-1c02d90d995e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
