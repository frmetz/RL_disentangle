{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7b88ab",
   "metadata": {},
   "source": [
    "# <center>Reinforcement Learning to Disentangle Multiqubit Quantum States<br>from Partial Observations</center>\n",
    "---\n",
    "### <center>*Interactive Demos*</center>\n",
    "\n",
    "This notebook accompanies the corresponding preprint article (arxiv:.....) where we present a deep reinforcement learning (RL) approach to constructing short disentangling circuits for arbitrary 4-, 5-, and 6-qubit states using an actor-critic algorithm. The agent has access only to two-qubit reduced density matrices and, given this partial information, decides which pairs of qubits to apply two-qubit gates on. Utilizing a permutation-equivariant transformer architecture, the agent can autonomously identify qubit permutations within the state, and adjusts the disentangling protocol accordingly. Once trained, it provides circuits from different initial states without further optimization. For all details regarding the methods we refer to the manuscript. \n",
    "\n",
    "This notebook demonstrates the disentangling abilities of our RL agents. We only show the results of trained 4 and 5-qubit agents, because they produce short enough circuits for this presentation format. Within the demo you can choose from different initial states to start from or specify a custom initial state. Furthermore the demo allows you to modify the multiqubit state by applying arbitrary single- and two-qubit gates. This lets you explore the generalization capabilities of our RL agents. The demo gives you insights about the action selection of the agent by displaying the policy output probabilities $\\pi(a|o)$ and the attention scores of the transformer model (only for the 4-qubit agent). You can observe how the agent produces the disentangling circuit step-by-step and adapts to changes in the quantum state. Moreover, we display the expected average reduction in the single-qubit entanglement entropy $\\Delta S_\\mathrm{avg}$ for every step and each possible action (qubit pair $(i,j)$)\n",
    "\n",
    "$$\\Delta S_\\mathrm{avg} = \\frac{1}{L}\\sum_{i=1}^{i=L}{\\Delta S_\\mathrm{ent}(\\rho^{(i)})}$$\n",
    "\n",
    "Using this information, it can be seen that our agent is not greedy - there are examples where the chosen action is not the one that minimizes $\\Delta S_\\mathrm{avg}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "from demo_impl import start_demo_4q, start_demo_5q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aec4e0-415b-4932-9b66-3891e3ab67ce",
   "metadata": {},
   "source": [
    "#### Use this cell to define additional initial states that you can utilize in the demos below\n",
    "The demos already contain some pre-defined initial states such as `|0>|Bell>|0>` corresponding to $|0_1\\rangle|\\mathrm{Bell_{23}}\\rangle|0_4\\rangle$, `|GHZ>|Bell>` corresponding to $\\mathrm{|GHZ_{123}\\rangle|Bell_{45}\\rangle}$, `|RRRR>|R>` corresponding to $\\mathrm{|R_{1234}\\rangle|R_5\\rangle}$ and so on ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956ac2c-4bcb-4910-9f72-7a01e981d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States are normalized and converted to np.complex64 automatically\n",
    "# You can add both 4q and 5q states here - they will appear\n",
    "# in the corresponding demo below, respectively\n",
    "my_initial_states = {\n",
    "    \"My4qState\": np.random.randn(16) + 1j * np.random.randn(16),\n",
    "    \"My5qState\": np.random.randn(32) + 1j * np.random.randn(32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51609e8-d087-4d56-8e26-61c8de143b6a",
   "metadata": {},
   "source": [
    "### Demo with 4-qubit agent\n",
    "\n",
    "#### Running the agent\n",
    "- The initial state of the circuit (e.g. `|0>|Bell>|0>`) can be specified through the $\\mathrm{Initial\\ state}$ dropdown menu.\n",
    "- Use the `Step` button to advance the episode step and apply one action (i.e. gate). The taken action is always the one with the highest probability according to the RL policy.\n",
    "- Use the `Undo` button to remove the last applied gate (i.e. to undo the latest action).\n",
    "- Use the `Reset` button to clear everything and initialize the circuit again in the selected state in the $\\mathrm{Initial\\ state}$ dropdown menu.\n",
    "\n",
    "#### Additional information\n",
    "- The current episode step and the corresponding disentangling quantum circuit diagram are displayed in the center left.\n",
    "- The entanglement entropy of each qubit $S_\\mathrm{ent}(\\rho^{(i)})$ with the rest of the system is shown in the status box **Single qubit entanglements**. Whenever a qubit is disentangled, it's numeric value turns <mark style=\"background-color:lightgreen;\">green</mark>. \n",
    "- The probabilites $\\pi(a|o)$ of choosing each action (i.e., qubit indices $(i,j)$) are plotted in blue below the circuit. The action with the highest probability that will be chosen next is indicated in red.\n",
    "- The average expected entanglement reductions $\\Delta S_\\mathrm{avg}$ for each possible action (i.e., qubit pair $(i,j)$) are plotted in green below their corresponding policy probabilities.\n",
    "- The attention scores of the transformer policy network are shown on the right.\n",
    "\n",
    "#### Changing the quantum state\n",
    "- You can apply additional single- and two-qubit gates to the quantum state at any episode step. (Note that these gates are not shown in the circuit diagram; only gates chosen by the agent are displayed.)\n",
    "    - Use **Single qubit rotation** to apply a rotation gate to qubit $i$ (selected trough the dropdown menu). Drag the handles of the sliders to specify the angles of the rotation gate.\n",
    "    - Use **Two-qubit rotation** to apply a two-qubit gate to qubits $(i,j)$ (selected trough the dropdown menu). Drag the handles of the sliders to specify the angles of the two-qubit rotation gate.\n",
    "- You can also specify the exact quantum state amplitudes in the computational basis (z-basis) at the bottom. Use the `Set` button to apply the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f6f45-8c96-4cd4-8a3e-feda58c3332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_demo_4q(my_initial_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82839ff-848a-4a84-ac68-efc3bf25c93b",
   "metadata": {},
   "source": [
    "### Demo with 5-qubit agent\n",
    "The instructions and information shown are the same as in the 4-qubit demo case above. However here, attention scores are not displayed simply because they would take up too much space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48dc4d-0c8b-47ee-a338-33df3d31e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_demo_5q(my_initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d9a77-372d-4477-babb-1c02d90d995e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
