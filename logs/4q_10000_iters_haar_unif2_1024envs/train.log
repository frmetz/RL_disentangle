
Iteration (1 / 10000):
    Value Loss: {'avg': 44.15324161052704, 'std': 10.621328060009319}
    Value Grad Norm: {'avg': 17.37217625975609, 'std': 10.553282059840825}
    Policy Loss: {'avg': -0.023615046736085787, 'std': 0.007943486273325171}
    Total_Loss: {'avg': -0.20063890479505062, 'std': 0.007933182787608673}
    Policy Entropy: {'avg': 1.7717481851577759, 'std': 0.020300351083278656}
    KL Divergence: {'avg': 0.01558946818113327, 'std': 0.16118496656417847}
    Policy Grad Norm: {'avg': 0.3044688869267702, 'std': 0.07409822140487801}
    Num PPO updates: {'avg': 80}
    Return: {'avg': -2.4899800369837646, 'std': 4.371117930399689, 'run': -7.213940274715688, 'test_avg': -27.970466411137817, 'test_std': 7.552871897591048}
    Episode Length: {'avg': 2.757197696737044, 'std': 2.2666680581143934, 'run': 5.054854549828055, 'test_avg': 9.6416015625, 'test_std': 1.0804855378474802}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.1240234375}

Iteration (101 / 10000):
    Value Loss: {'avg': 1.8523987784981728, 'std': 0.3708908078979083}
    Value Grad Norm: {'avg': 12.856164759397506, 'std': 7.394339646657795}
    Policy Loss: {'avg': 0.005925565608777106, 'std': 0.013920746062627061}
    Total_Loss: {'avg': -0.0467593758367002, 'std': 0.01398147925147521}
    Policy Entropy: {'avg': 0.5797398090362549, 'std': 0.48768243193626404}
    KL Divergence: {'avg': 0.06291677802801132, 'std': 0.5150245428085327}
    Policy Grad Norm: {'avg': 4.072843916714191, 'std': 2.624238846968663}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.3814261684811138, 'std': 4.0675650205853895, 'run': -1.7642737021185286, 'test_avg': -7.103047800766054, 'test_std': 2.0094440505808953}
    Episode Length: {'avg': 2.59, 'std': 1.7930490790828901, 'run': 2.7922305387530746, 'test_avg': 5.150390625, 'test_std': 0.58366420989479}
    Ratio Terminated: {'avg': 0.99875, 'test_avg': 0.9951171875}

Iteration (201 / 10000):
    Value Loss: {'avg': 3.2862847059965135, 'std': 0.6644045336237411}
    Value Grad Norm: {'avg': 28.215657198429106, 'std': 14.621429464995206}
    Policy Loss: {'avg': -0.01711946225259453, 'std': 0.024609013651343967}
    Total_Loss: {'avg': -0.07555789570324123, 'std': 0.02445041960535791}
    Policy Entropy: {'avg': 0.5420265197753906, 'std': 0.4885806143283844}
    KL Divergence: {'avg': 0.04867041856050491, 'std': 0.3297789990901947}
    Policy Grad Norm: {'avg': 4.421044640243053, 'std': 3.4625804842164487}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.4566912255745992, 'std': 4.571058961513293, 'run': -1.1370165246204709, 'test_avg': -6.832482210767921, 'test_std': 1.062562584037986}
    Episode Length: {'avg': 2.586206896551724, 'std': 1.929708194070085, 'run': 2.424927614973191, 'test_avg': 5.02734375, 'test_std': 0.2710554728020401}
    Ratio Terminated: {'avg': 0.9965827896862379, 'test_avg': 1.0}

Iteration (301 / 10000):
    Value Loss: {'avg': 0.5856307417154312, 'std': 0.22302419916960636}
    Value Grad Norm: {'avg': 8.412515547871589, 'std': 3.8080016263083354}
    Policy Loss: {'avg': 0.005779541374067776, 'std': 0.011285486770262958}
    Total_Loss: {'avg': -0.034086422878317535, 'std': 0.011843514253495417}
    Policy Entropy: {'avg': 0.39976954460144043, 'std': 0.5039430260658264}
    KL Divergence: {'avg': 0.031669557094573975, 'std': 0.2425491213798523}
    Policy Grad Norm: {'avg': 1.6321266256272793, 'std': 0.4771650584702787}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.046124290974868, 'std': 3.5537798413189656, 'run': -1.1477081202465471, 'test_avg': -6.793080137670997, 'test_std': 1.6415959974697873}
    Episode Length: {'avg': 2.458047178262168, 'std': 1.6273780751216458, 'run': 2.4841357772363235, 'test_avg': 5.0732421875, 'test_std': 0.5186999561116377}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (401 / 10000):
    Value Loss: {'avg': 0.5576334409415722, 'std': 0.2051225189323381}
    Value Grad Norm: {'avg': 12.568855798244476, 'std': 6.036457803157561}
    Policy Loss: {'avg': 0.013502403686288744, 'std': 0.019118993651689616}
    Total_Loss: {'avg': -0.028579710982739925, 'std': 0.018752253655530998}
    Policy Entropy: {'avg': 0.4254092276096344, 'std': 0.5141587853431702}
    KL Divergence: {'avg': 0.02361416257917881, 'std': 0.24407842755317688}
    Policy Grad Norm: {'avg': 4.071258902549744, 'std': 4.755649562129394}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.0164461623960186, 'std': 3.545010650864012, 'run': -1.4677590991305747, 'test_avg': -6.671979388556792, 'test_std': 1.00448502526608}
    Episode Length: {'avg': 2.4473131191834283, 'std': 1.626992319751688, 'run': 2.641222884834781, 'test_avg': 5.04296875, 'test_std': 0.30315620812287103}
    Ratio Terminated: {'avg': 0.9993995797057941, 'test_avg': 1.0}

Iteration (501 / 10000):
    Value Loss: {'avg': 0.3074058542959392, 'std': 0.12055721477520227}
    Value Grad Norm: {'avg': 4.839849652349949, 'std': 2.1101468274589448}
    Policy Loss: {'avg': 0.006446975196013227, 'std': 0.012520698873434015}
    Total_Loss: {'avg': -0.03239476657472551, 'std': 0.01243258982358384}
    Policy Entropy: {'avg': 0.3980966806411743, 'std': 0.48973339796066284}
    KL Divergence: {'avg': 0.03445158153772354, 'std': 0.26772376894950867}
    Policy Grad Norm: {'avg': 2.2381711304187775, 'std': 1.885228497931809}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9277508959512225, 'std': 3.426063561268474, 'run': -1.1494939578471015, 'test_avg': -6.560362849158992, 'test_std': 0.6646483288076007}
    Episode Length: {'avg': 2.4177881802223524, 'std': 1.5881913636831457, 'run': 2.5267058686257258, 'test_avg': 5.0146484375, 'test_std': 0.1733749139258866}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (601 / 10000):
    Value Loss: {'avg': 0.5885590575635433, 'std': 0.15754795632703836}
    Value Grad Norm: {'avg': 7.6397259622812275, 'std': 3.7849733161672776}
    Policy Loss: {'avg': -0.000604718952672556, 'std': 0.013887677360622516}
    Total_Loss: {'avg': -0.044984804349951446, 'std': 0.014508751722401098}
    Policy Entropy: {'avg': 0.4545830488204956, 'std': 0.5477197766304016}
    KL Divergence: {'avg': 0.05104152113199234, 'std': 0.34681177139282227}
    Policy Grad Norm: {'avg': 3.1212530434131622, 'std': 3.822414890746803}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.1429240977675037, 'std': 3.7899029796681956, 'run': -1.4082263650011284, 'test_avg': -6.592031424002926, 'test_std': 0.6517435217817589}
    Episode Length: {'avg': 2.5173140620295094, 'std': 1.7305076023260664, 'run': 2.6789571292967524, 'test_avg': 5.01171875, 'test_std': 0.13926205835918662}
    Ratio Terminated: {'avg': 0.999096657633243, 'test_avg': 1.0}

Iteration (701 / 10000):
    Value Loss: {'avg': 0.2939303655177355, 'std': 0.11873231502004311}
    Value Grad Norm: {'avg': 5.237294927239418, 'std': 3.6311028613043637}
    Policy Loss: {'avg': 0.0029699061706196517, 'std': 0.0060561605595493215}
    Total_Loss: {'avg': -0.03807435976341367, 'std': 0.006369949549009381}
    Policy Entropy: {'avg': 0.4151594042778015, 'std': 0.530232310295105}
    KL Divergence: {'avg': 0.04122784361243248, 'std': 0.348570317029953}
    Policy Grad Norm: {'avg': 2.497102152556181, 'std': 1.6475629152537279}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.0346611706247848, 'std': 3.5964981108122416, 'run': -1.0913247191621847, 'test_avg': -6.582528639474276, 'test_std': 0.7295865716205011}
    Episode Length: {'avg': 2.451130026416202, 'std': 1.632119377640637, 'run': 2.4700850440593762, 'test_avg': 5.015625, 'test_std': 0.17044862679118303}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 10000):
    Value Loss: {'avg': 0.40260446425527335, 'std': 0.1291414153326709}
    Value Grad Norm: {'avg': 5.8376721575856205, 'std': 2.974759304529981}
    Policy Loss: {'avg': 0.002974063449073583, 'std': 0.01841913564987051}
    Total_Loss: {'avg': -0.04143379861488938, 'std': 0.01855564562725699}
    Policy Entropy: {'avg': 0.39148491621017456, 'std': 0.5313823223114014}
    KL Divergence: {'avg': 0.026225727051496506, 'std': 0.2603612542152405}
    Policy Grad Norm: {'avg': 2.5731061659753323, 'std': 5.246314054955507}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.941485265886114, 'std': 3.5090355907883692, 'run': -0.9950183509239263, 'test_avg': -6.580257269888534, 'test_std': 0.7998152997512334}
    Episode Length: {'avg': 2.4100147275405006, 'std': 1.6210380044464359, 'run': 2.51401354757292, 'test_avg': 5.01953125, 'test_std': 0.2244989538359533}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (901 / 10000):
    Value Loss: {'avg': 0.23682965440675616, 'std': 0.1405144843267371}
    Value Grad Norm: {'avg': 3.9991103410720825, 'std': 2.6364038292642604}
    Policy Loss: {'avg': 0.008171088411472738, 'std': 0.016820287233778045}
    Total_Loss: {'avg': -0.029940821463242173, 'std': 0.01661181265446743}
    Policy Entropy: {'avg': 0.41075289249420166, 'std': 0.547756016254425}
    KL Divergence: {'avg': 0.02726849727332592, 'std': 0.3009396493434906}
    Policy Grad Norm: {'avg': 2.0411660112440586, 'std': 1.4329190638986251}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.88432898277014, 'std': 3.4046981860297567, 'run': -0.9490547856201886, 'test_avg': -6.5958676254590785, 'test_std': 1.028516101623264}
    Episode Length: {'avg': 2.3825464949928468, 'std': 1.5894443776132405, 'run': 2.416944857163915, 'test_avg': 5.0283203125, 'test_std': 0.30647107922266065}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1001 / 10000):
    Value Loss: {'avg': 0.20146992998197674, 'std': 0.10771408689737606}
    Value Grad Norm: {'avg': 1.4723619230091571, 'std': 0.5561715511082835}
    Policy Loss: {'avg': 0.001925153483171016, 'std': 0.00757734577310775}
    Total_Loss: {'avg': -0.03914751682896167, 'std': 0.0075416767817790544}
    Policy Entropy: {'avg': 0.42714348435401917, 'std': 0.5483860373497009}
    KL Divergence: {'avg': 0.057706594467163086, 'std': 0.4452250003814697}
    Policy Grad Norm: {'avg': 2.1291334480047226, 'std': 1.3542163109459482}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9019023160339514, 'std': 3.4370395389365456, 'run': -0.7320718487125747, 'test_avg': -7.220970678507824, 'test_std': 4.6191937543340025}
    Episode Length: {'avg': 2.394904458598726, 'std': 1.5819031510099653, 'run': 2.379917775923333, 'test_avg': 5.1103515625, 'test_std': 0.7184308214113649}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9794921875}

Iteration (1101 / 10000):
    Value Loss: {'avg': 0.1284957851283252, 'std': 0.0615163512117466}
    Value Grad Norm: {'avg': 1.680577776581049, 'std': 0.8860337399300529}
    Policy Loss: {'avg': 0.012137100740801543, 'std': 0.019844564726493638}
    Total_Loss: {'avg': -0.027318568900227547, 'std': 0.02017152391593896}
    Policy Entropy: {'avg': 0.3908533751964569, 'std': 0.564777135848999}
    KL Divergence: {'avg': 0.02501147799193859, 'std': 0.23891231417655945}
    Policy Grad Norm: {'avg': 3.5670873150229454, 'std': 4.363434041492346}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7842044509543191, 'std': 3.327949658926416, 'run': -0.7721349765476905, 'test_avg': -6.57212463360009, 'test_std': 0.6699442323163536}
    Episode Length: {'avg': 2.3389974511469838, 'std': 1.5632805091961177, 'run': 2.308825158265569, 'test_avg': 5.0126953125, 'test_std': 0.18966191378483804}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1201 / 10000):
    Value Loss: {'avg': 0.1292345135472715, 'std': 0.08482263792806571}
    Value Grad Norm: {'avg': 1.286092982813716, 'std': 0.8210099528875481}
    Policy Loss: {'avg': 0.0010560505033936352, 'std': 0.00576088724289089}
    Total_Loss: {'avg': -0.03883815836161375, 'std': 0.0054043928671674716}
    Policy Entropy: {'avg': 0.39054906368255615, 'std': 0.5523842573165894}
    KL Divergence: {'avg': 0.01732890121638775, 'std': 0.21342776715755463}
    Policy Grad Norm: {'avg': 1.6343271099030972, 'std': 0.863407747310328}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9660959308697196, 'std': 3.4301872088485874, 'run': -0.8114421241944407, 'test_avg': -6.563110553797742, 'test_std': 0.7456371410504989}
    Episode Length: {'avg': 2.4180807489760094, 'std': 1.5983061002833072, 'run': 2.4165545854578823, 'test_avg': 5.0146484375, 'test_std': 0.21373783188478496}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 10000):
    Value Loss: {'avg': 0.13648311914876105, 'std': 0.06599252212497936}
    Value Grad Norm: {'avg': 1.7692728906869888, 'std': 0.9526957755507636}
    Policy Loss: {'avg': 0.005456713028252125, 'std': 0.014340620148480024}
    Total_Loss: {'avg': -0.03783371613826603, 'std': 0.014864621130340297}
    Policy Entropy: {'avg': 0.398294597864151, 'std': 0.5625438690185547}
    KL Divergence: {'avg': 0.01926525868475437, 'std': 0.2611648738384247}
    Policy Grad Norm: {'avg': 3.3795728851109743, 'std': 7.089184462283197}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8931484606255574, 'std': 3.374016381872052, 'run': -0.8378718699283976, 'test_avg': -6.576276116666257, 'test_std': 0.8837919978031527}
    Episode Length: {'avg': 2.3643655113148094, 'std': 1.5881009008831033, 'run': 2.2702943425459803, 'test_avg': 5.0185546875, 'test_std': 0.2875126711499466}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (1401 / 10000):
    Value Loss: {'avg': 0.09955368358641863, 'std': 0.03207661513405959}
    Value Grad Norm: {'avg': 0.893812870234251, 'std': 0.28910502533491805}
    Policy Loss: {'avg': 0.00872797059128061, 'std': 0.01089605978369452}
    Total_Loss: {'avg': -0.03085313457995653, 'std': 0.010100621436162183}
    Policy Entropy: {'avg': 0.39061230421066284, 'std': 0.5606911778450012}
    KL Divergence: {'avg': 0.0183428805321455, 'std': 0.23336032032966614}
    Policy Grad Norm: {'avg': 2.4862039759755135, 'std': 1.3890179685303343}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8519205702274657, 'std': 3.374489582165475, 'run': -0.6460374588728075, 'test_avg': -6.540145403741917, 'test_std': 0.5145778657886825}
    Episode Length: {'avg': 2.378134110787172, 'std': 1.5786993260875308, 'run': 2.1949394378899956, 'test_avg': 5.0048828125, 'test_std': 0.08253542053015689}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 10000):
    Value Loss: {'avg': 0.09585357392206788, 'std': 0.054049833919181424}
    Value Grad Norm: {'avg': 1.4209833517670631, 'std': 0.7836509799663655}
    Policy Loss: {'avg': -0.0014264842102420516, 'std': 0.008577901729239945}
    Total_Loss: {'avg': -0.03890554659301415, 'std': 0.008630571106530056}
    Policy Entropy: {'avg': 0.4195719361305237, 'std': 0.583477258682251}
    KL Divergence: {'avg': 0.0253034345805645, 'std': 0.23899902403354645}
    Policy Grad Norm: {'avg': 1.3546634633094072, 'std': 1.0922755669969266}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.9459247013199508, 'std': 3.4465036917822705, 'run': -0.7593656545958339, 'test_avg': -6.553041187682538, 'test_std': 0.6896429318549562}
    Episode Length: {'avg': 2.4434075857916917, 'std': 1.5952462329330814, 'run': 2.4277891774057108, 'test_avg': 5.0107421875, 'test_std': 0.17919589255257734}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 10000):
    Value Loss: {'avg': 0.07632315936498343, 'std': 0.02513679358619778}
    Value Grad Norm: {'avg': 0.6594367191195488, 'std': 0.24109051808574425}
    Policy Loss: {'avg': 0.0019438592426013201, 'std': 0.007095342415629686}
    Total_Loss: {'avg': -0.036624995176680386, 'std': 0.007491179248212902}
    Policy Entropy: {'avg': 0.3774740993976593, 'std': 0.560828685760498}
    KL Divergence: {'avg': 0.02481434866786003, 'std': 0.34602925181388855}
    Policy Grad Norm: {'avg': 1.7734014987945557, 'std': 1.3108197570912}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7996637647449066, 'std': 3.3272029929214106, 'run': -0.6754179180203703, 'test_avg': -6.583680646985595, 'test_std': 0.7802897543100444}
    Episode Length: {'avg': 2.352206736353078, 'std': 1.5572479772723578, 'run': 2.3091498575168665, 'test_avg': 5.015625, 'test_std': 0.2415566380271923}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1701 / 10000):
    Value Loss: {'avg': 0.1772047786973417, 'std': 0.10771376098335268}
    Value Grad Norm: {'avg': 3.976749587804079, 'std': 2.4937012595160257}
    Policy Loss: {'avg': 0.0011314459843561053, 'std': 0.007953417967502216}
    Total_Loss: {'avg': -0.037483357707969844, 'std': 0.007812356759486605}
    Policy Entropy: {'avg': 0.3802153468132019, 'std': 0.5430921316146851}
    KL Divergence: {'avg': 0.03342686593532562, 'std': 0.3330349624156952}
    Policy Grad Norm: {'avg': 1.6009481698274612, 'std': 0.9764952014216428}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8551172012489073, 'std': 3.435979381742678, 'run': -0.528854479340356, 'test_avg': -6.553538668114925, 'test_std': 0.586761420136988}
    Episode Length: {'avg': 2.3822248039500438, 'std': 1.5942636202496463, 'run': 2.2369101843038384, 'test_avg': 5.0107421875, 'test_std': 0.12055307091781131}
    Ratio Terminated: {'avg': 0.9994191112401976, 'test_avg': 1.0}

Iteration (1801 / 10000):
    Value Loss: {'avg': 0.07755644242279232, 'std': 0.03095107553746694}
    Value Grad Norm: {'avg': 0.7022697050124407, 'std': 0.5346656003161435}
    Policy Loss: {'avg': 0.003922970412531868, 'std': 0.008023137507555393}
    Total_Loss: {'avg': -0.03402116848155856, 'std': 0.009211860239810788}
    Policy Entropy: {'avg': 0.41566145420074463, 'std': 0.5707206130027771}
    KL Divergence: {'avg': 0.028264950960874557, 'std': 0.2787701487541199}
    Policy Grad Norm: {'avg': 2.420557212084532, 'std': 2.023968703391031}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8223732673852251, 'std': 3.3596345740407587, 'run': -0.9264494102569992, 'test_avg': -6.542962364008417, 'test_std': 0.6102648851419473}
    Episode Length: {'avg': 2.3709724238026126, 'std': 1.571877049223398, 'run': 2.496229870288166, 'test_avg': 5.0048828125, 'test_std': 0.13612804869713604}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 10000):
    Value Loss: {'avg': 0.13479819619096817, 'std': 0.08372085888452413}
    Value Grad Norm: {'avg': 2.4334520936012267, 'std': 2.2493605293102785}
    Policy Loss: {'avg': 0.0015023467130959034, 'std': 0.008035856247930873}
    Total_Loss: {'avg': -0.03790939366444945, 'std': 0.008005057673809018}
    Policy Entropy: {'avg': 0.3816578984260559, 'std': 0.5489903688430786}
    KL Divergence: {'avg': 0.016917061060667038, 'std': 0.22423334419727325}
    Policy Grad Norm: {'avg': 1.6227825451642275, 'std': 1.1663675978251815}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8756628385972278, 'std': 3.427644493540358, 'run': -0.6304499554533383, 'test_avg': -6.554702443696442, 'test_std': 0.5095434602003338}
    Episode Length: {'avg': 2.3868977673325498, 'std': 1.589797047887961, 'run': 2.285917546274146, 'test_avg': 5.0048828125, 'test_std': 0.06970631708883954}
    Ratio Terminated: {'avg': 0.9997062279670975, 'test_avg': 1.0}

Iteration (2001 / 10000):
    Value Loss: {'avg': 0.3138711258769035, 'std': 0.09388215916463649}
    Value Grad Norm: {'avg': 2.360820337384939, 'std': 2.679781435894111}
    Policy Loss: {'avg': -0.008454838942270726, 'std': 0.006264652789554699}
    Total_Loss: {'avg': -0.050893523497506976, 'std': 0.006484175527321044}
    Policy Entropy: {'avg': 0.4344685971736908, 'std': 0.5798804759979248}
    KL Divergence: {'avg': 0.10375585407018661, 'std': 0.6740728616714478}
    Policy Grad Norm: {'avg': 1.6286669373512268, 'std': 1.7701643982733772}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -1.0685997704007237, 'std': 3.4978401518080373, 'run': -1.0541383723938347, 'test_avg': -6.549888516492501, 'test_std': 0.5567135982793211}
    Episode Length: {'avg': 2.485913359588004, 'std': 1.6427892222451679, 'run': 2.5055593174952002, 'test_avg': 5.005859375, 'test_std': 0.09864731483729992}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 10000):
    Value Loss: {'avg': 0.10579371836502105, 'std': 0.05233855233862177}
    Value Grad Norm: {'avg': 0.8792824901640415, 'std': 0.5931240543962969}
    Policy Loss: {'avg': -0.0025111747187717506, 'std': 0.010613740867489311}
    Total_Loss: {'avg': -0.040619100987290345, 'std': 0.011350615902790368}
    Policy Entropy: {'avg': 0.3892570734024048, 'std': 0.5485937595367432}
    KL Divergence: {'avg': 0.015441207215189934, 'std': 0.15987297892570496}
    Policy Grad Norm: {'avg': 0.9138124125699202, 'std': 0.6216329600559192}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -0.8715472954715218, 'std': 3.3933453256482577, 'run': -1.448400978685166, 'test_avg': -6.49616414065531, 'test_std': 0.4994586448251124}
    Episode Length: {'avg': 2.3962885363663573, 'std': 1.5840527076142803, 'run': 2.5772342549375904, 'test_avg': 5.00390625, 'test_std': 0.07644681949523799}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 10000):
    Value Loss: {'avg': 0.151349838078022, 'std': 0.05719109622903959}
    Value Grad Norm: {'avg': 1.567281912639737, 'std': 1.532463621132899}
    Policy Loss: {'avg': -0.00528397606103681, 'std': 0.006310382511674667}
    Total_Loss: {'avg': -0.045148377190344036, 'std': 0.006821084764297646}
    Policy Entropy: {'avg': 0.4107283353805542, 'std': 0.5622900128364563}
    KL Divergence: {'avg': 0.041839949786663055, 'std': 0.42010924220085144}
    Policy Grad Norm: {'avg': 1.6096440069377422, 'std': 1.2222975205549513}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.943297965121198, 'std': 3.3899101816523873, 'run': -1.282495364474541, 'test_avg': -6.5633030212238825, 'test_std': 0.7655016852171841}
    Episode Length: {'avg': 2.42874109263658, 'std': 1.5821617197093887, 'run': 2.5745093116497557, 'test_avg': 5.01171875, 'test_std': 0.23355978013869919}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (2301 / 10000):
    Value Loss: {'avg': 0.07118387366645038, 'std': 0.0326999361813103}
    Value Grad Norm: {'avg': 0.5890027321875095, 'std': 0.27374917391013276}
    Policy Loss: {'avg': -0.0013131515006534755, 'std': 0.00807974806937882}
    Total_Loss: {'avg': -0.038576228893361986, 'std': 0.00890801381094005}
    Policy Entropy: {'avg': 0.38130247592926025, 'std': 0.5507258176803589}
    KL Divergence: {'avg': 0.018249616026878357, 'std': 0.20828711986541748}
    Policy Grad Norm: {'avg': 1.3643369041383266, 'std': 1.1925998983172132}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8165660715871568, 'std': 3.3446113521546406, 'run': -0.8413693185349206, 'test_avg': -6.543885546052479, 'test_std': 0.8162857039534961}
    Episode Length: {'avg': 2.363194046937607, 'std': 1.5626678963657148, 'run': 2.381061194451693, 'test_avg': 5.0107421875, 'test_std': 0.2315071120024498}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (2401 / 10000):
    Value Loss: {'avg': 0.11541414335370064, 'std': 0.07758288702599228}
    Value Grad Norm: {'avg': 0.8539487712085247, 'std': 0.3794727209268987}
    Policy Loss: {'avg': 0.0010022856295108795, 'std': 0.011201865864877654}
    Total_Loss: {'avg': -0.03783573384862393, 'std': 0.011751174543843992}
    Policy Entropy: {'avg': 0.3801116943359375, 'std': 0.5393781065940857}
    KL Divergence: {'avg': 0.017034713178873062, 'std': 0.23366551101207733}
    Policy Grad Norm: {'avg': 1.7837440259754658, 'std': 1.4663500369874372}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8206251615110939, 'std': 3.3526410737501036, 'run': -1.1061353622294394, 'test_avg': -6.520152825809156, 'test_std': 0.6877733408423277}
    Episode Length: {'avg': 2.3578247035001447, 'std': 1.5706642127959487, 'run': 2.4348857103263697, 'test_avg': 5.0078125, 'test_std': 0.19748788530882092}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2501 / 10000):
    Value Loss: {'avg': 0.16180969676934182, 'std': 0.14651080625519883}
    Value Grad Norm: {'avg': 4.388566748052836, 'std': 3.4653746460475614}
    Policy Loss: {'avg': 0.010651905206032097, 'std': 0.019570371494139618}
    Total_Loss: {'avg': -0.029154747258871794, 'std': 0.01881325329258631}
    Policy Entropy: {'avg': 0.450140118598938, 'std': 0.521856963634491}
    KL Divergence: {'avg': 0.06867768615484238, 'std': 0.27556613087654114}
    Policy Grad Norm: {'avg': 2.172321053221822, 'std': 1.722919311906156}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9439058448098815, 'std': 3.4970488590105187, 'run': -0.8760412680028539, 'test_avg': -6.551827877628966, 'test_std': 0.7730483514858258}
    Episode Length: {'avg': 2.4347697756788667, 'std': 1.6096836644307269, 'run': 2.3908225517665063, 'test_avg': 5.0205078125, 'test_std': 0.239158142505048}
    Ratio Terminated: {'avg': 0.9991145218417946, 'test_avg': 0.9990234375}

Iteration (2601 / 10000):
    Value Loss: {'avg': 0.06451738083269447, 'std': 0.025394865574594725}
    Value Grad Norm: {'avg': 0.6936486758291721, 'std': 0.4562130260271119}
    Policy Loss: {'avg': 0.0009526402864139527, 'std': 0.007916291841784965}
    Total_Loss: {'avg': -0.03994259494356811, 'std': 0.008640987803014071}
    Policy Entropy: {'avg': 0.4176173210144043, 'std': 0.5747054815292358}
    KL Divergence: {'avg': 0.035825639963150024, 'std': 0.306112676858902}
    Policy Grad Norm: {'avg': 1.979749783873558, 'std': 1.2490985163211379}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7717916459224299, 'std': 3.354186359503323, 'run': -0.5804468207798356, 'test_avg': -7.37021606231559, 'test_std': 5.187842512758465}
    Episode Length: {'avg': 2.3416594889463105, 'std': 1.5577158502615795, 'run': 2.249846095213521, 'test_avg': 5.134765625, 'test_std': 0.8121407521595991}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9736328125}

Iteration (2701 / 10000):
    Value Loss: {'avg': 0.09743788884952664, 'std': 0.06680076576164796}
    Value Grad Norm: {'avg': 1.497593442723155, 'std': 1.6382701685271703}
    Policy Loss: {'avg': -0.0018476478289812803, 'std': 0.005240372645768996}
    Total_Loss: {'avg': -0.041177772800438106, 'std': 0.005741639913328611}
    Policy Entropy: {'avg': 0.3975718021392822, 'std': 0.5819923281669617}
    KL Divergence: {'avg': 0.024052390828728676, 'std': 0.22701233625411987}
    Policy Grad Norm: {'avg': 1.6364448722451925, 'std': 1.354609920500352}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7993942905943862, 'std': 3.3754219408927777, 'run': -1.155841638156883, 'test_avg': -6.506647425267147, 'test_std': 0.5197722381333592}
    Episode Length: {'avg': 2.3617205542725173, 'std': 1.5688366103265334, 'run': 2.526182584841885, 'test_avg': 5.0009765625, 'test_std': 0.09374491359899796}
    Ratio Terminated: {'avg': 0.9997113163972287, 'test_avg': 1.0}

Iteration (2801 / 10000):
    Value Loss: {'avg': 0.05814114063978195, 'std': 0.01923966302445174}
    Value Grad Norm: {'avg': 0.5092724476009607, 'std': 0.21503376601431407}
    Policy Loss: {'avg': 0.01714905998960603, 'std': 0.038711336717141734}
    Total_Loss: {'avg': -0.020952494931407273, 'std': 0.039929155951208044}
    Policy Entropy: {'avg': 0.35516610741615295, 'std': 0.5223585367202759}
    KL Divergence: {'avg': 0.01911255717277527, 'std': 0.2697141170501709}
    Policy Grad Norm: {'avg': 2.4404975697398186, 'std': 1.9944446361586223}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8151787892664245, 'std': 3.3712932949577024, 'run': -0.6933819507749859, 'test_avg': -6.566096911435535, 'test_std': 0.964266416518002}
    Episode Length: {'avg': 2.384683357879234, 'std': 1.5635392364505565, 'run': 2.3383332509558086, 'test_avg': 5.0244140625, 'test_std': 0.3192851641593234}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (2901 / 10000):
    Value Loss: {'avg': 0.06164250879082829, 'std': 0.045438341914968525}
    Value Grad Norm: {'avg': 0.6174460895359516, 'std': 0.27585955852478383}
    Policy Loss: {'avg': 0.007170701021095738, 'std': 0.01066378479478455}
    Total_Loss: {'avg': -0.030160689144395292, 'std': 0.009942386007763168}
    Policy Entropy: {'avg': 0.39716461300849915, 'std': 0.5835381746292114}
    KL Divergence: {'avg': 0.021623311564326286, 'std': 0.2416529506444931}
    Policy Grad Norm: {'avg': 2.286462590098381, 'std': 1.5000698662527208}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7653077370232216, 'std': 3.3474816149845545, 'run': -0.5543793687902683, 'test_avg': -6.50995055596286, 'test_std': 0.6231700629593149}
    Episode Length: {'avg': 2.3638993346832513, 'std': 1.5571473065042525, 'run': 2.246386080161358, 'test_avg': 5.0126953125, 'test_std': 0.1557333989243391}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 10000):
    Value Loss: {'avg': 0.251598609611392, 'std': 0.13018617590810835}
    Value Grad Norm: {'avg': 1.7098073206841946, 'std': 0.7744605104759497}
    Policy Loss: {'avg': -0.0029674437537323684, 'std': 0.004688035966703165}
    Total_Loss: {'avg': -0.04205761174671352, 'std': 0.004567808370441685}
    Policy Entropy: {'avg': 0.40995579957962036, 'std': 0.5936191082000732}
    KL Divergence: {'avg': 0.03408225625753403, 'std': 0.4036688804626465}
    Policy Grad Norm: {'avg': 1.3216394111514091, 'std': 1.0387446422645232}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9556517423674151, 'std': 3.6617154282047664, 'run': -0.9852742979981233, 'test_avg': -6.520359376023407, 'test_std': 0.5609702433168032}
    Episode Length: {'avg': 2.3916666666666666, 'std': 1.6359079813276929, 'run': 2.4398894931970028, 'test_avg': 5.00390625, 'test_std': 0.12493894993530841}
    Ratio Terminated: {'avg': 0.9994252873563219, 'test_avg': 1.0}

Iteration (3101 / 10000):
    Value Loss: {'avg': 0.1762101450469345, 'std': 0.11162075051499765}
    Value Grad Norm: {'avg': 1.4298054106533526, 'std': 0.8746059091649884}
    Policy Loss: {'avg': 0.0020177541591692716, 'std': 0.005352605288847477}
    Total_Loss: {'avg': -0.03317764215171337, 'std': 0.005588467132670174}
    Policy Entropy: {'avg': 0.3766961991786957, 'std': 0.5529343485832214}
    KL Divergence: {'avg': 0.02943742834031582, 'std': 0.30837029218673706}
    Policy Grad Norm: {'avg': 2.573605189099908, 'std': 3.694670827687749}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9352328565387954, 'std': 3.481701044524498, 'run': -1.3486939635137178, 'test_avg': -6.564969279716024, 'test_std': 0.829291957446155}
    Episode Length: {'avg': 2.4368819080860966, 'std': 1.6109178272305524, 'run': 2.6373627999638183, 'test_avg': 5.017578125, 'test_std': 0.22896590253023347}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 10000):
    Value Loss: {'avg': 0.046559159038588406, 'std': 0.017396149116718936}
    Value Grad Norm: {'avg': 0.6742268554866314, 'std': 0.28184519733667596}
    Policy Loss: {'avg': -0.00015462430019397289, 'std': 0.009618030565545431}
    Total_Loss: {'avg': -0.03851120738545433, 'std': 0.009499369838472473}
    Policy Entropy: {'avg': 0.39313921332359314, 'std': 0.5777214169502258}
    KL Divergence: {'avg': 0.03931049630045891, 'std': 0.3419359624385834}
    Policy Grad Norm: {'avg': 1.4859925555065274, 'std': 1.879564189781774}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.787284277003488, 'std': 3.3406717175515124, 'run': -1.404909588833821, 'test_avg': -6.577393226332273, 'test_std': 0.8861749088843955}
    Episode Length: {'avg': 2.3608277470125327, 'std': 1.564814150411304, 'run': 2.6342605816027658, 'test_avg': 5.017578125, 'test_std': 0.2824343012480679}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (3301 / 10000):
    Value Loss: {'avg': 0.0924075338523835, 'std': 0.04541840661408957}
    Value Grad Norm: {'avg': 0.8097538318485021, 'std': 0.2995475283732568}
    Policy Loss: {'avg': -0.0026043665493489243, 'std': 0.011842628667353937}
    Total_Loss: {'avg': -0.04346488288138062, 'std': 0.01073070327052473}
    Policy Entropy: {'avg': 0.40635767579078674, 'std': 0.5765479803085327}
    KL Divergence: {'avg': 0.022852685302495956, 'std': 0.33350908756256104}
    Policy Grad Norm: {'avg': 1.4945201091468334, 'std': 1.5067173859374425}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.7577874436744311, 'std': 3.317193081131995, 'run': -0.7075720866444697, 'test_avg': -6.510226397136544, 'test_std': 0.6363312455138642}
    Episode Length: {'avg': 2.3353379152348226, 'std': 1.556525570077009, 'run': 2.2456161736251583, 'test_avg': 5.0078125, 'test_std': 0.16517480087395292}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3401 / 10000):
    Value Loss: {'avg': 0.12039031726308166, 'std': 0.0723185697711569}
    Value Grad Norm: {'avg': 1.7721241846680642, 'std': 1.528182444125116}
    Policy Loss: {'avg': 0.0015681179356761277, 'std': 0.00616144388914778}
    Total_Loss: {'avg': -0.03522536426316947, 'std': 0.006613004693921081}
    Policy Entropy: {'avg': 0.3715009093284607, 'std': 0.5498948097229004}
    KL Divergence: {'avg': 0.019205402582883835, 'std': 0.27454566955566406}
    Policy Grad Norm: {'avg': 2.0505277514457703, 'std': 2.19218051969925}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9050795700285224, 'std': 3.442719126100785, 'run': -0.8358372128383403, 'test_avg': -6.510774117457913, 'test_std': 0.6311884100759063}
    Episode Length: {'avg': 2.4082962962962964, 'std': 1.597903042875483, 'run': 2.350436593938227, 'test_avg': 5.0048828125, 'test_std': 0.13612804869713604}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 10000):
    Value Loss: {'avg': 0.05276010897941887, 'std': 0.020713885680808848}
    Value Grad Norm: {'avg': 0.48502115793526174, 'std': 0.37079687934719036}
    Policy Loss: {'avg': 0.004258557775756344, 'std': 0.005574012070114901}
    Total_Loss: {'avg': -0.03418914170470089, 'std': 0.005719827273416006}
    Policy Entropy: {'avg': 0.43576371669769287, 'std': 0.616095244884491}
    KL Divergence: {'avg': 0.01782825216650963, 'std': 0.24807485938072205}
    Policy Grad Norm: {'avg': 2.4210547395050526, 'std': 1.6560939562590153}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8480378420572264, 'std': 3.3729003716314487, 'run': -0.5819532932877347, 'test_avg': -6.531711132163764, 'test_std': 0.506691682431524}
    Episode Length: {'avg': 2.3744531933508313, 'std': 1.5800965764602006, 'run': 2.2469778803016975, 'test_avg': 5.0, 'test_std': 0.08838834764831845}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3601 / 10000):
    Value Loss: {'avg': 0.06909389167558402, 'std': 0.06596946519582206}
    Value Grad Norm: {'avg': 0.7021777126938105, 'std': 0.48598827077026896}
    Policy Loss: {'avg': 0.008662613428896293, 'std': 0.013558399728210284}
    Total_Loss: {'avg': -0.0290787557605654, 'std': 0.012454829060852551}
    Policy Entropy: {'avg': 0.397678017616272, 'std': 0.5585855841636658}
    KL Divergence: {'avg': 0.025133416056632996, 'std': 0.2720757722854614}
    Policy Grad Norm: {'avg': 2.618352524936199, 'std': 2.002172455510407}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8470676709433095, 'std': 3.4004485307287107, 'run': -1.0196291461182696, 'test_avg': -6.5267613478215125, 'test_std': 0.6813528523705499}
    Episode Length: {'avg': 2.3874593315587105, 'std': 1.5884108044397942, 'run': 2.4694095943256946, 'test_avg': 5.005859375, 'test_std': 0.19755548011788834}
    Ratio Terminated: {'avg': 0.9997042295178941, 'test_avg': 0.9990234375}

Iteration (3701 / 10000):
    Value Loss: {'avg': 0.07681556835304945, 'std': 0.027537304068808055}
    Value Grad Norm: {'avg': 0.7258552759885788, 'std': 0.46415376948701165}
    Policy Loss: {'avg': 0.01303422954515554, 'std': 0.05239727348967924}
    Total_Loss: {'avg': -0.025696026510559022, 'std': 0.05265383387708197}
    Policy Entropy: {'avg': 0.4030659794807434, 'std': 0.5652583837509155}
    KL Divergence: {'avg': 0.021580616012215614, 'std': 0.2539348006248474}
    Policy Grad Norm: {'avg': 2.124427992850542, 'std': 2.4264950044296545}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7824596510443623, 'std': 3.396353881969817, 'run': -0.9191989161216899, 'test_avg': -6.52365941858443, 'test_std': 0.521392662925202}
    Episode Length: {'avg': 2.3570387642086854, 'std': 1.5698659238608725, 'run': 2.3493762186590152, 'test_avg': 5.001953125, 'test_std': 0.07652163290687396}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3801 / 10000):
    Value Loss: {'avg': 0.057219403749331835, 'std': 0.027001295906521346}
    Value Grad Norm: {'avg': 0.6765439547598362, 'std': 0.6546440295946636}
    Policy Loss: {'avg': -0.0016766346719426413, 'std': 0.02651917813397535}
    Total_Loss: {'avg': -0.040556713046195604, 'std': 0.026401041916040528}
    Policy Entropy: {'avg': 0.40573352575302124, 'std': 0.5805045962333679}
    KL Divergence: {'avg': 0.016100812703371048, 'std': 0.26286381483078003}
    Policy Grad Norm: {'avg': 1.8544767384106915, 'std': 5.564137681784938}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -0.9986926240093057, 'std': 3.428436189552156, 'run': -0.6025309318684859, 'test_avg': -6.524077463604044, 'test_std': 0.5017510757954936}
    Episode Length: {'avg': 2.440515433023674, 'std': 1.6087528709086854, 'run': 2.22629677136524, 'test_avg': 5.0029296875, 'test_std': 0.0826278066461427}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 10000):
    Value Loss: {'avg': 0.19365642410703005, 'std': 0.11138407857526939}
    Value Grad Norm: {'avg': 2.0322219997644426, 'std': 1.2751929138048772}
    Policy Loss: {'avg': 8.478574454784393e-05, 'std': 0.005298614789766089}
    Total_Loss: {'avg': -0.0381544012343511, 'std': 0.006478519751872718}
    Policy Entropy: {'avg': 0.37711358070373535, 'std': 0.5494097471237183}
    KL Divergence: {'avg': 0.03656693547964096, 'std': 0.4383557438850403}
    Policy Grad Norm: {'avg': 1.9764992482960224, 'std': 1.5329350766474348}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8747953950349245, 'std': 3.391180204508872, 'run': -0.9099934812552931, 'test_avg': -6.5121982292912435, 'test_std': 0.491044948972395}
    Episode Length: {'avg': 2.4040165386887185, 'std': 1.5860162487719118, 'run': 2.4053949603236724, 'test_avg': 5.0, 'test_std': 0.08838834764831845}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4001 / 10000):
    Value Loss: {'avg': 0.05383483076002449, 'std': 0.023208762670561378}
    Value Grad Norm: {'avg': 0.99985232912004, 'std': 0.9807801374006656}
    Policy Loss: {'avg': -0.0007192262492026202, 'std': 0.010612460411894826}
    Total_Loss: {'avg': -0.04021832626312971, 'std': 0.010686533880206909}
    Policy Entropy: {'avg': 0.4357087314128876, 'std': 0.5983772277832031}
    KL Divergence: {'avg': 0.02229071781039238, 'std': 0.2817610800266266}
    Policy Grad Norm: {'avg': 1.7966593811288476, 'std': 2.271096387648948}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.9576772120638057, 'std': 3.445331320383043, 'run': -0.8554308695971925, 'test_avg': -6.502739156814641, 'test_std': 0.5436431037722246}
    Episode Length: {'avg': 2.4424460431654675, 'std': 1.5995118447742338, 'run': 2.390101182092107, 'test_avg': 5.0, 'test_std': 0.13258252147247765}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 10000):
    Value Loss: {'avg': 0.047283362108282746, 'std': 0.016815204542986247}
    Value Grad Norm: {'avg': 0.45249058715999124, 'std': 0.1485581506498069}
    Policy Loss: {'avg': 0.002230704529210925, 'std': 0.005427363699443736}
    Total_Loss: {'avg': -0.03521946875844151, 'std': 0.006826251991020865}
    Policy Entropy: {'avg': 0.42141690850257874, 'std': 0.597692608833313}
    KL Divergence: {'avg': 0.01689251698553562, 'std': 0.22961515188217163}
    Policy Grad Norm: {'avg': 1.6863133795559406, 'std': 1.2375100978529838}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7969666258572229, 'std': 3.34129638964823, 'run': -0.8413119238434402, 'test_avg': -6.5181201977684395, 'test_std': 0.584842927534738}
    Episode Length: {'avg': 2.3673232908458863, 'std': 1.5593914331293142, 'run': 2.315109930692622, 'test_avg': 5.00390625, 'test_std': 0.15304326581374791}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4201 / 10000):
    Value Loss: {'avg': 0.10269204308278859, 'std': 0.029644283236700313}
    Value Grad Norm: {'avg': 0.780848203599453, 'std': 0.3461919892659286}
    Policy Loss: {'avg': -0.003819339966867119, 'std': 0.00740062827127676}
    Total_Loss: {'avg': -0.0420534429140389, 'std': 0.00759855279499196}
    Policy Entropy: {'avg': 0.36304643750190735, 'std': 0.56232088804245}
    KL Divergence: {'avg': 0.08600761741399765, 'std': 0.8761556148529053}
    Policy Grad Norm: {'avg': 1.8879333101212978, 'std': 1.4061220616890862}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7659651374776268, 'std': 3.302767478182739, 'run': -0.31219269153559126, 'test_avg': -6.511536579600715, 'test_std': 0.7448648453089441}
    Episode Length: {'avg': 2.3593524139924833, 'std': 1.5492609797975845, 'run': 2.1122016247601847, 'test_avg': 5.0107421875, 'test_std': 0.2046382000207069}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4301 / 10000):
    Value Loss: {'avg': 0.07302181469276547, 'std': 0.02757918908352356}
    Value Grad Norm: {'avg': 0.6002928368747235, 'std': 0.263240460502697}
    Policy Loss: {'avg': -0.008634157202322967, 'std': 0.005273172715198961}
    Total_Loss: {'avg': -0.048756676726043224, 'std': 0.005855585720298459}
    Policy Entropy: {'avg': 0.4394443929195404, 'std': 0.5716499090194702}
    KL Divergence: {'avg': 0.02114429697394371, 'std': 0.2374507188796997}
    Policy Grad Norm: {'avg': 0.9868486756458879, 'std': 0.564789689096568}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8662146117195761, 'std': 3.42431056194866, 'run': -0.9049019411646908, 'test_avg': -6.5020737911982, 'test_std': 0.4837029369354428}
    Episode Length: {'avg': 2.3819830359754315, 'std': 1.5775859614100054, 'run': 2.461792963597692, 'test_avg': 5.0009765625, 'test_std': 0.06987030002571618}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 10000):
    Value Loss: {'avg': 0.04684081191662699, 'std': 0.01900443722181431}
    Value Grad Norm: {'avg': 0.5341888949275017, 'std': 0.24555178382307838}
    Policy Loss: {'avg': 0.004032648568681907, 'std': 0.027776324124066533}
    Total_Loss: {'avg': -0.03273872204590589, 'std': 0.028177280854501368}
    Policy Entropy: {'avg': 0.32938432693481445, 'std': 0.5251806378364563}
    KL Divergence: {'avg': 0.021366186439990997, 'std': 0.2546469271183014}
    Policy Grad Norm: {'avg': 4.224460779689252, 'std': 15.687457151641116}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.9359019232086586, 'std': 3.4328756621890353, 'run': -0.6053083478461186, 'test_avg': -6.497054938823567, 'test_std': 0.6493627761897357}
    Episode Length: {'avg': 2.427210479309318, 'std': 1.603430469733119, 'run': 2.3622581570691352, 'test_avg': 5.001953125, 'test_std': 0.17676590537412573}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4501 / 10000):
    Value Loss: {'avg': 0.07847232513595373, 'std': 0.04366113617319217}
    Value Grad Norm: {'avg': 0.665467843413353, 'std': 0.3347278643533065}
    Policy Loss: {'avg': 0.003812512179138139, 'std': 0.006386560759507028}
    Total_Loss: {'avg': -0.03479126316960901, 'std': 0.006671395139258947}
    Policy Entropy: {'avg': 0.37624746561050415, 'std': 0.5719926357269287}
    KL Divergence: {'avg': 0.015286502428352833, 'std': 0.22738198935985565}
    Policy Grad Norm: {'avg': 2.5496458150446415, 'std': 1.6221641860184468}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7830213556620996, 'std': 3.334777784366954, 'run': -0.5275946681662889, 'test_avg': -6.483461919473484, 'test_std': 0.508318751647016}
    Episode Length: {'avg': 2.3464387464387464, 'std': 1.566633067863986, 'run': 2.229373816245235, 'test_avg': 5.0029296875, 'test_std': 0.0937042124514813}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4601 / 10000):
    Value Loss: {'avg': 0.06512799449265003, 'std': 0.044819364067573184}
    Value Grad Norm: {'avg': 0.5127178840339184, 'std': 0.18060941553216422}
    Policy Loss: {'avg': 0.0018958103901240975, 'std': 0.0039056252215958587}
    Total_Loss: {'avg': -0.037815909599885345, 'std': 0.004400325517804068}
    Policy Entropy: {'avg': 0.42763638496398926, 'std': 0.5866264700889587}
    KL Divergence: {'avg': 0.017608225345611572, 'std': 0.28192201256752014}
    Policy Grad Norm: {'avg': 2.157214231789112, 'std': 1.218365858089147}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.807004202947038, 'std': 3.3513093856928933, 'run': -0.6149046147891714, 'test_avg': -6.525864784081932, 'test_std': 0.5641637917627879}
    Episode Length: {'avg': 2.3543869677050586, 'std': 1.5721715540197438, 'run': 2.229024787784001, 'test_avg': 5.00390625, 'test_std': 0.12493894993530841}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4701 / 10000):
    Value Loss: {'avg': 0.10635679541155696, 'std': 0.07396799968088391}
    Value Grad Norm: {'avg': 1.1657493598759174, 'std': 0.966019938866557}
    Policy Loss: {'avg': -0.0022005112914484926, 'std': 0.01182621103632306}
    Total_Loss: {'avg': -0.041587959858588874, 'std': 0.012424175501625482}
    Policy Entropy: {'avg': 0.43168604373931885, 'std': 0.5810551643371582}
    KL Divergence: {'avg': 0.022474221885204315, 'std': 0.26166436076164246}
    Policy Grad Norm: {'avg': 1.3712812820449471, 'std': 1.5706224292892828}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.6858883399090855, 'std': 3.287625604476341, 'run': -0.38077224517115177, 'test_avg': -6.520445695336093, 'test_std': 0.44858343933523065}
    Episode Length: {'avg': 2.3263729977116703, 'std': 1.5360474487342075, 'run': 2.176019204586302, 'test_avg': 4.9990234375, 'test_std': 0.05411777735350551}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4801 / 10000):
    Value Loss: {'avg': 0.14228282240219414, 'std': 0.0912018476616191}
    Value Grad Norm: {'avg': 1.569842604547739, 'std': 1.0591478718773775}
    Policy Loss: {'avg': 0.0005314442387316376, 'std': 0.005093649046598584}
    Total_Loss: {'avg': -0.037485944922082126, 'std': 0.006297393984427091}
    Policy Entropy: {'avg': 0.43278205394744873, 'std': 0.6126426458358765}
    KL Divergence: {'avg': 0.024304693564772606, 'std': 0.3571036756038666}
    Policy Grad Norm: {'avg': 1.4290896374732256, 'std': 0.9702888048502428}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9268880880232999, 'std': 3.4175050484130356, 'run': -1.114027134898495, 'test_avg': -6.494953915098449, 'test_std': 0.48293686167516764}
    Episode Length: {'avg': 2.41701244813278, 'std': 1.5930219318527024, 'run': 2.531437152175058, 'test_avg': 5.0, 'test_std': 0.0625}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4901 / 10000):
    Value Loss: {'avg': 0.07756337719038128, 'std': 0.04825688290001893}
    Value Grad Norm: {'avg': 0.8839054375886917, 'std': 0.9175554416265498}
    Policy Loss: {'avg': 0.0007993276813067496, 'std': 0.010534912036986996}
    Total_Loss: {'avg': -0.03804312343709171, 'std': 0.010812905428601274}
    Policy Entropy: {'avg': 0.3770467936992645, 'std': 0.5736514329910278}
    KL Divergence: {'avg': 0.01566985249519348, 'std': 0.1989860236644745}
    Policy Grad Norm: {'avg': 1.5148122254759073, 'std': 1.3131360108764358}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8405185563789436, 'std': 3.39226153013647, 'run': -1.0168041821400733, 'test_avg': -6.515308725327486, 'test_std': 0.6955031665918592}
    Episode Length: {'avg': 2.3708879184861718, 'std': 1.5833457097668695, 'run': 2.414855004809828, 'test_avg': 5.0107421875, 'test_std': 0.1845651454303191}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5001 / 10000):
    Value Loss: {'avg': 0.06383998948149383, 'std': 0.03572030756011545}
    Value Grad Norm: {'avg': 0.6027771955356002, 'std': 0.261480802751642}
    Policy Loss: {'avg': 0.006018828687956557, 'std': 0.01967257489788959}
    Total_Loss: {'avg': -0.03348606813233346, 'std': 0.019432641972857347}
    Policy Entropy: {'avg': 0.354654461145401, 'std': 0.5405048131942749}
    KL Divergence: {'avg': 0.018126124516129494, 'std': 0.253411203622818}
    Policy Grad Norm: {'avg': 4.0836266204714775, 'std': 8.772005210747276}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9318758676537783, 'std': 3.408488662455388, 'run': -1.4655966239406635, 'test_avg': -6.499842392659048, 'test_std': 0.4639438690291432}
    Episode Length: {'avg': 2.4240822320117474, 'std': 1.5980554682430483, 'run': 2.6393559016155703, 'test_avg': 5.0009765625, 'test_std': 0.031234737483827102}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5101 / 10000):
    Value Loss: {'avg': 0.07118751034140587, 'std': 0.0384502232768004}
    Value Grad Norm: {'avg': 0.6114008475095034, 'std': 0.2850998621094717}
    Policy Loss: {'avg': -0.0017702559707686305, 'std': 0.004172997304199845}
    Total_Loss: {'avg': -0.0413300737272948, 'std': 0.004765181478132004}
    Policy Entropy: {'avg': 0.3818765878677368, 'std': 0.554467499256134}
    KL Divergence: {'avg': 0.02307988330721855, 'std': 0.2589379847049713}
    Policy Grad Norm: {'avg': 1.1690179910510778, 'std': 1.1241836843537178}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9017482348123574, 'std': 3.3967017118157794, 'run': -0.8040224242974015, 'test_avg': -6.523562531656353, 'test_std': 0.5476650533938805}
    Episode Length: {'avg': 2.398496240601504, 'std': 1.5913364510798202, 'run': 2.3648635797829654, 'test_avg': 5.00390625, 'test_std': 0.11686152579415306}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5201 / 10000):
    Value Loss: {'avg': 0.08086054935120046, 'std': 0.029334594189808313}
    Value Grad Norm: {'avg': 0.6958082646131516, 'std': 0.2898876890016513}
    Policy Loss: {'avg': -0.0008224667981266975, 'std': 0.0076933642839827655}
    Total_Loss: {'avg': -0.03954655665438622, 'std': 0.008262504397185472}
    Policy Entropy: {'avg': 0.3701871931552887, 'std': 0.555283784866333}
    KL Divergence: {'avg': 0.026530228555202484, 'std': 0.40124163031578064}
    Policy Grad Norm: {'avg': 2.012047130614519, 'std': 1.462643395189687}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9615712291888965, 'std': 3.4583703097296086, 'run': -1.137836301287132, 'test_avg': -6.5662952762927205, 'test_std': 0.806644027883277}
    Episode Length: {'avg': 2.4429550193625262, 'std': 1.6091344378346073, 'run': 2.498908337163949, 'test_avg': 5.015625, 'test_std': 0.2415566380271923}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5301 / 10000):
    Value Loss: {'avg': 0.05699069213587791, 'std': 0.020304883470658303}
    Value Grad Norm: {'avg': 0.48736870363354684, 'std': 0.17146589412125227}
    Policy Loss: {'avg': 0.008979326288681477, 'std': 0.03870389820512894}
    Total_Loss: {'avg': -0.03196066012606025, 'std': 0.038400649730120584}
    Policy Entropy: {'avg': 0.43465089797973633, 'std': 0.5615438222885132}
    KL Divergence: {'avg': 0.024842895567417145, 'std': 0.22518061101436615}
    Policy Grad Norm: {'avg': 3.3282870054244995, 'std': 6.958201267125949}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8344198369811261, 'std': 3.3522330568105767, 'run': -0.6666528085154224, 'test_avg': -6.485239570218255, 'test_std': 0.5269584766380065}
    Episode Length: {'avg': 2.3787922565732447, 'std': 1.5728852564452782, 'run': 2.267465871323317, 'test_avg': 5.0009765625, 'test_std': 0.09374491359899796}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5401 / 10000):
    Value Loss: {'avg': 0.040240849182009694, 'std': 0.017154842463780802}
    Value Grad Norm: {'avg': 0.4652907392010093, 'std': 0.2141675324152935}
    Policy Loss: {'avg': -0.002012756041949615, 'std': 0.0076327153579008235}
    Total_Loss: {'avg': -0.040031264477875084, 'std': 0.007977641918459228}
    Policy Entropy: {'avg': 0.37326768040657043, 'std': 0.5552643537521362}
    KL Divergence: {'avg': 0.018453478813171387, 'std': 0.2269783467054367}
    Policy Grad Norm: {'avg': 1.2058663312345743, 'std': 0.7506220191701026}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8497756368881981, 'std': 3.3849131059692974, 'run': -0.8302920260392522, 'test_avg': -6.580380632698507, 'test_std': 0.8051398085813775}
    Episode Length: {'avg': 2.389880081895291, 'std': 1.5774153567194609, 'run': 2.3912880051332674, 'test_avg': 5.01953125, 'test_std': 0.23719012473844164}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5501 / 10000):
    Value Loss: {'avg': 0.05123061807826161, 'std': 0.017679459506532647}
    Value Grad Norm: {'avg': 0.6020550193265081, 'std': 0.24637783814631867}
    Policy Loss: {'avg': -0.0038394571165554225, 'std': 0.007434780751747559}
    Total_Loss: {'avg': -0.04198121698573232, 'std': 0.008043178783456882}
    Policy Entropy: {'avg': 0.4294932782649994, 'std': 0.5415815711021423}
    KL Divergence: {'avg': 0.03390079364180565, 'std': 0.2504659593105316}
    Policy Grad Norm: {'avg': 1.572407097555697, 'std': 1.6043926826150097}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8293652928321619, 'std': 3.3959953061561077, 'run': -1.0214668798815882, 'test_avg': -6.570105203703555, 'test_std': 1.0379497936948954}
    Episode Length: {'avg': 2.392836342457775, 'std': 1.5781951693107472, 'run': 2.4058830575087558, 'test_avg': 5.0244140625, 'test_std': 0.35409111264227755}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (5601 / 10000):
    Value Loss: {'avg': 0.05151452491991222, 'std': 0.022013132579491043}
    Value Grad Norm: {'avg': 0.5650826832279563, 'std': 0.2539637854547497}
    Policy Loss: {'avg': 0.007879538548877463, 'std': 0.017288726503668212}
    Total_Loss: {'avg': -0.029566490557044744, 'std': 0.01711375891396927}
    Policy Entropy: {'avg': 0.3690659701824188, 'std': 0.5517981052398682}
    KL Divergence: {'avg': 0.018232744187116623, 'std': 0.2138393223285675}
    Policy Grad Norm: {'avg': 2.4159098751842976, 'std': 2.9802045957492034}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8459184314264835, 'std': 3.374196478337586, 'run': -0.698882337867608, 'test_avg': -6.504852763060626, 'test_std': 0.5157330353245755}
    Episode Length: {'avg': 2.3878205128205128, 'std': 1.5813978076560657, 'run': 2.383850898414371, 'test_avg': 5.0048828125, 'test_std': 0.11256762697192228}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5701 / 10000):
    Value Loss: {'avg': 0.05768039778340608, 'std': 0.03056702432984046}
    Value Grad Norm: {'avg': 0.6078042401000857, 'std': 0.4181360177426164}
    Policy Loss: {'avg': 0.0022350409999489784, 'std': 0.005240708909364615}
    Total_Loss: {'avg': -0.03750739572569728, 'std': 0.006295896243587158}
    Policy Entropy: {'avg': 0.34972846508026123, 'std': 0.5054336190223694}
    KL Divergence: {'avg': 0.0188736692070961, 'std': 0.22315675020217896}
    Policy Grad Norm: {'avg': 1.8299657460302114, 'std': 1.0757439879462738}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9107993296936537, 'std': 3.401200223805471, 'run': -1.0581412799037044, 'test_avg': -6.521032439507607, 'test_std': 0.8007683115635834}
    Episode Length: {'avg': 2.415149735760423, 'std': 1.591316929299709, 'run': 2.5511671271916896, 'test_avg': 5.01171875, 'test_std': 0.2457835346365527}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (5801 / 10000):
    Value Loss: {'avg': 0.04739085650071502, 'std': 0.02510899652487774}
    Value Grad Norm: {'avg': 0.6962827179580927, 'std': 0.5640899602367516}
    Policy Loss: {'avg': -0.0035558008239604533, 'std': 0.00603241593864951}
    Total_Loss: {'avg': -0.04280486796051264, 'std': 0.006544435279247216}
    Policy Entropy: {'avg': 0.3892129063606262, 'std': 0.5746679306030273}
    KL Divergence: {'avg': 0.02446744218468666, 'std': 0.27566903829574585}
    Policy Grad Norm: {'avg': 1.0542709408327937, 'std': 0.6654742710061065}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8365729611989366, 'std': 3.3680498082022603, 'run': -0.7807249171025572, 'test_avg': -6.47448253116454, 'test_std': 0.45026386147033454}
    Episode Length: {'avg': 2.379802095459837, 'std': 1.5751783779677238, 'run': 2.4180361669166217, 'test_avg': 5.0, 'test_std': 0.04419417382415922}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5901 / 10000):
    Value Loss: {'avg': 0.04783669232856482, 'std': 0.02541561856495385}
    Value Grad Norm: {'avg': 0.8468444995582104, 'std': 0.7990971771072175}
    Policy Loss: {'avg': 0.0032007007976062596, 'std': 0.01010429613885764}
    Total_Loss: {'avg': -0.03589255758561194, 'std': 0.010102722682450596}
    Policy Entropy: {'avg': 0.3498648405075073, 'std': 0.5528947114944458}
    KL Divergence: {'avg': 0.017505265772342682, 'std': 0.22229906916618347}
    Policy Grad Norm: {'avg': 1.8002222999930382, 'std': 2.3080750790499343}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8250599552494834, 'std': 3.3494564874645616, 'run': -0.6430812212808037, 'test_avg': -6.5072628271373105, 'test_std': 0.5227982602711767}
    Episode Length: {'avg': 2.3759791122715406, 'std': 1.5764744085843592, 'run': 2.3303688508178277, 'test_avg': 5.0009765625, 'test_std': 0.09374491359899796}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6001 / 10000):
    Value Loss: {'avg': 0.04278884958475828, 'std': 0.016334008206987626}
    Value Grad Norm: {'avg': 0.5008624220266938, 'std': 0.513214058907116}
    Policy Loss: {'avg': 0.0008139158308040351, 'std': 0.004273234747927361}
    Total_Loss: {'avg': -0.03694913093931973, 'std': 0.005191768826850848}
    Policy Entropy: {'avg': 0.39300039410591125, 'std': 0.5654290318489075}
    KL Divergence: {'avg': 0.015240099281072617, 'std': 0.1920386254787445}
    Policy Grad Norm: {'avg': 1.6913114339113235, 'std': 0.8415336776754094}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8940354791197771, 'std': 3.3846956598883624, 'run': -0.8236582090886289, 'test_avg': -6.488427048554513, 'test_std': 0.5649620453146591}
    Episode Length: {'avg': 2.4080209241499566, 'std': 1.5910913917990677, 'run': 2.35435728216479, 'test_avg': 5.0, 'test_std': 0.10825317547305482}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6101 / 10000):
    Value Loss: {'avg': 0.04163860934786499, 'std': 0.023734416140906923}
    Value Grad Norm: {'avg': 0.4354959508404136, 'std': 0.28761630086575507}
    Policy Loss: {'avg': 0.00496110983658582, 'std': 0.009613998714580305}
    Total_Loss: {'avg': -0.034402737859636545, 'std': 0.009027740931327539}
    Policy Entropy: {'avg': 0.3918420672416687, 'std': 0.5707414150238037}
    KL Divergence: {'avg': 0.0194488987326622, 'std': 0.26475003361701965}
    Policy Grad Norm: {'avg': 2.849422287195921, 'std': 4.444303986416633}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7828939250636456, 'std': 3.3546685229867834, 'run': -0.9907825617961314, 'test_avg': -6.494005102693336, 'test_std': 0.4671110723429435}
    Episode Length: {'avg': 2.359203693017888, 'std': 1.5621193271716953, 'run': 2.4315878197205154, 'test_avg': 4.9970703125, 'test_std': 0.05404724258602231}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6201 / 10000):
    Value Loss: {'avg': 0.2569348168559372, 'std': 0.17681424929216677}
    Value Grad Norm: {'avg': 4.145640556514263, 'std': 2.7239451459821487}
    Policy Loss: {'avg': -0.004365774730104022, 'std': 0.008185981796881913}
    Total_Loss: {'avg': -0.04416281229350716, 'std': 0.00805522883067592}
    Policy Entropy: {'avg': 0.387931764125824, 'std': 0.552967369556427}
    KL Divergence: {'avg': 0.02150210738182068, 'std': 0.2918039560317993}
    Policy Grad Norm: {'avg': 1.5975447101518512, 'std': 2.2174621827499763}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8763758460664458, 'std': 3.49042276957036, 'run': -0.7812194103920189, 'test_avg': -6.505155050333997, 'test_std': 0.4837101635720839}
    Episode Length: {'avg': 2.394045534150613, 'std': 1.6211566907685226, 'run': 2.3365132240634163, 'test_avg': 5.0009765625, 'test_std': 0.08267396098944088}
    Ratio Terminated: {'avg': 0.9988324576765908, 'test_avg': 1.0}

Iteration (6301 / 10000):
    Value Loss: {'avg': 0.059183458960615096, 'std': 0.0322374309716398}
    Value Grad Norm: {'avg': 0.786159423366189, 'std': 0.5719516662038584}
    Policy Loss: {'avg': 0.009579461009707302, 'std': 0.03341422744613593}
    Total_Loss: {'avg': -0.03136011096648872, 'std': 0.03305955924039135}
    Policy Entropy: {'avg': 0.4250788688659668, 'std': 0.5687500238418579}
    KL Divergence: {'avg': 0.02038506790995598, 'std': 0.23175400495529175}
    Policy Grad Norm: {'avg': 4.7369585651904345, 'std': 9.619567973522733}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8552235291505147, 'std': 3.380076620059539, 'run': -0.7818098405950737, 'test_avg': -6.552457053427716, 'test_std': 0.8504629187927014}
    Episode Length: {'avg': 2.3836132020845398, 'std': 1.585135836063223, 'run': 2.407370197731391, 'test_avg': 5.017578125, 'test_std': 0.2718634942788097}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6401 / 10000):
    Value Loss: {'avg': 0.04140455569140613, 'std': 0.01660525273405413}
    Value Grad Norm: {'avg': 0.44977077674120663, 'std': 0.22006781828575178}
    Policy Loss: {'avg': 0.005640227813273668, 'std': 0.015402776317851112}
    Total_Loss: {'avg': -0.03356242342852056, 'std': 0.014934030743466662}
    Policy Entropy: {'avg': 0.43130964040756226, 'std': 0.5815398693084717}
    KL Divergence: {'avg': 0.019277140498161316, 'std': 0.21466782689094543}
    Policy Grad Norm: {'avg': 1.72299275547266, 'std': 1.619618609966093}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8002634677539148, 'std': 3.3475562451932377, 'run': -1.0173367662274584, 'test_avg': -6.511388617043849, 'test_std': 0.55173777402139}
    Episode Length: {'avg': 2.3661726242371404, 'std': 1.566377185483032, 'run': 2.4044150370321233, 'test_avg': 5.0009765625, 'test_std': 0.11266924525212545}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6501 / 10000):
    Value Loss: {'avg': 0.04604497374966741, 'std': 0.020295725372259134}
    Value Grad Norm: {'avg': 0.7896828047931195, 'std': 0.7892514065932391}
    Policy Loss: {'avg': -0.000484939941088669, 'std': 0.011001235276955013}
    Total_Loss: {'avg': -0.04042132309405133, 'std': 0.01166345800596089}
    Policy Entropy: {'avg': 0.3951353430747986, 'std': 0.5657908320426941}
    KL Divergence: {'avg': 0.017105232924222946, 'std': 0.2244710773229599}
    Policy Grad Norm: {'avg': 1.757480377331376, 'std': 2.1353827604766464}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -1.0061501538308855, 'std': 3.455565922029026, 'run': -0.48424324449079886, 'test_avg': -6.489878089167178, 'test_std': 0.48144381044770823}
    Episode Length: {'avg': 2.456373853889382, 'std': 1.612654697709882, 'run': 2.2404248231356205, 'test_avg': 5.0029296875, 'test_std': 0.05404724258602231}
    Ratio Terminated: {'avg': 0.9997042295178941, 'test_avg': 1.0}

Iteration (6601 / 10000):
    Value Loss: {'avg': 0.05660299677401781, 'std': 0.03799532166719262}
    Value Grad Norm: {'avg': 0.5608761524781585, 'std': 0.43602503160706807}
    Policy Loss: {'avg': -0.001414111946360208, 'std': 0.00900780462820964}
    Total_Loss: {'avg': -0.042523085547145456, 'std': 0.009321025294582803}
    Policy Entropy: {'avg': 0.41112595796585083, 'std': 0.5822888612747192}
    KL Divergence: {'avg': 0.027191918343305588, 'std': 0.2879081964492798}
    Policy Grad Norm: {'avg': 1.476825195364654, 'std': 2.250896563366211}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.741733886854458, 'std': 3.2896824757144505, 'run': -0.5655491801424346, 'test_avg': -6.536944784175183, 'test_std': 0.8323675950318372}
    Episode Length: {'avg': 2.328448275862069, 'std': 1.5467414413550422, 'run': 2.226834276879355, 'test_avg': 5.0107421875, 'test_std': 0.2315071120024498}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6701 / 10000):
    Value Loss: {'avg': 0.092985459882766, 'std': 0.0515013733336268}
    Value Grad Norm: {'avg': 0.5312078960239888, 'std': 0.18137149810743708}
    Policy Loss: {'avg': -0.006926563277374953, 'std': 0.007061003588783445}
    Total_Loss: {'avg': -0.04943129187449813, 'std': 0.008599121755565644}
    Policy Entropy: {'avg': 0.42798271775245667, 'std': 0.5675960183143616}
    KL Divergence: {'avg': 0.030642155557870865, 'std': 0.33145445585250854}
    Policy Grad Norm: {'avg': 1.362483024597168, 'std': 0.9402965843011579}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9244083182269549, 'std': 3.422452915694372, 'run': -0.7833828224669809, 'test_avg': -6.490181478307932, 'test_std': 0.5616709788272298}
    Episode Length: {'avg': 2.4115916446013532, 'std': 1.592234694912855, 'run': 2.340252065968139, 'test_avg': 5.0009765625, 'test_std': 0.11266924525212545}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6801 / 10000):
    Value Loss: {'avg': 0.046018558694049715, 'std': 0.021518131746541196}
    Value Grad Norm: {'avg': 0.4315586077049375, 'std': 0.15009383989573302}
    Policy Loss: {'avg': -0.0033495453923630216, 'std': 0.01734492866734318}
    Total_Loss: {'avg': -0.04079702120119085, 'std': 0.01723449844797631}
    Policy Entropy: {'avg': 0.41709810495376587, 'std': 0.5869521498680115}
    KL Divergence: {'avg': 0.01930517517030239, 'std': 0.2109157294034958}
    Policy Grad Norm: {'avg': 1.4756494133422773, 'std': 4.008391648594304}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -0.8156978255508378, 'std': 3.3620648444864827, 'run': -0.8330701631838167, 'test_avg': -6.518783232213068, 'test_std': 0.6690237554064797}
    Episode Length: {'avg': 2.3944525547445257, 'std': 1.5656993585377719, 'run': 2.4034147396822068, 'test_avg': 5.0078125, 'test_std': 0.18204969058954756}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6901 / 10000):
    Value Loss: {'avg': 0.034304471244104205, 'std': 0.010392356793098153}
    Value Grad Norm: {'avg': 0.39359681829810145, 'std': 0.26643695098292786}
    Policy Loss: {'avg': 0.0015197450848063454, 'std': 0.012000899524735402}
    Total_Loss: {'avg': -0.03770535212242976, 'std': 0.012173383592987351}
    Policy Entropy: {'avg': 0.3573726415634155, 'std': 0.5257750749588013}
    KL Divergence: {'avg': 0.02076975628733635, 'std': 0.2549314796924591}
    Policy Grad Norm: {'avg': 1.9612153246998787, 'std': 2.7273011545893815}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8610591347245522, 'std': 3.370864870794318, 'run': -1.2561934037929356, 'test_avg': -6.557884478956112, 'test_std': 0.7680158758383354}
    Episode Length: {'avg': 2.3932683790965457, 'std': 1.5770878035409974, 'run': 2.501533328053799, 'test_avg': 5.013671875, 'test_std': 0.2249318337496593}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7001 / 10000):
    Value Loss: {'avg': 0.04456536741927266, 'std': 0.015080442752921253}
    Value Grad Norm: {'avg': 0.4231508668512106, 'std': 0.166440559041555}
    Policy Loss: {'avg': 0.008285968448035419, 'std': 0.02814284885057546}
    Total_Loss: {'avg': -0.03251988906413317, 'std': 0.02814113316689516}
    Policy Entropy: {'avg': 0.4133986234664917, 'std': 0.5807626843452454}
    KL Divergence: {'avg': 0.01891712285578251, 'std': 0.24679432809352875}
    Policy Grad Norm: {'avg': 2.236938513815403, 'std': 2.782373221181659}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8903098439804824, 'std': 3.3730959891144203, 'run': -0.5617898823551298, 'test_avg': -6.50483112866641, 'test_std': 0.46895323663113947}
    Episode Length: {'avg': 2.375325803649001, 'std': 1.5998097336978643, 'run': 2.1724843116009938, 'test_avg': 4.998046875, 'test_std': 0.062469474967654204}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7101 / 10000):
    Value Loss: {'avg': 0.1138782398076728, 'std': 0.078658787343529}
    Value Grad Norm: {'avg': 0.7799873784184456, 'std': 0.4383068626219423}
    Policy Loss: {'avg': 0.00034625164698809385, 'std': 0.0038193014450369754}
    Total_Loss: {'avg': -0.0377534453291446, 'std': 0.005038464748506049}
    Policy Entropy: {'avg': 0.3922428488731384, 'std': 0.5785903930664062}
    KL Divergence: {'avg': 0.01940244808793068, 'std': 0.24869771301746368}
    Policy Grad Norm: {'avg': 1.671798912808299, 'std': 1.134877012390192}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9078210459007577, 'std': 3.430312829253461, 'run': -0.5808386595316373, 'test_avg': -6.487345902415862, 'test_std': 0.6991077990843296}
    Episode Length: {'avg': 2.4248385202583678, 'std': 1.5947523549906215, 'run': 2.3243966831789966, 'test_avg': 5.0068359375, 'test_std': 0.20951988559202703}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7201 / 10000):
    Value Loss: {'avg': 0.04257682559546083, 'std': 0.018429025448146598}
    Value Grad Norm: {'avg': 0.3731115525588393, 'std': 0.12793114082634402}
    Policy Loss: {'avg': 0.0006336156511679292, 'std': 0.004215836849213898}
    Total_Loss: {'avg': -0.040437063202261925, 'std': 0.003945714419629921}
    Policy Entropy: {'avg': 0.39416784048080444, 'std': 0.5727390646934509}
    KL Divergence: {'avg': 0.01871911808848381, 'std': 0.22381387650966644}
    Policy Grad Norm: {'avg': 1.650246649980545, 'std': 1.0253818587906327}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7077726962546917, 'std': 3.304065261671876, 'run': -0.7093544472894215, 'test_avg': -6.5184010582306655, 'test_std': 0.6023143677769165}
    Episode Length: {'avg': 2.32574679943101, 'std': 1.5445973308769976, 'run': 2.3762792421409666, 'test_avg': 5.0029296875, 'test_std': 0.14317551966433487}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7301 / 10000):
    Value Loss: {'avg': 0.06268019827548414, 'std': 0.054279198909142186}
    Value Grad Norm: {'avg': 0.7508053220808506, 'std': 0.6198081883493164}
    Policy Loss: {'avg': -0.004749110928969458, 'std': 0.005542008116829199}
    Total_Loss: {'avg': -0.04469288350082934, 'std': 0.005776475518002579}
    Policy Entropy: {'avg': 0.3894258737564087, 'std': 0.5544657111167908}
    KL Divergence: {'avg': 0.025165196508169174, 'std': 0.3051575720310211}
    Policy Grad Norm: {'avg': 1.3783572833053768, 'std': 2.615137512806932}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8024626437099427, 'std': 3.349153491706098, 'run': -0.7813509063435738, 'test_avg': -6.482848930187174, 'test_std': 0.464121105328599}
    Episode Length: {'avg': 2.364872685185185, 'std': 1.570018535363048, 'run': 2.3691192488752617, 'test_avg': 5.0, 'test_std': 0.04419417382415922}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7401 / 10000):
    Value Loss: {'avg': 0.03658748522866517, 'std': 0.011573169998805354}
    Value Grad Norm: {'avg': 0.4390865063294768, 'std': 0.17721088284197445}
    Policy Loss: {'avg': 0.0055949275847524405, 'std': 0.008130876064053875}
    Total_Loss: {'avg': -0.03383751004002988, 'std': 0.008031313704000094}
    Policy Entropy: {'avg': 0.4143025279045105, 'std': 0.5594306588172913}
    KL Divergence: {'avg': 0.016393741592764854, 'std': 0.20622190833091736}
    Policy Grad Norm: {'avg': 1.427750401198864, 'std': 0.5259124313087686}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8255829185160428, 'std': 3.359870258880837, 'run': -0.9142400440336559, 'test_avg': -6.474302045797231, 'test_std': 0.4646934980704789}
    Episode Length: {'avg': 2.373671782762692, 'std': 1.579544896105893, 'run': 2.3495788507272, 'test_avg': 4.9990234375, 'test_std': 0.05411777735350551}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7501 / 10000):
    Value Loss: {'avg': 0.07345736646093429, 'std': 0.06219552431733857}
    Value Grad Norm: {'avg': 0.7054310699924826, 'std': 0.6248052071093573}
    Policy Loss: {'avg': -0.004180175936198793, 'std': 0.0062651422313165514}
    Total_Loss: {'avg': -0.04415986401727423, 'std': 0.007070844254877249}
    Policy Entropy: {'avg': 0.3860287070274353, 'std': 0.5589359998703003}
    KL Divergence: {'avg': 0.017806150019168854, 'std': 0.21429955959320068}
    Policy Grad Norm: {'avg': 1.0860341656953096, 'std': 0.5637123375539874}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8196533377048921, 'std': 3.3615900032641903, 'run': -0.7012020750805084, 'test_avg': -6.484174151148181, 'test_std': 0.446183069494166}
    Episode Length: {'avg': 2.3745694603903558, 'std': 1.5738778604366028, 'run': 2.347680150453058, 'test_avg': 4.998046875, 'test_std': 0.044150994357255134}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7601 / 10000):
    Value Loss: {'avg': 0.03482063466217369, 'std': 0.016089008775590646}
    Value Grad Norm: {'avg': 0.32262400165200233, 'std': 0.10350612280403512}
    Policy Loss: {'avg': -0.0022297952382359654, 'std': 0.008622956644497156}
    Total_Loss: {'avg': -0.041851150803267956, 'std': 0.008999918468220718}
    Policy Entropy: {'avg': 0.41612690687179565, 'std': 0.575825035572052}
    KL Divergence: {'avg': 0.017844848334789276, 'std': 0.17032372951507568}
    Policy Grad Norm: {'avg': 1.2268362073227763, 'std': 0.9727859143797817}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.845234641612909, 'std': 3.3788766654299716, 'run': -0.6376402137833314, 'test_avg': -6.485664811829338, 'test_std': 0.4721147854751782}
    Episode Length: {'avg': 2.3941690962099127, 'std': 1.5765300663557524, 'run': 2.344501771408145, 'test_avg': 5.0, 'test_std': 0.04419417382415922}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7701 / 10000):
    Value Loss: {'avg': 0.11791982273571193, 'std': 0.10121711560796369}
    Value Grad Norm: {'avg': 0.6607709884643554, 'std': 0.33713101456423294}
    Policy Loss: {'avg': 0.005910967360250652, 'std': 0.021737272049172807}
    Total_Loss: {'avg': -0.03475569060537964, 'std': 0.021639574995748784}
    Policy Entropy: {'avg': 0.39410147070884705, 'std': 0.5496853590011597}
    KL Divergence: {'avg': 0.03408241271972656, 'std': 0.4657163619995117}
    Policy Grad Norm: {'avg': 2.1671252883970737, 'std': 1.5270852028792226}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9081624078420386, 'std': 3.393251851223104, 'run': -1.2311762209537154, 'test_avg': -6.5157194174926465, 'test_std': 0.760780534850812}
    Episode Length: {'avg': 2.392105263157895, 'std': 1.5990847932658763, 'run': 2.537761709491718, 'test_avg': 5.0078125, 'test_std': 0.2337230515883061}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7801 / 10000):
    Value Loss: {'avg': 0.03935058293864131, 'std': 0.015501209271421644}
    Value Grad Norm: {'avg': 0.5137024840340019, 'std': 0.32098225400751784}
    Policy Loss: {'avg': 0.0021289024443831295, 'std': 0.0048434665142745815}
    Total_Loss: {'avg': -0.03744761843699962, 'std': 0.005137073270210233}
    Policy Entropy: {'avg': 0.3985190987586975, 'std': 0.5812652707099915}
    KL Divergence: {'avg': 0.015231067314743996, 'std': 0.2734280824661255}
    Policy Grad Norm: {'avg': 2.4810772575438023, 'std': 2.59343760707304}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8836851957354436, 'std': 3.3963307717587465, 'run': -0.6731905692983886, 'test_avg': -6.488627212471329, 'test_std': 0.4982535677795784}
    Episode Length: {'avg': 2.3942223519112926, 'std': 1.5928060480400135, 'run': 2.3108915502490004, 'test_avg': 5.0009765625, 'test_std': 0.08267396098944088}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7901 / 10000):
    Value Loss: {'avg': 0.24204608350992202, 'std': 0.14546959650535993}
    Value Grad Norm: {'avg': 3.1581976376473904, 'std': 1.8499585075515894}
    Policy Loss: {'avg': -0.003611239604651928, 'std': 0.006937950445972582}
    Total_Loss: {'avg': -0.04388193320482969, 'std': 0.0074393442627703685}
    Policy Entropy: {'avg': 0.42743438482284546, 'std': 0.5918150544166565}
    KL Divergence: {'avg': 0.031119175255298615, 'std': 0.3941170871257782}
    Policy Grad Norm: {'avg': 1.589878000319004, 'std': 1.3234183414573986}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.840103899615235, 'std': 3.448330891338819, 'run': -0.4543781099804419, 'test_avg': -6.525427577929804, 'test_std': 0.5569436892898589}
    Episode Length: {'avg': 2.392677886034839, 'std': 1.6116766876056798, 'run': 2.1847373515262527, 'test_avg': 5.0029296875, 'test_std': 0.11263538267858969}
    Ratio Terminated: {'avg': 0.9991142604074402, 'test_avg': 1.0}

Iteration (8001 / 10000):
    Value Loss: {'avg': 0.10477024775464087, 'std': 0.06569216100344032}
    Value Grad Norm: {'avg': 0.8411897215992212, 'std': 0.5953789004401465}
    Policy Loss: {'avg': -0.004299049389373977, 'std': 0.006637216698815406}
    Total_Loss: {'avg': -0.04559258359950036, 'std': 0.0076423702570018424}
    Policy Entropy: {'avg': 0.4199464023113251, 'std': 0.5985259413719177}
    KL Divergence: {'avg': 0.01795465499162674, 'std': 0.2074030190706253}
    Policy Grad Norm: {'avg': 0.9478474259376526, 'std': 0.808481265698274}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.7573462177999942, 'std': 3.3155197480110767, 'run': -1.0007757260832688, 'test_avg': -6.517460216862673, 'test_std': 0.5787914018185734}
    Episode Length: {'avg': 2.3325628431089283, 'std': 1.5643954708227643, 'run': 2.463956587234917, 'test_avg': 5.00390625, 'test_std': 0.1465234322930551}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8101 / 10000):
    Value Loss: {'avg': 0.03175412286072969, 'std': 0.009157365780720933}
    Value Grad Norm: {'avg': 0.3432996550574899, 'std': 0.12750446614497588}
    Policy Loss: {'avg': -0.0022611054591834545, 'std': 0.010839609025259067}
    Total_Loss: {'avg': -0.040519496775232255, 'std': 0.011360691677510186}
    Policy Entropy: {'avg': 0.3960002660751343, 'std': 0.5669270753860474}
    KL Divergence: {'avg': 0.021072227507829666, 'std': 0.21780528128147125}
    Policy Grad Norm: {'avg': 1.4111277787014842, 'std': 2.7376674978704876}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.7714623992733528, 'std': 3.3325270348808695, 'run': -0.7734740134324627, 'test_avg': -6.520432494256801, 'test_std': 0.798779522856204}
    Episode Length: {'avg': 2.3660714285714284, 'std': 1.5576224066564515, 'run': 2.378257002671098, 'test_avg': 5.01171875, 'test_std': 0.2417776269600591}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (8201 / 10000):
    Value Loss: {'avg': 0.15275174975395203, 'std': 0.10981364310892872}
    Value Grad Norm: {'avg': 0.9638186406344176, 'std': 0.4773934877531284}
    Policy Loss: {'avg': 0.0007895705930422992, 'std': 0.010578670248268585}
    Total_Loss: {'avg': -0.041492639924399555, 'std': 0.01090497871328551}
    Policy Entropy: {'avg': 0.3845430016517639, 'std': 0.5703915953636169}
    KL Divergence: {'avg': 0.0319971889257431, 'std': 0.4676360785961151}
    Policy Grad Norm: {'avg': 2.2359811207279563, 'std': 2.4287996925572584}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9009034370904728, 'std': 3.4067825842917103, 'run': -0.9065630829119494, 'test_avg': -6.4920550796960015, 'test_std': 0.48809019606109066}
    Episode Length: {'avg': 2.3969820081253626, 'std': 1.6019185222990844, 'run': 2.4161674160589954, 'test_avg': 5.0, 'test_std': 0.0625}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8301 / 10000):
    Value Loss: {'avg': 0.04603576494846493, 'std': 0.017101110006229877}
    Value Grad Norm: {'avg': 0.45310971662402155, 'std': 0.26527120481811045}
    Policy Loss: {'avg': -0.0008673659831401892, 'std': 0.014404578728073292}
    Total_Loss: {'avg': -0.041216382349375635, 'std': 0.014358784676206215}
    Policy Entropy: {'avg': 0.40458303689956665, 'std': 0.5760898590087891}
    KL Divergence: {'avg': 0.02196827530860901, 'std': 0.281913697719574}
    Policy Grad Norm: {'avg': 1.4475726578384638, 'std': 1.547205578221337}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.9563328585208765, 'std': 3.4217818258489183, 'run': -0.8162845198459054, 'test_avg': -6.507706665201113, 'test_std': 0.49292102416892797}
    Episode Length: {'avg': 2.4362053437406184, 'std': 1.6029837118354482, 'run': 2.373954505067272, 'test_avg': 5.0, 'test_std': 0.07654655446197431}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8401 / 10000):
    Value Loss: {'avg': 0.05354642453603446, 'std': 0.028865720163513964}
    Value Grad Norm: {'avg': 0.5288825541734695, 'std': 0.25415761519531843}
    Policy Loss: {'avg': 0.0021651328715961426, 'std': 0.009755522987390207}
    Total_Loss: {'avg': -0.03696557262446731, 'std': 0.010036929576159658}
    Policy Entropy: {'avg': 0.39880847930908203, 'std': 0.5947226881980896}
    KL Divergence: {'avg': 0.016820210963487625, 'std': 0.2578107714653015}
    Policy Grad Norm: {'avg': 2.1956597715616226, 'std': 1.9821718788496074}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8461857624109909, 'std': 3.379529861598837, 'run': -0.6552438774960256, 'test_avg': -6.537670762181733, 'test_std': 0.6705043589478717}
    Episode Length: {'avg': 2.396556755179457, 'std': 1.5754610229993355, 'run': 2.1916489846716347, 'test_avg': 5.0068359375, 'test_std': 0.19503642597857482}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8501 / 10000):
    Value Loss: {'avg': 0.09354404758196325, 'std': 0.0924126279934057}
    Value Grad Norm: {'avg': 0.7379675600677729, 'std': 0.6566594406243188}
    Policy Loss: {'avg': 0.00041618008981458843, 'std': 0.008944272156669262}
    Total_Loss: {'avg': -0.03998973814304918, 'std': 0.0082434457932899}
    Policy Entropy: {'avg': 0.41242173314094543, 'std': 0.5732023119926453}
    KL Divergence: {'avg': 0.023653142154216766, 'std': 0.3132258355617523}
    Policy Grad Norm: {'avg': 1.5087206959724426, 'std': 1.031930921322118}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8534600720809267, 'std': 3.3977916686563394, 'run': -0.9226565266745009, 'test_avg': -6.4830219570721965, 'test_std': 0.4677045676307543}
    Episode Length: {'avg': 2.3876664736537347, 'std': 1.5956217775253139, 'run': 2.3735343140013807, 'test_avg': 5.0009765625, 'test_std': 0.031234737483827102}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8601 / 10000):
    Value Loss: {'avg': 0.09236373761668801, 'std': 0.03701762390752951}
    Value Grad Norm: {'avg': 0.7017957597970963, 'std': 0.24937620474752917}
    Policy Loss: {'avg': -0.0007439145701937377, 'std': 0.012863630731039856}
    Total_Loss: {'avg': -0.043776640901342034, 'std': 0.012610665529391742}
    Policy Entropy: {'avg': 0.4211139678955078, 'std': 0.5530470609664917}
    KL Divergence: {'avg': 0.026478596031665802, 'std': 0.33219021558761597}
    Policy Grad Norm: {'avg': 3.268199894577265, 'std': 3.5874485011106265}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9025100473985584, 'std': 3.409314250966588, 'run': -0.8789972204028621, 'test_avg': -6.550946356839477, 'test_std': 0.9399758695700436}
    Episode Length: {'avg': 2.397316219369895, 'std': 1.5949942945525706, 'run': 2.3772696099749564, 'test_avg': 5.021484375, 'test_std': 0.31487743112338074}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (8701 / 10000):
    Value Loss: {'avg': 0.1012242551194504, 'std': 0.06974481266057618}
    Value Grad Norm: {'avg': 1.5920171733945607, 'std': 1.5807031577483521}
    Policy Loss: {'avg': -0.0004595589416567236, 'std': 0.0055668218242678124}
    Total_Loss: {'avg': -0.04175058868713677, 'std': 0.005291000106546211}
    Policy Entropy: {'avg': 0.45949220657348633, 'std': 0.626492440700531}
    KL Divergence: {'avg': 0.01587715372443199, 'std': 0.2232290804386139}
    Policy Grad Norm: {'avg': 1.1995432591065764, 'std': 1.282595471564094}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.7996584652993228, 'std': 3.349948795965869, 'run': -0.8902804922635051, 'test_avg': -6.502715846989304, 'test_std': 0.44883672534232755}
    Episode Length: {'avg': 2.357122384637432, 'std': 1.576284683877399, 'run': 2.3593986310880566, 'test_avg': 4.9990234375, 'test_std': 0.031234737483827102}
    Ratio Terminated: {'avg': 0.999713384924047, 'test_avg': 1.0}

Iteration (8801 / 10000):
    Value Loss: {'avg': 0.0636481384979561, 'std': 0.0437103645859316}
    Value Grad Norm: {'avg': 0.6569479318335653, 'std': 0.3589452135251716}
    Policy Loss: {'avg': 0.007201919594081119, 'std': 0.019042063098115458}
    Total_Loss: {'avg': -0.031210770714096725, 'std': 0.018376758610996708}
    Policy Entropy: {'avg': 0.4003588855266571, 'std': 0.5926670432090759}
    KL Divergence: {'avg': 0.01687534712255001, 'std': 0.23522906005382538}
    Policy Grad Norm: {'avg': 2.3789018522948027, 'std': 1.8432207012602124}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7255994999050334, 'std': 3.333230807216199, 'run': -1.0433614223415684, 'test_avg': -6.5175815138123525, 'test_std': 0.654001218114486}
    Episode Length: {'avg': 2.3506787330316743, 'std': 1.5496275982208196, 'run': 2.4493713103464403, 'test_avg': 5.0078125, 'test_std': 0.18204969058954756}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8901 / 10000):
    Value Loss: {'avg': 0.03838941641151905, 'std': 0.01229700834507177}
    Value Grad Norm: {'avg': 0.4093944201245904, 'std': 0.15796508838728943}
    Policy Loss: {'avg': -7.17140210326761e-05, 'std': 0.00689351939846702}
    Total_Loss: {'avg': -0.03849071846343577, 'std': 0.00788239921468593}
    Policy Entropy: {'avg': 0.3971060812473297, 'std': 0.5821927189826965}
    KL Divergence: {'avg': 0.01739957556128502, 'std': 0.21283669769763947}
    Policy Grad Norm: {'avg': 1.2065994068980217, 'std': 0.7704191653917907}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8621486720549435, 'std': 3.4013485694231886, 'run': -1.123108817702248, 'test_avg': -6.480329180179979, 'test_std': 0.465873466701682}
    Episode Length: {'avg': 2.407189157336476, 'std': 1.5839561497818178, 'run': 2.539884654588928, 'test_avg': 4.9970703125, 'test_std': 0.05404724258602231}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9001 / 10000):
    Value Loss: {'avg': 0.06340378893073648, 'std': 0.03707761817041783}
    Value Grad Norm: {'avg': 1.1292710982263088, 'std': 1.0327438545890701}
    Policy Loss: {'avg': 0.0007230460178107023, 'std': 0.00519343413283907}
    Total_Loss: {'avg': -0.039272301946766675, 'std': 0.007053350922001371}
    Policy Entropy: {'avg': 0.45053747296333313, 'std': 0.5950632691383362}
    KL Divergence: {'avg': 0.018578078597784042, 'std': 0.3092707097530365}
    Policy Grad Norm: {'avg': 1.5659753382205963, 'std': 1.2262602944801166}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.9020734477122673, 'std': 3.444650623369699, 'run': -0.7885901443801604, 'test_avg': -6.518479309161194, 'test_std': 0.5069095448801625}
    Episode Length: {'avg': 2.4328669246799643, 'std': 1.5986570997654082, 'run': 2.376008492094867, 'test_avg': 5.0, 'test_std': 0.09882117688026186}
    Ratio Terminated: {'avg': 0.9997022923489134, 'test_avg': 1.0}

Iteration (9101 / 10000):
    Value Loss: {'avg': 0.05229081322904676, 'std': 0.03441918500262838}
    Value Grad Norm: {'avg': 0.7267012385651469, 'std': 0.687570329294947}
    Policy Loss: {'avg': -0.0003601294883992523, 'std': 0.004187633094144964}
    Total_Loss: {'avg': -0.03823786252178252, 'std': 0.004278297285339235}
    Policy Entropy: {'avg': 0.38982000946998596, 'std': 0.5757831335067749}
    KL Divergence: {'avg': 0.02152441255748272, 'std': 0.2765262722969055}
    Policy Grad Norm: {'avg': 1.4534678664058447, 'std': 1.2598964763038227}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7896701716869207, 'std': 3.342243495311084, 'run': -1.0612999454948133, 'test_avg': -6.4845852258004015, 'test_std': 0.46038461023972205}
    Episode Length: {'avg': 2.3616343088959724, 'std': 1.5648523215695453, 'run': 2.474307676089498, 'test_avg': 4.9990234375, 'test_std': 0.05411777735350551}
    Ratio Terminated: {'avg': 0.9997102289191538, 'test_avg': 1.0}

Iteration (9201 / 10000):
    Value Loss: {'avg': 0.10438973272684962, 'std': 0.07019318106990487}
    Value Grad Norm: {'avg': 1.5480386897921563, 'std': 1.122488625537246}
    Policy Loss: {'avg': 0.001269732543732971, 'std': 0.008955238892897566}
    Total_Loss: {'avg': -0.037499412428587675, 'std': 0.009793339132845665}
    Policy Entropy: {'avg': 0.3870905637741089, 'std': 0.5471070408821106}
    KL Divergence: {'avg': 0.024130944162607193, 'std': 0.315915584564209}
    Policy Grad Norm: {'avg': 2.2926904195919633, 'std': 3.7642546753202373}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7595563481113731, 'std': 3.3602029288256987, 'run': -0.8975231356295057, 'test_avg': -6.614251965443663, 'test_std': 1.3285326188867659}
    Episode Length: {'avg': 2.342675527304247, 'std': 1.5698682189817215, 'run': 2.3637732370403923, 'test_avg': 5.0419921875, 'test_std': 0.4710302205686646}
    Ratio Terminated: {'avg': 0.999711066165848, 'test_avg': 0.9921875}

Iteration (9301 / 10000):
    Value Loss: {'avg': 0.05154961829539388, 'std': 0.027320621822051774}
    Value Grad Norm: {'avg': 0.5589519590139389, 'std': 0.26659459201363367}
    Policy Loss: {'avg': -0.0034384116224828176, 'std': 0.006186344259030683}
    Total_Loss: {'avg': -0.04361675406107679, 'std': 0.006596796291582698}
    Policy Entropy: {'avg': 0.39225056767463684, 'std': 0.5435789227485657}
    KL Divergence: {'avg': 0.019098782911896706, 'std': 0.23959803581237793}
    Policy Grad Norm: {'avg': 1.085364568978548, 'std': 0.8851728970096084}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.9625831376352054, 'std': 3.444387542204953, 'run': -1.103015029039739, 'test_avg': -6.509334636881249, 'test_std': 0.4714401078765406}
    Episode Length: {'avg': 2.426340601060695, 'std': 1.6083977055497776, 'run': 2.4635809707569183, 'test_avg': 4.9990234375, 'test_std': 0.06987030002571618}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9401 / 10000):
    Value Loss: {'avg': 0.04503833279013634, 'std': 0.028003666075873537}
    Value Grad Norm: {'avg': 0.49590196888893845, 'std': 0.28822477475232305}
    Policy Loss: {'avg': -0.007575232069939375, 'std': 0.006855412141514458}
    Total_Loss: {'avg': -0.04869681977046033, 'std': 0.0077404472146703875}
    Policy Entropy: {'avg': 0.39479947090148926, 'std': 0.5554142594337463}
    KL Divergence: {'avg': 0.017862830311059952, 'std': 0.19430086016654968}
    Policy Grad Norm: {'avg': 0.8329412533591191, 'std': 0.5073426902273911}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -0.7894861368077284, 'std': 3.349530065969676, 'run': -0.9238444815793283, 'test_avg': -6.5177893237245215, 'test_std': 0.6191621336701516}
    Episode Length: {'avg': 2.344323394495413, 'std': 1.572362689561824, 'run': 2.3632970421644814, 'test_avg': 5.00390625, 'test_std': 0.15929647268831001}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9501 / 10000):
    Value Loss: {'avg': 0.21192197469063104, 'std': 0.15291279080469275}
    Value Grad Norm: {'avg': 2.735156314074993, 'std': 2.3715487697626205}
    Policy Loss: {'avg': 0.004616055928636342, 'std': 0.02681457797151541}
    Total_Loss: {'avg': -0.03574183420278132, 'std': 0.026764550944516744}
    Policy Entropy: {'avg': 0.4061001241207123, 'std': 0.6103622913360596}
    KL Divergence: {'avg': 0.03533053770661354, 'std': 0.4627700448036194}
    Policy Grad Norm: {'avg': 2.631262421607971, 'std': 5.346194310055461}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.7978021899436998, 'std': 3.346111487895827, 'run': -0.20387295895027863, 'test_avg': -6.524780999156064, 'test_std': 0.4870204100993823}
    Episode Length: {'avg': 2.34964234620887, 'std': 1.5785342119668677, 'run': 2.0949708346462215, 'test_avg': 5.0009765625, 'test_std': 0.06987030002571618}
    Ratio Terminated: {'avg': 0.9991416309012876, 'test_avg': 1.0}

Iteration (9601 / 10000):
    Value Loss: {'avg': 0.03751207578461617, 'std': 0.01764716767769566}
    Value Grad Norm: {'avg': 0.44397543780505655, 'std': 0.20398459809822553}
    Policy Loss: {'avg': 0.002447322738589719, 'std': 0.015623382708835265}
    Total_Loss: {'avg': -0.0364290033467114, 'std': 0.01638601514381881}
    Policy Entropy: {'avg': 0.4104011654853821, 'std': 0.589744508266449}
    KL Divergence: {'avg': 0.02020099386572838, 'std': 0.2556549310684204}
    Policy Grad Norm: {'avg': 1.8918167240917683, 'std': 4.188594374816281}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.7850549645904648, 'std': 3.3457012876656376, 'run': -0.7758690203159978, 'test_avg': -6.461596783890855, 'test_std': 0.45851869006495055}
    Episode Length: {'avg': 2.372193436960276, 'std': 1.5643695618626792, 'run': 2.3216646282228246, 'test_avg': 4.9970703125, 'test_std': 0.05404724258602231}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9701 / 10000):
    Value Loss: {'avg': 0.08943682366516441, 'std': 0.07462582279157765}
    Value Grad Norm: {'avg': 0.9840946603566408, 'std': 0.8862240777417314}
    Policy Loss: {'avg': -0.00262884478433989, 'std': 0.004907829070727647}
    Total_Loss: {'avg': -0.04283912538085133, 'std': 0.005383534399881605}
    Policy Entropy: {'avg': 0.4173189401626587, 'std': 0.5526822805404663}
    KL Divergence: {'avg': 0.015565728768706322, 'std': 0.22188527882099152}
    Policy Grad Norm: {'avg': 1.3802070189267397, 'std': 1.1888003559075209}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8143815041126369, 'std': 3.3842463527167004, 'run': -0.8786513151201789, 'test_avg': -6.493411358853336, 'test_std': 0.5317237677985517}
    Episode Length: {'avg': 2.3812154696132595, 'std': 1.5735553170929342, 'run': 2.343795744902354, 'test_avg': 5.001953125, 'test_std': 0.11691047986700925}
    Ratio Terminated: {'avg': 0.9997092177958709, 'test_avg': 1.0}

Iteration (9801 / 10000):
    Value Loss: {'avg': 0.05975469460245222, 'std': 0.05179075326156013}
    Value Grad Norm: {'avg': 0.5635882942005992, 'std': 0.2608091699945832}
    Policy Loss: {'avg': -0.004378526791697368, 'std': 0.006617917195599838}
    Total_Loss: {'avg': -0.04409823496825993, 'std': 0.007202785781975863}
    Policy Entropy: {'avg': 0.3733954131603241, 'std': 0.5513712763786316}
    KL Divergence: {'avg': 0.0168411023914814, 'std': 0.25228047370910645}
    Policy Grad Norm: {'avg': 1.0202690679579973, 'std': 1.0816997959200032}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -0.8040658726425861, 'std': 3.332877529353657, 'run': -0.8650821031052552, 'test_avg': -6.488896803718731, 'test_std': 0.6025111790588181}
    Episode Length: {'avg': 2.363033448673587, 'std': 1.5646340916856691, 'run': 2.355907649996163, 'test_avg': 5.0029296875, 'test_std': 0.16235333206051653}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9901 / 10000):
    Value Loss: {'avg': 0.07784780689980834, 'std': 0.055993986153369625}
    Value Grad Norm: {'avg': 0.7780671505257487, 'std': 0.6610388632427413}
    Policy Loss: {'avg': 0.0010698821279220283, 'std': 0.008896835414734228}
    Total_Loss: {'avg': -0.038649725960567594, 'std': 0.010443291223235573}
    Policy Entropy: {'avg': 0.40968000888824463, 'std': 0.5809237360954285}
    KL Divergence: {'avg': 0.021216509863734245, 'std': 0.22022955119609833}
    Policy Grad Norm: {'avg': 2.319599499925971, 'std': 3.8277240731527926}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -0.8162355662477863, 'std': 3.3549821053476534, 'run': -0.9610740951253425, 'test_avg': -6.505696579492017, 'test_std': 0.6918781273034528}
    Episode Length: {'avg': 2.3834542815674893, 'std': 1.567305370083076, 'run': 2.451795589113556, 'test_avg': 5.0078125, 'test_std': 0.20237240385919716}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Training took 35919.731 seconds in total.
