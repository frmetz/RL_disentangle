
Iteration (1 / 10001):
    Value Loss: {'avg': 2298.2913513183594, 'std': 202.3309409497349}
    Value Grad Norm: {'avg': 518.3627154032389, 'std': 140.4183381376772}
    Policy Loss: {'avg': -0.0005211706350867947, 'std': 0.003147658450533273}
    Total_Loss: {'avg': -0.23045067706455788, 'std': 0.0031326462590380876}
    Policy Entropy: {'avg': 2.2994863986968994, 'std': 0.007044532801955938}
    KL Divergence: {'avg': 0.0033091530203819275, 'std': 0.06635323911905289}
    Policy Grad Norm: {'avg': 0.13320530330141386, 'std': 0.05314348828627187}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -160.1597385082485, 'std': 45.0833509624191, 'run': -120.89277141325346, 'test_avg': -174.70747310463503, 'test_std': 30.133089513982593}
    Episode Length: {'avg': 37.09090909090909, 'std': 7.225546259901275, 'run': 28.71292293968673, 'test_avg': 38.0908203125, 'test_std': 3.4036047226928985}
    Ratio Terminated: {'avg': 0.24475524475524477, 'test_avg': 0.318359375}

Iteration (101 / 10001):
    Value Loss: {'avg': 249.59953498840332, 'std': 30.52983287997773}
    Value Grad Norm: {'avg': 1095.6078592936199, 'std': 726.6946043870657}
    Policy Loss: {'avg': -0.006433283493000393, 'std': 0.009520060333141095}
    Total_Loss: {'avg': -0.20927237657209238, 'std': 0.009089884643680525}
    Policy Entropy: {'avg': 2.023834705352783, 'std': 0.2986309826374054}
    KL Divergence: {'avg': 0.014571241103112698, 'std': 0.1819891333580017}
    Policy Grad Norm: {'avg': 1.2617424397418897, 'std': 0.4510543067093265}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -136.29406774254358, 'std': 42.87295316210065, 'run': -137.75049961969017, 'test_avg': -120.10484700227678, 'test_std': 13.545667676458876}
    Episode Length: {'avg': 34.406639004149376, 'std': 8.776181784352787, 'run': 34.57062729161498, 'test_avg': 30.8681640625, 'test_std': 2.920696979846334}
    Ratio Terminated: {'avg': 0.6514522821576764, 'test_avg': 0.9970703125}

Iteration (201 / 10001):
    Value Loss: {'avg': 155.55488061904907, 'std': 22.73667052967736}
    Value Grad Norm: {'avg': 1626.9979775746663, 'std': 958.0007595485977}
    Policy Loss: {'avg': 0.013134545064531267, 'std': 0.009376800315802571}
    Total_Loss: {'avg': -0.16954662557691336, 'std': 0.008987905843180672}
    Policy Entropy: {'avg': 1.8269152641296387, 'std': 0.39939165115356445}
    KL Divergence: {'avg': 0.019125938415527344, 'std': 0.2337203025817871}
    Policy Grad Norm: {'avg': 2.319780319929123, 'std': 0.6384861115415065}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -120.88655996809663, 'std': 38.07604345532553, 'run': -116.79111947380684, 'test_avg': -117.644813832549, 'test_std': 13.507130654011938}
    Episode Length: {'avg': 30.739285714285714, 'std': 8.283367124446878, 'run': 29.896687740919347, 'test_avg': 30.0263671875, 'test_std': 2.9912450516337405}
    Ratio Terminated: {'avg': 0.975, 'test_avg': 1.0}

Iteration (301 / 10001):
    Value Loss: {'avg': 164.29004764556885, 'std': 18.695825797589396}
    Value Grad Norm: {'avg': 2050.456305821737, 'std': 1283.3995355692446}
    Policy Loss: {'avg': 0.00030088986386545, 'std': 0.008562333830975032}
    Total_Loss: {'avg': -0.18755544163286686, 'std': 0.007987693515325876}
    Policy Entropy: {'avg': 1.9005846977233887, 'std': 0.34208405017852783}
    KL Divergence: {'avg': 0.01973903551697731, 'std': 0.20791314542293549}
    Policy Grad Norm: {'avg': 1.9585166033357382, 'std': 0.6938689792851573}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -123.7182688296316, 'std': 37.779529110252255, 'run': -122.02601071732266, 'test_avg': -112.9542376619234, 'test_std': 13.375790455668213}
    Episode Length: {'avg': 31.215686274509803, 'std': 8.189217505510323, 'run': 30.786143499508515, 'test_avg': 28.712890625, 'test_std': 2.9430781219306956}
    Ratio Terminated: {'avg': 0.9333333333333333, 'test_avg': 1.0}

Iteration (401 / 10001):
    Value Loss: {'avg': 133.92455212275186, 'std': 15.508213409624293}
    Value Grad Norm: {'avg': 4723.157418568929, 'std': 3216.7205107615255}
    Policy Loss: {'avg': -0.0027373801567591727, 'std': 0.010112968014286629}
    Total_Loss: {'avg': -0.18031326355412602, 'std': 0.010010091917905911}
    Policy Entropy: {'avg': 1.761054515838623, 'std': 0.4099572002887726}
    KL Divergence: {'avg': 0.017456570640206337, 'std': 0.19378449022769928}
    Policy Grad Norm: {'avg': 1.8787632547318935, 'std': 0.6012651562352626}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -115.22750603070695, 'std': 39.38420250976154, 'run': -116.48358784777706, 'test_avg': -112.50902597543157, 'test_std': 13.60244817337296}
    Episode Length: {'avg': 29.421818181818182, 'std': 8.529961971759864, 'run': 29.643651113330385, 'test_avg': 28.6103515625, 'test_std': 3.0598729602148205}
    Ratio Terminated: {'avg': 0.9818181818181818, 'test_avg': 1.0}

Iteration (501 / 10001):
    Value Loss: {'avg': 156.71753120422363, 'std': 12.586465907921687}
    Value Grad Norm: {'avg': 2582.2896060943604, 'std': 1597.283796202682}
    Policy Loss: {'avg': 0.006497267255326733, 'std': 0.005985121475938379}
    Total_Loss: {'avg': -0.16670446749776602, 'std': 0.0066313617028094}
    Policy Entropy: {'avg': 1.7313110828399658, 'std': 0.41430139541625977}
    KL Divergence: {'avg': 0.025884412229061127, 'std': 0.29449281096458435}
    Policy Grad Norm: {'avg': 1.6301181465387344, 'std': 0.5510953332965475}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -110.17762886448897, 'std': 35.40697804541685, 'run': -110.19546463632629, 'test_avg': -106.11125948520916, 'test_std': 16.30131610090009}
    Episode Length: {'avg': 27.773519163763066, 'std': 7.71583257234603, 'run': 27.787783733956008, 'test_avg': 26.4072265625, 'test_std': 3.4208669353388235}
    Ratio Terminated: {'avg': 0.9930313588850174, 'test_avg': 0.9892578125}

Iteration (601 / 10001):
    Value Loss: {'avg': 147.3166216214498, 'std': 16.90440015021996}
    Value Grad Norm: {'avg': 2327.9585247039795, 'std': 1371.3574976444806}
    Policy Loss: {'avg': 0.005856355914147571, 'std': 0.005204005881347605}
    Total_Loss: {'avg': -0.16405413206666708, 'std': 0.006005223385971851}
    Policy Entropy: {'avg': 1.7002488374710083, 'std': 0.424638569355011}
    KL Divergence: {'avg': 0.015095289796590805, 'std': 0.2046949565410614}
    Policy Grad Norm: {'avg': 1.8913760110735893, 'std': 0.465649336310952}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -108.29739022558464, 'std': 35.72281722599012, 'run': -108.77427242124605, 'test_avg': -97.47488357161228, 'test_std': 12.242434063373842}
    Episode Length: {'avg': 27.25245901639344, 'std': 7.640607789689334, 'run': 27.410513311672936, 'test_avg': 24.4072265625, 'test_std': 2.822756735762831}
    Ratio Terminated: {'avg': 0.9967213114754099, 'test_avg': 1.0}

Iteration (701 / 10001):
    Value Loss: {'avg': 154.8119681676229, 'std': 14.070965826210134}
    Value Grad Norm: {'avg': 2063.9749838511148, 'std': 1601.9460548002362}
    Policy Loss: {'avg': -0.002393603305487583, 'std': 0.012427692496013188}
    Total_Loss: {'avg': -0.17229765995095173, 'std': 0.011934952452966422}
    Policy Entropy: {'avg': 1.6325435638427734, 'std': 0.47427278757095337}
    KL Divergence: {'avg': 0.013741000555455685, 'std': 0.2217104583978653}
    Policy Grad Norm: {'avg': 2.046773586422205, 'std': 0.6270286251991322}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -106.59417609441499, 'std': 32.33855008878105, 'run': -107.16047367844442, 'test_avg': -95.1897923770191, 'test_std': 12.726491920283564}
    Episode Length: {'avg': 26.561290322580646, 'std': 6.922225887551882, 'run': 26.641289979016868, 'test_avg': 23.5869140625, 'test_std': 2.746493618368655}
    Ratio Terminated: {'avg': 0.9838709677419355, 'test_avg': 0.9951171875}

Iteration (801 / 10001):
    Value Loss: {'avg': 151.19744777679443, 'std': 12.40341270736857}
    Value Grad Norm: {'avg': 1633.8375752766926, 'std': 1083.2552497558106}
    Policy Loss: {'avg': 0.006787105667172, 'std': 0.0080059545803504}
    Total_Loss: {'avg': -0.1651831716299057, 'std': 0.007783572050772892}
    Policy Entropy: {'avg': 1.6872732639312744, 'std': 0.43964695930480957}
    KL Divergence: {'avg': 0.015977511182427406, 'std': 0.20999673008918762}
    Policy Grad Norm: {'avg': 2.1578481271862984, 'std': 0.6310251688138167}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -103.77795148422253, 'std': 32.20908676475573, 'run': -102.73004966118856, 'test_avg': -92.00435145418282, 'test_std': 9.030584182134088}
    Episode Length: {'avg': 25.745398773006134, 'std': 6.8650149125078785, 'run': 25.57348105193103, 'test_avg': 22.689453125, 'test_std': 1.9939474073876007}
    Ratio Terminated: {'avg': 0.99079754601227, 'test_avg': 1.0}

Iteration (901 / 10001):
    Value Loss: {'avg': 124.33318042755127, 'std': 14.387620659243767}
    Value Grad Norm: {'avg': 1714.168872197469, 'std': 967.0526356851924}
    Policy Loss: {'avg': 0.0081602590798866, 'std': 0.012382274664267534}
    Total_Loss: {'avg': -0.15015735011547804, 'std': 0.011798490579844627}
    Policy Entropy: {'avg': 1.4910335540771484, 'std': 0.5061373114585876}
    KL Divergence: {'avg': 0.030003998428583145, 'std': 0.2815554738044739}
    Policy Grad Norm: {'avg': 2.6282009705901146, 'std': 0.9186829953300647}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -97.50109938077921, 'std': 33.72932397101423, 'run': -96.40948729144522, 'test_avg': -92.53802554501607, 'test_std': 10.246579163310038}
    Episode Length: {'avg': 24.594029850746267, 'std': 7.198007199280922, 'run': 24.352456904990678, 'test_avg': 23.05859375, 'test_std': 2.379207698470425}
    Ratio Terminated: {'avg': 0.9970149253731343, 'test_avg': 1.0}

Iteration (1001 / 10001):
    Value Loss: {'avg': 123.22119506200154, 'std': 10.63952355968075}
    Value Grad Norm: {'avg': 1971.0754464467366, 'std': 963.4756957534157}
    Policy Loss: {'avg': 0.006228753074537963, 'std': 0.008944595117599477}
    Total_Loss: {'avg': -0.15002814400941133, 'std': 0.009683372081811746}
    Policy Entropy: {'avg': 1.5343644618988037, 'std': 0.5086724162101746}
    KL Divergence: {'avg': 0.017329141497612, 'std': 0.1916450411081314}
    Policy Grad Norm: {'avg': 2.7795585989952087, 'std': 1.4982363744934462}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -96.03011315847775, 'std': 33.84033542078192, 'run': -94.79739091813649, 'test_avg': -91.32721100648064, 'test_std': 9.787298400521674}
    Episode Length: {'avg': 23.926470588235293, 'std': 7.180275630606941, 'run': 23.6397801631106, 'test_avg': 22.5888671875, 'test_std': 2.1963911020093483}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 10001):
    Value Loss: {'avg': 111.10193618138631, 'std': 9.828863575753516}
    Value Grad Norm: {'avg': 1156.4043261210124, 'std': 597.2938031689621}
    Policy Loss: {'avg': 0.0036038586986251175, 'std': 0.006324017230640257}
    Total_Loss: {'avg': -0.1515748705714941, 'std': 0.008203299454840038}
    Policy Entropy: {'avg': 1.5422848463058472, 'std': 0.43148699402809143}
    KL Divergence: {'avg': 0.01697399653494358, 'std': 0.2194254845380783}
    Policy Grad Norm: {'avg': 2.2503819689154625, 'std': 0.5121747075076115}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -99.67594866477127, 'std': 29.468445988378054, 'run': -97.55613278261107, 'test_avg': -90.45397289971106, 'test_std': 9.079037178312005}
    Episode Length: {'avg': 24.831360946745562, 'std': 6.366375143466695, 'run': 24.35794663454953, 'test_avg': 22.388671875, 'test_std': 2.015396933257562}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 10001):
    Value Loss: {'avg': 96.54857158660889, 'std': 9.835195000665882}
    Value Grad Norm: {'avg': 1150.8895867665608, 'std': 593.451413350378}
    Policy Loss: {'avg': -0.0006451564404414967, 'std': 0.008263949011954406}
    Total_Loss: {'avg': -0.14647706039249897, 'std': 0.00854557937605567}
    Policy Entropy: {'avg': 1.4114339351654053, 'std': 0.494829922914505}
    KL Divergence: {'avg': 0.016673514619469643, 'std': 0.18820765614509583}
    Policy Grad Norm: {'avg': 2.4636011198163033, 'std': 0.632992226058313}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -96.45709726142564, 'std': 29.133199158483702, 'run': -98.55014564539375, 'test_avg': -89.41793272945631, 'test_std': 9.88278861038521}
    Episode Length: {'avg': 24.062314540059347, 'std': 6.227080562218885, 'run': 24.460289790713958, 'test_avg': 22.2890625, 'test_std': 2.1620026297610626}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1301 / 10001):
    Value Loss: {'avg': 99.97529220581055, 'std': 10.833492222239085}
    Value Grad Norm: {'avg': 1722.9634164174397, 'std': 1107.128591646273}
    Policy Loss: {'avg': 0.002755287161562592, 'std': 0.00636383449602473}
    Total_Loss: {'avg': -0.14530630595982075, 'std': 0.007158790787060559}
    Policy Entropy: {'avg': 1.4850661754608154, 'std': 0.5171642899513245}
    KL Divergence: {'avg': 0.019363917410373688, 'std': 0.19121895730495453}
    Policy Grad Norm: {'avg': 2.297315299510956, 'std': 0.8777522928307323}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -94.52190056300796, 'std': 30.134215033786802, 'run': -93.32612799470301, 'test_avg': -88.63918444256183, 'test_std': 8.437435909130715}
    Episode Length: {'avg': 23.675213675213676, 'std': 6.430202585939517, 'run': 23.390245011219907, 'test_avg': 21.9765625, 'test_std': 1.8369677960143314}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 10001):
    Value Loss: {'avg': 88.60632022221883, 'std': 8.164444414542821}
    Value Grad Norm: {'avg': 1303.1325410207112, 'std': 840.6734477904465}
    Policy Loss: {'avg': 0.007317777170101181, 'std': 0.008829729387372578}
    Total_Loss: {'avg': -0.13621977344155312, 'std': 0.008772189501272318}
    Policy Entropy: {'avg': 1.407080888748169, 'std': 0.4604559540748596}
    KL Divergence: {'avg': 0.017534036189317703, 'std': 0.18590404093265533}
    Policy Grad Norm: {'avg': 2.4582672268152237, 'std': 0.7989552362938328}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -95.95334746230398, 'std': 27.256122659147216, 'run': -93.068507712556, 'test_avg': -88.24526988225279, 'test_std': 8.398741274950385}
    Episode Length: {'avg': 23.915204678362574, 'std': 5.872560072082024, 'run': 23.29539659132678, 'test_avg': 21.841796875, 'test_std': 1.8636036719861426}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 10001):
    Value Loss: {'avg': 97.59561395645142, 'std': 7.376053924210036}
    Value Grad Norm: {'avg': 1597.1292845408123, 'std': 923.6661097484421}
    Policy Loss: {'avg': -0.013387897692155093, 'std': 0.011048775723962527}
    Total_Loss: {'avg': -0.1718718841051062, 'std': 0.011879194896673264}
    Policy Entropy: {'avg': 1.6155046224594116, 'std': 0.43051421642303467}
    KL Divergence: {'avg': 0.01635497435927391, 'std': 0.20544908940792084}
    Policy Grad Norm: {'avg': 1.882914366821448, 'std': 0.7185221589303031}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -98.39768640623748, 'std': 31.493523453465063, 'run': -96.67329631991888, 'test_avg': -88.86458817782011, 'test_std': 9.32581709157406}
    Episode Length: {'avg': 24.567164179104477, 'std': 6.757690766484752, 'run': 24.216087989487992, 'test_avg': 22.173828125, 'test_std': 2.080663063294724}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 10001):
    Value Loss: {'avg': 86.1265377998352, 'std': 6.635113946526775}
    Value Grad Norm: {'avg': 1017.5278981526693, 'std': 482.5884563965873}
    Policy Loss: {'avg': -0.01028477832248124, 'std': 0.009996480429104369}
    Total_Loss: {'avg': -0.15953674539923668, 'std': 0.011058735017617524}
    Policy Entropy: {'avg': 1.5076854228973389, 'std': 0.4720540940761566}
    KL Divergence: {'avg': 0.02023128606379032, 'std': 0.19303584098815918}
    Policy Grad Norm: {'avg': 2.5682587598760924, 'std': 0.9254046485046297}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -95.99842636205587, 'std': 27.641255257742248, 'run': -94.00617614320656, 'test_avg': -87.22952819898094, 'test_std': 8.114082441817438}
    Episode Length: {'avg': 23.8953488372093, 'std': 5.81753378133013, 'run': 23.482173857797015, 'test_avg': 21.6640625, 'test_std': 1.798012547535125}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 10001):
    Value Loss: {'avg': 75.68764607111613, 'std': 8.22411356506764}
    Value Grad Norm: {'avg': 939.6383717854818, 'std': 434.7615290541539}
    Policy Loss: {'avg': 0.006597454630536959, 'std': 0.006841579361682732}
    Total_Loss: {'avg': -0.13076565926894546, 'std': 0.00716907533921753}
    Policy Entropy: {'avg': 1.4075404405593872, 'std': 0.47328847646713257}
    KL Divergence: {'avg': 0.01707538217306137, 'std': 0.2059617042541504}
    Policy Grad Norm: {'avg': 2.474809404462576, 'std': 0.9343272654226991}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -90.614413760034, 'std': 27.910779041775864, 'run': -91.23676300871401, 'test_avg': -85.90640735292122, 'test_std': 8.193449685812627}
    Episode Length: {'avg': 22.605978260869566, 'std': 5.901332487664306, 'run': 22.747425267341157, 'test_avg': 21.2978515625, 'test_std': 1.773875984734082}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 10001):
    Value Loss: {'avg': 89.08089955647786, 'std': 9.173413101070024}
    Value Grad Norm: {'avg': 1261.6069094340007, 'std': 662.6973117477226}
    Policy Loss: {'avg': -0.0040184026438510045, 'std': 0.009111391345569297}
    Total_Loss: {'avg': -0.14639977272599936, 'std': 0.009680380890173106}
    Policy Entropy: {'avg': 1.3713380098342896, 'std': 0.48902276158332825}
    KL Divergence: {'avg': 0.023729264736175537, 'std': 0.224491149187088}
    Policy Grad Norm: {'avg': 1.9843997471034527, 'std': 0.5949500729840014}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -92.3811740044606, 'std': 30.000951731854197, 'run': -89.78657636497284, 'test_avg': -86.6274292466678, 'test_std': 8.869909609411032}
    Episode Length: {'avg': 23.110481586402265, 'std': 6.423375163672677, 'run': 22.531573103363314, 'test_avg': 21.7138671875, 'test_std': 2.006620654511171}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 10001):
    Value Loss: {'avg': 78.72979752222697, 'std': 8.428135931709889}
    Value Grad Norm: {'avg': 1042.7756258646648, 'std': 538.9763807860961}
    Policy Loss: {'avg': 0.00609147862996906, 'std': 0.0057777734681081555}
    Total_Loss: {'avg': -0.12537202471867204, 'std': 0.005647879901089453}
    Policy Entropy: {'avg': 1.378324031829834, 'std': 0.4893697202205658}
    KL Divergence: {'avg': 0.027359532192349434, 'std': 0.26172107458114624}
    Policy Grad Norm: {'avg': 2.529957264661789, 'std': 0.7847841900411687}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -86.34283708252022, 'std': 30.6515910247456, 'run': -88.07770069477482, 'test_avg': -85.20636793083888, 'test_std': 7.880100374390262}
    Episode Length: {'avg': 21.788359788359788, 'std': 6.463382569593317, 'run': 22.16520348769585, 'test_avg': 21.2646484375, 'test_std': 1.7335387267173492}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 10001):
    Value Loss: {'avg': 69.10318676630656, 'std': 7.023207748318058}
    Value Grad Norm: {'avg': 1221.6091213226318, 'std': 648.7706865609398}
    Policy Loss: {'avg': 0.0005376157641876489, 'std': 0.010029547475553222}
    Total_Loss: {'avg': -0.13047519023530185, 'std': 0.010399241249741018}
    Policy Entropy: {'avg': 1.2393369674682617, 'std': 0.5036610960960388}
    KL Divergence: {'avg': 0.031242426484823227, 'std': 0.2765424847602844}
    Policy Grad Norm: {'avg': 2.8189353458583355, 'std': 1.3586143777127333}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -88.90826477727609, 'std': 28.48265677687363, 'run': -87.99237516018127, 'test_avg': -85.49322687297325, 'test_std': 8.491759399932604}
    Episode Length: {'avg': 22.506811989100818, 'std': 6.127112430037455, 'run': 22.276524481917736, 'test_avg': 21.3779296875, 'test_std': 1.8689332087600543}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 10001):
    Value Loss: {'avg': 75.22092731793721, 'std': 9.353060973969068}
    Value Grad Norm: {'avg': 1401.7261358896892, 'std': 931.7180991301774}
    Policy Loss: {'avg': 0.005527295230422169, 'std': 0.007048968945162622}
    Total_Loss: {'avg': -0.12891921820119023, 'std': 0.0057522073418106705}
    Policy Entropy: {'avg': 1.4112755060195923, 'std': 0.4795966148376465}
    KL Divergence: {'avg': 0.01859099045395851, 'std': 0.20355194807052612}
    Policy Grad Norm: {'avg': 2.513505406677723, 'std': 0.62645356233697}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -89.32457433605458, 'std': 28.35620304149842, 'run': -89.54859169072074, 'test_avg': -85.75751991883618, 'test_std': 8.783240728820768}
    Episode Length: {'avg': 22.63013698630137, 'std': 6.135695803650421, 'run': 22.672198292412087, 'test_avg': 21.5078125, 'test_std': 1.9684864654967151}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 10001):
    Value Loss: {'avg': 61.03414114316305, 'std': 6.551122357148989}
    Value Grad Norm: {'avg': 1164.7712364196777, 'std': 781.2547720245173}
    Policy Loss: {'avg': 0.003124500814010389, 'std': 0.011470889913524216}
    Total_Loss: {'avg': -0.13416835735552013, 'std': 0.012478169966330933}
    Policy Entropy: {'avg': 1.3926358222961426, 'std': 0.48739245533943176}
    KL Divergence: {'avg': 0.020977690815925598, 'std': 0.19595074653625488}
    Policy Grad Norm: {'avg': 2.838052960112691, 'std': 1.3482654828033582}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -88.6369264130848, 'std': 27.461757078653232, 'run': -89.91102720432347, 'test_avg': -84.54466966970276, 'test_std': 8.152530646939326}
    Episode Length: {'avg': 22.200534759358288, 'std': 5.822682893449444, 'run': 22.42825340007644, 'test_avg': 21.3037109375, 'test_std': 1.8040064728106913}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 10001):
    Value Loss: {'avg': 60.4489594300588, 'std': 5.230262554599895}
    Value Grad Norm: {'avg': 990.8594258626302, 'std': 455.9648928884016}
    Policy Loss: {'avg': 0.0030187037773430347, 'std': 0.007382593373140728}
    Total_Loss: {'avg': -0.12311108969151974, 'std': 0.006119142450934109}
    Policy Entropy: {'avg': 1.3269670009613037, 'std': 0.496773362159729}
    KL Divergence: {'avg': 0.01768576353788376, 'std': 0.17351065576076508}
    Policy Grad Norm: {'avg': 2.4541763067245483, 'std': 0.7943850883582242}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -87.13717858925587, 'std': 27.365897860521738, 'run': -86.844059875253, 'test_avg': -83.65389429055591, 'test_std': 8.013332129437023}
    Episode Length: {'avg': 21.8283378746594, 'std': 5.718221100192861, 'run': 21.765809569573076, 'test_avg': 21.0263671875, 'test_std': 1.7941659159407024}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2401 / 10001):
    Value Loss: {'avg': 62.49325895309448, 'std': 6.373452168966153}
    Value Grad Norm: {'avg': 1368.371976216634, 'std': 696.6982778480733}
    Policy Loss: {'avg': 0.00012050379882566631, 'std': 0.006141135551540149}
    Total_Loss: {'avg': -0.13092552172020078, 'std': 0.006685337090415119}
    Policy Entropy: {'avg': 1.3031160831451416, 'std': 0.5308710336685181}
    KL Divergence: {'avg': 0.015660785138607025, 'std': 0.19185906648635864}
    Policy Grad Norm: {'avg': 2.984871119260788, 'std': 1.5037811895915099}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -86.70029103581514, 'std': 29.456288681950216, 'run': -87.30108739168357, 'test_avg': -84.34603224286474, 'test_std': 8.85309560522832}
    Episode Length: {'avg': 21.879679144385026, 'std': 6.142598163360265, 'run': 22.003294355118143, 'test_avg': 21.361328125, 'test_std': 1.9501373633885344}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 10001):
    Value Loss: {'avg': 60.3145436445872, 'std': 6.4300348385906965}
    Value Grad Norm: {'avg': 830.8319114049276, 'std': 363.77594065631723}
    Policy Loss: {'avg': -0.000513327911903616, 'std': 0.00951544602998622}
    Total_Loss: {'avg': -0.12106598052196205, 'std': 0.010045675323602583}
    Policy Entropy: {'avg': 1.2294723987579346, 'std': 0.497185081243515}
    KL Divergence: {'avg': 0.025672558695077896, 'std': 0.2103448212146759}
    Policy Grad Norm: {'avg': 2.236261110752821, 'std': 0.6791657279186131}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -84.5066757902463, 'std': 26.254340823180925, 'run': -84.98824724323558, 'test_avg': -83.52988398469734, 'test_std': 8.376658573008598}
    Episode Length: {'avg': 21.31099195710456, 'std': 5.528848285057625, 'run': 21.43062950233709, 'test_avg': 21.013671875, 'test_std': 1.8167537889967327}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 10001):
    Value Loss: {'avg': 54.4761331876119, 'std': 7.120279988831048}
    Value Grad Norm: {'avg': 1443.385259628296, 'std': 663.1323865264176}
    Policy Loss: {'avg': 0.005122479342389852, 'std': 0.010504582361157581}
    Total_Loss: {'avg': -0.12001748895272613, 'std': 0.010467887723058043}
    Policy Entropy: {'avg': 1.244523525238037, 'std': 0.5398837327957153}
    KL Divergence: {'avg': 0.018284322693943977, 'std': 0.17877379059791565}
    Policy Grad Norm: {'avg': 2.3775662034749985, 'std': 0.8219024282330895}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -85.54650457439693, 'std': 27.85328372055278, 'run': -84.49765282357691, 'test_avg': -83.25938629194968, 'test_std': 8.099339510479785}
    Episode Length: {'avg': 21.589147286821706, 'std': 5.932365224260657, 'run': 21.34221738644743, 'test_avg': 20.9990234375, 'test_std': 1.8025045031360347}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 10001):
    Value Loss: {'avg': 63.611254612604775, 'std': 5.1892475289976066}
    Value Grad Norm: {'avg': 1076.503017425537, 'std': 665.8195370931325}
    Policy Loss: {'avg': 0.006757472263416275, 'std': 0.012823904663263068}
    Total_Loss: {'avg': -0.12975914124399424, 'std': 0.012856137507793946}
    Policy Entropy: {'avg': 1.3974629640579224, 'std': 0.44255760312080383}
    KL Divergence: {'avg': 0.02363033965229988, 'std': 0.2365693300962448}
    Policy Grad Norm: {'avg': 3.656413607299328, 'std': 2.1438372665554293}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -87.34340286215509, 'std': 28.793780920355452, 'run': -88.44538509273562, 'test_avg': -82.55039463164564, 'test_std': 7.746249460252792}
    Episode Length: {'avg': 22.115183246073297, 'std': 6.184114918275841, 'run': 22.328527036323194, 'test_avg': 20.849609375, 'test_std': 1.7198405187435577}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 10001):
    Value Loss: {'avg': 50.815570990244545, 'std': 4.908481835213333}
    Value Grad Norm: {'avg': 1064.7148717244465, 'std': 618.2074176198877}
    Policy Loss: {'avg': 0.0024735559709370136, 'std': 0.005759891890056054}
    Total_Loss: {'avg': -0.12233611242845654, 'std': 0.004660112722242307}
    Policy Entropy: {'avg': 1.3008298873901367, 'std': 0.49944964051246643}
    KL Divergence: {'avg': 0.015436063520610332, 'std': 0.1845492124557495}
    Policy Grad Norm: {'avg': 2.525355577468872, 'std': 1.3587265223515896}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -86.04645264604838, 'std': 25.30436117609011, 'run': -86.87293667315933, 'test_avg': -83.05228561296929, 'test_std': 8.358152929522726}
    Episode Length: {'avg': 21.6781914893617, 'std': 5.3504973844684915, 'run': 21.846385404320795, 'test_avg': 20.9609375, 'test_std': 1.8536380771590095}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 10001):
    Value Loss: {'avg': 45.20518716176351, 'std': 3.951678165088971}
    Value Grad Norm: {'avg': 693.0809605916342, 'std': 294.95699302829127}
    Policy Loss: {'avg': 0.002910401322878897, 'std': 0.007668702422092966}
    Total_Loss: {'avg': -0.11374068213626742, 'std': 0.005710431645623488}
    Policy Entropy: {'avg': 1.2621550559997559, 'std': 0.5366111397743225}
    KL Divergence: {'avg': 0.024296211078763008, 'std': 0.19212204217910767}
    Policy Grad Norm: {'avg': 2.597482569515705, 'std': 1.3388350413280865}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.3613796787345, 'std': 25.74954052054713, 'run': -84.59925976863246, 'test_avg': -81.85022437664674, 'test_std': 7.587770141362036}
    Episode Length: {'avg': 21.196891191709845, 'std': 5.427104369541984, 'run': 21.215024141966705, 'test_avg': 20.6689453125, 'test_std': 1.6626563780241175}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 10001):
    Value Loss: {'avg': 50.268186807632446, 'std': 4.309560039939113}
    Value Grad Norm: {'avg': 895.5313510894775, 'std': 438.8713283700738}
    Policy Loss: {'avg': 0.005066812824225053, 'std': 0.005417286050889641}
    Total_Loss: {'avg': -0.12020578142255545, 'std': 0.006566404519714084}
    Policy Entropy: {'avg': 1.1879860162734985, 'std': 0.5364329814910889}
    KL Divergence: {'avg': 0.01980554684996605, 'std': 0.22369857132434845}
    Policy Grad Norm: {'avg': 2.0274659991264343, 'std': 0.5425713281216415}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -85.37171761610833, 'std': 26.08216218691576, 'run': -87.24726904559571, 'test_avg': -82.5736049272917, 'test_std': 8.170028425434964}
    Episode Length: {'avg': 21.504, 'std': 5.543463177473085, 'run': 21.96113694835007, 'test_avg': 20.8154296875, 'test_std': 1.7782640024033698}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3101 / 10001):
    Value Loss: {'avg': 46.34352970123291, 'std': 4.575942650845106}
    Value Grad Norm: {'avg': 814.2576128641764, 'std': 384.91823961878265}
    Policy Loss: {'avg': 0.002627081878017634, 'std': 0.005264422247418387}
    Total_Loss: {'avg': -0.12288453802466393, 'std': 0.004785269516168431}
    Policy Entropy: {'avg': 1.2547123432159424, 'std': 0.5379680395126343}
    KL Divergence: {'avg': 0.015015493147075176, 'std': 0.15169119834899902}
    Policy Grad Norm: {'avg': 2.422586604952812, 'std': 1.026877960907383}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -85.97597186816478, 'std': 25.330900720132433, 'run': -88.66857379200067, 'test_avg': -82.12848652006528, 'test_std': 8.434738681453604}
    Episode Length: {'avg': 21.69371727748691, 'std': 5.4208162194925045, 'run': 22.328564813862656, 'test_avg': 20.7177734375, 'test_std': 1.7775280532018147}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3201 / 10001):
    Value Loss: {'avg': 40.02120566368103, 'std': 5.174214651563813}
    Value Grad Norm: {'avg': 767.5582529703776, 'std': 356.986397642266}
    Policy Loss: {'avg': 0.005728893564082682, 'std': 0.011688003492432826}
    Total_Loss: {'avg': -0.10570292780175805, 'std': 0.011011187316293226}
    Policy Entropy: {'avg': 1.1300479173660278, 'std': 0.526206910610199}
    KL Divergence: {'avg': 0.018266377970576286, 'std': 0.1714683175086975}
    Policy Grad Norm: {'avg': 2.6237998977303505, 'std': 0.9618365848517986}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.5991291851334, 'std': 27.1566649419365, 'run': -82.84430874783477, 'test_avg': -82.35742498946445, 'test_std': 8.27577118050622}
    Episode Length: {'avg': 20.513853904282115, 'std': 5.722634762370592, 'run': 20.95551914381467, 'test_avg': 20.8330078125, 'test_std': 1.7936640702244009}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 10001):
    Value Loss: {'avg': 44.060441652933754, 'std': 4.389963183611143}
    Value Grad Norm: {'avg': 1022.1999066670736, 'std': 547.6509198215709}
    Policy Loss: {'avg': 0.006453043548390269, 'std': 0.006306256077942848}
    Total_Loss: {'avg': -0.11143992561846972, 'std': 0.006335440303240427}
    Policy Entropy: {'avg': 1.1434657573699951, 'std': 0.5393964052200317}
    KL Divergence: {'avg': 0.021369002759456635, 'std': 0.1829024702310562}
    Policy Grad Norm: {'avg': 2.308370418846607, 'std': 0.5915011820925824}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.3188541737942, 'std': 24.53230158719991, 'run': -80.26951783310105, 'test_avg': -81.92924293267492, 'test_std': 8.295148121017435}
    Episode Length: {'avg': 20.835051546391753, 'std': 5.182107226468912, 'run': 20.370520429697017, 'test_avg': 20.6875, 'test_std': 1.7416093491365967}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3401 / 10001):
    Value Loss: {'avg': 45.9064355691274, 'std': 4.561510385738847}
    Value Grad Norm: {'avg': 700.7178389231364, 'std': 303.74044598228335}
    Policy Loss: {'avg': 0.002645994711201638, 'std': 0.003679241892121427}
    Total_Loss: {'avg': -0.1233872096054256, 'std': 0.004726453326919588}
    Policy Entropy: {'avg': 1.2420754432678223, 'std': 0.5613430142402649}
    KL Divergence: {'avg': 0.01996135711669922, 'std': 0.19973334670066833}
    Policy Grad Norm: {'avg': 2.650627873837948, 'std': 0.8717996942279319}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.88356219042433, 'std': 24.225661377284254, 'run': -86.13512365191318, 'test_avg': -81.29443560360266, 'test_std': 7.946825068050181}
    Episode Length: {'avg': 21.344559585492227, 'std': 5.035926260723482, 'run': 21.584482719465157, 'test_avg': 20.57421875, 'test_std': 1.7140160303067289}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 10001):
    Value Loss: {'avg': 41.92490808169047, 'std': 4.604776350762421}
    Value Grad Norm: {'avg': 784.8357702891032, 'std': 340.00010919566114}
    Policy Loss: {'avg': 0.0013783926842734218, 'std': 0.004834350937786701}
    Total_Loss: {'avg': -0.11681864596903324, 'std': 0.005479696161985944}
    Policy Entropy: {'avg': 1.189049243927002, 'std': 0.49461492896080017}
    KL Divergence: {'avg': 0.017571408301591873, 'std': 0.16987904906272888}
    Policy Grad Norm: {'avg': 2.4286805763840675, 'std': 0.635996730672302}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -83.20629598237771, 'std': 26.040683320330263, 'run': -83.08011512735301, 'test_avg': -81.4678082724534, 'test_std': 7.374567656474101}
    Episode Length: {'avg': 21.082010582010582, 'std': 5.557410247226012, 'run': 20.99701972193855, 'test_avg': 20.546875, 'test_std': 1.5810616241547955}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3601 / 10001):
    Value Loss: {'avg': 37.538101037343345, 'std': 3.508776050688844}
    Value Grad Norm: {'avg': 749.5344543457031, 'std': 333.487934801299}
    Policy Loss: {'avg': 0.0028508537507150322, 'std': 0.0054190041164932125}
    Total_Loss: {'avg': -0.10976143926382065, 'std': 0.006403488210312161}
    Policy Entropy: {'avg': 1.1595402956008911, 'std': 0.5021969676017761}
    KL Divergence: {'avg': 0.01750536821782589, 'std': 0.1829923689365387}
    Policy Grad Norm: {'avg': 2.530032344162464, 'std': 0.9704832848334656}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.02211019514819, 'std': 26.751999160133114, 'run': -79.1477626941645, 'test_avg': -82.46404426550743, 'test_std': 9.51188359746405}
    Episode Length: {'avg': 20.502487562189053, 'std': 5.6433154029708, 'run': 20.314969592978418, 'test_avg': 20.9462890625, 'test_std': 1.9754464236452658}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3701 / 10001):
    Value Loss: {'avg': 37.44392522176107, 'std': 3.9326863675568395}
    Value Grad Norm: {'avg': 981.8149382273356, 'std': 597.2310528207502}
    Policy Loss: {'avg': 0.004722783342003822, 'std': 0.005189993477949815}
    Total_Loss: {'avg': -0.10564276063814759, 'std': 0.006017686439289111}
    Policy Entropy: {'avg': 1.097343921661377, 'std': 0.5084284543991089}
    KL Divergence: {'avg': 0.020586419850587845, 'std': 0.1747664511203766}
    Policy Grad Norm: {'avg': 2.1701758205890656, 'std': 0.5063663227062564}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.54296166932532, 'std': 26.516564827343366, 'run': -81.57372996410149, 'test_avg': -81.33090443244578, 'test_std': 8.634839078765335}
    Episode Length: {'avg': 20.392592592592592, 'std': 5.519120026875321, 'run': 20.587516656736433, 'test_avg': 20.4716796875, 'test_std': 1.809042691563663}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3801 / 10001):
    Value Loss: {'avg': 50.49897313117981, 'std': 4.647688687144515}
    Value Grad Norm: {'avg': 984.1103134155273, 'std': 575.5777055240858}
    Policy Loss: {'avg': 0.003243400016799569, 'std': 0.003565405624701486}
    Total_Loss: {'avg': -0.11892397794872522, 'std': 0.005731013989870355}
    Policy Entropy: {'avg': 1.2326065301895142, 'std': 0.5090482234954834}
    KL Divergence: {'avg': 0.015350284054875374, 'std': 0.1579422652721405}
    Policy Grad Norm: {'avg': 2.8706945702433586, 'std': 1.0875558884640275}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.76897134980815, 'std': 27.203419006429566, 'run': -83.7324252729818, 'test_avg': -81.52906245480908, 'test_std': 7.730153516696205}
    Episode Length: {'avg': 21.436363636363637, 'std': 5.771558323205112, 'run': 21.23027326658205, 'test_avg': 20.6953125, 'test_std': 1.7050412098667147}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 10001):
    Value Loss: {'avg': 38.5714103380839, 'std': 3.9501417688031246}
    Value Grad Norm: {'avg': 695.4589099884033, 'std': 344.5363413108456}
    Policy Loss: {'avg': 0.004442735458724201, 'std': 0.004464163701649353}
    Total_Loss: {'avg': -0.1109161889180541, 'std': 0.005148449105124518}
    Policy Entropy: {'avg': 1.163851261138916, 'std': 0.49830344319343567}
    KL Divergence: {'avg': 0.01805557869374752, 'std': 0.19672469794750214}
    Policy Grad Norm: {'avg': 2.557007610797882, 'std': 1.1084972579138155}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -81.15861027766485, 'std': 27.318211059493294, 'run': -81.35238517707242, 'test_avg': -81.21070369367828, 'test_std': 7.367960655893524}
    Episode Length: {'avg': 20.6025, 'std': 5.7423421832907175, 'run': 20.70216820675919, 'test_avg': 20.533203125, 'test_std': 1.5820252218249349}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4001 / 10001):
    Value Loss: {'avg': 36.46232092380524, 'std': 3.6462886174776754}
    Value Grad Norm: {'avg': 589.3817660013834, 'std': 250.5292480474078}
    Policy Loss: {'avg': 0.001512338756583631, 'std': 0.003783359787521887}
    Total_Loss: {'avg': -0.1089852312579751, 'std': 0.0038839060385854325}
    Policy Entropy: {'avg': 1.1206543445587158, 'std': 0.5328888297080994}
    KL Divergence: {'avg': 0.023061204701662064, 'std': 0.21336525678634644}
    Policy Grad Norm: {'avg': 2.3328825905919075, 'std': 0.6385712701699475}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.23779518212505, 'std': 27.782693970581676, 'run': -75.83457795983418, 'test_avg': -81.60995235405932, 'test_std': 12.187108593492576}
    Episode Length: {'avg': 20.14004914004914, 'std': 5.819356246432451, 'run': 19.396384401833274, 'test_avg': 20.490234375, 'test_std': 2.3339173630547334}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9921875}

Iteration (4101 / 10001):
    Value Loss: {'avg': 34.84952731927236, 'std': 3.065850155386963}
    Value Grad Norm: {'avg': 856.2131878534952, 'std': 575.4025456404872}
    Policy Loss: {'avg': 0.001943975395988673, 'std': 0.004656856896561761}
    Total_Loss: {'avg': -0.10976928053423762, 'std': 0.004783678773922611}
    Policy Entropy: {'avg': 1.1173231601715088, 'std': 0.5663477778434753}
    KL Divergence: {'avg': 0.016279753297567368, 'std': 0.1530544012784958}
    Policy Grad Norm: {'avg': 2.5260051265358925, 'std': 0.797586661073744}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -81.10445126362657, 'std': 25.766806830978844, 'run': -81.98002573425778, 'test_avg': -81.46267951278344, 'test_std': 9.904301128508935}
    Episode Length: {'avg': 20.581683168316832, 'std': 5.350188405918582, 'run': 20.82191921830878, 'test_avg': 20.5703125, 'test_std': 1.9845441610968877}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (4201 / 10001):
    Value Loss: {'avg': 45.69444823265076, 'std': 4.4805764232274905}
    Value Grad Norm: {'avg': 839.6700849533081, 'std': 442.4693332973191}
    Policy Loss: {'avg': 0.0059392048278823495, 'std': 0.007403079752510134}
    Total_Loss: {'avg': -0.11078298091888428, 'std': 0.007179639949248915}
    Policy Entropy: {'avg': 1.1574957370758057, 'std': 0.5717160105705261}
    KL Divergence: {'avg': 0.016469232738018036, 'std': 0.16604042053222656}
    Policy Grad Norm: {'avg': 2.2654303833842278, 'std': 0.8082558388787826}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -83.7974918116051, 'std': 23.76309339633329, 'run': -83.63796172250551, 'test_avg': -81.45051625616772, 'test_std': 9.218365492845113}
    Episode Length: {'avg': 21.29242819843342, 'std': 5.041666609152885, 'run': 21.2407081862907, 'test_avg': 20.609375, 'test_std': 1.8951392387829977}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (4301 / 10001):
    Value Loss: {'avg': 36.45614790916443, 'std': 2.4401523411080626}
    Value Grad Norm: {'avg': 797.2664909362793, 'std': 442.0951509926338}
    Policy Loss: {'avg': 0.0024283156380988657, 'std': 0.0065724292908481}
    Total_Loss: {'avg': -0.10199802974238992, 'std': 0.006619271194690775}
    Policy Entropy: {'avg': 1.0674998760223389, 'std': 0.5487374663352966}
    KL Divergence: {'avg': 0.022109255194664, 'std': 0.20029953122138977}
    Policy Grad Norm: {'avg': 2.957062743604183, 'std': 1.6516137135357132}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.30870690808247, 'std': 25.51199727974908, 'run': -78.63356186536153, 'test_avg': -80.04296219483601, 'test_std': 7.320756165032663}
    Episode Length: {'avg': 20.223039215686274, 'std': 5.383959343656711, 'run': 20.101316100232243, 'test_avg': 20.21875, 'test_std': 1.5646859708900058}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 10001):
    Value Loss: {'avg': 42.37269457181295, 'std': 3.3715854245715686}
    Value Grad Norm: {'avg': 1433.0291659037273, 'std': 618.6642830097869}
    Policy Loss: {'avg': 0.0012868380290456116, 'std': 0.007099023315215098}
    Total_Loss: {'avg': -0.11756688635796309, 'std': 0.006774710164248855}
    Policy Entropy: {'avg': 1.2013850212097168, 'std': 0.5355172157287598}
    KL Divergence: {'avg': 0.023708093911409378, 'std': 0.18674275279045105}
    Policy Grad Norm: {'avg': 2.668533146381378, 'std': 1.1595995484722232}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.06199839038175, 'std': 25.603177895940448, 'run': -81.53158045287265, 'test_avg': -81.15088541654342, 'test_std': 7.379164995859043}
    Episode Length: {'avg': 20.899497487437184, 'std': 5.437627119636353, 'run': 20.767836570450168, 'test_avg': 20.5439453125, 'test_std': 1.6026170189753002}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4501 / 10001):
    Value Loss: {'avg': 39.600506703058876, 'std': 3.58837829780836}
    Value Grad Norm: {'avg': 852.0739816029867, 'std': 353.6847969973608}
    Policy Loss: {'avg': 0.002647464192705229, 'std': 0.0059695103274160525}
    Total_Loss: {'avg': -0.11520735919475555, 'std': 0.006953116128309951}
    Policy Entropy: {'avg': 1.1374166011810303, 'std': 0.5404483675956726}
    KL Divergence: {'avg': 0.018736032769083977, 'std': 0.18930767476558685}
    Policy Grad Norm: {'avg': 2.820044681429863, 'std': 1.1488624829902596}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.66867189496843, 'std': 25.803801487553063, 'run': -82.68424878395226, 'test_avg': -80.5129726212208, 'test_std': 8.138940988767395}
    Episode Length: {'avg': 20.997455470737915, 'std': 5.463037363992997, 'run': 21.02687515341898, 'test_avg': 20.4189453125, 'test_std': 1.7536993435689816}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4601 / 10001):
    Value Loss: {'avg': 47.67387048403422, 'std': 5.153792238680714}
    Value Grad Norm: {'avg': 1447.8924541473389, 'std': 618.9926938823634}
    Policy Loss: {'avg': 0.005003389436751604, 'std': 0.008159140141654617}
    Total_Loss: {'avg': -0.10681138141080737, 'std': 0.00782141345459483}
    Policy Entropy: {'avg': 1.0521340370178223, 'std': 0.5499839186668396}
    KL Divergence: {'avg': 0.02121732383966446, 'std': 0.19455969333648682}
    Policy Grad Norm: {'avg': 3.172235958278179, 'std': 1.5100622567868947}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.30015807417625, 'std': 26.650689330629206, 'run': -80.31622026626984, 'test_avg': -80.96105370448598, 'test_std': 10.643369187053711}
    Episode Length: {'avg': 20.49497487437186, 'std': 5.67625087485953, 'run': 20.489015138657706, 'test_avg': 20.3896484375, 'test_std': 2.171713184942664}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (4701 / 10001):
    Value Loss: {'avg': 31.095546921094257, 'std': 2.986012970217624}
    Value Grad Norm: {'avg': 517.9896144866943, 'std': 246.91858970640197}
    Policy Loss: {'avg': 0.005915683490457013, 'std': 0.007815341969182748}
    Total_Loss: {'avg': -0.10447302600368857, 'std': 0.008525420024128708}
    Policy Entropy: {'avg': 1.0966715812683105, 'std': 0.5180408954620361}
    KL Divergence: {'avg': 0.022203339263796806, 'std': 0.18013663589954376}
    Policy Grad Norm: {'avg': 2.7412416711449623, 'std': 1.339517275781193}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.55114060552945, 'std': 23.99449591367348, 'run': -80.4627980737062, 'test_avg': -80.52566453991585, 'test_std': 9.30640688121632}
    Episode Length: {'avg': 20.397560975609757, 'std': 5.021951219512196, 'run': 20.39495276170649, 'test_avg': 20.3369140625, 'test_std': 1.8282624543510557}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (4801 / 10001):
    Value Loss: {'avg': 32.92472000916799, 'std': 3.829329065400012}
    Value Grad Norm: {'avg': 714.8729836146036, 'std': 306.0447736489461}
    Policy Loss: {'avg': 0.00667057151440531, 'std': 0.008130453811549912}
    Total_Loss: {'avg': -0.1044460884295404, 'std': 0.008015289721732509}
    Policy Entropy: {'avg': 1.1642742156982422, 'std': 0.4906448721885681}
    KL Divergence: {'avg': 0.027179665863513947, 'std': 0.2047138512134552}
    Policy Grad Norm: {'avg': 2.5290184542536736, 'std': 0.7850978513072213}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.21873523870333, 'std': 26.163935167059318, 'run': -79.042357826771, 'test_avg': -84.20115066847899, 'test_std': 19.301988455722917}
    Episode Length: {'avg': 20.14074074074074, 'std': 5.5241283939669215, 'run': 20.07413384748572, 'test_avg': 20.982421875, 'test_std': 3.4823331452521145}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.974609375}

Iteration (4901 / 10001):
    Value Loss: {'avg': 33.13269706567129, 'std': 4.0073816347496765}
    Value Grad Norm: {'avg': 786.5174191792806, 'std': 471.4465220728023}
    Policy Loss: {'avg': 0.00266832928173244, 'std': 0.005891064577779783}
    Total_Loss: {'avg': -0.10148272849619389, 'std': 0.006281402653564505}
    Policy Entropy: {'avg': 1.08176851272583, 'std': 0.5390445590019226}
    KL Divergence: {'avg': 0.021337850019335747, 'std': 0.18812629580497742}
    Policy Grad Norm: {'avg': 2.165840059518814, 'std': 0.43354489306080973}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.44126885911122, 'std': 23.55353921196236, 'run': -78.47721537090646, 'test_avg': -81.04241198345264, 'test_std': 11.199935254885569}
    Episode Length: {'avg': 20.44110275689223, 'std': 5.023844376347841, 'run': 20.00556716805948, 'test_avg': 20.4501953125, 'test_std': 2.1730459884924267}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (5001 / 10001):
    Value Loss: {'avg': 30.515323479970295, 'std': 2.495126648080278}
    Value Grad Norm: {'avg': 604.6719462076823, 'std': 255.21943014524985}
    Policy Loss: {'avg': 0.003968736331444234, 'std': 0.006493171756502205}
    Total_Loss: {'avg': -0.10742525849491358, 'std': 0.006303099687401317}
    Policy Entropy: {'avg': 1.1100554466247559, 'std': 0.537735104560852}
    KL Divergence: {'avg': 0.02352619543671608, 'std': 0.20504707098007202}
    Policy Grad Norm: {'avg': 2.1699707582592964, 'std': 0.48253092994321073}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.4880474777364, 'std': 29.37030847510594, 'run': -77.54444056379782, 'test_avg': -80.98358387454493, 'test_std': 11.147177177248622}
    Episode Length: {'avg': 19.65509259259259, 'std': 6.1511834145011495, 'run': 19.81589488729619, 'test_avg': 20.4677734375, 'test_std': 2.154423257781403}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (5101 / 10001):
    Value Loss: {'avg': 31.991740028063457, 'std': 3.1004758292142767}
    Value Grad Norm: {'avg': 557.3212407430013, 'std': 267.5443467880612}
    Policy Loss: {'avg': 0.002807466735248454, 'std': 0.008147707194094777}
    Total_Loss: {'avg': -0.10718332650139928, 'std': 0.006692622307165468}
    Policy Entropy: {'avg': 1.143813967704773, 'std': 0.5148832201957703}
    KL Divergence: {'avg': 0.02069171704351902, 'std': 0.19157083332538605}
    Policy Grad Norm: {'avg': 2.2113630026578903, 'std': 0.5707239984851227}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.71820542182925, 'std': 26.742705648619943, 'run': -80.65816136999467, 'test_avg': -79.72219827682393, 'test_std': 7.2928329466366835}
    Episode Length: {'avg': 20.098522167487683, 'std': 5.659914165239875, 'run': 20.519799241105638, 'test_avg': 20.2197265625, 'test_std': 1.5760541869592979}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5201 / 10001):
    Value Loss: {'avg': 32.15357712904612, 'std': 2.4299091449807873}
    Value Grad Norm: {'avg': 714.540781656901, 'std': 280.865748369117}
    Policy Loss: {'avg': -0.002597827697172761, 'std': 0.004632074994239119}
    Total_Loss: {'avg': -0.10858587687835097, 'std': 0.004776078226110374}
    Policy Entropy: {'avg': 1.0600727796554565, 'std': 0.5717342495918274}
    KL Divergence: {'avg': 0.02157551608979702, 'std': 0.20663957297801971}
    Policy Grad Norm: {'avg': 2.5254084914922714, 'std': 0.9046331115054876}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.70997117549933, 'std': 27.633249585940142, 'run': -76.92769804135241, 'test_avg': -80.22264771499525, 'test_std': 8.493070675019576}
    Episode Length: {'avg': 19.899761336515514, 'std': 5.823126876998071, 'run': 19.727082825839393, 'test_avg': 20.3671875, 'test_std': 1.771612497089516}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (5301 / 10001):
    Value Loss: {'avg': 31.74887192249298, 'std': 4.310809343805731}
    Value Grad Norm: {'avg': 872.0917065938314, 'std': 550.7834658992779}
    Policy Loss: {'avg': 0.0040479027084074914, 'std': 0.005293516681623101}
    Total_Loss: {'avg': -0.104015760589391, 'std': 0.004838510078191446}
    Policy Entropy: {'avg': 1.1029889583587646, 'std': 0.4929620325565338}
    KL Divergence: {'avg': 0.022572610527276993, 'std': 0.17861473560333252}
    Policy Grad Norm: {'avg': 2.492854095995426, 'std': 0.947564550051025}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.6884816353375, 'std': 25.609865989480404, 'run': -77.24575651457693, 'test_avg': -79.56850998942292, 'test_std': 7.082777624266943}
    Episode Length: {'avg': 20.055825242718445, 'std': 5.361612028324637, 'run': 19.71287358786611, 'test_avg': 20.1767578125, 'test_std': 1.5255015939749834}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5401 / 10001):
    Value Loss: {'avg': 34.75555340449015, 'std': 2.7315313565849584}
    Value Grad Norm: {'avg': 578.5877323150635, 'std': 228.01125683254764}
    Policy Loss: {'avg': 0.0051101690623909235, 'std': 0.005634675057702795}
    Total_Loss: {'avg': -0.10383466025814414, 'std': 0.0055262593571455305}
    Policy Entropy: {'avg': 1.0157649517059326, 'std': 0.5475813746452332}
    KL Divergence: {'avg': 0.02287021093070507, 'std': 0.2033008337020874}
    Policy Grad Norm: {'avg': 2.929732784628868, 'std': 0.5368634908683901}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.70860703478375, 'std': 28.189061522645968, 'run': -75.34351632220952, 'test_avg': -79.4796426589578, 'test_std': 8.30065083104666}
    Episode Length: {'avg': 19.66826923076923, 'std': 5.961862196544945, 'run': 19.352870819667714, 'test_avg': 20.1728515625, 'test_std': 1.7321650541565918}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5501 / 10001):
    Value Loss: {'avg': 31.815643151601154, 'std': 3.170531463414558}
    Value Grad Norm: {'avg': 801.4394903182983, 'std': 451.3701805090272}
    Policy Loss: {'avg': 0.004688606888521463, 'std': 0.0051041061400013575}
    Total_Loss: {'avg': -0.10602795705199242, 'std': 0.005853391852645233}
    Policy Entropy: {'avg': 1.0914771556854248, 'std': 0.5344493985176086}
    KL Divergence: {'avg': 0.01835654303431511, 'std': 0.17051616311073303}
    Policy Grad Norm: {'avg': 2.286537528038025, 'std': 0.37967117333517825}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.85574908323176, 'std': 26.328914861374592, 'run': -80.19603545926832, 'test_avg': -79.95652540821817, 'test_std': 8.234895569615768}
    Episode Length: {'avg': 19.869249394673123, 'std': 5.47389567119782, 'run': 20.34485580848134, 'test_avg': 20.2666015625, 'test_std': 1.789241332065789}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (5601 / 10001):
    Value Loss: {'avg': 30.577356417973835, 'std': 2.5512698349178513}
    Value Grad Norm: {'avg': 456.80976072947186, 'std': 145.97554907102264}
    Policy Loss: {'avg': 0.003610310086514801, 'std': 0.00712857157808347}
    Total_Loss: {'avg': -0.10186128970235586, 'std': 0.006514525514578402}
    Policy Entropy: {'avg': 1.100578784942627, 'std': 0.5137148499488831}
    KL Divergence: {'avg': 0.020571254193782806, 'std': 0.18074776232242584}
    Policy Grad Norm: {'avg': 2.700336791574955, 'std': 1.0036392508865335}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.47968719236158, 'std': 24.105379383301166, 'run': -77.67100180939588, 'test_avg': -79.6901123359803, 'test_std': 7.303261116804653}
    Episode Length: {'avg': 20.03911980440098, 'std': 5.064226634076997, 'run': 19.85723102123453, 'test_avg': 20.2314453125, 'test_std': 1.5725139919319564}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5701 / 10001):
    Value Loss: {'avg': 30.414716800053913, 'std': 2.9439913909477253}
    Value Grad Norm: {'avg': 774.147996266683, 'std': 304.1936407150065}
    Policy Loss: {'avg': 0.004094667907338589, 'std': 0.006434603678446238}
    Total_Loss: {'avg': -0.09696702379733324, 'std': 0.0062557112955450005}
    Policy Entropy: {'avg': 1.05579674243927, 'std': 0.5470982789993286}
    KL Divergence: {'avg': 0.01938704028725624, 'std': 0.17521116137504578}
    Policy Grad Norm: {'avg': 2.7650233060121536, 'std': 1.4316814886419775}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.28076293400566, 'std': 24.918133210638626, 'run': -77.76398290430704, 'test_avg': -79.73440009969647, 'test_std': 8.20427825511897}
    Episode Length: {'avg': 20.03667481662592, 'std': 5.260093307935915, 'run': 19.912402744875653, 'test_avg': 20.265625, 'test_std': 1.7149816644428009}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5801 / 10001):
    Value Loss: {'avg': 33.58685771624247, 'std': 2.7911284097923383}
    Value Grad Norm: {'avg': 474.52206802368164, 'std': 152.74427111826512}
    Policy Loss: {'avg': 0.00544239382725209, 'std': 0.004978581893330775}
    Total_Loss: {'avg': -0.1048721456900239, 'std': 0.004911184881671731}
    Policy Entropy: {'avg': 1.0760661363601685, 'std': 0.5348625183105469}
    KL Divergence: {'avg': 0.015549766831099987, 'std': 0.1555156260728836}
    Policy Grad Norm: {'avg': 2.95546405762434, 'std': 1.0685201189556062}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.7658768675837, 'std': 24.289662471677698, 'run': -78.85300565272897, 'test_avg': -79.93352581159638, 'test_std': 10.540212124697877}
    Episode Length: {'avg': 20.281795511221944, 'std': 5.112001698421874, 'run': 20.065060715596303, 'test_avg': 20.2392578125, 'test_std': 2.058324807132663}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (5901 / 10001):
    Value Loss: {'avg': 33.08007021745046, 'std': 3.326219940876255}
    Value Grad Norm: {'avg': 657.782054901123, 'std': 301.1732842258247}
    Policy Loss: {'avg': 0.0001730098738335073, 'std': 0.010287631065481258}
    Total_Loss: {'avg': -0.10798740317113698, 'std': 0.010380669449089755}
    Policy Entropy: {'avg': 1.0856983661651611, 'std': 0.534135103225708}
    KL Divergence: {'avg': 0.023440612480044365, 'std': 0.18768846988677979}
    Policy Grad Norm: {'avg': 3.6992344111204147, 'std': 2.051391488393784}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -78.92255377180211, 'std': 24.6513017693049, 'run': -80.16412065767636, 'test_avg': -79.52338928639776, 'test_std': 7.922596428675218}
    Episode Length: {'avg': 20.051724137931036, 'std': 5.21269617960283, 'run': 20.33086423009334, 'test_avg': 20.1767578125, 'test_std': 1.6473839452963643}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6001 / 10001):
    Value Loss: {'avg': 28.479529062906902, 'std': 2.794251533411022}
    Value Grad Norm: {'avg': 607.5997460683187, 'std': 291.1877745356136}
    Policy Loss: {'avg': 0.010719771031290293, 'std': 0.011319133935211289}
    Total_Loss: {'avg': -0.08918810542672873, 'std': 0.010157488991022362}
    Policy Entropy: {'avg': 1.0297163724899292, 'std': 0.5216233134269714}
    KL Divergence: {'avg': 0.02612164244055748, 'std': 0.19513118267059326}
    Policy Grad Norm: {'avg': 3.1000236123800278, 'std': 1.313659762344849}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.72821157358564, 'std': 24.431156432959316, 'run': -76.56018404443084, 'test_avg': -79.89637316058896, 'test_std': 7.585896636047603}
    Episode Length: {'avg': 19.70952380952381, 'std': 5.146557310882199, 'run': 19.673536445554745, 'test_avg': 20.2626953125, 'test_std': 1.6400549488631555}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6101 / 10001):
    Value Loss: {'avg': 28.510620792706806, 'std': 2.6573577260602446}
    Value Grad Norm: {'avg': 574.0045394897461, 'std': 240.22959491125613}
    Policy Loss: {'avg': 0.00209684856235981, 'std': 0.004817729246776464}
    Total_Loss: {'avg': -0.09930645674467087, 'std': 0.005094850558308327}
    Policy Entropy: {'avg': 1.010512351989746, 'std': 0.5594962239265442}
    KL Divergence: {'avg': 0.026817120611667633, 'std': 0.23392552137374878}
    Policy Grad Norm: {'avg': 2.5611071959137917, 'std': 0.6500997762402351}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.92489573097994, 'std': 26.415587225938484, 'run': -74.68613417631532, 'test_avg': -79.07958984839257, 'test_std': 7.206864160711041}
    Episode Length: {'avg': 19.686131386861312, 'std': 5.525545838194458, 'run': 19.26986048589902, 'test_avg': 20.0556640625, 'test_std': 1.5308759582820537}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6201 / 10001):
    Value Loss: {'avg': 29.98669703801473, 'std': 2.6529915719119965}
    Value Grad Norm: {'avg': 593.5784317652384, 'std': 301.22158477062635}
    Policy Loss: {'avg': 0.008283589442726225, 'std': 0.00831193755894546}
    Total_Loss: {'avg': -0.09523440478369594, 'std': 0.007583206880210454}
    Policy Entropy: {'avg': 1.0787975788116455, 'std': 0.5369589328765869}
    KL Divergence: {'avg': 0.021942507475614548, 'std': 0.20045380294322968}
    Policy Grad Norm: {'avg': 3.3538937643170357, 'std': 1.6622642493316122}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.21955360218769, 'std': 26.452583475774944, 'run': -77.85502681040134, 'test_avg': -79.57148743406029, 'test_std': 7.725982741094457}
    Episode Length: {'avg': 19.767386091127097, 'std': 5.5495233772138475, 'run': 19.96277554561616, 'test_avg': 20.185546875, 'test_std': 1.6149769293020053}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6301 / 10001):
    Value Loss: {'avg': 27.664727330207825, 'std': 2.106744511195311}
    Value Grad Norm: {'avg': 493.432575861613, 'std': 194.3366242901295}
    Policy Loss: {'avg': 0.008862490474712104, 'std': 0.007337811707105645}
    Total_Loss: {'avg': -0.09441730659455061, 'std': 0.00819047595800998}
    Policy Entropy: {'avg': 1.0129151344299316, 'std': 0.592277467250824}
    KL Divergence: {'avg': 0.022721488028764725, 'std': 0.19161555171012878}
    Policy Grad Norm: {'avg': 2.899953819811344, 'std': 1.3198510867201596}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.71279547833737, 'std': 25.195183441518438, 'run': -76.39232002919637, 'test_avg': -79.46119126931887, 'test_std': 7.232836950795563}
    Episode Length: {'avg': 19.693236714975846, 'std': 5.306099184664059, 'run': 19.600624137587154, 'test_avg': 20.17578125, 'test_std': 1.5763013519465234}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6401 / 10001):
    Value Loss: {'avg': 30.032125274340313, 'std': 3.906688078892612}
    Value Grad Norm: {'avg': 614.9974737167358, 'std': 267.3161044321165}
    Policy Loss: {'avg': 0.008469358552247286, 'std': 0.008832063024444213}
    Total_Loss: {'avg': -0.09835417987778783, 'std': 0.010230348842229243}
    Policy Entropy: {'avg': 1.1109007596969604, 'std': 0.5456721782684326}
    KL Divergence: {'avg': 0.01951216533780098, 'std': 0.18814128637313843}
    Policy Grad Norm: {'avg': 2.796734631061554, 'std': 1.3630896598906257}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.26768034913144, 'std': 24.508817918269223, 'run': -80.1046155023578, 'test_avg': -79.86334546705646, 'test_std': 10.008133156392255}
    Episode Length: {'avg': 20.175182481751825, 'std': 5.1896834920563615, 'run': 20.354054576986066, 'test_avg': 20.208984375, 'test_std': 1.9518814400485136}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (6501 / 10001):
    Value Loss: {'avg': 30.182144045829773, 'std': 2.54274414376296}
    Value Grad Norm: {'avg': 790.0604337056478, 'std': 405.94516907621573}
    Policy Loss: {'avg': 0.005612878070678562, 'std': 0.0062885556371371065}
    Total_Loss: {'avg': -0.0997734540142119, 'std': 0.006013690974847831}
    Policy Entropy: {'avg': 1.0210237503051758, 'std': 0.5329042673110962}
    KL Divergence: {'avg': 0.017720624804496765, 'std': 0.1871083527803421}
    Policy Grad Norm: {'avg': 2.799595892429352, 'std': 0.9267324145821052}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.62481598964432, 'std': 23.081407532468585, 'run': -80.68957364380519, 'test_avg': -79.65034028928866, 'test_std': 8.834809058081648}
    Episode Length: {'avg': 20.228643216080403, 'std': 4.851615662956717, 'run': 20.42891129015699, 'test_avg': 20.1650390625, 'test_std': 1.837943292201672}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (6601 / 10001):
    Value Loss: {'avg': 37.05213983853658, 'std': 3.4484489001635787}
    Value Grad Norm: {'avg': 551.8505249023438, 'std': 203.55800985657288}
    Policy Loss: {'avg': 0.00415015165344812, 'std': 0.008157948419591174}
    Total_Loss: {'avg': -0.10564528731629252, 'std': 0.007543904506668325}
    Policy Entropy: {'avg': 1.1455990076065063, 'std': 0.5230074524879456}
    KL Divergence: {'avg': 0.015418285503983498, 'std': 0.15682180225849152}
    Policy Grad Norm: {'avg': 2.842454545199871, 'std': 0.8347465537472941}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.7377096341916, 'std': 28.115793694631368, 'run': -78.71182490008005, 'test_avg': -79.5921240527199, 'test_std': 8.723720510601726}
    Episode Length: {'avg': 19.885085574572127, 'std': 5.917443242493274, 'run': 20.077705310387504, 'test_avg': 20.1767578125, 'test_std': 1.8272585649601467}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6701 / 10001):
    Value Loss: {'avg': 29.108925819396973, 'std': 2.9155376607700867}
    Value Grad Norm: {'avg': 558.5362310409546, 'std': 237.0799136856392}
    Policy Loss: {'avg': 0.004071085510076955, 'std': 0.006095724900416998}
    Total_Loss: {'avg': -0.10156376892700791, 'std': 0.006344085186895551}
    Policy Entropy: {'avg': 1.0733280181884766, 'std': 0.5142890214920044}
    KL Divergence: {'avg': 0.02047378569841385, 'std': 0.1633368283510208}
    Policy Grad Norm: {'avg': 2.6700512915849686, 'std': 0.825885154354764}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.56215573687552, 'std': 25.346547326270414, 'run': -77.6193113274144, 'test_avg': -79.16176333362543, 'test_std': 7.688559042207813}
    Episode Length: {'avg': 19.949397590361446, 'std': 5.353061808109447, 'run': 20.0061380972747, 'test_avg': 20.078125, 'test_std': 1.6535207465813666}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6801 / 10001):
    Value Loss: {'avg': 30.609644214312237, 'std': 3.155989482867936}
    Value Grad Norm: {'avg': 594.517833073934, 'std': 232.27450817874785}
    Policy Loss: {'avg': 0.004016594844870269, 'std': 0.0036469095579532563}
    Total_Loss: {'avg': -0.10338069079443812, 'std': 0.004153733883644764}
    Policy Entropy: {'avg': 0.9927800893783569, 'std': 0.5613825917243958}
    KL Divergence: {'avg': 0.020208172500133514, 'std': 0.195001021027565}
    Policy Grad Norm: {'avg': 2.5367239490151405, 'std': 0.8423476289508841}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.12317989972313, 'std': 28.81798581256817, 'run': -75.13405644266167, 'test_avg': -78.50305319003576, 'test_std': 7.539834565003234}
    Episode Length: {'avg': 19.32867132867133, 'std': 6.0291941930009925, 'run': 19.33054917355719, 'test_avg': 19.943359375, 'test_std': 1.6131523764355336}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6901 / 10001):
    Value Loss: {'avg': 27.18109409014384, 'std': 2.6970053970698036}
    Value Grad Norm: {'avg': 644.4568436940511, 'std': 360.6117969547625}
    Policy Loss: {'avg': -0.0029109447496011853, 'std': 0.008623094704014752}
    Total_Loss: {'avg': -0.10586644010618329, 'std': 0.010590299814113894}
    Policy Entropy: {'avg': 1.060745358467102, 'std': 0.509355902671814}
    KL Divergence: {'avg': 0.02677411586046219, 'std': 0.2224549502134323}
    Policy Grad Norm: {'avg': 2.255168791860342, 'std': 0.5258307469969625}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -76.14908756568614, 'std': 26.662175582670525, 'run': -74.58747384437662, 'test_avg': -78.76969908986894, 'test_std': 7.156974580882695}
    Episode Length: {'avg': 19.58432304038005, 'std': 5.657327985334566, 'run': 19.267336646203418, 'test_avg': 20.0478515625, 'test_std': 1.532415141358995}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7001 / 10001):
    Value Loss: {'avg': 23.683202425638836, 'std': 1.8373198780103517}
    Value Grad Norm: {'avg': 450.58181285858154, 'std': 161.24787065246795}
    Policy Loss: {'avg': 0.003929657832486555, 'std': 0.006232162214759596}
    Total_Loss: {'avg': -0.08948799734935164, 'std': 0.007164262316248964}
    Policy Entropy: {'avg': 0.9744646549224854, 'std': 0.5466769337654114}
    KL Divergence: {'avg': 0.023983974009752274, 'std': 0.2077968865633011}
    Policy Grad Norm: {'avg': 2.7254694998264313, 'std': 0.6827338259651121}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.0691021854547, 'std': 24.07240416026129, 'run': -75.14033129987665, 'test_avg': -79.30726367749003, 'test_std': 10.207674242935441}
    Episode Length: {'avg': 19.5, 'std': 5.059100474160945, 'run': 19.324165152208387, 'test_avg': 20.0498046875, 'test_std': 1.9735704777390208}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (7101 / 10001):
    Value Loss: {'avg': 29.622726996739704, 'std': 2.5659558510767484}
    Value Grad Norm: {'avg': 638.9413057963053, 'std': 347.1363982932206}
    Policy Loss: {'avg': 0.0060113476938568056, 'std': 0.009372775730048818}
    Total_Loss: {'avg': -0.10096141323447227, 'std': 0.007184546265336962}
    Policy Entropy: {'avg': 1.1221641302108765, 'std': 0.518071711063385}
    KL Divergence: {'avg': 0.020467408001422882, 'std': 0.179607555270195}
    Policy Grad Norm: {'avg': 2.4993889704346657, 'std': 0.6485561409852314}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.56640556043767, 'std': 22.698408705884745, 'run': -82.2233424234823, 'test_avg': -79.32847772892968, 'test_std': 10.316269941507754}
    Episode Length: {'avg': 20.24317617866005, 'std': 4.819874264623244, 'run': 20.765105582186695, 'test_avg': 20.1171875, 'test_std': 2.013610306102884}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (7201 / 10001):
    Value Loss: {'avg': 28.95705791314443, 'std': 2.4474476903123215}
    Value Grad Norm: {'avg': 529.4394776026407, 'std': 200.36931140806757}
    Policy Loss: {'avg': 0.002543405396863818, 'std': 0.005417575570543048}
    Total_Loss: {'avg': -0.10160294827073812, 'std': 0.005977075429056114}
    Policy Entropy: {'avg': 1.047702670097351, 'std': 0.5145739316940308}
    KL Divergence: {'avg': 0.023755718022584915, 'std': 0.1779012382030487}
    Policy Grad Norm: {'avg': 2.9971689358353615, 'std': 1.2074480108173071}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.330222291839, 'std': 23.05108078972249, 'run': -81.76124050556429, 'test_avg': -78.78030988299255, 'test_std': 7.911764162356773}
    Episode Length: {'avg': 20.193467336683415, 'std': 4.83291245021526, 'run': 20.663805953689632, 'test_avg': 19.970703125, 'test_std': 1.6150903049412544}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7301 / 10001):
    Value Loss: {'avg': 29.827816486358643, 'std': 2.543321624731609}
    Value Grad Norm: {'avg': 425.2206554412842, 'std': 146.81402890857242}
    Policy Loss: {'avg': 0.0029798360192216933, 'std': 0.006232258424478525}
    Total_Loss: {'avg': -0.09994946606457233, 'std': 0.007370460850460389}
    Policy Entropy: {'avg': 1.0178725719451904, 'std': 0.5078957676887512}
    KL Divergence: {'avg': 0.016439056023955345, 'std': 0.17988409101963043}
    Policy Grad Norm: {'avg': 3.3016005530953407, 'std': 1.787564619475196}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.47302490931702, 'std': 23.759574050803288, 'run': -78.64275832745402, 'test_avg': -79.04171377698037, 'test_std': 8.73577917545372}
    Episode Length: {'avg': 20.03667481662592, 'std': 5.030092786612691, 'run': 20.043320179032392, 'test_avg': 20.033203125, 'test_std': 1.817576697828797}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (7401 / 10001):
    Value Loss: {'avg': 25.493866364161175, 'std': 1.9953251915748689}
    Value Grad Norm: {'avg': 567.2131284077963, 'std': 232.96790605769812}
    Policy Loss: {'avg': 0.0028407913632690907, 'std': 0.006611283558395225}
    Total_Loss: {'avg': -0.09768102131783962, 'std': 0.007883082827088318}
    Policy Entropy: {'avg': 1.0372486114501953, 'std': 0.5195990800857544}
    KL Divergence: {'avg': 0.019845731556415558, 'std': 0.18441987037658691}
    Policy Grad Norm: {'avg': 3.124607130885124, 'std': 1.3442966317972134}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.67258553232263, 'std': 23.777815412333982, 'run': -76.90255811559595, 'test_avg': -78.16907914431295, 'test_std': 7.750376524061805}
    Episode Length: {'avg': 19.776412776412776, 'std': 4.9949983737183095, 'run': 19.64062761843505, 'test_avg': 19.8837890625, 'test_std': 1.6444660092277283}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7501 / 10001):
    Value Loss: {'avg': 24.209858616193134, 'std': 2.041943683767649}
    Value Grad Norm: {'avg': 526.5894533793131, 'std': 188.77082752027516}
    Policy Loss: {'avg': 0.0059753136010840535, 'std': 0.005891357301078142}
    Total_Loss: {'avg': -0.09404506767168641, 'std': 0.00501051631139973}
    Policy Entropy: {'avg': 1.0136539936065674, 'std': 0.5647789239883423}
    KL Divergence: {'avg': 0.025316739454865456, 'std': 0.18559758365154266}
    Policy Grad Norm: {'avg': 2.614738442003727, 'std': 0.7224353180149391}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.72558536022552, 'std': 23.609420412494305, 'run': -75.4060012028095, 'test_avg': -77.80216830833496, 'test_std': 7.028262672310445}
    Episode Length: {'avg': 19.522673031026255, 'std': 5.0653332064274545, 'run': 19.435007468636535, 'test_avg': 19.8271484375, 'test_std': 1.4942615734339515}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7601 / 10001):
    Value Loss: {'avg': 27.159963965415955, 'std': 2.6215161527567874}
    Value Grad Norm: {'avg': 425.4940118789673, 'std': 125.44571624145621}
    Policy Loss: {'avg': -0.002968551212688908, 'std': 0.008260286044088199}
    Total_Loss: {'avg': -0.11004066746681929, 'std': 0.009057810931649913}
    Policy Entropy: {'avg': 1.0434821844100952, 'std': 0.5302407741546631}
    KL Divergence: {'avg': 0.03045700304210186, 'std': 0.20576557517051697}
    Policy Grad Norm: {'avg': 2.8719084188342094, 'std': 1.017417145177519}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -77.88945417117733, 'std': 24.412791756416997, 'run': -76.66762078098512, 'test_avg': -78.5053615903555, 'test_std': 6.633859174432786}
    Episode Length: {'avg': 19.8705035971223, 'std': 5.147001453954859, 'run': 19.59705454948724, 'test_avg': 19.951171875, 'test_std': 1.4188871745875302}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7701 / 10001):
    Value Loss: {'avg': 28.66109045346578, 'std': 2.7078456797093438}
    Value Grad Norm: {'avg': 610.1244796117147, 'std': 253.25996825110096}
    Policy Loss: {'avg': 0.0020109082688577473, 'std': 0.006515350886939986}
    Total_Loss: {'avg': -0.10445626312866807, 'std': 0.008086413662720882}
    Policy Entropy: {'avg': 1.082831859588623, 'std': 0.5263490676879883}
    KL Divergence: {'avg': 0.020229481160640717, 'std': 0.1852688044309616}
    Policy Grad Norm: {'avg': 2.7801605463027954, 'std': 1.3108166724263677}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.63488155954805, 'std': 25.00868978137782, 'run': -78.32037630531674, 'test_avg': -78.17971284572428, 'test_std': 6.6371830382211945}
    Episode Length: {'avg': 20.004926108374384, 'std': 5.233933931891672, 'run': 19.89760978407453, 'test_avg': 19.8759765625, 'test_std': 1.4091113332347744}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7801 / 10001):
    Value Loss: {'avg': 28.507423202196758, 'std': 2.530813476457858}
    Value Grad Norm: {'avg': 678.5115292867025, 'std': 265.167842035409}
    Policy Loss: {'avg': 0.0031542577198706567, 'std': 0.007235215813634643}
    Total_Loss: {'avg': -0.10465320199728012, 'std': 0.0072340262476544}
    Policy Entropy: {'avg': 1.1010892391204834, 'std': 0.5082116723060608}
    KL Divergence: {'avg': 0.017555613070726395, 'std': 0.17514967918395996}
    Policy Grad Norm: {'avg': 2.399647146463394, 'std': 0.8744897088979334}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.65261392689956, 'std': 24.451133551423503, 'run': -78.53202827236633, 'test_avg': -79.14552826208137, 'test_std': 6.9828254952294255}
    Episode Length: {'avg': 19.935323383084576, 'std': 5.187124896936491, 'run': 20.069555697146022, 'test_avg': 20.0888671875, 'test_std': 1.5196991266319264}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7901 / 10001):
    Value Loss: {'avg': 30.882009029388428, 'std': 2.629304839961706}
    Value Grad Norm: {'avg': 514.8544969558716, 'std': 187.2531664856614}
    Policy Loss: {'avg': -0.00027697047335095704, 'std': 0.0052825488285699095}
    Total_Loss: {'avg': -0.10832838155329227, 'std': 0.006777470195005893}
    Policy Entropy: {'avg': 1.0448033809661865, 'std': 0.5264189839363098}
    KL Divergence: {'avg': 0.017384763807058334, 'std': 0.2422764152288437}
    Policy Grad Norm: {'avg': 2.535409688949585, 'std': 0.6071473691315152}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.9695233052444, 'std': 25.294621925012603, 'run': -78.99833134383233, 'test_avg': -78.52433141586636, 'test_std': 6.9412348058896525}
    Episode Length: {'avg': 20.411910669975185, 'std': 5.375623416736985, 'run': 20.175963732475367, 'test_avg': 19.9951171875, 'test_std': 1.4813210643348356}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8001 / 10001):
    Value Loss: {'avg': 31.345836003621418, 'std': 2.6735062896791564}
    Value Grad Norm: {'avg': 498.7210480372111, 'std': 191.89344645178565}
    Policy Loss: {'avg': 0.006853182829217985, 'std': 0.009999489489059845}
    Total_Loss: {'avg': -0.10529316123574972, 'std': 0.009887317052296224}
    Policy Entropy: {'avg': 1.1139461994171143, 'std': 0.520837128162384}
    KL Divergence: {'avg': 0.02938351221382618, 'std': 0.23684774339199066}
    Policy Grad Norm: {'avg': 3.1998610347509384, 'std': 1.8973708662843036}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.73134122320225, 'std': 22.928924161188874, 'run': -79.36893663717393, 'test_avg': -79.39621925873627, 'test_std': 10.015254187219892}
    Episode Length: {'avg': 20.351620947630924, 'std': 4.833234241465843, 'run': 20.31873601697871, 'test_avg': 20.130859375, 'test_std': 2.1038619724151606}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (8101 / 10001):
    Value Loss: {'avg': 25.49923284848531, 'std': 2.598718178778766}
    Value Grad Norm: {'avg': 545.5570112864176, 'std': 202.87674538307874}
    Policy Loss: {'avg': 0.005612923298031092, 'std': 0.007023547740426053}
    Total_Loss: {'avg': -0.09621932823210955, 'std': 0.007749892242074814}
    Policy Entropy: {'avg': 1.0155212879180908, 'std': 0.4952857792377472}
    KL Divergence: {'avg': 0.021188810467720032, 'std': 0.17494255304336548}
    Policy Grad Norm: {'avg': 2.6709468364715576, 'std': 0.8881788181272002}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.74709873410576, 'std': 23.616514980497485, 'run': -77.41023038698316, 'test_avg': -77.8131148251905, 'test_std': 6.660490402447871}
    Episode Length: {'avg': 19.636363636363637, 'std': 4.983400021278125, 'run': 19.765010054652887, 'test_avg': 19.8291015625, 'test_std': 1.3817634698312367}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8201 / 10001):
    Value Loss: {'avg': 24.54393442471822, 'std': 2.411240017457638}
    Value Grad Norm: {'avg': 560.2859907150269, 'std': 259.34272074378254}
    Policy Loss: {'avg': -0.004011543787783012, 'std': 0.008310973602732892}
    Total_Loss: {'avg': -0.10792457452043891, 'std': 0.008418391790256313}
    Policy Entropy: {'avg': 1.0689679384231567, 'std': 0.49488815665245056}
    KL Divergence: {'avg': 0.01685483381152153, 'std': 0.15981754660606384}
    Policy Grad Norm: {'avg': 2.520727500319481, 'std': 1.078724896698776}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -77.73488460478285, 'std': 23.881953034269554, 'run': -79.1073910369724, 'test_avg': -77.64313843774255, 'test_std': 6.659234451905177}
    Episode Length: {'avg': 19.893564356435643, 'std': 5.043970831677036, 'run': 20.193338698463872, 'test_avg': 19.826171875, 'test_std': 1.4392172466167101}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8301 / 10001):
    Value Loss: {'avg': 29.107069333394367, 'std': 2.58266872852191}
    Value Grad Norm: {'avg': 452.95107491811115, 'std': 131.85940482158537}
    Policy Loss: {'avg': -0.003676710242871195, 'std': 0.00832748385582811}
    Total_Loss: {'avg': -0.10974672879092395, 'std': 0.009295121015006744}
    Policy Entropy: {'avg': 1.032118320465088, 'std': 0.5141828656196594}
    KL Divergence: {'avg': 0.023004872724413872, 'std': 0.20130153000354767}
    Policy Grad Norm: {'avg': 2.758191507309675, 'std': 1.0667489794976839}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -79.01424519173868, 'std': 23.357490805359795, 'run': -77.43430019795193, 'test_avg': -78.39094815210768, 'test_std': 6.705057433968162}
    Episode Length: {'avg': 20.16256157635468, 'std': 4.948819567654839, 'run': 19.805255327950935, 'test_avg': 19.9267578125, 'test_std': 1.4325685915411572}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8401 / 10001):
    Value Loss: {'avg': 26.71183915932973, 'std': 2.3674871189066318}
    Value Grad Norm: {'avg': 462.0927273432414, 'std': 189.7620227984786}
    Policy Loss: {'avg': -0.0029060099477646872, 'std': 0.008514546179103763}
    Total_Loss: {'avg': -0.10236419574357569, 'std': 0.00943018047764758}
    Policy Entropy: {'avg': 1.0059454441070557, 'std': 0.5247792601585388}
    KL Divergence: {'avg': 0.026119545102119446, 'std': 0.2053794115781784}
    Policy Grad Norm: {'avg': 3.011093243956566, 'std': 1.281751526365051}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -75.77810261952067, 'std': 25.892288974690608, 'run': -73.91640129442652, 'test_avg': -79.05272462699065, 'test_std': 9.060460092420044}
    Episode Length: {'avg': 19.477326968973745, 'std': 5.467311103909651, 'run': 19.06581877143267, 'test_avg': 20.03125, 'test_std': 1.8068338156842205}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (8501 / 10001):
    Value Loss: {'avg': 23.86432405312856, 'std': 3.3167143567497295}
    Value Grad Norm: {'avg': 499.7821219762166, 'std': 176.70716836532887}
    Policy Loss: {'avg': 0.0034352109069004655, 'std': 0.009131011038248754}
    Total_Loss: {'avg': -0.0940339514054358, 'std': 0.009070684111943797}
    Policy Entropy: {'avg': 0.957931637763977, 'std': 0.5568814277648926}
    KL Divergence: {'avg': 0.02498764544725418, 'std': 0.2217385321855545}
    Policy Grad Norm: {'avg': 3.823123574256897, 'std': 3.6289500247392037}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.05421776739398, 'std': 26.2189610080274, 'run': -75.0016447423966, 'test_avg': -78.11016879503234, 'test_std': 7.424402270299642}
    Episode Length: {'avg': 19.36150234741784, 'std': 5.532729894940659, 'run': 19.34808931809142, 'test_avg': 19.892578125, 'test_std': 1.5768663278069845}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8601 / 10001):
    Value Loss: {'avg': 24.92935037612915, 'std': 2.0302195344326868}
    Value Grad Norm: {'avg': 475.10014088948566, 'std': 169.49970157009182}
    Policy Loss: {'avg': 0.005890558415558189, 'std': 0.005237135104106269}
    Total_Loss: {'avg': -0.0949012953788042, 'std': 0.005515593327704535}
    Policy Entropy: {'avg': 0.9992284774780273, 'std': 0.5395790934562683}
    KL Divergence: {'avg': 0.016311218962073326, 'std': 0.1488807052373886}
    Policy Grad Norm: {'avg': 2.8720598444342613, 'std': 0.8826847611177117}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.051827650686, 'std': 24.485072990220655, 'run': -73.58941781770845, 'test_avg': -77.85403696288174, 'test_std': 7.458958602101076}
    Episode Length: {'avg': 19.514354066985646, 'std': 5.132319461186147, 'run': 19.013654542248954, 'test_avg': 19.7900390625, 'test_std': 1.5012554636783577}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8701 / 10001):
    Value Loss: {'avg': 25.359158913294475, 'std': 3.0776017405790244}
    Value Grad Norm: {'avg': 543.3212804794312, 'std': 238.33119253239386}
    Policy Loss: {'avg': 0.004699238284956664, 'std': 0.00635485708681131}
    Total_Loss: {'avg': -0.09657865669578314, 'std': 0.006775124702643888}
    Policy Entropy: {'avg': 1.037113904953003, 'std': 0.5126907825469971}
    KL Divergence: {'avg': 0.017979778349399567, 'std': 0.1751834899187088}
    Policy Grad Norm: {'avg': 2.5862658098340034, 'std': 1.029031589991189}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.65582204690932, 'std': 25.55409169550963, 'run': -77.50428404822479, 'test_avg': -78.32708436190296, 'test_std': 9.904217429674093}
    Episode Length: {'avg': 19.440191387559807, 'std': 5.419044210445081, 'run': 19.873806746450505, 'test_avg': 19.896484375, 'test_std': 1.88358123408067}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (8801 / 10001):
    Value Loss: {'avg': 25.055995146433514, 'std': 2.590057718983315}
    Value Grad Norm: {'avg': 379.8861090342204, 'std': 124.49050540942595}
    Policy Loss: {'avg': 0.00630866753635928, 'std': 0.009535025093557253}
    Total_Loss: {'avg': -0.09470765385776758, 'std': 0.00920111838245305}
    Policy Entropy: {'avg': 1.0248236656188965, 'std': 0.5231449604034424}
    KL Divergence: {'avg': 0.027737323194742203, 'std': 0.21151664853096008}
    Policy Grad Norm: {'avg': 2.766364149749279, 'std': 1.114817146186443}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.98933423068642, 'std': 23.83504200711903, 'run': -76.15369460886463, 'test_avg': -77.8590616904462, 'test_std': 6.562825375906729}
    Episode Length: {'avg': 19.496402877697843, 'std': 5.018967525531704, 'run': 19.481463552049178, 'test_avg': 19.7724609375, 'test_std': 1.3764138322236599}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8901 / 10001):
    Value Loss: {'avg': 22.9427486260732, 'std': 1.7318921403547627}
    Value Grad Norm: {'avg': 355.0724871953328, 'std': 121.39213136718415}
    Policy Loss: {'avg': 0.000753715808968991, 'std': 0.004731351917085817}
    Total_Loss: {'avg': -0.10085085779428482, 'std': 0.005210012539227561}
    Policy Entropy: {'avg': 1.0210950374603271, 'std': 0.5355897545814514}
    KL Divergence: {'avg': 0.015833638608455658, 'std': 0.16466780006885529}
    Policy Grad Norm: {'avg': 2.808253027498722, 'std': 0.7073359167819864}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.16874099524819, 'std': 26.845684078177683, 'run': -74.74546754287529, 'test_avg': -77.69714664509752, 'test_std': 6.694574876623811}
    Episode Length: {'avg': 19.33096926713948, 'std': 5.627453875598354, 'run': 19.223575918385862, 'test_avg': 19.806640625, 'test_std': 1.4120418379423498}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9001 / 10001):
    Value Loss: {'avg': 22.58655099074046, 'std': 1.5110534321455766}
    Value Grad Norm: {'avg': 591.1770420074463, 'std': 232.4759968690073}
    Policy Loss: {'avg': 0.006596361752599478, 'std': 0.008303501522513404}
    Total_Loss: {'avg': -0.08569784881547093, 'std': 0.009560079557881617}
    Policy Entropy: {'avg': 0.9316513538360596, 'std': 0.5179153084754944}
    KL Divergence: {'avg': 0.018407870084047318, 'std': 0.18765786290168762}
    Policy Grad Norm: {'avg': 3.107155092060566, 'std': 0.7772291661285949}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.45041013746355, 'std': 24.9164877682427, 'run': -75.76442918614119, 'test_avg': -78.23182684295716, 'test_std': 6.557126844522429}
    Episode Length: {'avg': 19.117924528301888, 'std': 5.235965917444807, 'run': 19.406715934135786, 'test_avg': 19.865234375, 'test_std': 1.3783348563822797}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9101 / 10001):
    Value Loss: {'avg': 24.101767539978027, 'std': 2.0961329365791563}
    Value Grad Norm: {'avg': 652.5575434366862, 'std': 266.088240613025}
    Policy Loss: {'avg': 0.0048435825447086245, 'std': 0.005190739103374664}
    Total_Loss: {'avg': -0.09190311701968312, 'std': 0.005164384840792983}
    Policy Entropy: {'avg': 0.9439582824707031, 'std': 0.5465269088745117}
    KL Divergence: {'avg': 0.01803627423942089, 'std': 0.19359274208545685}
    Policy Grad Norm: {'avg': 3.267768830060959, 'std': 1.1231938964191863}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.11399870143232, 'std': 22.94116216877039, 'run': -77.1853454556868, 'test_avg': -77.69570768571404, 'test_std': 7.396107384056821}
    Episode Length: {'avg': 19.737745098039216, 'std': 4.879162055763012, 'run': 19.780778055438315, 'test_avg': 19.7841796875, 'test_std': 1.5852419074741881}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9201 / 10001):
    Value Loss: {'avg': 23.3238441546758, 'std': 2.0578754314945686}
    Value Grad Norm: {'avg': 536.3678166071574, 'std': 230.92508200842624}
    Policy Loss: {'avg': 0.010506589023862034, 'std': 0.007195813217481065}
    Total_Loss: {'avg': -0.07957353442907333, 'std': 0.005786473975320918}
    Policy Entropy: {'avg': 0.904892086982727, 'std': 0.5564355850219727}
    KL Divergence: {'avg': 0.02550583705306053, 'std': 0.19121351838111877}
    Policy Grad Norm: {'avg': 3.7058459669351578, 'std': 1.584062228285106}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.93977553152861, 'std': 20.35223698473286, 'run': -77.63781078173457, 'test_avg': -77.65688196906704, 'test_std': 7.026489805217653}
    Episode Length: {'avg': 19.704057279236277, 'std': 4.318827932198303, 'run': 19.81878000517997, 'test_avg': 19.771484375, 'test_std': 1.4745653966951955}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9301 / 10001):
    Value Loss: {'avg': 24.482173403104145, 'std': 2.0418933957059906}
    Value Grad Norm: {'avg': 504.53706518809, 'std': 190.9735613913622}
    Policy Loss: {'avg': 0.0021834814397152513, 'std': 0.00513365019579659}
    Total_Loss: {'avg': -0.09415716119110584, 'std': 0.006475401733990302}
    Policy Entropy: {'avg': 0.9062110185623169, 'std': 0.5171248316764832}
    KL Divergence: {'avg': 0.019385233521461487, 'std': 0.18663954734802246}
    Policy Grad Norm: {'avg': 2.7764426916837692, 'std': 0.8697607852191417}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.48953605888214, 'std': 24.030543331185292, 'run': -75.78098292211467, 'test_avg': -77.56036880974634, 'test_std': 6.831273464590779}
    Episode Length: {'avg': 19.63895486935867, 'std': 5.106263012035513, 'run': 19.510438293232667, 'test_avg': 19.7158203125, 'test_std': 1.414318419844839}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9401 / 10001):
    Value Loss: {'avg': 25.56196121374766, 'std': 2.6438611321994574}
    Value Grad Norm: {'avg': 497.38115151723224, 'std': 186.3772371263367}
    Policy Loss: {'avg': 0.0035129222960677, 'std': 0.006931757335023908}
    Total_Loss: {'avg': -0.0969439665786922, 'std': 0.005320765586188751}
    Policy Entropy: {'avg': 1.063038945198059, 'std': 0.540542721748352}
    KL Divergence: {'avg': 0.023322388529777527, 'std': 0.21006405353546143}
    Policy Grad Norm: {'avg': 2.324518270790577, 'std': 0.7314643625794016}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.57409303412558, 'std': 25.538264655503202, 'run': -78.8502980735463, 'test_avg': -77.85288032977286, 'test_std': 9.00315857477491}
    Episode Length: {'avg': 19.50835322195704, 'std': 5.420002017569825, 'run': 20.18616607216286, 'test_avg': 19.849609375, 'test_std': 1.8143416946408164}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (9501 / 10001):
    Value Loss: {'avg': 27.527196764945984, 'std': 3.1179832772727485}
    Value Grad Norm: {'avg': 556.3620144526163, 'std': 234.1361764725638}
    Policy Loss: {'avg': 0.002524061710573733, 'std': 0.005525183793116621}
    Total_Loss: {'avg': -0.09016681183129549, 'std': 0.006126711927519705}
    Policy Entropy: {'avg': 0.9033039808273315, 'std': 0.5483640432357788}
    KL Divergence: {'avg': 0.024336939677596092, 'std': 0.23155036568641663}
    Policy Grad Norm: {'avg': 2.873421400785446, 'std': 0.9021150332165603}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.33267751704057, 'std': 24.8729628405684, 'run': -75.78215547817464, 'test_avg': -77.81331217419881, 'test_std': 7.146664497706859}
    Episode Length: {'avg': 19.411214953271028, 'std': 5.283466136140084, 'run': 19.51378076697043, 'test_avg': 19.837890625, 'test_std': 1.524887881300494}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9601 / 10001):
    Value Loss: {'avg': 21.20501975218455, 'std': 2.8545869734044955}
    Value Grad Norm: {'avg': 519.6512009302775, 'std': 250.58794763537992}
    Policy Loss: {'avg': 0.0031711198098491877, 'std': 0.004953592717348277}
    Total_Loss: {'avg': -0.09274978004395962, 'std': 0.005068454814481903}
    Policy Entropy: {'avg': 0.972338080406189, 'std': 0.5351881980895996}
    KL Divergence: {'avg': 0.018485773354768753, 'std': 0.18353696167469025}
    Policy Grad Norm: {'avg': 2.4562722221016884, 'std': 0.6698052103422936}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.59429956215706, 'std': 23.348523988768015, 'run': -75.16052047572103, 'test_avg': -77.79467590493907, 'test_std': 6.51329791607928}
    Episode Length: {'avg': 19.428909952606634, 'std': 4.940731017006774, 'run': 19.346717330182543, 'test_avg': 19.8056640625, 'test_std': 1.3586841450079543}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9701 / 10001):
    Value Loss: {'avg': 22.619350512822468, 'std': 2.0412877888196395}
    Value Grad Norm: {'avg': 396.8636465072632, 'std': 118.39438720042462}
    Policy Loss: {'avg': 0.006438509561121464, 'std': 0.007199564467371132}
    Total_Loss: {'avg': -0.08670276403427124, 'std': 0.00727675106312259}
    Policy Entropy: {'avg': 0.9329957365989685, 'std': 0.5353059768676758}
    KL Divergence: {'avg': 0.016806824132800102, 'std': 0.15552061796188354}
    Policy Grad Norm: {'avg': 3.1751117408275604, 'std': 0.986985254380676}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.13077440132587, 'std': 24.987137010967317, 'run': -74.56634931350447, 'test_avg': -78.1101644278418, 'test_std': 7.701724406722214}
    Episode Length: {'avg': 19.334916864608076, 'std': 5.270762974442691, 'run': 19.20604151916714, 'test_avg': 19.873046875, 'test_std': 1.5529382727760734}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9801 / 10001):
    Value Loss: {'avg': 19.80551799138387, 'std': 1.64937725618148}
    Value Grad Norm: {'avg': 329.90992132822674, 'std': 134.36343241603367}
    Policy Loss: {'avg': 0.005909574465476908, 'std': 0.005300561666608057}
    Total_Loss: {'avg': -0.08025538735091686, 'std': 0.005246172941986858}
    Policy Entropy: {'avg': 0.8866243362426758, 'std': 0.519022524356842}
    KL Divergence: {'avg': 0.023432448506355286, 'std': 0.1796962022781372}
    Policy Grad Norm: {'avg': 2.732466757297516, 'std': 0.6287150468665463}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.9116743312777, 'std': 22.501751026702276, 'run': -74.72952482502357, 'test_avg': -77.41701963333666, 'test_std': 6.6139678422973835}
    Episode Length: {'avg': 19.27634660421546, 'std': 4.72409517021931, 'run': 19.239648840982092, 'test_avg': 19.7236328125, 'test_std': 1.393619698904023}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9901 / 10001):
    Value Loss: {'avg': 24.38725217183431, 'std': 1.8916530851662519}
    Value Grad Norm: {'avg': 433.5803066889445, 'std': 159.42327241573554}
    Policy Loss: {'avg': 0.008285778167191893, 'std': 0.008284420155980101}
    Total_Loss: {'avg': -0.09021639917045832, 'std': 0.008124329719793136}
    Policy Entropy: {'avg': 0.995335578918457, 'std': 0.5342493653297424}
    KL Divergence: {'avg': 0.023204991593956947, 'std': 0.18579131364822388}
    Policy Grad Norm: {'avg': 2.8793168887495995, 'std': 1.0327685389156678}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.15105215637983, 'std': 22.88829734896048, 'run': -76.08811961631774, 'test_avg': -77.73769294400384, 'test_std': 7.07196318147453}
    Episode Length: {'avg': 19.455205811138015, 'std': 4.8072839475944384, 'run': 19.45256332678619, 'test_avg': 19.8203125, 'test_std': 1.488542668969805}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (10001 / 10001):
    Value Loss: {'avg': 24.880884965260822, 'std': 3.122689299063159}
    Value Grad Norm: {'avg': 488.88366889953613, 'std': 173.0410619673793}
    Policy Loss: {'avg': 0.006147392763523385, 'std': 0.006607847470369092}
    Total_Loss: {'avg': -0.09576826822012663, 'std': 0.005850522554631523}
    Policy Entropy: {'avg': 1.056706190109253, 'std': 0.5200030207633972}
    KL Divergence: {'avg': 0.019173597916960716, 'std': 0.1826324164867401}
    Policy Grad Norm: {'avg': 3.0864281579852104, 'std': 0.9518270122720444}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.63731674898025, 'std': 24.98321018695309, 'run': -74.61189901914508, 'test_avg': -78.04022225800719, 'test_std': 7.262898300190684}
    Episode Length: {'avg': 19.513002364066192, 'std': 5.280249673290796, 'run': 19.276767918848147, 'test_avg': 19.955078125, 'test_std': 1.5668481978629851}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Training took 29161.408 seconds in total.
