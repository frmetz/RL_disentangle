
Iteration (1 / 2001):
    Value Loss: {'avg': 174.2806396484375, 'std': 1.8967222847952605}
    Value Grad Norm: {'avg': 69.78565470377605, 'std': 0.5750961215598707}
    Policy Loss: {'avg': -0.006237994879484177, 'std': 0.0050835412271112755}
    Total_Loss: {'avg': -0.25253404676914215, 'std': 0.0051909798536467384}
    Policy Entropy: {'avg': 2.4641928672790527, 'std': 0.018584437668323517}
    KL Divergence: {'avg': 0.008656560443341732, 'std': 0.06565874814987183}
    Policy Grad Norm: {'avg': 0.4351179798444112, 'std': 0.003339785507346943}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -23.705523193975804, 'std': 6.339259389764796, 'run': -18.145216653665372, 'test_avg': -23.64192537540488, 'test_std': 5.867013833126242}
    Episode Length: {'avg': 7.796875, 'std': 0.8692613153563202, 'run': 7.380474608905306, 'test_avg': 7.826171875, 'test_std': 0.6695516469690627}
    Ratio Terminated: {'avg': 0.09375, 'test_avg': 0.0830078125}

Iteration (101 / 2001):
    Value Loss: {'avg': 17.839532216389973, 'std': 0.05907624737331367}
    Value Grad Norm: {'avg': 2.944279352823893, 'std': 0.06924545438806759}
    Policy Loss: {'avg': -0.0015476644039154053, 'std': 0.003457714319091592}
    Total_Loss: {'avg': -0.1587853729724884, 'std': 0.002290982441942805}
    Policy Entropy: {'avg': 1.5568640232086182, 'std': 0.49139830470085144}
    KL Divergence: {'avg': 0.02058027870953083, 'std': 0.1726343184709549}
    Policy Grad Norm: {'avg': 3.3454129298528037, 'std': 1.3482451810924971}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -10.650952348698956, 'std': 6.672603934122493, 'run': -10.314719630097901, 'test_avg': -8.128473348534136, 'test_std': 3.394940872526516}
    Episode Length: {'avg': 5.836956521739131, 'std': 1.6502778021280529, 'run': 5.761937886757529, 'test_avg': 5.291015625, 'test_std': 0.8299080708161956}
    Ratio Terminated: {'avg': 0.7608695652173914, 'test_avg': 0.9560546875}

Iteration (201 / 2001):
    Value Loss: {'avg': 11.882025082906088, 'std': 0.0556679230431334}
    Value Grad Norm: {'avg': 5.765951315561931, 'std': 0.6430498084417021}
    Policy Loss: {'avg': -0.0034523438662290573, 'std': 0.0028279985220330556}
    Total_Loss: {'avg': -0.12902164459228516, 'std': 0.003502921889402713}
    Policy Entropy: {'avg': 1.2651678323745728, 'std': 0.4967705309391022}
    KL Divergence: {'avg': 0.026536105200648308, 'std': 0.16054575145244598}
    Policy Grad Norm: {'avg': 2.166233460108439, 'std': 0.8751146727055729}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -8.533221250447095, 'std': 5.080731802724508, 'run': -8.46619081165586, 'test_avg': -7.615911062186837, 'test_std': 2.526121078575848}
    Episode Length: {'avg': 5.33, 'std': 1.288836684766538, 'run': 5.33462939302742, 'test_avg': 5.134765625, 'test_std': 0.5891286797622056}
    Ratio Terminated: {'avg': 0.91, 'test_avg': 0.98046875}

Iteration (301 / 2001):
    Value Loss: {'avg': 6.509292443593343, 'std': 0.02181956411191608}
    Value Grad Norm: {'avg': 5.094565232594808, 'std': 0.7883834942118391}
    Policy Loss: {'avg': -0.0013031736016273499, 'std': 0.001303166151046753}
    Total_Loss: {'avg': -0.12248490005731583, 'std': 0.0023334920406341553}
    Policy Entropy: {'avg': 1.2221205234527588, 'std': 0.5280864238739014}
    KL Divergence: {'avg': 0.02377714216709137, 'std': 0.1432616412639618}
    Policy Grad Norm: {'avg': 1.9042614698410034, 'std': 0.5669671297073364}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -7.988773733883762, 'std': 4.309470776402392, 'run': -7.772832999226063, 'test_avg': -7.3017488511722135, 'test_std': 1.5612922115048922}
    Episode Length: {'avg': 5.205882352941177, 'std': 1.2154095194150243, 'run': 5.156165108951766, 'test_avg': 5.06640625, 'test_std': 0.4092251335890032}
    Ratio Terminated: {'avg': 0.9411764705882353, 'test_avg': 0.9912109375}

Iteration (401 / 2001):
    Value Loss: {'avg': 2.6428211530049643, 'std': 0.027160645870912725}
    Value Grad Norm: {'avg': 3.266735394795736, 'std': 0.3583910407842012}
    Policy Loss: {'avg': -0.005571443897982438, 'std': 0.004292974017170033}
    Total_Loss: {'avg': -0.13474215070406595, 'std': 0.0039023164714426274}
    Policy Entropy: {'avg': 1.2884098291397095, 'std': 0.6056842803955078}
    KL Divergence: {'avg': 0.00787031278014183, 'std': 0.12021070718765259}
    Policy Grad Norm: {'avg': 1.9204893509546916, 'std': 0.5980972049828246}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.083234894205731, 'std': 2.992027411712148, 'run': -7.148692441401328, 'test_avg': -7.158694083875162, 'test_std': 1.1667833636191227}
    Episode Length: {'avg': 5.0095238095238095, 'std': 0.9511420513330586, 'run': 5.030464607697811, 'test_avg': 5.0400390625, 'test_std': 0.3146153381100818}
    Ratio Terminated: {'avg': 0.9714285714285714, 'test_avg': 0.998046875}

Iteration (501 / 2001):
    Value Loss: {'avg': 2.9748128255208335, 'std': 0.008933595597332545}
    Value Grad Norm: {'avg': 4.213895320892334, 'std': 0.04972219298652421}
    Policy Loss: {'avg': -0.004234181717038155, 'std': 0.00423419289290905}
    Total_Loss: {'avg': -0.12542515993118286, 'std': 0.002591758966445923}
    Policy Entropy: {'avg': 1.1954853534698486, 'std': 0.6327376961708069}
    KL Divergence: {'avg': 0.025392841547727585, 'std': 0.2530425190925598}
    Policy Grad Norm: {'avg': 4.079280257225037, 'std': 2.36739981174469}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -7.287973858975795, 'std': 2.385646813104158, 'run': -7.098006312643546, 'test_avg': -7.148913086244448, 'test_std': 1.3315331418753855}
    Episode Length: {'avg': 5.105769230769231, 'std': 0.7585191700681971, 'run': 5.029586966194459, 'test_avg': 5.0537109375, 'test_std': 0.36449598446741643}
    Ratio Terminated: {'avg': 0.9903846153846154, 'test_avg': 0.994140625}

Iteration (601 / 2001):
    Value Loss: {'avg': 4.952304522196452, 'std': 0.00553398265573314}
    Value Grad Norm: {'avg': 6.131969134012858, 'std': 0.2517139716454003}
    Policy Loss: {'avg': -0.005645304297407468, 'std': 0.004398884100046485}
    Total_Loss: {'avg': -0.1295963078737259, 'std': 0.0037442675184417833}
    Policy Entropy: {'avg': 1.2340449094772339, 'std': 0.6507934331893921}
    KL Divergence: {'avg': 0.006569388788193464, 'std': 0.10569367557764053}
    Policy Grad Norm: {'avg': 3.332934776941935, 'std': 0.8027447530594216}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.037570580183421, 'std': 2.890425131078082, 'run': -6.990134128644565, 'test_avg': -6.994896152473302, 'test_std': 0.7404547739037253}
    Episode Length: {'avg': 4.9523809523809526, 'std': 0.7973880262451231, 'run': 4.953857518589316, 'test_avg': 5.0107421875, 'test_std': 0.16202405039905293}
    Ratio Terminated: {'avg': 0.9714285714285714, 'test_avg': 0.9990234375}

Iteration (701 / 2001):
    Value Loss: {'avg': 2.654843807220459, 'std': 0.010328793058613582}
    Value Grad Norm: {'avg': 3.63123885790507, 'std': 0.20448088006929663}
    Policy Loss: {'avg': -0.003512547661860784, 'std': 0.0028001447595030434}
    Total_Loss: {'avg': -0.11963068693876266, 'std': 0.0030455601930849067}
    Policy Entropy: {'avg': 1.1639869213104248, 'std': 0.6872954368591309}
    KL Divergence: {'avg': 0.012325271964073181, 'std': 0.11638937890529633}
    Policy Grad Norm: {'avg': 1.2111547589302063, 'std': 0.21513069934008391}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.341277870412799, 'std': 2.6632770224864224, 'run': -6.523315518501246, 'test_avg': -7.052427620783419, 'test_std': 1.3609364753526056}
    Episode Length: {'avg': 4.78, 'std': 0.8435638683585257, 'run': 4.840500586396357, 'test_avg': 5.056640625, 'test_std': 0.37332286910877743}
    Ratio Terminated: {'avg': 0.99, 'test_avg': 0.994140625}

Iteration (801 / 2001):
    Value Loss: {'avg': 1.8967465957005818, 'std': 0.00501145716251954}
    Value Grad Norm: {'avg': 5.812557379404704, 'std': 0.4509572544216719}
    Policy Loss: {'avg': 0.001641087078799804, 'std': 0.003729037554948122}
    Total_Loss: {'avg': -0.12089750915765762, 'std': 0.002808416468370107}
    Policy Entropy: {'avg': 1.2188694477081299, 'std': 0.6782861948013306}
    KL Divergence: {'avg': 0.009948942810297012, 'std': 0.15144358575344086}
    Policy Grad Norm: {'avg': 9.556743939717611, 'std': 0.8768156408501887}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.894990484234503, 'std': 2.9231607379888644, 'run': -6.8342484137605775, 'test_avg': -6.937401701434283, 'test_std': 1.2779116284938912}
    Episode Length: {'avg': 4.951456310679611, 'std': 0.9071307671299478, 'run': 4.955365831954234, 'test_avg': 5.029296875, 'test_std': 0.25980967671592675}
    Ratio Terminated: {'avg': 0.9805825242718447, 'test_avg': 0.9970703125}

Iteration (901 / 2001):
    Value Loss: {'avg': 5.314255873362224, 'std': 0.02980917171946899}
    Value Grad Norm: {'avg': 10.084339459737143, 'std': 0.8717863065118684}
    Policy Loss: {'avg': -0.002925361040979624, 'std': 0.002925360109657049}
    Total_Loss: {'avg': -0.1326768845319748, 'std': 0.001876235008239746}
    Policy Entropy: {'avg': 1.2870240211486816, 'std': 0.6969242691993713}
    KL Divergence: {'avg': 0.018075549975037575, 'std': 0.2071295529603958}
    Policy Grad Norm: {'avg': 6.364897012710571, 'std': 2.4489009380340576}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -7.561920789038775, 'std': 3.3595824607880145, 'run': -7.111637221130982, 'test_avg': -7.188598740442103, 'test_std': 1.9658672747020292}
    Episode Length: {'avg': 5.206185567010309, 'std': 1.1023699336971795, 'run': 5.070450180893983, 'test_avg': 5.1005859375, 'test_std': 0.5045105615120917}
    Ratio Terminated: {'avg': 0.9484536082474226, 'test_avg': 0.98046875}

Iteration (1001 / 2001):
    Value Loss: {'avg': 3.10988982518514, 'std': 0.03998915492704131}
    Value Grad Norm: {'avg': 8.057552814483643, 'std': 1.5538638605551163}
    Policy Loss: {'avg': -0.006454860791563988, 'std': 0.00516716844184726}
    Total_Loss: {'avg': -0.12633637835582098, 'std': 0.00400941021893872}
    Policy Entropy: {'avg': 1.1803300380706787, 'std': 0.7202812433242798}
    KL Divergence: {'avg': 0.014339861460030079, 'std': 0.1259252429008484}
    Policy Grad Norm: {'avg': 4.312297185262044, 'std': 0.1989280105365119}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.1716518077913305, 'std': 2.3658036975509593, 'run': -6.971586070380936, 'test_avg': -6.866078271297738, 'test_std': 1.0077805151119401}
    Episode Length: {'avg': 5.071428571428571, 'std': 0.6888321972137825, 'run': 5.00735148377061, 'test_avg': 5.0322265625, 'test_std': 0.25375408601524746}
    Ratio Terminated: {'avg': 0.9795918367346939, 'test_avg': 0.998046875}

Iteration (1101 / 2001):
    Value Loss: {'avg': 3.1546321709950766, 'std': 0.0037884027532775286}
    Value Grad Norm: {'avg': 8.66738255818685, 'std': 0.20267709856763697}
    Policy Loss: {'avg': -0.0023543058584133783, 'std': 0.002801231109003314}
    Total_Loss: {'avg': -0.12021612375974655, 'std': 0.0028338112574210843}
    Policy Entropy: {'avg': 1.1790719032287598, 'std': 0.7441551089286804}
    KL Divergence: {'avg': 0.006141708232462406, 'std': 0.06928540766239166}
    Policy Grad Norm: {'avg': 2.058713515599569, 'std': 0.34045433293816335}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.65758284660288, 'std': 3.0461157777327053, 'run': -6.441763081382918, 'test_avg': -6.778784407248281, 'test_std': 1.2347962681537492}
    Episode Length: {'avg': 4.862745098039215, 'std': 0.8860489041329414, 'run': 4.8068428041177125, 'test_avg': 5.03125, 'test_std': 0.29481191037676885}
    Ratio Terminated: {'avg': 0.9705882352941176, 'test_avg': 0.994140625}

Iteration (1201 / 2001):
    Value Loss: {'avg': 0.5101203918457031, 'std': 0.010920262074855832}
    Value Grad Norm: {'avg': 5.097528298695882, 'std': 0.7946588517785297}
    Policy Loss: {'avg': -0.0008659145484368006, 'std': 0.0015671735013120377}
    Total_Loss: {'avg': -0.11968531459569931, 'std': 0.0017588868691704373}
    Policy Entropy: {'avg': 1.1908740997314453, 'std': 0.6867409944534302}
    KL Divergence: {'avg': 0.002697948133572936, 'std': 0.05633162334561348}
    Policy Grad Norm: {'avg': 1.8407786289850872, 'std': 0.5567679941663924}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.452413671382607, 'std': 1.7905442713390007, 'run': -6.522546200817337, 'test_avg': -6.68407104221842, 'test_std': 0.8397648493725216}
    Episode Length: {'avg': 4.834951456310679, 'std': 0.6400407659747385, 'run': 4.8670365433186324, 'test_avg': 5.0205078125, 'test_std': 0.23503934165680612}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 2001):
    Value Loss: {'avg': 1.3220607042312622, 'std': 0.0110521824834746}
    Value Grad Norm: {'avg': 8.40539820988973, 'std': 0.2911759093410463}
    Policy Loss: {'avg': -0.005004015130301316, 'std': 0.00358458448056519}
    Total_Loss: {'avg': -0.11823514103889465, 'std': 0.004085531196163474}
    Policy Entropy: {'avg': 1.1393826007843018, 'std': 0.6572071313858032}
    KL Divergence: {'avg': 0.012962287291884422, 'std': 0.10137646645307541}
    Policy Grad Norm: {'avg': 1.9353369275728862, 'std': 1.018548160767796}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.411121327909327, 'std': 2.6517221351644595, 'run': -6.34077356697864, 'test_avg': -6.6448312662832905, 'test_std': 0.720441053205866}
    Episode Length: {'avg': 4.846153846153846, 'std': 0.769230769230769, 'run': 4.821125454163979, 'test_avg': 5.015625, 'test_std': 0.18684782411095935}
    Ratio Terminated: {'avg': 0.9903846153846154, 'test_avg': 1.0}

Iteration (1401 / 2001):
    Value Loss: {'avg': 0.5637988249460856, 'std': 0.0019476491368915045}
    Value Grad Norm: {'avg': 3.8695310751597085, 'std': 0.46518903105518994}
    Policy Loss: {'avg': -0.008004105339447657, 'std': 0.006265643877024899}
    Total_Loss: {'avg': -0.11077229430278142, 'std': 0.00540499233444507}
    Policy Entropy: {'avg': 1.017052173614502, 'std': 0.5373954176902771}
    KL Divergence: {'avg': 0.01573878526687622, 'std': 0.15551316738128662}
    Policy Grad Norm: {'avg': 1.5607832670211792, 'std': 0.5288517953302687}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.215913267551473, 'std': 1.9606982220177478, 'run': -6.108294848158588, 'test_avg': -6.597352367105486, 'test_std': 0.7259577662014695}
    Episode Length: {'avg': 4.824074074074074, 'std': 0.7178762880074824, 'run': 4.781405272579279, 'test_avg': 5.0107421875, 'test_std': 0.16794319845624842}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (1501 / 2001):
    Value Loss: {'avg': 3.0736323992411294, 'std': 0.02695908188113535}
    Value Grad Norm: {'avg': 11.438018480936686, 'std': 1.9449997977731615}
    Policy Loss: {'avg': 0.0009425704677899679, 'std': 0.001356323432873772}
    Total_Loss: {'avg': -0.09862706810235977, 'std': 0.0013896790171208926}
    Policy Entropy: {'avg': 0.9940776824951172, 'std': 0.46574774384498596}
    KL Divergence: {'avg': 0.0002643647603690624, 'std': 0.06951811164617538}
    Policy Grad Norm: {'avg': 3.6817561785380044, 'std': 0.09777525855677892}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.105998794718933, 'std': 2.6259287131248708, 'run': -6.251725408823375, 'test_avg': -6.603971069467661, 'test_std': 0.9003055210047323}
    Episode Length: {'avg': 4.803738317757009, 'std': 0.7542930382796663, 'run': 4.835152975264044, 'test_avg': 5.0166015625, 'test_std': 0.22255128762278278}
    Ratio Terminated: {'avg': 0.9906542056074766, 'test_avg': 0.998046875}

Iteration (1601 / 2001):
    Value Loss: {'avg': 1.217793623606364, 'std': 0.00457124017442403}
    Value Grad Norm: {'avg': 5.491082350413005, 'std': 0.5150138759332598}
    Policy Loss: {'avg': -0.0045936452224850655, 'std': 0.004167225138293784}
    Total_Loss: {'avg': -0.10119464000066121, 'std': 0.00421963528520581}
    Policy Entropy: {'avg': 0.9667923450469971, 'std': 0.45800870656967163}
    KL Divergence: {'avg': 0.009673099033534527, 'std': 0.10431480407714844}
    Policy Grad Norm: {'avg': 2.358052889506022, 'std': 0.257154052932678}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -5.87828553126511, 'std': 2.4176571699765073, 'run': -5.90185824680424, 'test_avg': -6.572928130553919, 'test_std': 0.536953190398741}
    Episode Length: {'avg': 4.747572815533981, 'std': 0.8328037403497999, 'run': 4.759981548466125, 'test_avg': 5.005859375, 'test_std': 0.08819392113184091}
    Ratio Terminated: {'avg': 0.9902912621359223, 'test_avg': 1.0}

Iteration (1701 / 2001):
    Value Loss: {'avg': 1.646856149037679, 'std': 0.01401367341326862}
    Value Grad Norm: {'avg': 4.194109837214152, 'std': 0.2151831319030309}
    Policy Loss: {'avg': -0.00351590725282828, 'std': 0.003031008152928553}
    Total_Loss: {'avg': -0.09816460808118184, 'std': 0.0030508647564801237}
    Policy Entropy: {'avg': 0.9466565847396851, 'std': 0.41165125370025635}
    KL Divergence: {'avg': 0.01315856259316206, 'std': 0.08144255727529526}
    Policy Grad Norm: {'avg': 1.872941533724467, 'std': 0.3919326367657832}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.535100250244119, 'std': 1.8369275264080691, 'run': -6.384246395468407, 'test_avg': -6.592133658399689, 'test_std': 0.9647705836946523}
    Episode Length: {'avg': 4.951923076923077, 'std': 0.48792747909097206, 'run': 4.902830833519282, 'test_avg': 5.0234375, 'test_std': 0.2527920263650537}
    Ratio Terminated: {'avg': 0.9903846153846154, 'test_avg': 0.998046875}

Iteration (1801 / 2001):
    Value Loss: {'avg': 0.3442222476005554, 'std': 0.00493317429143338}
    Value Grad Norm: {'avg': 5.777853012084961, 'std': 0.8660404045551281}
    Policy Loss: {'avg': 6.51925802230835e-09, 'std': 0.0}
    Total_Loss: {'avg': -0.09475843608379364, 'std': 0.0}
    Policy Entropy: {'avg': 0.9475843906402588, 'std': 0.4047503173351288}
    KL Divergence: {'avg': 0.015239761210978031, 'std': 0.26034611463546753}
    Policy Grad Norm: {'avg': 9.790788650512695, 'std': 0.0}
    Num PPO updates: {'avg': 1}
    Return: {'avg': -6.2706197786202775, 'std': 2.0790632072612514, 'run': -6.165053640737338, 'test_avg': -6.563476494251518, 'test_std': 0.8739178712976086}
    Episode Length: {'avg': 4.907407407407407, 'std': 0.7395824276931801, 'run': 4.877103155844549, 'test_avg': 5.013671875, 'test_std': 0.2115063943099224}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (1901 / 2001):
    Value Loss: {'avg': 3.45694899559021, 'std': 0.02310560594961354}
    Value Grad Norm: {'avg': 5.644118944803874, 'std': 0.6279463140017595}
    Policy Loss: {'avg': -0.00517152560253938, 'std': 0.004717714681004313}
    Total_Loss: {'avg': -0.10208312918742497, 'std': 0.004656284068771072}
    Policy Entropy: {'avg': 0.9691739082336426, 'std': 0.4135587513446808}
    KL Divergence: {'avg': 0.011525604873895645, 'std': 0.066244937479496}
    Policy Grad Norm: {'avg': 2.586853583653768, 'std': 0.29131331270246136}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.339074570057922, 'std': 3.3135081685349252, 'run': -6.299387445078926, 'test_avg': -6.676036515018495, 'test_std': 1.3447803680025718}
    Episode Length: {'avg': 4.87962962962963, 'std': 1.0516089312606993, 'run': 4.888880814256926, 'test_avg': 5.0419921875, 'test_std': 0.3383010400352988}
    Ratio Terminated: {'avg': 0.9814814814814815, 'test_avg': 0.9951171875}

Iteration (2001 / 2001):
    Value Loss: {'avg': 0.47083842754364014, 'std': 0.008754223136130234}
    Value Grad Norm: {'avg': 8.209438482920328, 'std': 0.6982048368503642}
    Policy Loss: {'avg': -0.006087864749133587, 'std': 0.004764308816805441}
    Total_Loss: {'avg': -0.09992884347836177, 'std': 0.0041369878073463035}
    Policy Entropy: {'avg': 0.9303880929946899, 'std': 0.3824732303619385}
    KL Divergence: {'avg': 0.010747292079031467, 'std': 0.10435579717159271}
    Policy Grad Norm: {'avg': 2.1053016980489097, 'std': 1.0854595922153716}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.312321143676933, 'std': 1.6456806377194058, 'run': -6.244874713831269, 'test_avg': -6.622495185398819, 'test_std': 1.040339864248361}
    Episode Length: {'avg': 4.912621359223301, 'std': 0.5763426050351778, 'run': 4.874938578245935, 'test_avg': 5.0283203125, 'test_std': 0.2727513013716018}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Training took 351.384 seconds in total.
