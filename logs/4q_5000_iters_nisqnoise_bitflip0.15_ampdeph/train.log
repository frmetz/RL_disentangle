
Iteration (1 / 5000):
    Value Loss: {'avg': 94.23813796043396, 'std': 24.066038053671058}
    Value Grad Norm: {'avg': 66.59243988990784, 'std': 7.82075974689407}
    Policy Loss: {'avg': -0.008078743102184186, 'std': 0.008113055408615259}
    Total_Loss: {'avg': -0.1869114584599932, 'std': 0.008102423950209778}
    Policy Entropy: {'avg': 1.7885422706604004, 'std': 0.0038824635557830334}
    KL Divergence: {'avg': 0.0072119771502912045, 'std': 0.09592641144990921}
    Policy Grad Norm: {'avg': 0.17607043807705244, 'std': 0.07723233467308532}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -11.274168385535653, 'std': 5.787629164928911, 'run': -2.429746438805456, 'test_avg': -24.413480163201193, 'test_std': 12.100052270380846}
    Episode Length: {'avg': 6.34375, 'std': 1.7430105959230426, 'run': 3.233838841994948, 'test_avg': 9.9609375, 'test_std': 2.994206238069407}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.3359375}

Iteration (101 / 5000):
    Value Loss: {'avg': 8.99919679760933, 'std': 2.905837133267395}
    Value Grad Norm: {'avg': 21.231039086977642, 'std': 8.143079376275796}
    Policy Loss: {'avg': 0.002275033271871507, 'std': 0.021268975113800787}
    Total_Loss: {'avg': -0.07053106534294784, 'std': 0.01931420015519991}
    Policy Entropy: {'avg': 0.7748116254806519, 'std': 0.5695907473564148}
    KL Divergence: {'avg': 0.05270038917660713, 'std': 0.3512748181819916}
    Policy Grad Norm: {'avg': 3.0983304791152477, 'std': 1.8817206809496012}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -8.162124219188815, 'std': 5.418405686535569, 'run': -8.688961572183226, 'test_avg': -7.003849190500456, 'test_std': 2.290304320928226}
    Episode Length: {'avg': 5.425414364640884, 'std': 1.7034950973025984, 'run': 5.599266814109651, 'test_avg': 5.1455078125, 'test_std': 0.9495678169575171}
    Ratio Terminated: {'avg': 0.9530386740331491, 'test_avg': 0.986328125}

Iteration (201 / 5000):
    Value Loss: {'avg': 1.274252327779929, 'std': 0.4740297374283631}
    Value Grad Norm: {'avg': 11.232952564954758, 'std': 4.413276342133482}
    Policy Loss: {'avg': 0.01266191783361137, 'std': 0.0374071214253953}
    Total_Loss: {'avg': -0.034432204673066735, 'std': 0.0392556615032065}
    Policy Entropy: {'avg': 0.4368841052055359, 'std': 0.5308763384819031}
    KL Divergence: {'avg': 0.06471386551856995, 'std': 0.5565080046653748}
    Policy Grad Norm: {'avg': 3.649965964257717, 'std': 4.826113121162387}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.918555191467482, 'std': 2.2446101346891743, 'run': -6.830418820236692, 'test_avg': -6.9916866860586575, 'test_std': 2.411947687758413}
    Episode Length: {'avg': 5.055023923444976, 'std': 0.7698481329152053, 'run': 5.036522305665669, 'test_avg': 5.1181640625, 'test_std': 0.8319206343356895}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.986328125}

Iteration (301 / 5000):
    Value Loss: {'avg': 1.7235400540133317, 'std': 0.7722515004300788}
    Value Grad Norm: {'avg': 13.233292877674103, 'std': 3.9731274562301477}
    Policy Loss: {'avg': -0.002805443189572543, 'std': 0.012549790635541163}
    Total_Loss: {'avg': -0.05165126989595592, 'std': 0.012047288060136298}
    Policy Entropy: {'avg': 0.5041235685348511, 'std': 0.5498381853103638}
    KL Divergence: {'avg': 0.045976314693689346, 'std': 0.316058874130249}
    Policy Grad Norm: {'avg': 3.037684580311179, 'std': 4.266857127689237}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.115464546539418, 'std': 3.1622961652827084, 'run': -6.932328866827338, 'test_avg': -6.75860174979671, 'test_std': 1.528947946776027}
    Episode Length: {'avg': 5.105793450881612, 'std': 0.9410277288988912, 'run': 5.053396865763463, 'test_avg': 5.052734375, 'test_std': 0.52024665851244}
    Ratio Terminated: {'avg': 0.9899244332493703, 'test_avg': 0.9970703125}

Iteration (401 / 5000):
    Value Loss: {'avg': 1.9666981436312199, 'std': 0.8633473784996213}
    Value Grad Norm: {'avg': 16.595685104529064, 'std': 7.715490218616958}
    Policy Loss: {'avg': 0.0018053174717351794, 'std': 0.017084696328791848}
    Total_Loss: {'avg': -0.04869859025347978, 'std': 0.01712660639960559}
    Policy Entropy: {'avg': 0.5251624584197998, 'std': 0.5145432949066162}
    KL Divergence: {'avg': 0.029916509985923767, 'std': 0.22940324246883392}
    Policy Grad Norm: {'avg': 3.3178784176707268, 'std': 3.1441440791100166}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.017722419385564, 'std': 2.7424863670216384, 'run': -6.9837897962121, 'test_avg': -6.976393256674262, 'test_std': 2.398587597726227}
    Episode Length: {'avg': 5.085858585858586, 'std': 0.944255369179473, 'run': 5.050724564467722, 'test_avg': 5.107421875, 'test_std': 0.7475112312008994}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (501 / 5000):
    Value Loss: {'avg': 2.1157369973758855, 'std': 1.1959798988049133}
    Value Grad Norm: {'avg': 19.742325206597645, 'std': 9.747093647511125}
    Policy Loss: {'avg': 0.028732475941069424, 'std': 0.0782658789993061}
    Total_Loss: {'avg': -0.019034026190638542, 'std': 0.07727533676169175}
    Policy Entropy: {'avg': 0.46455031633377075, 'std': 0.52280193567276}
    KL Divergence: {'avg': 0.01957685872912407, 'std': 0.20036450028419495}
    Policy Grad Norm: {'avg': 5.703250853344798, 'std': 10.611040871616686}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.0009678768710915, 'std': 2.7762406437772333, 'run': -6.946552660365145, 'test_avg': -6.805596136811491, 'test_std': 1.8794924155237969}
    Episode Length: {'avg': 5.080310880829016, 'std': 0.9168971706182899, 'run': 5.067030014754505, 'test_avg': 5.076171875, 'test_std': 0.687541613619848}
    Ratio Terminated: {'avg': 0.9974093264248705, 'test_avg': 0.9912109375}

Iteration (601 / 5000):
    Value Loss: {'avg': 1.0756998049716155, 'std': 0.6595598183370244}
    Value Grad Norm: {'avg': 10.36253122985363, 'std': 4.399153012782852}
    Policy Loss: {'avg': 0.003016152768395841, 'std': 0.010661828190111614}
    Total_Loss: {'avg': -0.03561169118620455, 'std': 0.012871708903508939}
    Policy Entropy: {'avg': 0.4620072841644287, 'std': 0.45124250650405884}
    KL Divergence: {'avg': 0.025841154158115387, 'std': 0.2015676498413086}
    Policy Grad Norm: {'avg': 1.9493803698569536, 'std': 1.6499239992283545}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.524114131595592, 'std': 2.1211438644288547, 'run': -6.583661271477294, 'test_avg': -6.729219728726758, 'test_std': 1.2202219665207386}
    Episode Length: {'avg': 4.942857142857143, 'std': 0.7115184490941613, 'run': 4.9603046853726145, 'test_avg': 5.048828125, 'test_std': 0.3796053071401721}
    Ratio Terminated: {'avg': 0.9976190476190476, 'test_avg': 1.0}

Iteration (701 / 5000):
    Value Loss: {'avg': 1.5563197390486796, 'std': 0.876687162827701}
    Value Grad Norm: {'avg': 15.60232866803805, 'std': 7.203546590347212}
    Policy Loss: {'avg': 0.012058589491061866, 'std': 0.027723142230988925}
    Total_Loss: {'avg': -0.03204839886166155, 'std': 0.028403358645629928}
    Policy Entropy: {'avg': 0.44526612758636475, 'std': 0.5062753558158875}
    KL Divergence: {'avg': 0.025611259043216705, 'std': 0.24380837380886078}
    Policy Grad Norm: {'avg': 3.4691861048340797, 'std': 6.891559340618908}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.775781538928806, 'std': 2.407185008462246, 'run': -6.789093865177386, 'test_avg': -6.697428339679563, 'test_std': 1.1418031367206771}
    Episode Length: {'avg': 5.032828282828283, 'std': 0.835713619215037, 'run': 5.046934566125635, 'test_avg': 5.025390625, 'test_std': 0.3176756461583251}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (801 / 5000):
    Value Loss: {'avg': 2.405136371652285, 'std': 1.0008926134057181}
    Value Grad Norm: {'avg': 27.039644459883373, 'std': 9.226185749990357}
    Policy Loss: {'avg': 0.0010644476860761642, 'std': 0.031382059998204564}
    Total_Loss: {'avg': -0.05171256163157523, 'std': 0.0320691734568066}
    Policy Entropy: {'avg': 0.5463426113128662, 'std': 0.4677398204803467}
    KL Divergence: {'avg': 0.04668980836868286, 'std': 0.2689346671104431}
    Policy Grad Norm: {'avg': 2.480288077145815, 'std': 1.5213883613809895}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.473890457134351, 'std': 4.061726024350117, 'run': -7.062262211044314, 'test_avg': -7.019449168463481, 'test_std': 1.9871426535102013}
    Episode Length: {'avg': 5.243589743589744, 'std': 1.2298206814868395, 'run': 5.096252060049445, 'test_avg': 5.1396484375, 'test_std': 0.6502931080703598}
    Ratio Terminated: {'avg': 0.9871794871794872, 'test_avg': 1.0}

Iteration (901 / 5000):
    Value Loss: {'avg': 1.1874780176828306, 'std': 0.5714990516758456}
    Value Grad Norm: {'avg': 13.966681281725565, 'std': 6.3457331988088095}
    Policy Loss: {'avg': 0.0041563184931874275, 'std': 0.019148446255105783}
    Total_Loss: {'avg': -0.04353235336020589, 'std': 0.020630269309308072}
    Policy Entropy: {'avg': 0.4741698205471039, 'std': 0.5397482514381409}
    KL Divergence: {'avg': 0.03265184909105301, 'std': 0.35017311573028564}
    Policy Grad Norm: {'avg': 1.3907395247370005, 'std': 0.6460909852605378}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.444696257413514, 'std': 1.5429634001356325, 'run': -6.537954447966919, 'test_avg': -6.611259060038719, 'test_std': 0.5934901088844332}
    Episode Length: {'avg': 4.908415841584159, 'std': 0.511286927395256, 'run': 4.944374952204729, 'test_avg': 5.0068359375, 'test_std': 0.10341884479385802}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1001 / 5000):
    Value Loss: {'avg': 0.8929568277671933, 'std': 0.43727679509575007}
    Value Grad Norm: {'avg': 18.26874566078186, 'std': 11.10020418401335}
    Policy Loss: {'avg': 0.002131577581167221, 'std': 0.010351788081105137}
    Total_Loss: {'avg': -0.04031588463112712, 'std': 0.008834622106948627}
    Policy Entropy: {'avg': 0.42268139123916626, 'std': 0.46833404898643494}
    KL Divergence: {'avg': 0.036348871886730194, 'std': 0.3040083944797516}
    Policy Grad Norm: {'avg': 3.133631508797407, 'std': 2.886964207423257}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.497829006323873, 'std': 1.9566644451516682, 'run': -6.577998857458931, 'test_avg': -6.6277331026413435, 'test_std': 0.7054336132293908}
    Episode Length: {'avg': 4.945812807881773, 'std': 0.674679054831315, 'run': 4.983610314992195, 'test_avg': 5.013671875, 'test_std': 0.15875674736522027}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 5000):
    Value Loss: {'avg': 0.4255783896272381, 'std': 0.25588395001727793}
    Value Grad Norm: {'avg': 10.789607788125673, 'std': 6.647660437876129}
    Policy Loss: {'avg': -0.0034244265407323837, 'std': 0.01681219277576759}
    Total_Loss: {'avg': -0.03891678398940712, 'std': 0.01792145182604314}
    Policy Entropy: {'avg': 0.37350353598594666, 'std': 0.45207667350769043}
    KL Divergence: {'avg': 0.048228029161691666, 'std': 0.4805179536342621}
    Policy Grad Norm: {'avg': 2.003979355096817, 'std': 1.8184722419409411}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.421495686083961, 'std': 1.5766728027548316, 'run': -6.539541096332308, 'test_avg': -6.652611785284535, 'test_std': 0.8038281846129817}
    Episode Length: {'avg': 4.916666666666667, 'std': 0.5119601298960443, 'run': 4.949823699590939, 'test_avg': 5.01953125, 'test_std': 0.21104597905062655}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 5000):
    Value Loss: {'avg': 0.6023154314607382, 'std': 0.28583423497187277}
    Value Grad Norm: {'avg': 9.267951384186745, 'std': 4.278264120707738}
    Policy Loss: {'avg': 0.004094555391930044, 'std': 0.011468821159517997}
    Total_Loss: {'avg': -0.034167334786616266, 'std': 0.011838454384487905}
    Policy Entropy: {'avg': 0.43952667713165283, 'std': 0.4393962025642395}
    KL Divergence: {'avg': 0.02577185072004795, 'std': 0.31354790925979614}
    Policy Grad Norm: {'avg': 2.6709935814142227, 'std': 1.6296194057545095}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.494492424218913, 'std': 2.4150829382834376, 'run': -6.428730395728627, 'test_avg': -6.670514413348997, 'test_std': 1.072532739484716}
    Episode Length: {'avg': 4.9352517985611515, 'std': 0.7349640663350281, 'run': 4.928658585924539, 'test_avg': 5.025390625, 'test_std': 0.29537423916467287}
    Ratio Terminated: {'avg': 0.9976019184652278, 'test_avg': 1.0}

Iteration (1301 / 5000):
    Value Loss: {'avg': 0.6069970829412341, 'std': 0.3135868542973148}
    Value Grad Norm: {'avg': 13.889951636393866, 'std': 6.6981441273736255}
    Policy Loss: {'avg': 0.00854892609640956, 'std': 0.027904746270937135}
    Total_Loss: {'avg': -0.03488893329631537, 'std': 0.027976960817133772}
    Policy Entropy: {'avg': 0.4183509945869446, 'std': 0.4655524492263794}
    KL Divergence: {'avg': 0.024438530206680298, 'std': 0.22887936234474182}
    Policy Grad Norm: {'avg': 2.2648227028548717, 'std': 2.3664517129860676}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.5482359512020905, 'std': 1.711760512508542, 'run': -6.5462061254275845, 'test_avg': -6.617673568005557, 'test_std': 0.6989989906983768}
    Episode Length: {'avg': 4.943765281173594, 'std': 0.5968675391847846, 'run': 4.930916128669003, 'test_avg': 5.01171875, 'test_std': 0.14610628288488314}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 5000):
    Value Loss: {'avg': 0.3366561920071642, 'std': 0.15515999139825182}
    Value Grad Norm: {'avg': 7.400730142990748, 'std': 3.611333020121778}
    Policy Loss: {'avg': 0.007784009794704616, 'std': 0.011528208128720588}
    Total_Loss: {'avg': -0.030302677303552628, 'std': 0.011795632074541831}
    Policy Entropy: {'avg': 0.38974159955978394, 'std': 0.5079405307769775}
    KL Divergence: {'avg': 0.019700679928064346, 'std': 0.26401227712631226}
    Policy Grad Norm: {'avg': 2.0218732468783855, 'std': 1.9091834961587029}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.368047479213053, 'std': 1.6751281443862753, 'run': -6.369315774160552, 'test_avg': -6.610618540958967, 'test_std': 0.7009966960200745}
    Episode Length: {'avg': 4.902743142144638, 'std': 0.5763566507700636, 'run': 4.905391797089497, 'test_avg': 5.01171875, 'test_std': 0.15891285630318744}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 5000):
    Value Loss: {'avg': 0.7142309965565801, 'std': 0.3908595870972136}
    Value Grad Norm: {'avg': 11.27783727645874, 'std': 4.612622019611779}
    Policy Loss: {'avg': 0.006405680032912642, 'std': 0.018052898779220942}
    Total_Loss: {'avg': -0.03534283163025975, 'std': 0.01717593898914703}
    Policy Entropy: {'avg': 0.42456260323524475, 'std': 0.5184882879257202}
    KL Divergence: {'avg': 0.023991037160158157, 'std': 0.183844193816185}
    Policy Grad Norm: {'avg': 3.5373703464865685, 'std': 2.563772044721778}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.565855151166931, 'std': 1.6552817296497646, 'run': -6.529804856143342, 'test_avg': -6.779532803797338, 'test_std': 1.2728238140744799}
    Episode Length: {'avg': 4.977777777777778, 'std': 0.5854195498808662, 'run': 4.969390902539438, 'test_avg': 5.0625, 'test_std': 0.3903123748998999}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 5000):
    Value Loss: {'avg': 2.0418648639072976, 'std': 0.9689416557243749}
    Value Grad Norm: {'avg': 29.852575480937958, 'std': 14.691117216688642}
    Policy Loss: {'avg': 0.003303648380097002, 'std': 0.018013727163277152}
    Total_Loss: {'avg': -0.041353765525855124, 'std': 0.017175455537680046}
    Policy Entropy: {'avg': 0.5016525983810425, 'std': 0.5606696605682373}
    KL Divergence: {'avg': 0.06716962158679962, 'std': 0.4402376115322113}
    Policy Grad Norm: {'avg': 3.2055127397179604, 'std': 1.9931685657617104}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.8416478083382275, 'std': 3.1668061771045988, 'run': -6.810393506557545, 'test_avg': -6.8492158733312944, 'test_std': 1.7648330974138766}
    Episode Length: {'avg': 5.040963855421687, 'std': 1.071316737902679, 'run': 5.038588456530881, 'test_avg': 5.0888671875, 'test_std': 0.5969593248168922}
    Ratio Terminated: {'avg': 0.9951807228915662, 'test_avg': 0.9990234375}

Iteration (1701 / 5000):
    Value Loss: {'avg': 0.8120228502278527, 'std': 0.5431294727965459}
    Value Grad Norm: {'avg': 13.672778556744257, 'std': 6.308325778197483}
    Policy Loss: {'avg': 0.005583179066888988, 'std': 0.013395127336451054}
    Total_Loss: {'avg': -0.03327210480347276, 'std': 0.013044542631081834}
    Policy Entropy: {'avg': 0.37627696990966797, 'std': 0.4516693651676178}
    KL Divergence: {'avg': 0.016967376694083214, 'std': 0.22550712525844574}
    Policy Grad Norm: {'avg': 1.9827797040343285, 'std': 1.2354125385835957}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.435808153912298, 'std': 2.0312087552184708, 'run': -6.47915771240898, 'test_avg': -6.731376342817384, 'test_std': 1.127055600264725}
    Episode Length: {'avg': 4.894366197183099, 'std': 0.7287626642667697, 'run': 4.910320794097408, 'test_avg': 5.0546875, 'test_std': 0.35208294810136714}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 5000):
    Value Loss: {'avg': 1.0467408709228039, 'std': 0.42169863342983765}
    Value Grad Norm: {'avg': 19.133869002262752, 'std': 9.455937151473604}
    Policy Loss: {'avg': -0.009643927274737507, 'std': 0.015775337055556456}
    Total_Loss: {'avg': -0.05267056031152606, 'std': 0.016642262191750266}
    Policy Entropy: {'avg': 0.4616081714630127, 'std': 0.4686511754989624}
    KL Divergence: {'avg': 0.04602159559726715, 'std': 0.4083009362220764}
    Policy Grad Norm: {'avg': 1.6151040401309729, 'std': 0.8255573206585856}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.749322941804277, 'std': 2.3548656385782065, 'run': -6.5164118086092895, 'test_avg': -6.665460241649747, 'test_std': 1.1672788239197591}
    Episode Length: {'avg': 4.988151658767772, 'std': 0.7863479059120837, 'run': 4.929264731839417, 'test_avg': 5.037109375, 'test_std': 0.3488119397140949}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1901 / 5000):
    Value Loss: {'avg': 1.0794018727416794, 'std': 0.593253206341669}
    Value Grad Norm: {'avg': 11.084217220544815, 'std': 4.343847684021291}
    Policy Loss: {'avg': -0.00017547706374898553, 'std': 0.011609063040182936}
    Total_Loss: {'avg': -0.04640277265571058, 'std': 0.01190149108955832}
    Policy Entropy: {'avg': 0.44201913475990295, 'std': 0.5271342396736145}
    KL Divergence: {'avg': 0.021158114075660706, 'std': 0.2447642832994461}
    Policy Grad Norm: {'avg': 1.824160199612379, 'std': 1.3472554308379538}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.580574862212745, 'std': 1.842117121249068, 'run': -6.5505768148455195, 'test_avg': -6.60351038382214, 'test_std': 0.5930637375340252}
    Episode Length: {'avg': 4.952267303102626, 'std': 0.6463507734533939, 'run': 4.941425284676534, 'test_avg': 5.0078125, 'test_std': 0.11666550408646936}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 5000):
    Value Loss: {'avg': 0.4418240695570906, 'std': 0.2023295469277005}
    Value Grad Norm: {'avg': 10.734589790304502, 'std': 5.351039415456865}
    Policy Loss: {'avg': 0.002887367270886898, 'std': 0.019664126507562576}
    Total_Loss: {'avg': -0.03307689737994224, 'std': 0.019027101714287366}
    Policy Entropy: {'avg': 0.30866479873657227, 'std': 0.4301983416080475}
    KL Divergence: {'avg': 0.05135682225227356, 'std': 0.6356538534164429}
    Policy Grad Norm: {'avg': 4.344971340149641, 'std': 7.474175719384535}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.428128548074314, 'std': 2.2774054426822787, 'run': -6.429129425922465, 'test_avg': -6.600775654624158, 'test_std': 0.7299487660349085}
    Episode Length: {'avg': 4.912832929782082, 'std': 0.7824682890822231, 'run': 4.913967934025327, 'test_avg': 5.0048828125, 'test_std': 0.1950950938442324}
    Ratio Terminated: {'avg': 0.9975786924939467, 'test_avg': 1.0}

Iteration (2101 / 5000):
    Value Loss: {'avg': 0.7901676200951139, 'std': 0.5113492202089366}
    Value Grad Norm: {'avg': 15.177232712507248, 'std': 7.744252350358435}
    Policy Loss: {'avg': -0.0031869898084551096, 'std': 0.012386696348294922}
    Total_Loss: {'avg': -0.03959108318667859, 'std': 0.013602048730022307}
    Policy Entropy: {'avg': 0.3533255457878113, 'std': 0.4573652148246765}
    KL Divergence: {'avg': 0.030054356902837753, 'std': 0.29543420672416687}
    Policy Grad Norm: {'avg': 4.878052584826946, 'std': 3.440771384959317}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.612007492143302, 'std': 2.3397310039762305, 'run': -6.564919279930117, 'test_avg': -6.769305847915042, 'test_std': 2.184576793893302}
    Episode Length: {'avg': 4.96642685851319, 'std': 0.800973592254858, 'run': 4.943607971251931, 'test_avg': 5.05078125, 'test_std': 0.45859774274241416}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (2201 / 5000):
    Value Loss: {'avg': 0.4486225734775265, 'std': 0.22046007227287123}
    Value Grad Norm: {'avg': 7.334919313589732, 'std': 2.378129916729024}
    Policy Loss: {'avg': 0.004642247164156288, 'std': 0.01267715470643813}
    Total_Loss: {'avg': -0.03351993835531175, 'std': 0.01272272564160297}
    Policy Entropy: {'avg': 0.4100527763366699, 'std': 0.476364403963089}
    KL Divergence: {'avg': 0.019528385251760483, 'std': 0.22411146759986877}
    Policy Grad Norm: {'avg': 2.6776090748608112, 'std': 1.592686873679633}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.242549358818178, 'std': 2.018278328675864, 'run': -6.103363598090082, 'test_avg': -6.645327180406788, 'test_std': 0.8608484879990543}
    Episode Length: {'avg': 4.8585365853658535, 'std': 0.7453843695823038, 'run': 4.811734680437579, 'test_avg': 5.029296875, 'test_std': 0.27443317604698303}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 5000):
    Value Loss: {'avg': 0.814992809202522, 'std': 0.5139596008035507}
    Value Grad Norm: {'avg': 19.110202342271805, 'std': 10.3331598252722}
    Policy Loss: {'avg': 0.01433373527834192, 'std': 0.035386671352199583}
    Total_Loss: {'avg': -0.02510182245168835, 'std': 0.0356055979820486}
    Policy Entropy: {'avg': 0.4355006814002991, 'std': 0.45685771107673645}
    KL Divergence: {'avg': 0.027727855369448662, 'std': 0.18823407590389252}
    Policy Grad Norm: {'avg': 2.382704447954893, 'std': 2.7622151481897492}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.571701225243969, 'std': 2.2727028631232753, 'run': -6.61297714395796, 'test_avg': -6.9927095410871765, 'test_std': 2.555733340172137}
    Episode Length: {'avg': 4.97323600973236, 'std': 0.7994913165406993, 'run': 4.985180675108692, 'test_avg': 5.1689453125, 'test_std': 0.9311097109816208}
    Ratio Terminated: {'avg': 0.9975669099756691, 'test_avg': 0.986328125}

Iteration (2401 / 5000):
    Value Loss: {'avg': 0.6718365084379911, 'std': 0.3499684021135285}
    Value Grad Norm: {'avg': 9.417067940036455, 'std': 4.114014728573449}
    Policy Loss: {'avg': 0.005445163580588996, 'std': 0.029725989300406982}
    Total_Loss: {'avg': -0.037366846576333046, 'std': 0.027607679911344284}
    Policy Entropy: {'avg': 0.47772300243377686, 'std': 0.49322912096977234}
    KL Divergence: {'avg': 0.047723859548568726, 'std': 0.3171994090080261}
    Policy Grad Norm: {'avg': 2.626917991787195, 'std': 1.798216517598583}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.331836223295491, 'std': 2.1446221741429996, 'run': -6.222428353223393, 'test_avg': -6.756367084814231, 'test_std': 2.2127072778387524}
    Episode Length: {'avg': 4.876777251184834, 'std': 0.7471786063681459, 'run': 4.8255902755160465, 'test_avg': 5.041015625, 'test_std': 0.45099428322968727}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (2501 / 5000):
    Value Loss: {'avg': 0.5709161289657155, 'std': 0.3593033643345587}
    Value Grad Norm: {'avg': 16.417088667551678, 'std': 8.654419843027965}
    Policy Loss: {'avg': 0.004131939786020666, 'std': 0.010949246300006233}
    Total_Loss: {'avg': -0.03387456003110856, 'std': 0.010519233094351968}
    Policy Entropy: {'avg': 0.44345933198928833, 'std': 0.5188290476799011}
    KL Divergence: {'avg': 0.03475457429885864, 'std': 0.35142257809638977}
    Policy Grad Norm: {'avg': 2.640692938119173, 'std': 1.64849497125436}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.240041104183529, 'std': 2.096754365557656, 'run': -6.130903247739134, 'test_avg': -6.539450638592825, 'test_std': 0.5136967241335452}
    Episode Length: {'avg': 4.872289156626506, 'std': 0.7544747240030839, 'run': 4.814343883828951, 'test_avg': 5.0009765625, 'test_std': 0.08267396098944088}
    Ratio Terminated: {'avg': 0.9975903614457832, 'test_avg': 1.0}

Iteration (2601 / 5000):
    Value Loss: {'avg': 1.3234365383783977, 'std': 0.6364591294659369}
    Value Grad Norm: {'avg': 22.55984153350194, 'std': 9.295658896400086}
    Policy Loss: {'avg': -0.011582310951780528, 'std': 0.011727009460038199}
    Total_Loss: {'avg': -0.0509586816187948, 'std': 0.013945323609879563}
    Policy Entropy: {'avg': 0.36408308148384094, 'std': 0.3614620864391327}
    KL Divergence: {'avg': 0.09120200574398041, 'std': 0.5660707950592041}
    Policy Grad Norm: {'avg': 2.078825334087014, 'std': 1.9839370494001367}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.558497154349511, 'std': 2.1622409523398987, 'run': -6.686339515476798, 'test_avg': -6.559284303315508, 'test_std': 0.5063661843428707}
    Episode Length: {'avg': 4.979539641943734, 'std': 0.8214457922498517, 'run': 5.0265587143448665, 'test_avg': 4.9990234375, 'test_std': 0.06987030002571618}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 5000):
    Value Loss: {'avg': 0.9144867453724146, 'std': 0.351121126510422}
    Value Grad Norm: {'avg': 16.187954525152843, 'std': 5.952522213503643}
    Policy Loss: {'avg': 0.004344686982221901, 'std': 0.04789546601618118}
    Total_Loss: {'avg': -0.04682468203827739, 'std': 0.04652835629197992}
    Policy Entropy: {'avg': 0.4343961775302887, 'std': 0.49249252676963806}
    KL Divergence: {'avg': 0.03549143671989441, 'std': 0.3352164924144745}
    Policy Grad Norm: {'avg': 4.4905469454824924, 'std': 5.305388497376658}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.650346080650249, 'std': 2.2622462122824523, 'run': -6.526869512536658, 'test_avg': -6.571921799069969, 'test_std': 0.5441947112685281}
    Episode Length: {'avg': 5.0, 'std': 0.8422348876123157, 'run': 4.9471604962691025, 'test_avg': 5.0029296875, 'test_std': 0.11263538267858969}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 5000):
    Value Loss: {'avg': 0.4266806106703977, 'std': 0.20661596509746788}
    Value Grad Norm: {'avg': 10.915360187490782, 'std': 5.579301870988861}
    Policy Loss: {'avg': -0.0007257999386638403, 'std': 0.011001556294918854}
    Total_Loss: {'avg': -0.038031450007110834, 'std': 0.011377168986812876}
    Policy Entropy: {'avg': 0.38799500465393066, 'std': 0.480557382106781}
    KL Divergence: {'avg': 0.02786615677177906, 'std': 0.30721673369407654}
    Policy Grad Norm: {'avg': 2.264715038239956, 'std': 1.2611985441224773}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.329567297725664, 'std': 2.241319231326093, 'run': -6.1229264718805165, 'test_avg': -6.54284008077957, 'test_std': 0.6733679335157801}
    Episode Length: {'avg': 4.90453460620525, 'std': 0.8148112571881888, 'run': 4.824724020855217, 'test_avg': 5.0087890625, 'test_std': 0.1737705092366685}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 5000):
    Value Loss: {'avg': 0.6512964454789957, 'std': 0.49850847484628136}
    Value Grad Norm: {'avg': 14.016486451029778, 'std': 6.779333009584737}
    Policy Loss: {'avg': 0.0019145941478200257, 'std': 0.010139790746042881}
    Total_Loss: {'avg': -0.03557958477176726, 'std': 0.009376015691536788}
    Policy Entropy: {'avg': 0.37158170342445374, 'std': 0.4807485044002533}
    KL Divergence: {'avg': 0.03143913298845291, 'std': 0.29573097825050354}
    Policy Grad Norm: {'avg': 3.0727238059043884, 'std': 1.4560033540020831}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.371644612118269, 'std': 1.9608576114829588, 'run': -6.664813977547911, 'test_avg': -6.5565428015224825, 'test_std': 0.5245118557620735}
    Episode Length: {'avg': 4.915211970074813, 'std': 0.6975504110932186, 'run': 5.012394685853751, 'test_avg': 5.0048828125, 'test_std': 0.10352944335835021}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 5000):
    Value Loss: {'avg': 0.5726077745979031, 'std': 0.3710899773955272}
    Value Grad Norm: {'avg': 12.571153725186983, 'std': 6.541083650937396}
    Policy Loss: {'avg': 0.01002001203596592, 'std': 0.02722731075790318}
    Total_Loss: {'avg': -0.025674867443740368, 'std': 0.027070711228083945}
    Policy Entropy: {'avg': 0.3401455879211426, 'std': 0.45764172077178955}
    KL Divergence: {'avg': 0.053002599626779556, 'std': 0.46838775277137756}
    Policy Grad Norm: {'avg': 5.670704077929258, 'std': 5.968103961840151}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.288399188754972, 'std': 2.4463433375971615, 'run': -6.294530517247775, 'test_avg': -6.648968943616637, 'test_std': 1.1452325022183174}
    Episode Length: {'avg': 4.88, 'std': 0.8441912245039105, 'run': 4.877694248921186, 'test_avg': 5.046875, 'test_std': 0.3640993811790951}
    Ratio Terminated: {'avg': 0.9976470588235294, 'test_avg': 1.0}

Iteration (3101 / 5000):
    Value Loss: {'avg': 0.5194566308831176, 'std': 0.3110228302714876}
    Value Grad Norm: {'avg': 8.443479885657629, 'std': 3.6999441323769564}
    Policy Loss: {'avg': 0.012066228780895472, 'std': 0.024966461400808045}
    Total_Loss: {'avg': -0.028659627656452358, 'std': 0.02454964924915355}
    Policy Entropy: {'avg': 0.3519012928009033, 'std': 0.4687950611114502}
    KL Divergence: {'avg': 0.032158173620700836, 'std': 0.3180375099182129}
    Policy Grad Norm: {'avg': 5.7550122030079365, 'std': 10.863239217017323}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.2846401658358975, 'std': 2.1664801451714744, 'run': -6.2439472690444076, 'test_avg': -6.5750536206614925, 'test_std': 0.665879539123354}
    Episode Length: {'avg': 4.859122401847575, 'std': 0.7784725770039161, 'run': 4.853745798290743, 'test_avg': 5.005859375, 'test_std': 0.1464583310181069}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 5000):
    Value Loss: {'avg': 0.7789083973815044, 'std': 0.3735262336104025}
    Value Grad Norm: {'avg': 17.188209464152653, 'std': 6.9701855588534265}
    Policy Loss: {'avg': -0.006554513704031706, 'std': 0.011199795885709567}
    Total_Loss: {'avg': -0.050850421423092484, 'std': 0.01134063855572948}
    Policy Entropy: {'avg': 0.44713926315307617, 'std': 0.5240816473960876}
    KL Divergence: {'avg': 0.01647784188389778, 'std': 0.22058868408203125}
    Policy Grad Norm: {'avg': 2.020269550383091, 'std': 1.3579257464433265}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.688582897793964, 'std': 2.3197482840122032, 'run': -6.7056384871716554, 'test_avg': -6.561134056809706, 'test_std': 0.7674300495978428}
    Episode Length: {'avg': 5.079326923076923, 'std': 0.9908016998905065, 'run': 5.06846244826035, 'test_avg': 5.017578125, 'test_std': 0.2532669234651149}
    Ratio Terminated: {'avg': 0.9951923076923077, 'test_avg': 0.9990234375}

Iteration (3301 / 5000):
    Value Loss: {'avg': 0.7531174859032035, 'std': 0.5626174444939565}
    Value Grad Norm: {'avg': 17.155902087688446, 'std': 8.837244100729778}
    Policy Loss: {'avg': -0.004646079847589135, 'std': 0.008081081992585908}
    Total_Loss: {'avg': -0.04512130096554756, 'std': 0.009332125836082745}
    Policy Entropy: {'avg': 0.3450603783130646, 'std': 0.47403907775878906}
    KL Divergence: {'avg': 0.04118652641773224, 'std': 0.44409510493278503}
    Policy Grad Norm: {'avg': 2.4850765466690063, 'std': 1.2912297269557034}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.39806153675783, 'std': 2.7499236780865575, 'run': -6.55646395951417, 'test_avg': -6.51401281166909, 'test_std': 0.524100365162356}
    Episode Length: {'avg': 4.914893617021277, 'std': 0.9588904272996069, 'run': 4.941608650014306, 'test_avg': 4.9990234375, 'test_std': 0.08267396098944088}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 5000):
    Value Loss: {'avg': 0.326760108427455, 'std': 0.23147225056496795}
    Value Grad Norm: {'avg': 8.542707681655884, 'std': 4.959515436752551}
    Policy Loss: {'avg': 0.008594768994953483, 'std': 0.021131833459049065}
    Total_Loss: {'avg': -0.02548835938796401, 'std': 0.02085111155485368}
    Policy Entropy: {'avg': 0.3530576229095459, 'std': 0.5034675002098083}
    KL Divergence: {'avg': 0.029703624546527863, 'std': 0.2413512021303177}
    Policy Grad Norm: {'avg': 3.7144758254289627, 'std': 2.1608050000874024}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.270073837169023, 'std': 1.8260072886060115, 'run': -6.459686004716493, 'test_avg': -6.78560366395206, 'test_std': 2.126540816298731}
    Episode Length: {'avg': 4.894088669950739, 'std': 0.6629643326932108, 'run': 4.9631770561881865, 'test_avg': 5.0830078125, 'test_std': 0.5554632216123447}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3501 / 5000):
    Value Loss: {'avg': 0.33165460840488475, 'std': 0.28477894417109934}
    Value Grad Norm: {'avg': 11.35577167570591, 'std': 9.353040609560717}
    Policy Loss: {'avg': -0.002357473480515182, 'std': 0.012546325832407959}
    Total_Loss: {'avg': -0.03562205738853663, 'std': 0.011177221642727653}
    Policy Entropy: {'avg': 0.30348682403564453, 'std': 0.4236755967140198}
    KL Divergence: {'avg': 0.015286742709577084, 'std': 0.13065731525421143}
    Policy Grad Norm: {'avg': 2.398037441074848, 'std': 1.7177298224014166}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.13268642588094, 'std': 2.2226131629836434, 'run': -6.015433159271901, 'test_avg': -6.597137163455436, 'test_std': 1.2186384949960176}
    Episode Length: {'avg': 4.844705882352941, 'std': 0.8113178650816781, 'run': 4.800997405033576, 'test_avg': 5.029296875, 'test_std': 0.39912146411241073}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (3601 / 5000):
    Value Loss: {'avg': 1.9159248912086089, 'std': 0.9853624715678713}
    Value Grad Norm: {'avg': 32.99472204844157, 'std': 21.312492532043567}
    Policy Loss: {'avg': -0.0006817735265940428, 'std': 0.014511885284391613}
    Total_Loss: {'avg': -0.04097172012552619, 'std': 0.014939378583466152}
    Policy Entropy: {'avg': 0.4642193913459778, 'std': 0.5017650127410889}
    KL Divergence: {'avg': 0.03920197859406471, 'std': 0.3174803555011749}
    Policy Grad Norm: {'avg': 4.3303543627262115, 'std': 3.2828715342211843}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.475775203724615, 'std': 3.9344158855791886, 'run': -6.975720539066886, 'test_avg': -6.606755825217988, 'test_std': 0.9543675345527275}
    Episode Length: {'avg': 5.301047120418848, 'std': 1.3482387009125294, 'run': 5.128770941804667, 'test_avg': 5.029296875, 'test_std': 0.2849086574943527}
    Ratio Terminated: {'avg': 0.9973821989528796, 'test_avg': 1.0}

Iteration (3701 / 5000):
    Value Loss: {'avg': 0.30297107451284927, 'std': 0.26489062138833724}
    Value Grad Norm: {'avg': 7.01094093422095, 'std': 3.3589718011151164}
    Policy Loss: {'avg': 0.0032577776873949915, 'std': 0.008655230292793227}
    Total_Loss: {'avg': -0.03021622053347528, 'std': 0.009831383027103803}
    Policy Entropy: {'avg': 0.2926301658153534, 'std': 0.3927787244319916}
    KL Divergence: {'avg': 0.030013432726264, 'std': 0.31798478960990906}
    Policy Grad Norm: {'avg': 2.5038402192294598, 'std': 1.2546931845803784}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.17306087788419, 'std': 2.0174205993680405, 'run': -6.110966919436323, 'test_avg': -6.6826717487108676, 'test_std': 2.168332143765197}
    Episode Length: {'avg': 4.836065573770492, 'std': 0.7379390729087149, 'run': 4.811442823071008, 'test_avg': 5.0458984375, 'test_std': 0.5123883009350024}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (3801 / 5000):
    Value Loss: {'avg': 0.19871609075926244, 'std': 0.09284620921264773}
    Value Grad Norm: {'avg': 6.271064688762029, 'std': 2.63576957604215}
    Policy Loss: {'avg': 0.002167183381970972, 'std': 0.011665697438486715}
    Total_Loss: {'avg': -0.031093981466256082, 'std': 0.01203530724209187}
    Policy Entropy: {'avg': 0.33947569131851196, 'std': 0.40689945220947266}
    KL Divergence: {'avg': 0.02840500697493553, 'std': 0.21615482866764069}
    Policy Grad Norm: {'avg': 2.326556034386158, 'std': 1.1868121305001862}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.3002476992880645, 'std': 1.7540551904920418, 'run': -6.273481962892001, 'test_avg': -6.554903941250814, 'test_std': 0.7631556561951238}
    Episode Length: {'avg': 4.876190476190477, 'std': 0.642839505930903, 'run': 4.866636245300075, 'test_avg': 5.01171875, 'test_std': 0.19228116365998388}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 5000):
    Value Loss: {'avg': 0.6620303792878985, 'std': 0.4439464000291964}
    Value Grad Norm: {'avg': 16.836275810996693, 'std': 7.0549358446189245}
    Policy Loss: {'avg': 0.00357719708699733, 'std': 0.010143476154711423}
    Total_Loss: {'avg': -0.039944741409271955, 'std': 0.011637897386724523}
    Policy Entropy: {'avg': 0.4780339002609253, 'std': 0.5835790634155273}
    KL Divergence: {'avg': 0.029969055205583572, 'std': 0.4249376952648163}
    Policy Grad Norm: {'avg': 3.7924793288111687, 'std': 4.236539318489058}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.521867893262599, 'std': 2.328215921368215, 'run': -6.359413166659797, 'test_avg': -6.537561557437584, 'test_std': 0.5103670501604319}
    Episode Length: {'avg': 4.946987951807229, 'std': 0.8626573332173304, 'run': 4.905379779903517, 'test_avg': 5.0029296875, 'test_std': 0.06981568184263721}
    Ratio Terminated: {'avg': 0.9975903614457832, 'test_avg': 1.0}

Iteration (4001 / 5000):
    Value Loss: {'avg': 0.43994975866129, 'std': 0.26085923421455764}
    Value Grad Norm: {'avg': 7.291311398148537, 'std': 3.2313735130785766}
    Policy Loss: {'avg': 0.004830491612665355, 'std': 0.014023761132506127}
    Total_Loss: {'avg': -0.028223411296494305, 'std': 0.014252592145871431}
    Policy Entropy: {'avg': 0.3700815439224243, 'std': 0.4416308104991913}
    KL Divergence: {'avg': 0.03020571544766426, 'std': 0.349237322807312}
    Policy Grad Norm: {'avg': 3.707395577803254, 'std': 2.258707561911751}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -5.895783104680408, 'std': 2.289428491631237, 'run': -6.003058535995016, 'test_avg': -6.53701359409024, 'test_std': 0.6089713737436504}
    Episode Length: {'avg': 4.750593824228028, 'std': 0.8536805205817731, 'run': 4.7844247946657745, 'test_avg': 5.00390625, 'test_std': 0.1396996464238099}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 5000):
    Value Loss: {'avg': 0.32943788388123113, 'std': 0.21244481209523128}
    Value Grad Norm: {'avg': 5.565037568410237, 'std': 2.187031731559852}
    Policy Loss: {'avg': 0.009109979786444455, 'std': 0.016789596673810553}
    Total_Loss: {'avg': -0.028306949068792164, 'std': 0.016007206599648195}
    Policy Entropy: {'avg': 0.39838719367980957, 'std': 0.44068583846092224}
    KL Divergence: {'avg': 0.026046644896268845, 'std': 0.16721634566783905}
    Policy Grad Norm: {'avg': 3.299310214817524, 'std': 2.6194209589873685}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.175089086954544, 'std': 2.0955186553449154, 'run': -6.032057028375118, 'test_avg': -6.604067653385705, 'test_std': 1.3161819364285077}
    Episode Length: {'avg': 4.84652278177458, 'std': 0.7652172588996677, 'run': 4.801293735012793, 'test_avg': 5.0234375, 'test_std': 0.3178257126063749}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4201 / 5000):
    Value Loss: {'avg': 0.2003325461409986, 'std': 0.09871167533654261}
    Value Grad Norm: {'avg': 4.663623029987018, 'std': 1.372945068400327}
    Policy Loss: {'avg': 0.0010060056811198592, 'std': 0.014305464958490294}
    Total_Loss: {'avg': -0.03243869310244918, 'std': 0.015537003499633403}
    Policy Entropy: {'avg': 0.3045666813850403, 'std': 0.4275173842906952}
    KL Divergence: {'avg': 0.019165176898241043, 'std': 0.22219575941562653}
    Policy Grad Norm: {'avg': 3.145136784762144, 'std': 3.2644006241013686}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.2401697535627, 'std': 1.6016877799479963, 'run': -6.222963024571459, 'test_avg': -6.592879089061455, 'test_std': 1.0653541804183069}
    Episode Length: {'avg': 4.894736842105263, 'std': 0.5937642892818592, 'run': 4.894627660665913, 'test_avg': 5.033203125, 'test_std': 0.3709035285491827}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4301 / 5000):
    Value Loss: {'avg': 0.35344994300976396, 'std': 0.29974102895714977}
    Value Grad Norm: {'avg': 6.482489928603172, 'std': 3.2091636568538484}
    Policy Loss: {'avg': 0.010386150795966387, 'std': 0.02887737065447683}
    Total_Loss: {'avg': -0.026217499980702996, 'std': 0.030007382261333374}
    Policy Entropy: {'avg': 0.32501649856567383, 'std': 0.4598882496356964}
    KL Divergence: {'avg': 0.0177453700453043, 'std': 0.2382357120513916}
    Policy Grad Norm: {'avg': 5.865758802741766, 'std': 11.347737398630466}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.372818913193105, 'std': 2.105033377959524, 'run': -6.4130535170801855, 'test_avg': -6.540013991689193, 'test_std': 0.5553366846000907}
    Episode Length: {'avg': 4.907542579075426, 'std': 0.7488622643780409, 'run': 4.910480289242906, 'test_avg': 5.0029296875, 'test_std': 0.1288137392949694}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 5000):
    Value Loss: {'avg': 0.283383481670171, 'std': 0.2059073765192409}
    Value Grad Norm: {'avg': 6.077697267134984, 'std': 2.582146406789365}
    Policy Loss: {'avg': 0.0033892650972120464, 'std': 0.014629528964452227}
    Total_Loss: {'avg': -0.03384781221393496, 'std': 0.013656672094049282}
    Policy Entropy: {'avg': 0.3930211067199707, 'std': 0.5015440583229065}
    KL Divergence: {'avg': 0.03173094987869263, 'std': 0.27797839045524597}
    Policy Grad Norm: {'avg': 2.7331769466400146, 'std': 1.4013978650820793}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.451811915829823, 'std': 2.085592766665525, 'run': -6.52880657970079, 'test_avg': -6.516466162036522, 'test_std': 0.5042976087811128}
    Episode Length: {'avg': 4.923611111111111, 'std': 0.6709569704331564, 'run': 4.96261713282701, 'test_avg': 5.0009765625, 'test_std': 0.06987030002571618}
    Ratio Terminated: {'avg': 0.9976851851851852, 'test_avg': 1.0}

Iteration (4501 / 5000):
    Value Loss: {'avg': 0.33253962205102044, 'std': 0.2584867815717742}
    Value Grad Norm: {'avg': 4.984416350722313, 'std': 2.1645821562495136}
    Policy Loss: {'avg': 0.0012547234073281288, 'std': 0.027070648803191922}
    Total_Loss: {'avg': -0.03159899660386145, 'std': 0.0281162551749082}
    Policy Entropy: {'avg': 0.2973250448703766, 'std': 0.4340212941169739}
    KL Divergence: {'avg': 0.017528774216771126, 'std': 0.29795920848846436}
    Policy Grad Norm: {'avg': 3.648660162463784, 'std': 4.5367350255744645}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.083142102493702, 'std': 1.9578701648547103, 'run': -6.121676121644593, 'test_avg': -6.5435301893012365, 'test_std': 0.6673065867312216}
    Episode Length: {'avg': 4.815420560747664, 'std': 0.7273338592110404, 'run': 4.8435294017397235, 'test_avg': 5.0107421875, 'test_std': 0.1736607120442469}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4601 / 5000):
    Value Loss: {'avg': 0.7440281144032875, 'std': 0.5380932199048537}
    Value Grad Norm: {'avg': 13.79675136009852, 'std': 6.648580036520334}
    Policy Loss: {'avg': -0.0031866441713646054, 'std': 0.013663868479891964}
    Total_Loss: {'avg': -0.04141935135703534, 'std': 0.01320145479469626}
    Policy Entropy: {'avg': 0.3626229166984558, 'std': 0.39989572763442993}
    KL Divergence: {'avg': 0.027732158079743385, 'std': 0.23928721249103546}
    Policy Grad Norm: {'avg': 1.8358163889497519, 'std': 1.4437558751305573}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.399010529826035, 'std': 2.264691733203767, 'run': -6.378918362789931, 'test_avg': -6.519353584480996, 'test_std': 0.5200407124918089}
    Episode Length: {'avg': 4.928571428571429, 'std': 0.8100544930832239, 'run': 4.9377203413335895, 'test_avg': 5.00390625, 'test_std': 0.07644681949523799}
    Ratio Terminated: {'avg': 0.9976958525345622, 'test_avg': 1.0}

Iteration (4701 / 5000):
    Value Loss: {'avg': 0.6123255571971337, 'std': 0.48745205413410847}
    Value Grad Norm: {'avg': 15.107949356238047, 'std': 11.419995396064229}
    Policy Loss: {'avg': -0.0010450333647895604, 'std': 0.03392941227737684}
    Total_Loss: {'avg': -0.036179846501909196, 'std': 0.03378235450571888}
    Policy Entropy: {'avg': 0.3744776248931885, 'std': 0.4836670756340027}
    KL Divergence: {'avg': 0.019985567778348923, 'std': 0.2402256578207016}
    Policy Grad Norm: {'avg': 2.3661225363612175, 'std': 2.1565233292440142}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.2361779843333744, 'std': 2.2098666737597985, 'run': -6.1460747346031654, 'test_avg': -6.545291199698113, 'test_std': 0.5199311518210215}
    Episode Length: {'avg': 4.88, 'std': 0.7528455821669111, 'run': 4.8636592001260945, 'test_avg': 5.00390625, 'test_std': 0.09874394265441046}
    Ratio Terminated: {'avg': 0.9976470588235294, 'test_avg': 1.0}

Iteration (4801 / 5000):
    Value Loss: {'avg': 0.19783729764943322, 'std': 0.12267983991424607}
    Value Grad Norm: {'avg': 4.610938156644504, 'std': 1.6410279112740664}
    Policy Loss: {'avg': 0.002247805881779641, 'std': 0.009218571470473431}
    Total_Loss: {'avg': -0.03285510861314833, 'std': 0.007815617628712714}
    Policy Entropy: {'avg': 0.26671934127807617, 'std': 0.4302496314048767}
    KL Divergence: {'avg': 0.01994732767343521, 'std': 0.33956512808799744}
    Policy Grad Norm: {'avg': 2.883371092379093, 'std': 1.4728774530471422}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.185968571722851, 'std': 1.8133236441739207, 'run': -6.365950710199992, 'test_avg': -6.533645189475024, 'test_std': 0.5732560990749435}
    Episode Length: {'avg': 4.86013986013986, 'std': 0.6683110110410934, 'run': 4.924749251581612, 'test_avg': 5.009765625, 'test_std': 0.11651827139277074}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4901 / 5000):
    Value Loss: {'avg': 0.7819717869473001, 'std': 1.3120380657569115}
    Value Grad Norm: {'avg': 15.098378891746203, 'std': 15.573891976251346}
    Policy Loss: {'avg': -0.0021353126503527164, 'std': 0.022206430866333966}
    Total_Loss: {'avg': -0.038653024355880916, 'std': 0.02348961918445836}
    Policy Entropy: {'avg': 0.34520789980888367, 'std': 0.47168466448783875}
    KL Divergence: {'avg': 0.025190886110067368, 'std': 0.2751839756965637}
    Policy Grad Norm: {'avg': 2.1711594201624393, 'std': 1.7138073208220501}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.372605884060041, 'std': 2.324667417765359, 'run': -6.526461845034921, 'test_avg': -6.549760387068474, 'test_std': 0.686951594514476}
    Episode Length: {'avg': 4.914691943127962, 'std': 0.7136597320557154, 'run': 4.942353568157865, 'test_avg': 5.01171875, 'test_std': 0.17638784226368182}
    Ratio Terminated: {'avg': 0.9976303317535545, 'test_avg': 1.0}

Training took 8061.573 seconds in total.
