
Iteration (1 / 4000):
    Value Loss: {'avg': 3408.2235959653503, 'std': 358.48492749745884}
    Value Grad Norm: {'avg': 220.3508313694486, 'std': 283.1916154141756}
    Policy Loss: {'avg': 0.00020751586589203388, 'std': 0.004976480466866884}
    Total_Loss: {'avg': -0.2702430693777623, 'std': 0.0050383690511894026}
    Policy Entropy: {'avg': 2.7044832706451416, 'std': 0.006029157433658838}
    KL Divergence: {'avg': 0.0011268343077972531, 'std': 0.05357932671904564}
    Policy Grad Norm: {'avg': 0.038347397441544605, 'std': 0.03282293466184338}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -130.91640326354252, 'std': 164.46113699608912, 'run': -381.3795115258235, 'test_avg': -472.2235177701252, 'test_std': 24.810352350253932}
    Episode Length: {'avg': 32.885162601626014, 'std': 30.958962205268108, 'run': 73.73861257501372, 'test_avg': 87.916015625, 'test_std': 3.189150513813335}
    Ratio Terminated: {'avg': 0.8770325203252033, 'test_avg': 0.4921875}

Iteration (101 / 4000):
    Value Loss: {'avg': 531.4522315837719, 'std': 158.84941415583728}
    Value Grad Norm: {'avg': 23453.978245035807, 'std': 15274.13623399052}
    Policy Loss: {'avg': 0.006268483533575717, 'std': 0.013460111422616907}
    Total_Loss: {'avg': -0.21720350024600824, 'std': 0.013747785456000196}
    Policy Entropy: {'avg': 2.2679576873779297, 'std': 0.43790557980537415}
    KL Divergence: {'avg': 0.01848810538649559, 'std': 0.1879315972328186}
    Policy Grad Norm: {'avg': 1.3028963619636165, 'std': 0.585044941484906}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -108.64227542553778, 'std': 175.62280647740417, 'run': -107.55558650900656, 'test_avg': -420.2517442513211, 'test_std': 25.60897665368692}
    Episode Length: {'avg': 24.017478813559322, 'std': 30.552195744824292, 'run': 24.097292852132632, 'test_avg': 79.541015625, 'test_std': 4.8281277653460934}
    Ratio Terminated: {'avg': 0.8569915254237288, 'test_avg': 0.984375}

Iteration (201 / 4000):
    Value Loss: {'avg': 296.1145645706742, 'std': 96.99451088199761}
    Value Grad Norm: {'avg': 17511.24265362775, 'std': 11595.238292657805}
    Policy Loss: {'avg': -0.0004836736660864618, 'std': 0.012127975032493707}
    Total_Loss: {'avg': -0.224044828682586, 'std': 0.01189728453133686}
    Policy Entropy: {'avg': 2.2925145626068115, 'std': 0.2819333076477051}
    KL Divergence: {'avg': 0.010664080269634724, 'std': 0.13012094795703888}
    Policy Grad Norm: {'avg': 1.7897769890173718, 'std': 1.3513754853306934}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -108.48363853396826, 'std': 174.45426658328944, 'run': -94.07036813570562, 'test_avg': -399.85119945709755, 'test_std': 26.191138451707758}
    Episode Length: {'avg': 23.70606372045221, 'std': 30.70176025002809, 'run': 21.09301430297184, 'test_avg': 74.9833984375, 'test_std': 4.536389087217118}
    Ratio Terminated: {'avg': 0.8854059609455293, 'test_avg': 0.9931640625}

Iteration (301 / 4000):
    Value Loss: {'avg': 208.56629157596166, 'std': 93.62252859495995}
    Value Grad Norm: {'avg': 13134.569219518591, 'std': 8051.551508648765}
    Policy Loss: {'avg': 0.0008549755081292932, 'std': 0.011686088974618364}
    Total_Loss: {'avg': -0.21437889320982828, 'std': 0.011956643646861222}
    Policy Entropy: {'avg': 2.1672253608703613, 'std': 0.3582685887813568}
    KL Divergence: {'avg': 0.00921880267560482, 'std': 0.13643282651901245}
    Policy Grad Norm: {'avg': 2.4224801782656598, 'std': 1.7414491247086172}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -109.6186737202946, 'std': 175.8348486673946, 'run': -104.402141217466, 'test_avg': -388.3092318169032, 'test_std': 22.759285232598433}
    Episode Length: {'avg': 23.69596320899336, 'std': 31.209546923445732, 'run': 22.318979943419052, 'test_avg': 72.9453125, 'test_std': 4.1331521599553716}
    Ratio Terminated: {'avg': 0.912621359223301, 'test_avg': 0.9990234375}

Iteration (401 / 4000):
    Value Loss: {'avg': 147.06034158777308, 'std': 46.74802722637872}
    Value Grad Norm: {'avg': 10777.928591579861, 'std': 6869.490016819168}
    Policy Loss: {'avg': 0.0002154198095754341, 'std': 0.011778838010567306}
    Total_Loss: {'avg': -0.21091857581502862, 'std': 0.011720325286950889}
    Policy Entropy: {'avg': 2.1054039001464844, 'std': 0.3236492872238159}
    KL Divergence: {'avg': 0.00893283262848854, 'std': 0.13982857763767242}
    Policy Grad Norm: {'avg': 2.308502713452887, 'std': 1.1757616578791528}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -103.19042860497615, 'std': 166.49431314078626, 'run': -80.91513898106396, 'test_avg': -382.773555412378, 'test_std': 22.254307389236025}
    Episode Length: {'avg': 22.741116751269036, 'std': 29.86478810063808, 'run': 18.787368849002256, 'test_avg': 71.9013671875, 'test_std': 4.016936566688393}
    Ratio Terminated: {'avg': 0.9522842639593908, 'test_avg': 1.0}

Iteration (501 / 4000):
    Value Loss: {'avg': 128.06895668594925, 'std': 45.237542567921416}
    Value Grad Norm: {'avg': 8505.52084994846, 'std': 4889.394023689544}
    Policy Loss: {'avg': -0.0020820403997613875, 'std': 0.011994780271302859}
    Total_Loss: {'avg': -0.2078169930174395, 'std': 0.012378691792712695}
    Policy Entropy: {'avg': 2.062873601913452, 'std': 0.3403509259223938}
    KL Divergence: {'avg': 0.009306852705776691, 'std': 0.15076066553592682}
    Policy Grad Norm: {'avg': 2.561663103821101, 'std': 1.5950240060236738}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -101.96098831243974, 'std': 164.45457391770458, 'run': -120.22737183628641, 'test_avg': -382.60294729871475, 'test_std': 21.062279163074088}
    Episode Length: {'avg': 22.540218470705064, 'std': 29.610113297411367, 'run': 25.558407270001965, 'test_avg': 71.7392578125, 'test_std': 3.8315841305076046}
    Ratio Terminated: {'avg': 0.9702085402184707, 'test_avg': 0.9990234375}

Iteration (601 / 4000):
    Value Loss: {'avg': 108.63834931408917, 'std': 35.60082008350862}
    Value Grad Norm: {'avg': 7259.02767706977, 'std': 4136.17978408151}
    Policy Loss: {'avg': -0.0014118383653651647, 'std': 0.012335564582797274}
    Total_Loss: {'avg': -0.20138836625825476, 'std': 0.012613881745950515}
    Policy Entropy: {'avg': 2.011482000350952, 'std': 0.37281641364097595}
    KL Divergence: {'avg': 0.012335588224232197, 'std': 0.15631724894046783}
    Policy Grad Norm: {'avg': 3.2892355110910203, 'std': 2.4774218559250043}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -101.63740554540797, 'std': 164.8605193711049, 'run': -89.63308960981192, 'test_avg': -374.8593266018493, 'test_std': 22.01694590989478}
    Episode Length: {'avg': 22.25426944971537, 'std': 29.746092751048202, 'run': 20.183677816855738, 'test_avg': 70.37109375, 'test_std': 3.990342880469163}
    Ratio Terminated: {'avg': 0.9833965844402277, 'test_avg': 0.9990234375}

Iteration (701 / 4000):
    Value Loss: {'avg': 95.20404736554181, 'std': 28.293627570881547}
    Value Grad Norm: {'avg': 4962.096549705223, 'std': 2628.8437753697226}
    Policy Loss: {'avg': -0.0007179086579492799, 'std': 0.011960073550042487}
    Total_Loss: {'avg': -0.19278614730746657, 'std': 0.012259366892575731}
    Policy Entropy: {'avg': 1.9618337154388428, 'std': 0.31310662627220154}
    KL Divergence: {'avg': 0.010960854589939117, 'std': 0.15144936740398407}
    Policy Grad Norm: {'avg': 3.293660416757619, 'std': 2.259240373940641}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -97.32130376717264, 'std': 160.48986695425506, 'run': -97.81742158770668, 'test_avg': -374.0867475375727, 'test_std': 21.74642886005671}
    Episode Length: {'avg': 21.443413729128014, 'std': 28.935233291572644, 'run': 21.31303932349836, 'test_avg': 70.1669921875, 'test_std': 3.8250873580630764}
    Ratio Terminated: {'avg': 0.9897959183673469, 'test_avg': 1.0}

Iteration (801 / 4000):
    Value Loss: {'avg': 90.72261805357756, 'std': 17.054239246684382}
    Value Grad Norm: {'avg': 4455.80532543041, 'std': 2386.8724171518893}
    Policy Loss: {'avg': 0.0027883991029941375, 'std': 0.01179237077620629}
    Total_Loss: {'avg': -0.18670064869026343, 'std': 0.01174805862251741}
    Policy Entropy: {'avg': 1.9251837730407715, 'std': 0.3899102210998535}
    KL Divergence: {'avg': 0.016563933342695236, 'std': 0.18816301226615906}
    Policy Grad Norm: {'avg': 3.6350211593839856, 'std': 2.4166597932554947}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -85.9579206083746, 'std': 151.0248484110918, 'run': -68.04077645971024, 'test_avg': -374.10911935143963, 'test_std': 21.0831399421793}
    Episode Length: {'avg': 19.430247172182657, 'std': 27.395619293880777, 'run': 15.952333067338884, 'test_avg': 70.4189453125, 'test_std': 3.7704225741466004}
    Ratio Terminated: {'avg': 0.9941348973607038, 'test_avg': 1.0}

Iteration (901 / 4000):
    Value Loss: {'avg': 92.49327637354533, 'std': 23.281682242256988}
    Value Grad Norm: {'avg': 4156.549346697772, 'std': 2195.171969563979}
    Policy Loss: {'avg': 0.008001877242026643, 'std': 0.012744358297625945}
    Total_Loss: {'avg': -0.1752458594325516, 'std': 0.013466654914847635}
    Policy Entropy: {'avg': 1.9342772960662842, 'std': 0.4465557038784027}
    KL Divergence: {'avg': 0.01674344763159752, 'std': 0.17110538482666016}
    Policy Grad Norm: {'avg': 3.5016398390134174, 'std': 2.0386610043511855}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -94.46143161457246, 'std': 153.84181101870973, 'run': -102.678008270375, 'test_avg': -365.83017375151314, 'test_std': 21.887381497797694}
    Episode Length: {'avg': 20.916363636363638, 'std': 27.83329114330119, 'run': 22.468481180334166, 'test_avg': 68.5380859375, 'test_std': 3.781445584874222}
    Ratio Terminated: {'avg': 0.9990909090909091, 'test_avg': 1.0}

Iteration (1001 / 4000):
    Value Loss: {'avg': 133.04590644836426, 'std': 27.122241827493273}
    Value Grad Norm: {'avg': 3752.557208591037, 'std': 1614.7092858347567}
    Policy Loss: {'avg': 0.007362266491529428, 'std': 0.014518377861214047}
    Total_Loss: {'avg': -0.17771011599236064, 'std': 0.01480266433864261}
    Policy Entropy: {'avg': 1.805527925491333, 'std': 0.47368431091308594}
    KL Divergence: {'avg': 0.016169963404536247, 'std': 0.18066945672035217}
    Policy Grad Norm: {'avg': 4.1583376997047, 'std': 4.876958795312041}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -96.55798177550855, 'std': 153.6489635963937, 'run': -90.56622168742697, 'test_avg': -352.5762255037627, 'test_std': 27.6243154288354}
    Episode Length: {'avg': 21.172890733056708, 'std': 27.656776098554257, 'run': 19.900656067017945, 'test_avg': 65.716796875, 'test_std': 4.742785546489555}
    Ratio Terminated: {'avg': 0.9981558321807285, 'test_avg': 0.9970703125}

Iteration (1101 / 4000):
    Value Loss: {'avg': 104.40710244002166, 'std': 19.88113611563111}
    Value Grad Norm: {'avg': 3906.9448835584853, 'std': 1985.8136772249363}
    Policy Loss: {'avg': 0.006783874968661823, 'std': 0.012933455516299002}
    Total_Loss: {'avg': -0.17676200721826818, 'std': 0.013414208097155192}
    Policy Entropy: {'avg': 1.8055555820465088, 'std': 0.3891368806362152}
    KL Divergence: {'avg': 0.01711239293217659, 'std': 0.18262018263339996}
    Policy Grad Norm: {'avg': 4.089189221296046, 'std': 6.256711864653674}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -86.732510770688, 'std': 143.95570043128578, 'run': -83.40157841706906, 'test_avg': -349.71773334632064, 'test_std': 23.49065009606}
    Episode Length: {'avg': 19.519100169779286, 'std': 26.061229167938073, 'run': 19.1207178227963, 'test_avg': 65.517578125, 'test_std': 4.135602330316768}
    Ratio Terminated: {'avg': 0.9995755517826825, 'test_avg': 1.0}

Iteration (1201 / 4000):
    Value Loss: {'avg': 103.1050300138968, 'std': 24.273479134650326}
    Value Grad Norm: {'avg': 3159.286444091797, 'std': 1325.3985853716742}
    Policy Loss: {'avg': 0.005452283011335466, 'std': 0.013189795167079412}
    Total_Loss: {'avg': -0.18204831605156263, 'std': 0.013864245962749945}
    Policy Entropy: {'avg': 1.8648078441619873, 'std': 0.46617797017097473}
    KL Divergence: {'avg': 0.01714625582098961, 'std': 0.17659421265125275}
    Policy Grad Norm: {'avg': 3.3535589350594415, 'std': 1.9890300906922216}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -89.23941343223797, 'std': 145.71666678025682, 'run': -112.85515666670483, 'test_avg': -341.2173669341379, 'test_std': 22.798364268162256}
    Episode Length: {'avg': 20.013822894168467, 'std': 26.40535940811776, 'run': 24.41080024954425, 'test_avg': 63.82421875, 'test_std': 4.003216403986729}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 4000):
    Value Loss: {'avg': 103.3023624949985, 'std': 19.007801732282918}
    Value Grad Norm: {'avg': 3246.089518794307, 'std': 1364.4441980495315}
    Policy Loss: {'avg': 0.001976245229511901, 'std': 0.012888260795316577}
    Total_Loss: {'avg': -0.17951114270146246, 'std': 0.012982544488597562}
    Policy Entropy: {'avg': 1.8669872283935547, 'std': 0.40007126331329346}
    KL Divergence: {'avg': 0.014700638130307198, 'std': 0.17214477062225342}
    Policy Grad Norm: {'avg': 3.0602025582834527, 'std': 1.9474235930456605}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -87.82078002197387, 'std': 142.32670478280667, 'run': -86.8871711594839, 'test_avg': -336.8302854709485, 'test_std': 21.14018030271774}
    Episode Length: {'avg': 19.645612547689698, 'std': 25.725041465667022, 'run': 19.465351600183066, 'test_avg': 62.8720703125, 'test_std': 3.702332617088334}
    Ratio Terminated: {'avg': 0.9995760915642221, 'test_avg': 1.0}

Iteration (1401 / 4000):
    Value Loss: {'avg': 102.61358285833288, 'std': 19.489540208188014}
    Value Grad Norm: {'avg': 3045.4467617458768, 'std': 1157.3742721889075}
    Policy Loss: {'avg': 0.0013948954417611714, 'std': 0.013279830394273351}
    Total_Loss: {'avg': -0.18056320757777602, 'std': 0.013611461861900232}
    Policy Entropy: {'avg': 1.8279376029968262, 'std': 0.4317293167114258}
    KL Divergence: {'avg': 0.013665941543877125, 'std': 0.16433528065681458}
    Policy Grad Norm: {'avg': 3.2859418375072655, 'std': 3.012512895670358}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -90.8827899868661, 'std': 147.80641780160707, 'run': -88.22397059764596, 'test_avg': -341.9950586893727, 'test_std': 24.661508327577035}
    Episode Length: {'avg': 20.169439579684763, 'std': 26.592924566299704, 'run': 19.669968485969804, 'test_avg': 63.994140625, 'test_std': 4.208896460798793}
    Ratio Terminated: {'avg': 0.999124343257443, 'test_avg': 0.998046875}

Iteration (1501 / 4000):
    Value Loss: {'avg': 97.71687436986852, 'std': 20.04719662316938}
    Value Grad Norm: {'avg': 2552.072726666486, 'std': 845.1123673642097}
    Policy Loss: {'avg': 0.005347184636371417, 'std': 0.012537682186887365}
    Total_Loss: {'avg': -0.16897126467277607, 'std': 0.013210286137151327}
    Policy Entropy: {'avg': 1.7092900276184082, 'std': 0.4952685534954071}
    KL Divergence: {'avg': 0.01528272032737732, 'std': 0.1747136414051056}
    Policy Grad Norm: {'avg': 3.0361375308699077, 'std': 1.2703108332922821}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -91.69350212419641, 'std': 144.35977530584879, 'run': -96.33541370549995, 'test_avg': -331.69622674285944, 'test_std': 22.695007101543542}
    Episode Length: {'avg': 20.30873362445415, 'std': 25.884836698062745, 'run': 21.064369223284615, 'test_avg': 61.9443359375, 'test_std': 3.8451251539639117}
    Ratio Terminated: {'avg': 0.9995633187772925, 'test_avg': 0.998046875}

Iteration (1601 / 4000):
    Value Loss: {'avg': 104.0838114173324, 'std': 22.788571692120467}
    Value Grad Norm: {'avg': 2882.8096421983505, 'std': 1272.6669115026452}
    Policy Loss: {'avg': 0.00037456933253755175, 'std': 0.013205126115214556}
    Total_Loss: {'avg': -0.1822592036591636, 'std': 0.013561487359751954}
    Policy Entropy: {'avg': 1.8836333751678467, 'std': 0.4529273509979248}
    KL Divergence: {'avg': 0.01668514497578144, 'std': 0.17667366564273834}
    Policy Grad Norm: {'avg': 3.4058184819916884, 'std': 3.4722022137307023}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -93.45445289201074, 'std': 147.09718785296386, 'run': -94.37122609744053, 'test_avg': -333.2378327825896, 'test_std': 30.346663976827003}
    Episode Length: {'avg': 20.653024101864485, 'std': 26.565955720818557, 'run': 20.807954967498084, 'test_avg': 62.37109375, 'test_std': 4.868884823931547}
    Ratio Terminated: {'avg': 0.9990904956798545, 'test_avg': 0.9892578125}

Iteration (1701 / 4000):
    Value Loss: {'avg': 87.74755849131832, 'std': 23.2664331784806}
    Value Grad Norm: {'avg': 2227.9376793755428, 'std': 802.0671082912049}
    Policy Loss: {'avg': -0.001834287979916014, 'std': 0.01378088101638917}
    Total_Loss: {'avg': -0.17243729662150145, 'std': 0.014404070776142702}
    Policy Entropy: {'avg': 1.5392277240753174, 'std': 0.6065298914909363}
    KL Divergence: {'avg': 0.018908048048615456, 'std': 0.19369785487651825}
    Policy Grad Norm: {'avg': 2.708736633895724, 'std': 1.2940722727129734}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -81.0058183099971, 'std': 133.8503611783606, 'run': -76.7198422927091, 'test_avg': -320.7793774684676, 'test_std': 19.033542385548536}
    Episode Length: {'avg': 18.406530612244897, 'std': 24.261021863081112, 'run': 17.794387370479452, 'test_avg': 60.130859375, 'test_std': 3.3143368792225405}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 4000):
    Value Loss: {'avg': 95.97321776990538, 'std': 22.765125296573842}
    Value Grad Norm: {'avg': 2346.515425957574, 'std': 813.9822464781248}
    Policy Loss: {'avg': 0.006465709134418931, 'std': 0.011765949336520741}
    Total_Loss: {'avg': -0.16038944733639557, 'std': 0.012925895363976193}
    Policy Entropy: {'avg': 1.6646106243133545, 'std': 0.48015594482421875}
    KL Divergence: {'avg': 0.01958520896732807, 'std': 0.19292166829109192}
    Policy Grad Norm: {'avg': 3.364717467625936, 'std': 2.4215711407226745}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -82.59391123868099, 'std': 134.34456838517772, 'run': -95.11313236287617, 'test_avg': -318.93953364669807, 'test_std': 19.078916218234973}
    Episode Length: {'avg': 18.62040332147094, 'std': 24.23965610542724, 'run': 21.03216937922923, 'test_avg': 59.9423828125, 'test_std': 3.3330143934889613}
    Ratio Terminated: {'avg': 0.9996045867931989, 'test_avg': 1.0}

Iteration (1901 / 4000):
    Value Loss: {'avg': 87.57398461589106, 'std': 24.726741595380457}
    Value Grad Norm: {'avg': 2074.4297777529114, 'std': 706.1941957679726}
    Policy Loss: {'avg': 0.0042144446219835015, 'std': 0.014371849270326474}
    Total_Loss: {'avg': -0.16611822709027263, 'std': 0.014617225914829573}
    Policy Entropy: {'avg': 1.6630258560180664, 'std': 0.5008339285850525}
    KL Divergence: {'avg': 0.017595093697309494, 'std': 0.17551644146442413}
    Policy Grad Norm: {'avg': 2.755886681129535, 'std': 1.1600083618786357}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -79.72398814904605, 'std': 131.54902287114592, 'run': -84.8362923479269, 'test_avg': -315.360770127152, 'test_std': 19.607748085526307}
    Episode Length: {'avg': 18.035491419656786, 'std': 23.79504735403272, 'run': 19.16384313790422, 'test_avg': 59.2431640625, 'test_std': 3.38286874208984}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2001 / 4000):
    Value Loss: {'avg': 91.29721724898727, 'std': 33.86045481195027}
    Value Grad Norm: {'avg': 2064.556988694933, 'std': 674.4609645333211}
    Policy Loss: {'avg': 0.0028620127860146264, 'std': 0.014373053691415717}
    Total_Loss: {'avg': -0.16525462039021982, 'std': 0.015047408191968715}
    Policy Entropy: {'avg': 1.727247953414917, 'std': 0.5158860087394714}
    KL Divergence: {'avg': 0.018466774374246597, 'std': 0.1786033809185028}
    Policy Grad Norm: {'avg': 2.9002235357960067, 'std': 1.6933419068571873}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -79.32679811972463, 'std': 130.907252976005, 'run': -72.91514953082302, 'test_avg': -318.6377393714472, 'test_std': 23.380577595372095}
    Episode Length: {'avg': 18.00387747188833, 'std': 23.746985778197924, 'run': 16.821678850416127, 'test_avg': 59.736328125, 'test_std': 3.9229404172551465}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (2101 / 4000):
    Value Loss: {'avg': 83.31917220928051, 'std': 17.1046462858878}
    Value Grad Norm: {'avg': 1875.2827674018013, 'std': 589.2115593920723}
    Policy Loss: {'avg': 0.0028531451696633464, 'std': 0.013838802460049383}
    Total_Loss: {'avg': -0.15572067936882378, 'std': 0.014278922759453864}
    Policy Entropy: {'avg': 1.5496723651885986, 'std': 0.5235953330993652}
    KL Divergence: {'avg': 0.015026524662971497, 'std': 0.16096051037311554}
    Policy Grad Norm: {'avg': 3.0008685927424166, 'std': 1.4387513383013963}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -78.5000845020754, 'std': 128.76459175587158, 'run': -69.66964593292153, 'test_avg': -311.29257879963524, 'test_std': 17.731814536258593}
    Episode Length: {'avg': 17.772122161315583, 'std': 23.298422979909553, 'run': 16.224220132435907, 'test_avg': 58.521484375, 'test_std': 3.0601916274362395}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 4000):
    Value Loss: {'avg': 83.53525765736897, 'std': 27.81853566447753}
    Value Grad Norm: {'avg': 1790.9440034089264, 'std': 602.1935455282714}
    Policy Loss: {'avg': 0.006182503391108993, 'std': 0.013083682379095912}
    Total_Loss: {'avg': -0.15561859324160549, 'std': 0.01373152456159}
    Policy Entropy: {'avg': 1.6473575830459595, 'std': 0.5219972133636475}
    KL Divergence: {'avg': 0.01600717380642891, 'std': 0.16208800673484802}
    Policy Grad Norm: {'avg': 2.8381095487210484, 'std': 1.359607870406485}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -78.04498284089736, 'std': 128.67723358290894, 'run': -73.36827566087914, 'test_avg': -315.69668672810167, 'test_std': 18.94037853089531}
    Episode Length: {'avg': 17.750386996904023, 'std': 23.237916727711227, 'run': 17.016861387948847, 'test_avg': 59.3515625, 'test_std': 3.3359192036968985}
    Ratio Terminated: {'avg': 0.9996130030959752, 'test_avg': 1.0}

Iteration (2301 / 4000):
    Value Loss: {'avg': 71.66497566788284, 'std': 26.697973125612208}
    Value Grad Norm: {'avg': 1556.1065912882486, 'std': 500.14613141473524}
    Policy Loss: {'avg': 0.004702435333618067, 'std': 0.011936451851466873}
    Total_Loss: {'avg': -0.1507624031768905, 'std': 0.012343403630358058}
    Policy Entropy: {'avg': 1.5551832914352417, 'std': 0.4847067594528198}
    KL Divergence: {'avg': 0.019298933446407318, 'std': 0.17645135521888733}
    Policy Grad Norm: {'avg': 2.925553655293253, 'std': 1.2824888020117233}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -74.39005947776528, 'std': 125.1850696424381, 'run': -76.36547184657545, 'test_avg': -309.0021504312168, 'test_std': 18.596244038832314}
    Episode Length: {'avg': 17.058910162002945, 'std': 22.665010813141546, 'run': 17.206368284247187, 'test_avg': 58.0712890625, 'test_std': 3.1408653357105063}
    Ratio Terminated: {'avg': 0.9996318114874816, 'test_avg': 0.9990234375}

Iteration (2401 / 4000):
    Value Loss: {'avg': 68.31253001601608, 'std': 11.707036567886618}
    Value Grad Norm: {'avg': 1551.1836604083026, 'std': 507.89899476418805}
    Policy Loss: {'avg': 0.00501732087513018, 'std': 0.013256462900531415}
    Total_Loss: {'avg': -0.14758630163139766, 'std': 0.013704360426284165}
    Policy Entropy: {'avg': 1.5153553485870361, 'std': 0.5323883295059204}
    KL Divergence: {'avg': 0.015194199047982693, 'std': 0.16912072896957397}
    Policy Grad Norm: {'avg': 2.8783307390080557, 'std': 1.2089247406111727}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -78.91757861475789, 'std': 127.69528102792253, 'run': -86.38938908983226, 'test_avg': -308.8913104379046, 'test_std': 18.81162912820035}
    Episode Length: {'avg': 17.85, 'std': 23.122013320643166, 'run': 19.320812087155804, 'test_avg': 58.0361328125, 'test_std': 3.1859161331335826}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2501 / 4000):
    Value Loss: {'avg': 75.20891490159211, 'std': 38.2764105754534}
    Value Grad Norm: {'avg': 1489.421245094582, 'std': 446.7690618385159}
    Policy Loss: {'avg': 0.0009127737805506008, 'std': 0.012885306416060595}
    Total_Loss: {'avg': -0.15757103455770347, 'std': 0.013483611682710155}
    Policy Entropy: {'avg': 1.5955514907836914, 'std': 0.4741758108139038}
    KL Divergence: {'avg': 0.01676500216126442, 'std': 0.16493847966194153}
    Policy Grad Norm: {'avg': 2.7808366388910346, 'std': 1.1202092621980475}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -76.67208542897284, 'std': 125.09986992270521, 'run': -88.2418118839493, 'test_avg': -308.7643745921936, 'test_std': 17.999149726159267}
    Episode Length: {'avg': 17.546728971962615, 'std': 22.72062473537636, 'run': 19.8364689585095, 'test_avg': 58.017578125, 'test_std': 3.083740688599073}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 4000):
    Value Loss: {'avg': 82.7192912419637, 'std': 23.543826832971902}
    Value Grad Norm: {'avg': 1619.5011507387514, 'std': 542.824909593743}
    Policy Loss: {'avg': -0.0008534180071567082, 'std': 0.013533630789309043}
    Total_Loss: {'avg': -0.16466492883240183, 'std': 0.014312054986119175}
    Policy Entropy: {'avg': 1.6824719905853271, 'std': 0.4970795512199402}
    KL Divergence: {'avg': 0.016993319615721703, 'std': 0.16574706137180328}
    Policy Grad Norm: {'avg': 2.821620444042815, 'std': 1.235290319222448}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -81.26006971774596, 'std': 130.43345276026204, 'run': -84.98272418041405, 'test_avg': -306.9858030995231, 'test_std': 17.21497293760808}
    Episode Length: {'avg': 18.386223862238623, 'std': 23.598911875473053, 'run': 19.022842849133053, 'test_avg': 57.736328125, 'test_std': 2.960153440673977}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 4000):
    Value Loss: {'avg': 76.05272636060361, 'std': 13.77498483917977}
    Value Grad Norm: {'avg': 1572.8405111807365, 'std': 506.39585782611994}
    Policy Loss: {'avg': 5.605760573719939e-05, 'std': 0.013912081831453305}
    Total_Loss: {'avg': -0.1635250948783424, 'std': 0.014482450311428096}
    Policy Entropy: {'avg': 1.671267032623291, 'std': 0.5064064264297485}
    KL Divergence: {'avg': 0.016573529690504074, 'std': 0.17068710923194885}
    Policy Grad Norm: {'avg': 2.8415664970046945, 'std': 1.1883370387401113}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -79.76125899991166, 'std': 130.3510738806976, 'run': -84.38967462699596, 'test_avg': -307.82326460070533, 'test_std': 19.570645643350062}
    Episode Length: {'avg': 18.052341597796143, 'std': 23.59358465228184, 'run': 18.94095056435558, 'test_avg': 57.884765625, 'test_std': 3.284433328417302}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2801 / 4000):
    Value Loss: {'avg': 69.62958211192378, 'std': 13.076074990437426}
    Value Grad Norm: {'avg': 1394.249444523564, 'std': 424.24180357935757}
    Policy Loss: {'avg': -0.0010076267209283456, 'std': 0.025000173167577664}
    Total_Loss: {'avg': -0.155265655423756, 'std': 0.025339980777784703}
    Policy Entropy: {'avg': 1.4427030086517334, 'std': 0.6181500554084778}
    KL Divergence: {'avg': 0.019788384437561035, 'std': 0.1924530565738678}
    Policy Grad Norm: {'avg': 3.4180051262731905, 'std': 5.33703778920319}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -79.73332164117531, 'std': 127.95335312161785, 'run': -83.28266639754017, 'test_avg': -305.9573289565755, 'test_std': 18.647473887419892}
    Episode Length: {'avg': 18.027530050407133, 'std': 23.169830410326288, 'run': 19.020854787456912, 'test_avg': 57.541015625, 'test_std': 3.153661894291438}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2901 / 4000):
    Value Loss: {'avg': 71.2593010160658, 'std': 12.457161420519837}
    Value Grad Norm: {'avg': 1267.1073110509801, 'std': 378.1096436199313}
    Policy Loss: {'avg': 0.006406701680841959, 'std': 0.012580437467725188}
    Total_Loss: {'avg': -0.1505503173917532, 'std': 0.013387236952561943}
    Policy Entropy: {'avg': 1.4912259578704834, 'std': 0.5590451955795288}
    KL Divergence: {'avg': 0.015566839836537838, 'std': 0.16288648545742035}
    Policy Grad Norm: {'avg': 3.2777635453475846, 'std': 1.8808503717993448}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -76.57931425270921, 'std': 125.87382752185627, 'run': -68.42277375442112, 'test_avg': -305.33577608848043, 'test_std': 16.926951511178295}
    Episode Length: {'avg': 17.40974866717441, 'std': 22.712373456113006, 'run': 15.862912481341247, 'test_avg': 57.3583984375, 'test_std': 2.930088351483204}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 4000):
    Value Loss: {'avg': 68.10246475361012, 'std': 13.16589721655676}
    Value Grad Norm: {'avg': 1368.214342187952, 'std': 447.3497223244517}
    Policy Loss: {'avg': 0.004172975760108481, 'std': 0.012540017935588909}
    Total_Loss: {'avg': -0.14738181817034882, 'std': 0.013292834924493527}
    Policy Entropy: {'avg': 1.592229962348938, 'std': 0.5358974933624268}
    KL Divergence: {'avg': 0.015682602301239967, 'std': 0.17182128131389618}
    Policy Grad Norm: {'avg': 2.9466603404945797, 'std': 1.296585831280588}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -72.90379102776906, 'std': 123.75762355717303, 'run': -71.94212425652299, 'test_avg': -304.1835742227989, 'test_std': 18.117246334479884}
    Episode Length: {'avg': 16.67220063581773, 'std': 22.38111022119599, 'run': 16.526842839096144, 'test_avg': 57.2392578125, 'test_std': 3.0224391659151246}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3101 / 4000):
    Value Loss: {'avg': 69.93887517363937, 'std': 13.194710972353667}
    Value Grad Norm: {'avg': 1439.1848209522389, 'std': 447.7975346026087}
    Policy Loss: {'avg': 0.005821294487557477, 'std': 0.012653207638591504}
    Total_Loss: {'avg': -0.14664759393781424, 'std': 0.013216287280827963}
    Policy Entropy: {'avg': 1.470977783203125, 'std': 0.5289993286132812}
    KL Divergence: {'avg': 0.01668451353907585, 'std': 0.1735965460538864}
    Policy Grad Norm: {'avg': 2.9325611819823583, 'std': 1.1536548862533507}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -80.49776249335845, 'std': 130.20723997844092, 'run': -95.17731348910765, 'test_avg': -304.2205141986965, 'test_std': 19.442656823019508}
    Episode Length: {'avg': 18.020727414939383, 'std': 23.552916827063616, 'run': 20.812199080965378, 'test_avg': 57.21484375, 'test_std': 3.202893951270622}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3201 / 4000):
    Value Loss: {'avg': 64.58989214367337, 'std': 16.83422192184031}
    Value Grad Norm: {'avg': 1207.1010096514667, 'std': 376.2411329798009}
    Policy Loss: {'avg': -0.0003838592868608733, 'std': 0.012792670547358246}
    Total_Loss: {'avg': -0.15018291350247132, 'std': 0.013740264371619874}
    Policy Entropy: {'avg': 1.4640569686889648, 'std': 0.5787884593009949}
    KL Divergence: {'avg': 0.020021215081214905, 'std': 0.18350961804389954}
    Policy Grad Norm: {'avg': 3.234494808730152, 'std': 2.0219079054491877}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -78.39622830914678, 'std': 125.40008872393105, 'run': -78.87952417018283, 'test_avg': -303.36912041521737, 'test_std': 18.67894389754474}
    Episode Length: {'avg': 17.779296875, 'std': 22.711525697443033, 'run': 17.95235049335426, 'test_avg': 57.0712890625, 'test_std': 3.1240304587292154}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3301 / 4000):
    Value Loss: {'avg': 66.12342627136796, 'std': 12.236462403773913}
    Value Grad Norm: {'avg': 1272.4736403288664, 'std': 373.77626405808013}
    Policy Loss: {'avg': 0.005684286224034925, 'std': 0.01379931553876012}
    Total_Loss: {'avg': -0.14561692339678606, 'std': 0.014307278890018617}
    Policy Entropy: {'avg': 1.497391700744629, 'std': 0.5621708035469055}
    KL Divergence: {'avg': 0.01695072650909424, 'std': 0.17361809313297272}
    Policy Grad Norm: {'avg': 3.1840833213594224, 'std': 1.7942301516176584}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -74.97943032681195, 'std': 124.73236444578428, 'run': -84.26921115589832, 'test_avg': -304.10126351295844, 'test_std': 18.481953753183188}
    Episode Length: {'avg': 17.07469342251951, 'std': 22.606566550804043, 'run': 18.651995512665128, 'test_avg': 57.1923828125, 'test_std': 3.1245469337096843}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3401 / 4000):
    Value Loss: {'avg': 74.83314002708153, 'std': 14.106989753634597}
    Value Grad Norm: {'avg': 1299.4788299843117, 'std': 387.88346709699385}
    Policy Loss: {'avg': 0.0009154413199414396, 'std': 0.014127470362759268}
    Total_Loss: {'avg': -0.15845015873718593, 'std': 0.014683755353453865}
    Policy Entropy: {'avg': 1.6363747119903564, 'std': 0.5053337216377258}
    KL Divergence: {'avg': 0.01564590446650982, 'std': 0.15891918540000916}
    Policy Grad Norm: {'avg': 3.3545154742068712, 'std': 1.6152097735114535}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -73.95391513418564, 'std': 124.30201389430826, 'run': -74.45023645567943, 'test_avg': -304.6356264405003, 'test_std': 17.690467192909804}
    Episode Length: {'avg': 16.962922173274595, 'std': 22.56087583909002, 'run': 17.270263468185295, 'test_avg': 57.2724609375, 'test_std': 3.0383266940927567}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 4000):
    Value Loss: {'avg': 81.7295582877265, 'std': 14.464529152016427}
    Value Grad Norm: {'avg': 1369.162128081145, 'std': 395.17685248496235}
    Policy Loss: {'avg': 0.0007547640571525942, 'std': 0.01342080198502502}
    Total_Loss: {'avg': -0.163038924915923, 'std': 0.01409514543192089}
    Policy Entropy: {'avg': 1.7578909397125244, 'std': 0.4729131758213043}
    KL Divergence: {'avg': 0.022578829899430275, 'std': 0.19298404455184937}
    Policy Grad Norm: {'avg': 2.8978777350650895, 'std': 1.2110414540142027}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -80.28912347160146, 'std': 132.17158309494818, 'run': -72.71883222720673, 'test_avg': -302.6602034892012, 'test_std': 18.4431300090222}
    Episode Length: {'avg': 17.989096573208723, 'std': 23.795007319333234, 'run': 16.643104154153427, 'test_avg': 57.0, 'test_std': 3.087904831758906}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3601 / 4000):
    Value Loss: {'avg': 74.63322037944087, 'std': 16.670176427484517}
    Value Grad Norm: {'avg': 1255.6458203633626, 'std': 382.27172693577774}
    Policy Loss: {'avg': -0.0014676748098012198, 'std': 0.014712665773767416}
    Total_Loss: {'avg': -0.15571682877424692, 'std': 0.01524073360201062}
    Policy Entropy: {'avg': 1.529691457748413, 'std': 0.4953589141368866}
    KL Divergence: {'avg': 0.018220091238617897, 'std': 0.16997623443603516}
    Policy Grad Norm: {'avg': 2.988667325289161, 'std': 1.6382101482949192}
    Num PPO updates: {'avg': 1080}
    Return: {'avg': -74.11295655714409, 'std': 123.89828409070928, 'run': -83.14031862514679, 'test_avg': -303.4663786129219, 'test_std': 18.88570483507743}
    Episode Length: {'avg': 16.922337278106507, 'std': 22.491383054336485, 'run': 18.627851363723714, 'test_avg': 57.146484375, 'test_std': 3.2055291806316255}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3701 / 4000):
    Value Loss: {'avg': 70.47116355189571, 'std': 16.44733964695862}
    Value Grad Norm: {'avg': 1161.6334787721987, 'std': 337.08840754216186}
    Policy Loss: {'avg': 0.006492060377624714, 'std': 0.013932210560578223}
    Total_Loss: {'avg': -0.1426608086253206, 'std': 0.013978851992370403}
    Policy Entropy: {'avg': 1.458661675453186, 'std': 0.5278741121292114}
    KL Divergence: {'avg': 0.017170432955026627, 'std': 0.1764688640832901}
    Policy Grad Norm: {'avg': 2.888612618380123, 'std': 1.171587530357454}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -76.632510033829, 'std': 124.6818443296273, 'run': -96.70680361415171, 'test_avg': -301.6994063811345, 'test_std': 16.642761141334876}
    Episode Length: {'avg': 17.432206608431446, 'std': 22.61717724988252, 'run': 21.026256200263365, 'test_avg': 56.8046875, 'test_std': 2.8154390025968863}
    Ratio Terminated: {'avg': 0.9996202050892518, 'test_avg': 1.0}

Iteration (3801 / 4000):
    Value Loss: {'avg': 66.37788293979786, 'std': 12.818951017159815}
    Value Grad Norm: {'avg': 1117.0015040362323, 'std': 341.15812692456177}
    Policy Loss: {'avg': 0.006345244133586271, 'std': 0.014112876781614023}
    Total_Loss: {'avg': -0.14499154324746794, 'std': 0.014467850270619536}
    Policy Entropy: {'avg': 1.5753037929534912, 'std': 0.5399167537689209}
    KL Divergence: {'avg': 0.016367631033062935, 'std': 0.16244526207447052}
    Policy Grad Norm: {'avg': 2.962525622215536, 'std': 1.2960425451525697}
    Num PPO updates: {'avg': 360}
    Return: {'avg': -75.48287436893244, 'std': 123.87878147531363, 'run': -67.8451720125366, 'test_avg': -302.24756990044966, 'test_std': 20.111941663463302}
    Episode Length: {'avg': 17.17988032909499, 'std': 22.42748205260201, 'run': 15.940162210923942, 'test_avg': 56.8671875, 'test_std': 3.3289593291062824}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3901 / 4000):
    Value Loss: {'avg': 77.54129738984284, 'std': 17.09735060537748}
    Value Grad Norm: {'avg': 1246.2640445850514, 'std': 375.67234582153884}
    Policy Loss: {'avg': -0.001562732909547372, 'std': 0.013885320937768713}
    Total_Loss: {'avg': -0.16030417766628993, 'std': 0.01438380123642576}
    Policy Entropy: {'avg': 1.6041717529296875, 'std': 0.5304417014122009}
    KL Divergence: {'avg': 0.016126185655593872, 'std': 0.1684236079454422}
    Policy Grad Norm: {'avg': 3.120486451850997, 'std': 1.5017292875417736}
    Num PPO updates: {'avg': 720}
    Return: {'avg': -78.54075776816457, 'std': 128.05245194507555, 'run': -89.99425344737107, 'test_avg': -303.93694252809615, 'test_std': 20.975171389150567}
    Episode Length: {'avg': 17.70084485407066, 'std': 23.141619349933578, 'run': 19.847684974354486, 'test_avg': 57.19140625, 'test_std': 3.4119053360931537}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Training took 116907.407 seconds in total.
