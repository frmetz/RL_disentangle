
Iteration (1 / 2001):
    Value Loss: {'avg': 172.51671854654947, 'std': 1.453952324577076}
    Value Grad Norm: {'avg': 66.28671264648438, 'std': 0.45659775226761284}
    Policy Loss: {'avg': -0.006004367023706436, 'std': 0.00489548080536289}
    Total_Loss: {'avg': -0.1831050713857015, 'std': 0.004734999877074187}
    Policy Entropy: {'avg': 1.7689335346221924, 'std': 0.019679756835103035}
    KL Divergence: {'avg': 0.0029226418118923903, 'std': 0.07144439965486526}
    Policy Grad Norm: {'avg': 0.35243581732114154, 'std': 0.03114557281050252}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -23.911762250601285, 'std': 5.166092334325062, 'run': -17.482540726473268, 'test_avg': -25.283764707845584, 'test_std': 6.408247233908619}
    Episode Length: {'avg': 7.921875, 'std': 0.5094325120906595, 'run': 7.4398023222587115, 'test_avg': 7.794921875, 'test_std': 0.7146169167088646}
    Ratio Terminated: {'avg': 0.046875, 'test_avg': 0.0966796875}

Iteration (101 / 2001):
    Value Loss: {'avg': 11.784771919250488, 'std': 0.03796665346664118}
    Value Grad Norm: {'avg': 7.097480456034343, 'std': 0.7837838854969036}
    Policy Loss: {'avg': -5.177160104115804e-05, 'std': 0.0022323789837459113}
    Total_Loss: {'avg': -0.0756187414129575, 'std': 0.0015848399321509504}
    Policy Entropy: {'avg': 0.7497686743736267, 'std': 0.46686917543411255}
    KL Divergence: {'avg': -2.256571315228939e-05, 'std': 0.08272990584373474}
    Policy Grad Norm: {'avg': 2.829608917236328, 'std': 0.5030511510084699}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -9.238989437138272, 'std': 4.979667278496807, 'run': -9.057493297781223, 'test_avg': -7.947436526177626, 'test_std': 3.0738454692974924}
    Episode Length: {'avg': 5.584269662921348, 'std': 1.3723512896169734, 'run': 5.522957797147294, 'test_avg': 5.267578125, 'test_std': 0.8008074500287097}
    Ratio Terminated: {'avg': 0.8876404494382022, 'test_avg': 0.96484375}

Iteration (201 / 2001):
    Value Loss: {'avg': 10.186137835184732, 'std': 0.04295762199414893}
    Value Grad Norm: {'avg': 4.24160369237264, 'std': 0.7480497902441471}
    Policy Loss: {'avg': -0.004286437605818112, 'std': 0.004186957078772912}
    Total_Loss: {'avg': -0.07597693552573521, 'std': 0.002768233093008049}
    Policy Entropy: {'avg': 0.6972096562385559, 'std': 0.48715370893478394}
    KL Divergence: {'avg': 0.003225741907954216, 'std': 0.054915547370910645}
    Policy Grad Norm: {'avg': 3.4628129800160727, 'std': 1.9681963693529958}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -8.387816635662329, 'std': 4.327875261833422, 'run': -8.55728688200304, 'test_avg': -7.534315148352773, 'test_std': 1.9729684603609619}
    Episode Length: {'avg': 5.311111111111111, 'std': 1.101962334952661, 'run': 5.367316506930073, 'test_avg': 5.1279296875, 'test_std': 0.5193908042660674}
    Ratio Terminated: {'avg': 0.9333333333333333, 'test_avg': 0.9892578125}

Iteration (301 / 2001):
    Value Loss: {'avg': 5.285772959391276, 'std': 0.007687035428946996}
    Value Grad Norm: {'avg': 5.220994075139363, 'std': 1.0626227324015898}
    Policy Loss: {'avg': -0.002183834556490183, 'std': 0.002183842472732067}
    Total_Loss: {'avg': -0.06002218462526798, 'std': 0.0023793037980794907}
    Policy Entropy: {'avg': 0.5803381204605103, 'std': 0.5621882677078247}
    KL Divergence: {'avg': 0.01597033441066742, 'std': 0.09913204610347748}
    Policy Grad Norm: {'avg': 1.8251889944076538, 'std': 0.22990405559539795}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -7.635385961595271, 'std': 3.559871612576289, 'run': -7.473412150924834, 'test_avg': -7.564927949768457, 'test_std': 2.5361514736507837}
    Episode Length: {'avg': 5.147058823529412, 'std': 1.0038851862280007, 'run': 5.090394504517134, 'test_avg': 5.138671875, 'test_std': 0.5469273133461012}
    Ratio Terminated: {'avg': 0.9509803921568627, 'test_avg': 0.98046875}

Iteration (401 / 2001):
    Value Loss: {'avg': 3.260631481806437, 'std': 0.01626089712448804}
    Value Grad Norm: {'avg': 3.226982911427816, 'std': 0.6617199897096581}
    Policy Loss: {'avg': -0.0009189723059535027, 'std': 0.0012809412373250696}
    Total_Loss: {'avg': -0.053313413014014564, 'std': 0.0013301755139203749}
    Policy Entropy: {'avg': 0.5245965719223022, 'std': 0.6302170157432556}
    KL Divergence: {'avg': 0.0023558959364891052, 'std': 0.05916459113359451}
    Policy Grad Norm: {'avg': 3.657854954401652, 'std': 0.45972927918451356}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.854862495794646, 'std': 2.7172168022406034, 'run': -6.947045342145136, 'test_avg': -7.14160067735429, 'test_std': 1.3300652038066665}
    Episode Length: {'avg': 4.970873786407767, 'std': 0.841361710419157, 'run': 4.9977268208974115, 'test_avg': 5.05859375, 'test_std': 0.3650828980669151}
    Ratio Terminated: {'avg': 0.9902912621359223, 'test_avg': 0.9951171875}

Iteration (501 / 2001):
    Value Loss: {'avg': 1.587485631306966, 'std': 0.005680940693276243}
    Value Grad Norm: {'avg': 2.5312259991963706, 'std': 0.1836420311563009}
    Policy Loss: {'avg': -0.003210669383406639, 'std': 0.002780117903918662}
    Total_Loss: {'avg': -0.052233628928661346, 'std': 0.002764265260054494}
    Policy Entropy: {'avg': 0.4901549220085144, 'std': 0.6536185145378113}
    KL Divergence: {'avg': 0.0098875155672431, 'std': 0.09932215511798859}
    Policy Grad Norm: {'avg': 1.1679377953211467, 'std': 0.19808187952130926}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.74911928742295, 'std': 2.4936561759562643, 'run': -6.708448889969896, 'test_avg': -7.108508780543351, 'test_std': 1.663704568301609}
    Episode Length: {'avg': 4.943396226415095, 'std': 0.7870435326269513, 'run': 4.928915468471884, 'test_avg': 5.07421875, 'test_std': 0.41500114716520664}
    Ratio Terminated: {'avg': 0.9905660377358491, 'test_avg': 0.990234375}

Iteration (601 / 2001):
    Value Loss: {'avg': 1.5790838797887166, 'std': 0.01165058849662107}
    Value Grad Norm: {'avg': 2.442495663960775, 'std': 0.46972745177895386}
    Policy Loss: {'avg': -0.0035915104672312737, 'std': 0.0030327596218791756}
    Total_Loss: {'avg': -0.055262066423892975, 'std': 0.003024940976418873}
    Policy Entropy: {'avg': 0.5166079998016357, 'std': 0.6814833283424377}
    KL Divergence: {'avg': 0.005999376066029072, 'std': 0.07262714952230453}
    Policy Grad Norm: {'avg': 1.7773711681365967, 'std': 0.47925061992303586}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.475545194370253, 'std': 2.417282989059518, 'run': -6.549740330540027, 'test_avg': -7.020346128028905, 'test_std': 1.505392763779048}
    Episode Length: {'avg': 4.872549019607843, 'std': 0.8479683751438712, 'run': 4.883879635260682, 'test_avg': 5.0634765625, 'test_std': 0.40609855763494607}
    Ratio Terminated: {'avg': 0.9901960784313726, 'test_avg': 0.98828125}

Iteration (701 / 2001):
    Value Loss: {'avg': 2.161130905151367, 'std': 0.008371483366918156}
    Value Grad Norm: {'avg': 3.51786478360494, 'std': 0.6696083282144609}
    Policy Loss: {'avg': -0.004096124010781447, 'std': 0.003706867662553008}
    Total_Loss: {'avg': -0.054336304465929665, 'std': 0.0036739734985316414}
    Policy Entropy: {'avg': 0.5024926066398621, 'std': 0.635831892490387}
    KL Divergence: {'avg': 0.008938598446547985, 'std': 0.07817456871271133}
    Policy Grad Norm: {'avg': 2.0722262064615884, 'std': 0.19022919672893285}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.643974928671681, 'std': 2.2670474364348565, 'run': -6.536781087510255, 'test_avg': -6.934152765388717, 'test_std': 1.3404697977639632}
    Episode Length: {'avg': 4.913461538461538, 'std': 0.7858187416157469, 'run': 4.877192306242947, 'test_avg': 5.0556640625, 'test_std': 0.366874399005976}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (801 / 2001):
    Value Loss: {'avg': 4.2248428662618, 'std': 0.032894654764454585}
    Value Grad Norm: {'avg': 11.35873031616211, 'std': 1.3629965208269637}
    Policy Loss: {'avg': -0.006735891103744507, 'std': 0.006735906004905701}
    Total_Loss: {'avg': -0.05173785611987114, 'std': 0.00700107216835022}
    Policy Entropy: {'avg': 0.4526713192462921, 'std': 0.578888475894928}
    KL Divergence: {'avg': 0.01538502424955368, 'std': 0.12785890698432922}
    Policy Grad Norm: {'avg': 5.735821604728699, 'std': 3.1369487047195435}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -6.648314691595313, 'std': 2.6572791835430705, 'run': -6.743316479347365, 'test_avg': -6.781966977589103, 'test_std': 0.8181650645230386}
    Episode Length: {'avg': 4.895238095238096, 'std': 0.7674796044916488, 'run': 4.92399252471531, 'test_avg': 5.0166015625, 'test_std': 0.21359500373969095}
    Ratio Terminated: {'avg': 0.9809523809523809, 'test_avg': 0.998046875}

Iteration (901 / 2001):
    Value Loss: {'avg': 3.365997791290283, 'std': 0.02340525951936635}
    Value Grad Norm: {'avg': 4.696540832519531, 'std': 0.9104816215500318}
    Policy Loss: {'avg': 0.0002744244411587715, 'std': 0.0002744300290942192}
    Total_Loss: {'avg': -0.03796233795583248, 'std': 0.0001214202493429184}
    Policy Entropy: {'avg': 0.3863261342048645, 'std': 0.4645754396915436}
    KL Divergence: {'avg': 0.017108578234910965, 'std': 0.12740617990493774}
    Policy Grad Norm: {'avg': 3.7966396808624268, 'std': 0.805858850479126}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -6.462550173102167, 'std': 2.9486791533961534, 'run': -6.360080467646765, 'test_avg': -6.750071778340498, 'test_std': 1.1462384983318894}
    Episode Length: {'avg': 4.881188118811881, 'std': 0.8118811881188118, 'run': 4.854524823758904, 'test_avg': 5.0283203125, 'test_std': 0.2727513013716018}
    Ratio Terminated: {'avg': 0.9801980198019802, 'test_avg': 0.994140625}

Iteration (1001 / 2001):
    Value Loss: {'avg': 2.7338088353474936, 'std': 0.008837095608032959}
    Value Grad Norm: {'avg': 6.40939982732137, 'std': 0.8575282479432665}
    Policy Loss: {'avg': 0.0002003802607456843, 'std': 0.0012244168127915813}
    Total_Loss: {'avg': -0.03379951665798823, 'std': 0.001256345959259504}
    Policy Entropy: {'avg': 0.3364729583263397, 'std': 0.4275290369987488}
    KL Divergence: {'avg': 0.006362346466630697, 'std': 0.07631654292345047}
    Policy Grad Norm: {'avg': 3.487526019414266, 'std': 0.2506057341378874}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.534478650523348, 'std': 2.6199618771746773, 'run': -6.565588525218587, 'test_avg': -6.689590585861879, 'test_std': 1.024797430094845}
    Episode Length: {'avg': 4.931372549019608, 'std': 0.795327086759101, 'run': 4.950762431602826, 'test_avg': 5.029296875, 'test_std': 0.27443317604698303}
    Ratio Terminated: {'avg': 0.9803921568627451, 'test_avg': 0.99609375}

Iteration (1101 / 2001):
    Value Loss: {'avg': 0.5918460687001547, 'std': 0.012965702426691875}
    Value Grad Norm: {'avg': 7.712440490722656, 'std': 0.4939600853579808}
    Policy Loss: {'avg': -0.003156446230908235, 'std': 0.0022828616261498977}
    Total_Loss: {'avg': -0.031094903747240703, 'std': 0.002093290714227335}
    Policy Entropy: {'avg': 0.2769849896430969, 'std': 0.38877272605895996}
    KL Divergence: {'avg': 0.010004987940192223, 'std': 0.10727477073669434}
    Policy Grad Norm: {'avg': 1.3072574734687805, 'std': 0.5083415103600686}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -5.86433937342779, 'std': 2.293179151441583, 'run': -6.015076263082962, 'test_avg': -6.684610903736221, 'test_std': 1.0596713593044853}
    Episode Length: {'avg': 4.752293577981652, 'std': 0.8145011790615794, 'run': 4.798916120499063, 'test_avg': 5.0244140625, 'test_std': 0.2584313565576865}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (1201 / 2001):
    Value Loss: {'avg': 2.655401865641276, 'std': 0.009705313790861453}
    Value Grad Norm: {'avg': 4.0227499802907305, 'std': 0.5614574235773041}
    Policy Loss: {'avg': -0.006030394074817498, 'std': 0.004871782699917976}
    Total_Loss: {'avg': -0.0380167563756307, 'std': 0.0052190564516308505}
    Policy Entropy: {'avg': 0.32412686944007874, 'std': 0.42051318287849426}
    KL Divergence: {'avg': 0.011106018908321857, 'std': 0.09139649569988251}
    Policy Grad Norm: {'avg': 3.0006335179011026, 'std': 1.1155238671294172}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.054733362571102, 'std': 2.9247024250169535, 'run': -6.162734084337073, 'test_avg': -6.644532714533852, 'test_std': 0.8740381965966904}
    Episode Length: {'avg': 4.738317757009346, 'std': 0.9000150424301676, 'run': 4.786505554570546, 'test_avg': 5.021484375, 'test_std': 0.2013803531401695}
    Ratio Terminated: {'avg': 0.9906542056074766, 'test_avg': 0.9990234375}

Iteration (1301 / 2001):
    Value Loss: {'avg': 0.47492138544718426, 'std': 0.010673787565713171}
    Value Grad Norm: {'avg': 2.5640439987182617, 'std': 0.7242295268942642}
    Policy Loss: {'avg': -0.003849902811149756, 'std': 0.003412649825208213}
    Total_Loss: {'avg': -0.033682784686485924, 'std': 0.0031509404991009135}
    Policy Entropy: {'avg': 0.29429712891578674, 'std': 0.39697059988975525}
    KL Divergence: {'avg': 0.003847587388008833, 'std': 0.08702077716588974}
    Policy Grad Norm: {'avg': 2.5112212896347046, 'std': 1.0450173572566597}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.22879496010996, 'std': 1.9929930786846117, 'run': -6.214013472518635, 'test_avg': -6.7298602049049805, 'test_std': 1.3371606790044779}
    Episode Length: {'avg': 4.885714285714286, 'std': 0.7598782573454741, 'run': 4.8577232397640575, 'test_avg': 5.044921875, 'test_std': 0.3364764481304514}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (1401 / 2001):
    Value Loss: {'avg': 1.194334586461385, 'std': 0.0031822357529319905}
    Value Grad Norm: {'avg': 5.257227897644043, 'std': 0.40998646126795146}
    Policy Loss: {'avg': -0.0065477412814895315, 'std': 0.005277000176586413}
    Total_Loss: {'avg': -0.040653046220541, 'std': 0.0047686368014780425}
    Policy Entropy: {'avg': 0.33523645997047424, 'std': 0.4219837188720703}
    KL Divergence: {'avg': 0.010376124642789364, 'std': 0.12732048332691193}
    Policy Grad Norm: {'avg': 2.710633714993795, 'std': 1.2152903821586587}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -5.925336691909111, 'std': 2.5130801488795993, 'run': -6.095627615376398, 'test_avg': -6.640192287930404, 'test_std': 0.8095919756559791}
    Episode Length: {'avg': 4.75, 'std': 0.9379806460197845, 'run': 4.80636348408549, 'test_avg': 5.015625, 'test_std': 0.19702375332685143}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1501 / 2001):
    Value Loss: {'avg': 5.547933737436931, 'std': 0.07160511122371453}
    Value Grad Norm: {'avg': 15.205590883890787, 'std': 1.546890766282719}
    Policy Loss: {'avg': 0.009459145367145538, 'std': 0.008134945502217716}
    Total_Loss: {'avg': -0.028931527708967526, 'std': 0.007293791028129615}
    Policy Entropy: {'avg': 0.3881882429122925, 'std': 0.4823921322822571}
    KL Divergence: {'avg': 0.011162307113409042, 'std': 0.10460580885410309}
    Policy Grad Norm: {'avg': 13.503805160522461, 'std': 1.7453686643584887}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.6979301919278775, 'std': 3.4539710179802716, 'run': -6.577609548591423, 'test_avg': -6.801456188340079, 'test_std': 1.9503999500569316}
    Episode Length: {'avg': 4.9245283018867925, 'std': 0.8869931527202383, 'run': 4.918558777621641, 'test_avg': 5.0380859375, 'test_std': 0.3179442150200977}
    Ratio Terminated: {'avg': 0.9905660377358491, 'test_avg': 0.994140625}

Iteration (1601 / 2001):
    Value Loss: {'avg': 0.9507087667783102, 'std': 0.015355320933338369}
    Value Grad Norm: {'avg': 4.815388202667236, 'std': 0.5116874638256481}
    Policy Loss: {'avg': -0.0026038791984319687, 'std': 0.0025783023712879407}
    Total_Loss: {'avg': -0.029502852509419124, 'std': 0.0024401952303382737}
    Policy Entropy: {'avg': 0.26715680956840515, 'std': 0.3886965215206146}
    KL Divergence: {'avg': 0.003689786419272423, 'std': 0.08193159848451614}
    Policy Grad Norm: {'avg': 3.661060174306234, 'std': 0.8836973553161189}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.353816769107687, 'std': 2.1654676384136846, 'run': -6.220072913971091, 'test_avg': -6.626292794848268, 'test_std': 0.8308455685047468}
    Episode Length: {'avg': 4.923809523809524, 'std': 0.7130783446603766, 'run': 4.861386801450322, 'test_avg': 5.0146484375, 'test_std': 0.2182589878534412}
    Ratio Terminated: {'avg': 0.9904761904761905, 'test_avg': 0.9990234375}

Iteration (1701 / 2001):
    Value Loss: {'avg': 1.9600913921991985, 'std': 0.03930223824807949}
    Value Grad Norm: {'avg': 7.450428167978923, 'std': 2.4580866986839713}
    Policy Loss: {'avg': -0.008229113183915615, 'std': 0.008229088969528675}
    Total_Loss: {'avg': -0.04996968060731888, 'std': 0.004889816045761108}
    Policy Entropy: {'avg': 0.38401293754577637, 'std': 0.4013262391090393}
    KL Divergence: {'avg': 0.03370102867484093, 'std': 0.36860784888267517}
    Policy Grad Norm: {'avg': 5.661280155181885, 'std': 3.2560763359069824}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -6.8254706910869025, 'std': 3.4702556322704767, 'run': -6.753363434243687, 'test_avg': -6.726253336659283, 'test_std': 1.1231377297827738}
    Episode Length: {'avg': 5.03, 'std': 1.062591172558854, 'run': 5.0342534030586465, 'test_avg': 5.048828125, 'test_std': 0.32409518541469323}
    Ratio Terminated: {'avg': 0.98, 'test_avg': 0.998046875}

Iteration (1801 / 2001):
    Value Loss: {'avg': 0.42028873165448505, 'std': 0.0023860103577472576}
    Value Grad Norm: {'avg': 6.581947644551595, 'std': 0.7572740375409679}
    Policy Loss: {'avg': -0.0029869841722150645, 'std': 0.0026301241817291814}
    Total_Loss: {'avg': -0.03223460353910923, 'std': 0.0025647800857070374}
    Policy Entropy: {'avg': 0.2917180359363556, 'std': 0.38705819845199585}
    KL Divergence: {'avg': 0.005694681312888861, 'std': 0.09883464127779007}
    Policy Grad Norm: {'avg': 1.2162104447682698, 'std': 0.12262438168857072}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -5.962475135500701, 'std': 2.4747189164807777, 'run': -5.993237932860988, 'test_avg': -6.707450455486391, 'test_std': 1.080596028154627}
    Episode Length: {'avg': 4.745283018867925, 'std': 0.9013754767515031, 'run': 4.757965891097826, 'test_avg': 5.0478515625, 'test_std': 0.32273137508818167}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (1901 / 2001):
    Value Loss: {'avg': 0.91775510708491, 'std': 0.008916408714218336}
    Value Grad Norm: {'avg': 3.365228017171224, 'std': 0.369570482743549}
    Policy Loss: {'avg': -0.004695276729762554, 'std': 0.0040448140119133365}
    Total_Loss: {'avg': -0.031396130099892616, 'std': 0.004143698570339476}
    Policy Entropy: {'avg': 0.2682039141654968, 'std': 0.3719102442264557}
    KL Divergence: {'avg': 0.005287357605993748, 'std': 0.07366606593132019}
    Policy Grad Norm: {'avg': 1.4105826020240784, 'std': 0.3766051479301634}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -5.9305301155321875, 'std': 2.1587740125199306, 'run': -5.916771397402334, 'test_avg': -6.675845185302023, 'test_std': 1.0091547271363521}
    Episode Length: {'avg': 4.740384615384615, 'std': 0.8085503683907713, 'run': 4.7334247513479095, 'test_avg': 5.0322265625, 'test_std': 0.28287123602344866}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (2001 / 2001):
    Value Loss: {'avg': 3.120201826095581, 'std': 0.006389231050342224}
    Value Grad Norm: {'avg': 5.537087599436442, 'std': 0.45046987067328303}
    Policy Loss: {'avg': -0.007652653381228447, 'std': 0.0061078891695023575}
    Total_Loss: {'avg': -0.04616860797007879, 'std': 0.004904803285522149}
    Policy Entropy: {'avg': 0.3720504641532898, 'std': 0.4042396545410156}
    KL Divergence: {'avg': 0.003380836918950081, 'std': 0.11113062500953674}
    Policy Grad Norm: {'avg': 3.5502963860829673, 'std': 1.6628104066569296}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.727169025514496, 'std': 2.8737575059817195, 'run': -6.704461322590892, 'test_avg': -6.8218493992244476, 'test_std': 1.4619137280361754}
    Episode Length: {'avg': 4.990291262135922, 'std': 0.9703882280946221, 'run': 4.967922666390927, 'test_avg': 5.0673828125, 'test_std': 0.38571993606707683}
    Ratio Terminated: {'avg': 0.9902912621359223, 'test_avg': 0.9951171875}

Training took 289.678 seconds in total.
