
Iteration (1 / 10001):
    Value Loss: {'avg': 2270.0731887817383, 'std': 204.59025390201492}
    Value Grad Norm: {'avg': 515.979902267456, 'std': 137.07681756172514}
    Policy Loss: {'avg': -0.0011603099507434915, 'std': 0.0034418766556234483}
    Total_Loss: {'avg': -0.2310356479138136, 'std': 0.0034437278371846998}
    Policy Entropy: {'avg': 2.296926975250244, 'std': 0.008225481025874615}
    KL Divergence: {'avg': 0.005854418966919184, 'std': 0.07467126846313477}
    Policy Grad Norm: {'avg': 0.14724347740411758, 'std': 0.04844655784556753}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -160.99937974507884, 'std': 42.96030264299406, 'run': -129.21833443179932, 'test_avg': -196.67539973976778, 'test_std': 4.161672382390639}
    Episode Length: {'avg': 37.47517730496454, 'std': 6.746243041970019, 'run': 31.495075286860317, 'test_avg': 39.9931640625, 'test_std': 0.2186431623867897}
    Ratio Terminated: {'avg': 0.20567375886524822, 'test_avg': 0.0009765625}

Iteration (101 / 10001):
    Value Loss: {'avg': 248.14940929412842, 'std': 29.89901023143434}
    Value Grad Norm: {'avg': 904.749768892924, 'std': 386.4221773099109}
    Policy Loss: {'avg': -0.0042772826564032584, 'std': 0.010510512187540474}
    Total_Loss: {'avg': -0.20290683023631573, 'std': 0.009944303709838663}
    Policy Entropy: {'avg': 1.9967410564422607, 'std': 0.29682618379592896}
    KL Divergence: {'avg': 0.008713633753359318, 'std': 0.1686081439256668}
    Policy Grad Norm: {'avg': 1.4670551232993603, 'std': 0.4985935414272406}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -131.4176274702142, 'std': 40.507527161851115, 'run': -132.70018607341194, 'test_avg': -117.5000583565825, 'test_std': 14.36555718001569}
    Episode Length: {'avg': 33.638888888888886, 'std': 8.59958906569177, 'run': 33.81329505881515, 'test_avg': 30.0888671875, 'test_std': 3.0940519243357634}
    Ratio Terminated: {'avg': 0.7380952380952381, 'test_avg': 0.998046875}

Iteration (201 / 10001):
    Value Loss: {'avg': 176.80209891001383, 'std': 16.18807280424433}
    Value Grad Norm: {'avg': 1311.9599863688152, 'std': 695.306005013812}
    Policy Loss: {'avg': -0.002550445235101506, 'std': 0.00790137808069461}
    Total_Loss: {'avg': -0.19387002708390355, 'std': 0.008013618252948133}
    Policy Entropy: {'avg': 1.9415998458862305, 'std': 0.21404269337654114}
    KL Divergence: {'avg': 0.020310699939727783, 'std': 0.21668444573879242}
    Policy Grad Norm: {'avg': 1.835684895515442, 'std': 0.5020771612028339}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -120.78150656972726, 'std': 36.45601039527149, 'run': -121.25338527377124, 'test_avg': -108.4175013941379, 'test_std': 13.492669697341997}
    Episode Length: {'avg': 30.715355805243444, 'std': 7.960663364506167, 'run': 30.837372299393113, 'test_avg': 27.765625, 'test_std': 3.035234172905774}
    Ratio Terminated: {'avg': 0.9550561797752809, 'test_avg': 1.0}

Iteration (301 / 10001):
    Value Loss: {'avg': 125.47104438145955, 'std': 14.787614475890233}
    Value Grad Norm: {'avg': 1115.9468320210774, 'std': 528.5161342286959}
    Policy Loss: {'avg': -0.004100828082300723, 'std': 0.007661133524704766}
    Total_Loss: {'avg': -0.1743754893541336, 'std': 0.008105702058591215}
    Policy Entropy: {'avg': 1.711033582687378, 'std': 0.42470118403434753}
    KL Divergence: {'avg': 0.017500419169664383, 'std': 0.19540312886238098}
    Policy Grad Norm: {'avg': 2.056780783459544, 'std': 0.5805065551858495}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -108.00040216243009, 'std': 32.345954446741025, 'run': -110.07856454104827, 'test_avg': -100.83437032749785, 'test_std': 14.116227551611043}
    Episode Length: {'avg': 27.817241379310346, 'std': 7.166808983829662, 'run': 28.31397308626577, 'test_avg': 25.94921875, 'test_std': 3.2248666661814775}
    Ratio Terminated: {'avg': 0.993103448275862, 'test_avg': 1.0}

Iteration (401 / 10001):
    Value Loss: {'avg': 115.14101060231526, 'std': 12.612683894877382}
    Value Grad Norm: {'avg': 1273.8101072311401, 'std': 608.0836407629674}
    Policy Loss: {'avg': -0.00536637789142939, 'std': 0.011350083749630976}
    Total_Loss: {'avg': -0.17628161360820135, 'std': 0.01073934316154815}
    Policy Entropy: {'avg': 1.7236526012420654, 'std': 0.34089016914367676}
    KL Divergence: {'avg': 0.011324750259518623, 'std': 0.17324383556842804}
    Policy Grad Norm: {'avg': 2.031682493786017, 'std': 0.5753555144841116}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -105.75851117360229, 'std': 31.414809683509265, 'run': -102.3280566437667, 'test_avg': -97.58895362186078, 'test_std': 12.199670005252006}
    Episode Length: {'avg': 27.225589225589225, 'std': 6.932547916344262, 'run': 26.381402842061004, 'test_avg': 25.0546875, 'test_std': 2.7237628893396266}
    Ratio Terminated: {'avg': 0.98989898989899, 'test_avg': 1.0}

Iteration (501 / 10001):
    Value Loss: {'avg': 92.40493090947469, 'std': 7.442389358908431}
    Value Grad Norm: {'avg': 1025.9851239522297, 'std': 562.7745490486261}
    Policy Loss: {'avg': 0.0038663475424982607, 'std': 0.006446623136241183}
    Total_Loss: {'avg': -0.15325600001960993, 'std': 0.004725806240583945}
    Policy Entropy: {'avg': 1.545360803604126, 'std': 0.40065231919288635}
    KL Divergence: {'avg': 0.02121436595916748, 'std': 0.23651142418384552}
    Policy Grad Norm: {'avg': 2.0870940312743187, 'std': 0.7031835603221693}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -97.94750312380013, 'std': 30.144474866942154, 'run': -96.10346923729782, 'test_avg': -92.73309351464948, 'test_std': 10.956951276635385}
    Episode Length: {'avg': 25.31446540880503, 'std': 6.6414349862417845, 'run': 24.987927388190787, 'test_avg': 23.9169921875, 'test_std': 2.478017481892322}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (601 / 10001):
    Value Loss: {'avg': 72.69321846961975, 'std': 9.21751793289365}
    Value Grad Norm: {'avg': 840.251493136088, 'std': 431.5210454007152}
    Policy Loss: {'avg': 0.003807958564721048, 'std': 0.00768333879964346}
    Total_Loss: {'avg': -0.14781472459435463, 'std': 0.006483603086956159}
    Policy Entropy: {'avg': 1.557436466217041, 'std': 0.36835888028144836}
    KL Divergence: {'avg': 0.01967858336865902, 'std': 0.2035924345254898}
    Policy Grad Norm: {'avg': 2.4947918578982353, 'std': 0.8156859422819687}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -96.74819541529543, 'std': 29.12746889302688, 'run': -96.0048513562174, 'test_avg': -90.92177606218301, 'test_std': 9.839617937195879}
    Episode Length: {'avg': 24.944272445820435, 'std': 6.46040498112932, 'run': 24.80014883084886, 'test_avg': 23.3369140625, 'test_std': 2.1974693915933723}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (701 / 10001):
    Value Loss: {'avg': 79.1366237004598, 'std': 7.130111256297135}
    Value Grad Norm: {'avg': 701.6782321929932, 'std': 408.7758429786404}
    Policy Loss: {'avg': -0.0021620462648570538, 'std': 0.007629405353034097}
    Total_Loss: {'avg': -0.15425705071538687, 'std': 0.008866729440894715}
    Policy Entropy: {'avg': 1.5333361625671387, 'std': 0.4092334806919098}
    KL Divergence: {'avg': 0.018554043024778366, 'std': 0.20513662695884705}
    Policy Grad Norm: {'avg': 1.9823638387024403, 'std': 0.5946835447332545}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -92.58421617730637, 'std': 29.227569336357227, 'run': -93.07710305284076, 'test_avg': -87.64176216408782, 'test_std': 9.040399190083008}
    Episode Length: {'avg': 23.88046647230321, 'std': 6.348044193964472, 'run': 24.042603378486962, 'test_avg': 22.58203125, 'test_std': 2.0446933447398505}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 10001):
    Value Loss: {'avg': 78.97371164957683, 'std': 7.122951737573353}
    Value Grad Norm: {'avg': 634.9496415456136, 'std': 295.5676142178691}
    Policy Loss: {'avg': 0.0102194907667581, 'std': 0.009016455613587101}
    Total_Loss: {'avg': -0.13333586137741804, 'std': 0.007698595420372162}
    Policy Entropy: {'avg': 1.4896020889282227, 'std': 0.39209839701652527}
    KL Divergence: {'avg': 0.018153484910726547, 'std': 0.19825232028961182}
    Policy Grad Norm: {'avg': 2.461974985897541, 'std': 0.9083478973662427}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -91.18844411064455, 'std': 28.226727982811965, 'run': -90.47880937041516, 'test_avg': -87.86127376944059, 'test_std': 9.585052811409016}
    Episode Length: {'avg': 23.58160237388724, 'std': 6.13643251088023, 'run': 23.40246394732665, 'test_avg': 22.544921875, 'test_std': 2.1441994776947606}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (901 / 10001):
    Value Loss: {'avg': 72.24125321706136, 'std': 8.551406953210508}
    Value Grad Norm: {'avg': 1252.887438774109, 'std': 653.1633633234953}
    Policy Loss: {'avg': 0.010047465126262978, 'std': 0.011574289824100963}
    Total_Loss: {'avg': -0.12742338329553604, 'std': 0.011349583069489253}
    Policy Entropy: {'avg': 1.390220046043396, 'std': 0.44935572147369385}
    KL Divergence: {'avg': 0.015207519754767418, 'std': 0.19743861258029938}
    Policy Grad Norm: {'avg': 2.420957252383232, 'std': 1.3278776699024766}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -89.38149023430587, 'std': 27.51699505699215, 'run': -90.83769937926286, 'test_avg': -85.68296353871148, 'test_std': 8.9446092240785}
    Episode Length: {'avg': 23.115942028985508, 'std': 5.943541695041546, 'run': 23.38895391061031, 'test_avg': 22.1201171875, 'test_std': 1.9946768970856132}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1001 / 10001):
    Value Loss: {'avg': 70.86789870262146, 'std': 10.00449287986126}
    Value Grad Norm: {'avg': 760.9659191767374, 'std': 387.6833335703174}
    Policy Loss: {'avg': -0.0030348209547810256, 'std': 0.008788111540376578}
    Total_Loss: {'avg': -0.1438783446792513, 'std': 0.009595404033259109}
    Policy Entropy: {'avg': 1.3696215152740479, 'std': 0.4750288724899292}
    KL Divergence: {'avg': 0.02175130881369114, 'std': 0.19130834937095642}
    Policy Grad Norm: {'avg': 2.196771938353777, 'std': 0.6038633903722741}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -89.90107499975112, 'std': 28.05389504032735, 'run': -89.40169893194314, 'test_avg': -85.84909695991985, 'test_std': 8.629744226701245}
    Episode Length: {'avg': 23.16618911174785, 'std': 6.1365458470313845, 'run': 23.074858328091015, 'test_avg': 22.13671875, 'test_std': 1.9326702340022825}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 10001):
    Value Loss: {'avg': 78.73474510510762, 'std': 9.371226803779553}
    Value Grad Norm: {'avg': 820.3345928192139, 'std': 420.17350507852973}
    Policy Loss: {'avg': -0.005969399731839076, 'std': 0.007975166347026764}
    Total_Loss: {'avg': -0.15684761805459857, 'std': 0.007976333422945278}
    Policy Entropy: {'avg': 1.5174100399017334, 'std': 0.4200754761695862}
    KL Divergence: {'avg': 0.023310068994760513, 'std': 0.2589082717895508}
    Policy Grad Norm: {'avg': 1.9701498672366142, 'std': 0.7275002017489586}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -92.40275217433751, 'std': 31.23050750849638, 'run': -92.5991374752608, 'test_avg': -85.51094704413401, 'test_std': 8.897641795282404}
    Episode Length: {'avg': 23.839762611275965, 'std': 6.81013104206633, 'run': 23.847295262005407, 'test_avg': 21.99609375, 'test_std': 2.0029237357450578}
    Ratio Terminated: {'avg': 0.9940652818991098, 'test_avg': 1.0}

Iteration (1201 / 10001):
    Value Loss: {'avg': 64.22314890225728, 'std': 9.63420432480978}
    Value Grad Norm: {'avg': 741.8037576675415, 'std': 360.1638286574704}
    Policy Loss: {'avg': -0.00018634795560501516, 'std': 0.0021124723423315028}
    Total_Loss: {'avg': -0.1467299247160554, 'std': 0.0028142852189869953}
    Policy Entropy: {'avg': 1.4904025793075562, 'std': 0.40676164627075195}
    KL Divergence: {'avg': 0.01568639650940895, 'std': 0.14270971715450287}
    Policy Grad Norm: {'avg': 2.175711177289486, 'std': 0.5527777357129329}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -89.89284005842113, 'std': 29.106705491323574, 'run': -90.31462516468855, 'test_avg': -83.74223302864932, 'test_std': 7.695941144480545}
    Episode Length: {'avg': 23.225626740947074, 'std': 6.338353044341778, 'run': 23.341721497788335, 'test_avg': 21.5146484375, 'test_std': 1.6588365043845668}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 10001):
    Value Loss: {'avg': 42.97338422139486, 'std': 7.607522741919756}
    Value Grad Norm: {'avg': 543.6032546361288, 'std': 230.5376172359681}
    Policy Loss: {'avg': 0.00553808975382708, 'std': 0.004261629007342218}
    Total_Loss: {'avg': -0.12055478012189269, 'std': 0.005497505521521701}
    Policy Entropy: {'avg': 1.2725812196731567, 'std': 0.45765870809555054}
    KL Divergence: {'avg': 0.015274911187589169, 'std': 0.17199568450450897}
    Policy Grad Norm: {'avg': 2.237742356956005, 'std': 0.6570270578003913}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -86.11148583113626, 'std': 25.97571208346074, 'run': -84.73225360925713, 'test_avg': -83.18862762330639, 'test_std': 7.790625590998173}
    Episode Length: {'avg': 22.181571815718158, 'std': 5.537953475310803, 'run': 21.873374641025222, 'test_avg': 21.40625, 'test_std': 1.6744285405773518}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 10001):
    Value Loss: {'avg': 64.58072249094646, 'std': 7.167113483670822}
    Value Grad Norm: {'avg': 972.2648760477701, 'std': 527.4690936897333}
    Policy Loss: {'avg': -0.008119081302235523, 'std': 0.009173651101002614}
    Total_Loss: {'avg': -0.15954278595745564, 'std': 0.009577484238668416}
    Policy Entropy: {'avg': 1.5709024667739868, 'std': 0.3328632116317749}
    KL Divergence: {'avg': 0.03562531620264053, 'std': 0.25806668400764465}
    Policy Grad Norm: {'avg': 2.7999201168616614, 'std': 1.54008874728294}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -96.68715812266939, 'std': 23.832821668580305, 'run': -97.5219098493336, 'test_avg': -88.02418629393617, 'test_std': 11.262400438227328}
    Episode Length: {'avg': 24.71470588235294, 'std': 5.210658327659995, 'run': 24.94511072382544, 'test_avg': 22.744140625, 'test_std': 2.5324003643232658}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 10001):
    Value Loss: {'avg': 51.66320649782816, 'std': 6.0085620184668125}
    Value Grad Norm: {'avg': 654.984668413798, 'std': 332.2521268433131}
    Policy Loss: {'avg': 0.004153447953285649, 'std': 0.007515736300663148}
    Total_Loss: {'avg': -0.12279796367511153, 'std': 0.006824256640189015}
    Policy Entropy: {'avg': 1.2920539379119873, 'std': 0.45805904269218445}
    KL Divergence: {'avg': 0.02358534187078476, 'std': 0.19962964951992035}
    Policy Grad Norm: {'avg': 2.304924100637436, 'std': 0.5582198254440482}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.57772085041914, 'std': 26.42098425435466, 'run': -84.4449955310582, 'test_avg': -82.66147577781612, 'test_std': 7.678555030383389}
    Episode Length: {'avg': 22.110192837465565, 'std': 5.8322727772231024, 'run': 22.009163321034425, 'test_avg': 21.3017578125, 'test_std': 1.654703533898207}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 10001):
    Value Loss: {'avg': 44.929389556248985, 'std': 4.101556156684399}
    Value Grad Norm: {'avg': 829.0708646774292, 'std': 461.7890087706041}
    Policy Loss: {'avg': 0.0026688077487051487, 'std': 0.0068356222637965805}
    Total_Loss: {'avg': -0.1304723583161831, 'std': 0.007270255721704409}
    Policy Entropy: {'avg': 1.3231525421142578, 'std': 0.5085976123809814}
    KL Divergence: {'avg': 0.028872743248939514, 'std': 0.2529572546482086}
    Policy Grad Norm: {'avg': 2.530126415193081, 'std': 0.9738833999407198}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -85.9664190198909, 'std': 27.12893997579193, 'run': -85.33938417459647, 'test_avg': -81.36804842862674, 'test_std': 7.580454597203825}
    Episode Length: {'avg': 22.325333333333333, 'std': 5.833765926816818, 'run': 22.152752044765425, 'test_avg': 21.0634765625, 'test_std': 1.6186396027260619}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 10001):
    Value Loss: {'avg': 41.668119033177696, 'std': 4.179336937749239}
    Value Grad Norm: {'avg': 726.6736532847086, 'std': 346.70136761134603}
    Policy Loss: {'avg': 0.009433060098672286, 'std': 0.010831100649907935}
    Total_Loss: {'avg': -0.11482818704098463, 'std': 0.011201505712492581}
    Policy Entropy: {'avg': 1.2513153553009033, 'std': 0.4676460921764374}
    KL Divergence: {'avg': 0.02949470654129982, 'std': 0.23973743617534637}
    Policy Grad Norm: {'avg': 3.575037106871605, 'std': 3.539897484758502}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.02098187972425, 'std': 26.822778081757935, 'run': -79.93353585497576, 'test_avg': -81.93012064213465, 'test_std': 7.6825931787936135}
    Episode Length: {'avg': 21.403598971722364, 'std': 5.788392551714991, 'run': 20.982259358299306, 'test_avg': 21.13671875, 'test_std': 1.6443735078741806}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 10001):
    Value Loss: {'avg': 49.55929350852966, 'std': 6.823955674783611}
    Value Grad Norm: {'avg': 697.8872785568237, 'std': 423.87021055282884}
    Policy Loss: {'avg': 0.0028747659525834024, 'std': 0.00556698148380784}
    Total_Loss: {'avg': -0.12411170499399304, 'std': 0.006095907397858855}
    Policy Entropy: {'avg': 1.2518810033798218, 'std': 0.4680514335632324}
    KL Divergence: {'avg': 0.015188353136181831, 'std': 0.17735476791858673}
    Policy Grad Norm: {'avg': 2.7672744393348694, 'std': 0.7659632476674424}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.50850326921778, 'std': 23.954762130435498, 'run': -83.93888870115954, 'test_avg': -80.99409332349231, 'test_std': 7.468000171746121}
    Episode Length: {'avg': 21.83957219251337, 'std': 5.214740094720295, 'run': 21.73914057925914, 'test_avg': 21.0009765625, 'test_std': 1.582681856478327}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 10001):
    Value Loss: {'avg': 43.35800004005432, 'std': 5.0931515302504495}
    Value Grad Norm: {'avg': 671.7026958465576, 'std': 306.09518555809495}
    Policy Loss: {'avg': -0.002482478754245676, 'std': 0.010031448896063859}
    Total_Loss: {'avg': -0.1279487197753042, 'std': 0.010106416982459756}
    Policy Entropy: {'avg': 1.2851207256317139, 'std': 0.46379712224006653}
    KL Divergence: {'avg': 0.023548370227217674, 'std': 0.2134559005498886}
    Policy Grad Norm: {'avg': 2.2319886535406113, 'std': 0.7089516029578793}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -83.44716296427039, 'std': 26.476107278496237, 'run': -83.27976463119273, 'test_avg': -80.65565444964773, 'test_std': 7.376558077216812}
    Episode Length: {'avg': 21.589333333333332, 'std': 5.6753871723042435, 'run': 21.580157740932247, 'test_avg': 20.939453125, 'test_std': 1.5594489253988841}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 10001):
    Value Loss: {'avg': 46.0792388121287, 'std': 5.2240510901702315}
    Value Grad Norm: {'avg': 963.8693221410116, 'std': 457.4044632970375}
    Policy Loss: {'avg': 0.005099512462038547, 'std': 0.003828721408312412}
    Total_Loss: {'avg': -0.11563801066949964, 'std': 0.0042630045541257695}
    Policy Entropy: {'avg': 1.201355218887329, 'std': 0.46047478914260864}
    KL Divergence: {'avg': 0.02189061790704727, 'std': 0.21390169858932495}
    Policy Grad Norm: {'avg': 2.9070142656564713, 'std': 1.1929378235521964}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -81.5003577555243, 'std': 25.089568620349993, 'run': -81.97618552479858, 'test_avg': -79.71125280560932, 'test_std': 7.110636462138511}
    Episode Length: {'avg': 21.253968253968253, 'std': 5.297403538806576, 'run': 21.350277498635297, 'test_avg': 20.7333984375, 'test_std': 1.5175463895290182}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 10001):
    Value Loss: {'avg': 37.491304675738014, 'std': 3.7487809719122267}
    Value Grad Norm: {'avg': 894.743595123291, 'std': 502.100642753512}
    Policy Loss: {'avg': -0.00019746468751691282, 'std': 0.0043188167325783925}
    Total_Loss: {'avg': -0.11907659098505974, 'std': 0.0032889096822418386}
    Policy Entropy: {'avg': 1.1759463548660278, 'std': 0.4762442409992218}
    KL Divergence: {'avg': 0.030339542776346207, 'std': 0.2631275951862335}
    Policy Grad Norm: {'avg': 3.0725246220827103, 'std': 1.2474620747336578}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.59804477341793, 'std': 26.837823463812015, 'run': -82.48647194037565, 'test_avg': -79.71365942310956, 'test_std': 6.980058168193094}
    Episode Length: {'avg': 20.96725440806045, 'std': 5.865532310704747, 'run': 21.591461187257305, 'test_avg': 20.73046875, 'test_std': 1.4815299626647573}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 10001):
    Value Loss: {'avg': 37.41241240501404, 'std': 5.832736878433401}
    Value Grad Norm: {'avg': 623.4242372512817, 'std': 348.65217566054935}
    Policy Loss: {'avg': 0.005971357109956443, 'std': 0.006184733348618833}
    Total_Loss: {'avg': -0.11126802861690521, 'std': 0.007104932098839196}
    Policy Entropy: {'avg': 1.1619199514389038, 'std': 0.4799295663833618}
    KL Divergence: {'avg': 0.029646575450897217, 'std': 0.22772811353206635}
    Policy Grad Norm: {'avg': 2.2589695379137993, 'std': 1.1998898402782925}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.22209803559976, 'std': 25.220038785531614, 'run': -81.11585883691413, 'test_avg': -79.82055169138425, 'test_std': 7.06819461389734}
    Episode Length: {'avg': 20.925257731958762, 'std': 5.467531264606589, 'run': 21.132581988551518, 'test_avg': 20.7392578125, 'test_std': 1.5004497489611957}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 10001):
    Value Loss: {'avg': 37.74340136845907, 'std': 4.710749932310666}
    Value Grad Norm: {'avg': 727.8138465881348, 'std': 324.15605156355934}
    Policy Loss: {'avg': 0.012877259345259517, 'std': 0.016262690000602844}
    Total_Loss: {'avg': -0.10686513362452388, 'std': 0.014992966758956823}
    Policy Entropy: {'avg': 1.2182183265686035, 'std': 0.46760618686676025}
    KL Divergence: {'avg': 0.018670540302991867, 'std': 0.17567883431911469}
    Policy Grad Norm: {'avg': 4.162076808512211, 'std': 5.775589368332875}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.27118062170132, 'std': 24.871262980378358, 'run': -79.96183215515236, 'test_avg': -79.68756953900137, 'test_std': 7.488152462933445}
    Episode Length: {'avg': 20.962406015037594, 'std': 5.360309928716216, 'run': 20.901571332555708, 'test_avg': 20.767578125, 'test_std': 1.5967140310717771}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2401 / 10001):
    Value Loss: {'avg': 40.3618852297465, 'std': 3.4034414965620647}
    Value Grad Norm: {'avg': 809.482141494751, 'std': 437.46437230321783}
    Policy Loss: {'avg': -0.003480764018604532, 'std': 0.008317894407909782}
    Total_Loss: {'avg': -0.12984742945991457, 'std': 0.009576914732859446}
    Policy Entropy: {'avg': 1.230931043624878, 'std': 0.45098328590393066}
    KL Divergence: {'avg': 0.020989887416362762, 'std': 0.1990836262702942}
    Policy Grad Norm: {'avg': 2.5374164059758186, 'std': 1.0105964207278892}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -84.11714082458086, 'std': 24.796302711491716, 'run': -83.81165452143054, 'test_avg': -80.07361096709027, 'test_std': 7.716788137340486}
    Episode Length: {'avg': 21.926315789473684, 'std': 5.393450424285401, 'run': 21.858371594485256, 'test_avg': 20.8525390625, 'test_std': 1.6258211262041162}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 10001):
    Value Loss: {'avg': 36.5318257411321, 'std': 4.413266571616337}
    Value Grad Norm: {'avg': 818.9777949651083, 'std': 439.33166614573815}
    Policy Loss: {'avg': 0.002785525837680325, 'std': 0.007307802463366904}
    Total_Loss: {'avg': -0.11425970261916518, 'std': 0.00783829630967923}
    Policy Entropy: {'avg': 1.2007397413253784, 'std': 0.4801816940307617}
    KL Divergence: {'avg': 0.023871496319770813, 'std': 0.22223392128944397}
    Policy Grad Norm: {'avg': 2.8262259885668755, 'std': 1.2581265468384277}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.3679180292319, 'std': 24.126531466417926, 'run': -80.19324239557646, 'test_avg': -78.58549952492979, 'test_std': 7.301303371217988}
    Episode Length: {'avg': 21.455729166666668, 'std': 5.230929499300226, 'run': 21.020441616762437, 'test_avg': 20.5263671875, 'test_std': 1.5446758628991843}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 10001):
    Value Loss: {'avg': 36.95414912700653, 'std': 3.984824320000277}
    Value Grad Norm: {'avg': 636.0618410110474, 'std': 330.6629752930281}
    Policy Loss: {'avg': 0.003302969940705225, 'std': 0.0077299288078686405}
    Total_Loss: {'avg': -0.11624268535524607, 'std': 0.008521294909567975}
    Policy Entropy: {'avg': 1.1529879570007324, 'std': 0.5345064401626587}
    KL Divergence: {'avg': 0.02924991585314274, 'std': 0.22142338752746582}
    Policy Grad Norm: {'avg': 2.3599409386515617, 'std': 1.0225165344756306}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -81.41693073478365, 'std': 24.034258894220418, 'run': -78.67869356013662, 'test_avg': -79.6160382354634, 'test_std': 7.0342753868352625}
    Episode Length: {'avg': 21.265984654731458, 'std': 5.1514995696031365, 'run': 20.68965662096286, 'test_avg': 20.7470703125, 'test_std': 1.4985315764711642}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 10001):
    Value Loss: {'avg': 31.39920135339101, 'std': 2.3320740350923486}
    Value Grad Norm: {'avg': 731.0953089396158, 'std': 379.628327222407}
    Policy Loss: {'avg': 0.008500913332682103, 'std': 0.008633225928926657}
    Total_Loss: {'avg': -0.1035760729573667, 'std': 0.009515710851229401}
    Policy Entropy: {'avg': 1.0853511095046997, 'std': 0.5116758346557617}
    KL Divergence: {'avg': 0.025934681296348572, 'std': 0.21310727298259735}
    Policy Grad Norm: {'avg': 3.6240613386034966, 'std': 2.019104571897351}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.66068461485412, 'std': 23.380649446502215, 'run': -79.3793939376894, 'test_avg': -78.28356401912345, 'test_std': 7.408586183159915}
    Episode Length: {'avg': 20.655696202531647, 'std': 5.071432694869683, 'run': 20.86579959005909, 'test_avg': 20.4873046875, 'test_std': 1.5655704085222508}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 10001):
    Value Loss: {'avg': 31.21034598350525, 'std': 4.287496728508315}
    Value Grad Norm: {'avg': 741.9920736948649, 'std': 414.0819162898015}
    Policy Loss: {'avg': 0.005891427223104984, 'std': 0.0061971175604464135}
    Total_Loss: {'avg': -0.10583855025470257, 'std': 0.006706327571175257}
    Policy Entropy: {'avg': 1.192371129989624, 'std': 0.471517950296402}
    KL Divergence: {'avg': 0.026352006942033768, 'std': 0.2050318866968155}
    Policy Grad Norm: {'avg': 2.823421649634838, 'std': 0.9317288867305031}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.81020860934609, 'std': 23.533394471708515, 'run': -78.73820297271598, 'test_avg': -78.89213615384071, 'test_std': 7.388880854908732}
    Episode Length: {'avg': 20.89002557544757, 'std': 5.0980842647705815, 'run': 20.643761242378492, 'test_avg': 20.63671875, 'test_std': 1.5851050386010503}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 10001):
    Value Loss: {'avg': 37.22115111351013, 'std': 5.662129217310866}
    Value Grad Norm: {'avg': 792.323221206665, 'std': 405.42451026001635}
    Policy Loss: {'avg': 0.0025093178846873343, 'std': 0.005716498114301898}
    Total_Loss: {'avg': -0.10936622973531485, 'std': 0.005722240803603335}
    Policy Entropy: {'avg': 1.176009178161621, 'std': 0.48173919320106506}
    KL Divergence: {'avg': 0.024142049252986908, 'std': 0.20809921622276306}
    Policy Grad Norm: {'avg': 2.1748975589871407, 'std': 0.6687691527184797}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.57591206004865, 'std': 25.925905690514085, 'run': -80.13647371242439, 'test_avg': -78.4018524386722, 'test_std': 7.050895564858107}
    Episode Length: {'avg': 20.62849872773537, 'std': 5.635619365626311, 'run': 20.979575675397996, 'test_avg': 20.501953125, 'test_std': 1.4875774972426594}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 10001):
    Value Loss: {'avg': 37.024494767189026, 'std': 3.6842584813263595}
    Value Grad Norm: {'avg': 883.8858311971029, 'std': 523.1194664089651}
    Policy Loss: {'avg': 0.0025453570997342467, 'std': 0.0068165027907129624}
    Total_Loss: {'avg': -0.11136983847245574, 'std': 0.006686236925346233}
    Policy Entropy: {'avg': 1.0537478923797607, 'std': 0.49097341299057007}
    KL Divergence: {'avg': 0.016410252079367638, 'std': 0.18519461154937744}
    Policy Grad Norm: {'avg': 2.5693021044135094, 'std': 1.0699976082580849}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.25820677462697, 'std': 24.84690421099361, 'run': -80.51102375840269, 'test_avg': -78.68429618027889, 'test_std': 7.309919331846907}
    Episode Length: {'avg': 21.022959183673468, 'std': 5.385826393146138, 'run': 21.060738903566545, 'test_avg': 20.5888671875, 'test_std': 1.5461371617634188}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3101 / 10001):
    Value Loss: {'avg': 28.673864205678303, 'std': 2.8800627768228373}
    Value Grad Norm: {'avg': 761.0333814620972, 'std': 351.7023470992899}
    Policy Loss: {'avg': 0.005009903630707413, 'std': 0.0039958111312952925}
    Total_Loss: {'avg': -0.1079707033932209, 'std': 0.0038434367001273745}
    Policy Entropy: {'avg': 1.1603593826293945, 'std': 0.5196583271026611}
    KL Divergence: {'avg': 0.028393622487783432, 'std': 0.21366974711418152}
    Policy Grad Norm: {'avg': 2.6182067915797234, 'std': 0.885796949137932}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.963896644695, 'std': 24.71968248017468, 'run': -75.71655236952415, 'test_avg': -78.90087324244254, 'test_std': 7.821657923806131}
    Episode Length: {'avg': 20.347607052896727, 'std': 5.398486173361981, 'run': 20.046960645885495, 'test_avg': 20.6220703125, 'test_std': 1.6667536077075558}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 10001):
    Value Loss: {'avg': 33.64230446020762, 'std': 7.027225952938971}
    Value Grad Norm: {'avg': 1510.9165465037029, 'std': 869.2284491934282}
    Policy Loss: {'avg': 0.0048145172477234155, 'std': 0.0059856163109267245}
    Total_Loss: {'avg': -0.10213569132611156, 'std': 0.00652702255768442}
    Policy Entropy: {'avg': 1.094681978225708, 'std': 0.49124905467033386}
    KL Divergence: {'avg': 0.027858590707182884, 'std': 0.2285640835762024}
    Policy Grad Norm: {'avg': 2.762685850262642, 'std': 1.2514361860564431}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.2819381204283, 'std': 25.658116132743757, 'run': -75.88376716434215, 'test_avg': -78.47026362209236, 'test_std': 6.981786900820001}
    Episode Length: {'avg': 20.06879606879607, 'std': 5.569766074795712, 'run': 20.00855485679294, 'test_avg': 20.5166015625, 'test_std': 1.4868294751324238}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 10001):
    Value Loss: {'avg': 32.41835939884186, 'std': 3.8044117150445307}
    Value Grad Norm: {'avg': 728.2371759414673, 'std': 384.09131706578}
    Policy Loss: {'avg': 0.001094412466045469, 'std': 0.006173052282652796}
    Total_Loss: {'avg': -0.11543617816641927, 'std': 0.007321011671847932}
    Policy Entropy: {'avg': 1.1862804889678955, 'std': 0.49199697375297546}
    KL Divergence: {'avg': 0.019882960245013237, 'std': 0.20418091118335724}
    Policy Grad Norm: {'avg': 2.577053003013134, 'std': 0.7597569685926071}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.1474794290747, 'std': 26.221965988483472, 'run': -76.082307747345, 'test_avg': -78.24671057340197, 'test_std': 6.755477178042101}
    Episode Length: {'avg': 20.32418952618454, 'std': 5.671791195519814, 'run': 20.0735115839139, 'test_avg': 20.4775390625, 'test_std': 1.4528673825530742}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 10001):
    Value Loss: {'avg': 31.57265905539195, 'std': 4.496421158585197}
    Value Grad Norm: {'avg': 621.5272318522135, 'std': 328.1229135140802}
    Policy Loss: {'avg': 0.004342686181189492, 'std': 0.006047567291558534}
    Total_Loss: {'avg': -0.10888982890173793, 'std': 0.006437899791270692}
    Policy Entropy: {'avg': 1.1312382221221924, 'std': 0.5060056447982788}
    KL Divergence: {'avg': 0.018650848418474197, 'std': 0.18184781074523926}
    Policy Grad Norm: {'avg': 2.4406805858016014, 'std': 1.0434500830433782}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.62293042824083, 'std': 26.236937230671124, 'run': -77.57868382941213, 'test_avg': -77.81652167255587, 'test_std': 6.830014287829249}
    Episode Length: {'avg': 20.111922141119223, 'std': 5.706284489934705, 'run': 20.31004303252715, 'test_avg': 20.3701171875, 'test_std': 1.4295724290909817}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 10001):
    Value Loss: {'avg': 31.369429151217144, 'std': 3.2026520765961}
    Value Grad Norm: {'avg': 776.1846888860067, 'std': 471.214551877031}
    Policy Loss: {'avg': 0.004541804359178059, 'std': 0.008514308743154656}
    Total_Loss: {'avg': -0.1133328159339726, 'std': 0.00928443982785156}
    Policy Entropy: {'avg': 1.2092740535736084, 'std': 0.4778955280780792}
    KL Divergence: {'avg': 0.019901391118764877, 'std': 0.19933415949344635}
    Policy Grad Norm: {'avg': 3.6540832445025444, 'std': 4.13668131227184}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.13400412395225, 'std': 25.68748479092387, 'run': -75.81555259474435, 'test_avg': -78.66794514334123, 'test_std': 7.406479783096831}
    Episode Length: {'avg': 20.5479797979798, 'std': 5.543238757151255, 'run': 20.003555450797943, 'test_avg': 20.6064453125, 'test_std': 1.5868100927479563}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3601 / 10001):
    Value Loss: {'avg': 30.572153687477112, 'std': 3.7475672768908184}
    Value Grad Norm: {'avg': 902.1057697931925, 'std': 508.48710712531135}
    Policy Loss: {'avg': 0.008394483127631247, 'std': 0.009980280825776148}
    Total_Loss: {'avg': -0.10012221429497004, 'std': 0.008732769694886781}
    Policy Entropy: {'avg': 1.0990551710128784, 'std': 0.5035660266876221}
    KL Divergence: {'avg': 0.015917442739009857, 'std': 0.17705698311328888}
    Policy Grad Norm: {'avg': 3.5971591249108315, 'std': 1.9935864937623302}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.35434269430644, 'std': 24.55985500981814, 'run': -75.35134965767361, 'test_avg': -77.69194566455491, 'test_std': 7.021971486235022}
    Episode Length: {'avg': 20.11881188118812, 'std': 5.310716102284772, 'run': 19.87040268430297, 'test_avg': 20.369140625, 'test_std': 1.5349015274520412}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3701 / 10001):
    Value Loss: {'avg': 27.01189597447713, 'std': 3.2730467756431887}
    Value Grad Norm: {'avg': 728.1595144271851, 'std': 517.3190375483671}
    Policy Loss: {'avg': 0.003053941676625982, 'std': 0.005910117104574161}
    Total_Loss: {'avg': -0.10318529792129993, 'std': 0.006237652536558818}
    Policy Entropy: {'avg': 1.083806037902832, 'std': 0.4944246709346771}
    KL Divergence: {'avg': 0.018472639843821526, 'std': 0.1773352026939392}
    Policy Grad Norm: {'avg': 2.292432017624378, 'std': 0.5268138315225719}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.63206830960355, 'std': 26.444179586849813, 'run': -76.54889914079159, 'test_avg': -77.48993206378245, 'test_std': 6.879839627459993}
    Episode Length: {'avg': 19.89952153110048, 'std': 5.693482361249727, 'run': 20.137798879981364, 'test_avg': 20.2646484375, 'test_std': 1.4324913671742698}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3801 / 10001):
    Value Loss: {'avg': 30.85475703080495, 'std': 2.6402541781712467}
    Value Grad Norm: {'avg': 709.2918059031168, 'std': 341.3195903884766}
    Policy Loss: {'avg': 0.008663766435347497, 'std': 0.007522617845369738}
    Total_Loss: {'avg': -0.10134629905223846, 'std': 0.007495435579957755}
    Policy Entropy: {'avg': 1.0946650505065918, 'std': 0.5144690275192261}
    KL Divergence: {'avg': 0.017721690237522125, 'std': 0.17421042919158936}
    Policy Grad Norm: {'avg': 2.889080561697483, 'std': 1.2861950549126115}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.14857755821335, 'std': 26.301467903416167, 'run': -74.97059224298701, 'test_avg': -77.82580426147759, 'test_std': 8.463412746414422}
    Episode Length: {'avg': 20.039408866995075, 'std': 5.706139088375078, 'run': 19.767232925531435, 'test_avg': 20.369140625, 'test_std': 1.664327251166251}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3901 / 10001):
    Value Loss: {'avg': 27.766581296920776, 'std': 4.200484353146801}
    Value Grad Norm: {'avg': 798.5050328572592, 'std': 490.1605357198257}
    Policy Loss: {'avg': 0.007434034981997684, 'std': 0.0072321270915801416}
    Total_Loss: {'avg': -0.09583902359008789, 'std': 0.008034633141999132}
    Policy Entropy: {'avg': 1.0128469467163086, 'std': 0.5109918713569641}
    KL Divergence: {'avg': 0.02090241014957428, 'std': 0.193768709897995}
    Policy Grad Norm: {'avg': 2.3032411336898804, 'std': 0.7343766174820491}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.83864145914903, 'std': 23.735207013870614, 'run': -76.15442361815941, 'test_avg': -77.73495916969692, 'test_std': 7.000846344725637}
    Episode Length: {'avg': 20.27970297029703, 'std': 5.1375615349730595, 'run': 20.129188013367255, 'test_avg': 20.39453125, 'test_std': 1.4858083129305197}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4001 / 10001):
    Value Loss: {'avg': 27.27438509464264, 'std': 3.5695320201141603}
    Value Grad Norm: {'avg': 567.6783057848612, 'std': 268.7593385251948}
    Policy Loss: {'avg': 0.007726021809503436, 'std': 0.007578764779173679}
    Total_Loss: {'avg': -0.10251226415857673, 'std': 0.007202278950122865}
    Policy Entropy: {'avg': 1.109423279762268, 'std': 0.5441741943359375}
    KL Divergence: {'avg': 0.0189782977104187, 'std': 0.2055438905954361}
    Policy Grad Norm: {'avg': 2.4871812909841537, 'std': 0.822435687429531}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.08641028615376, 'std': 23.61494551498214, 'run': -78.44456876719586, 'test_avg': -76.6503397220878, 'test_std': 6.904507172608238}
    Episode Length: {'avg': 20.525252525252526, 'std': 5.166116166847423, 'run': 20.60156950754923, 'test_avg': 20.16015625, 'test_std': 1.4414803503988314}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 10001):
    Value Loss: {'avg': 28.584129810333252, 'std': 3.7377096049756875}
    Value Grad Norm: {'avg': 1148.9415404001873, 'std': 586.8933670272221}
    Policy Loss: {'avg': 0.0152454394265078, 'std': 0.015168857766176215}
    Total_Loss: {'avg': -0.08950726012699306, 'std': 0.014122980322734574}
    Policy Entropy: {'avg': 1.022396206855774, 'std': 0.514140248298645}
    KL Divergence: {'avg': 0.026769664138555527, 'std': 0.20520487427711487}
    Policy Grad Norm: {'avg': 3.3325062319636345, 'std': 1.6091441351200824}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.57128743578379, 'std': 25.204961422190053, 'run': -73.89039787207761, 'test_avg': -77.34856935819941, 'test_std': 6.544776260638793}
    Episode Length: {'avg': 19.901913875598087, 'std': 5.4682595371643, 'run': 19.555009449595392, 'test_avg': 20.310546875, 'test_std': 1.3888668991043507}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4201 / 10001):
    Value Loss: {'avg': 25.16762940088908, 'std': 3.9042325266624736}
    Value Grad Norm: {'avg': 826.1982997258505, 'std': 597.2559089819548}
    Policy Loss: {'avg': 0.00453070632647723, 'std': 0.007573939025982951}
    Total_Loss: {'avg': -0.0937905851751566, 'std': 0.00898062670676206}
    Policy Entropy: {'avg': 0.9917629957199097, 'std': 0.5229692459106445}
    KL Divergence: {'avg': 0.026247285306453705, 'std': 0.21466325223445892}
    Policy Grad Norm: {'avg': 3.1648408323526382, 'std': 1.3651046921943266}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.23928735873115, 'std': 24.79716032542381, 'run': -73.6446267514992, 'test_avg': -77.6600824781145, 'test_std': 7.070121630953154}
    Episode Length: {'avg': 19.843520782396087, 'std': 5.379937677462656, 'run': 19.493316510478994, 'test_avg': 20.3974609375, 'test_std': 1.5107794315060095}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4301 / 10001):
    Value Loss: {'avg': 23.066914836565655, 'std': 2.4823239098398724}
    Value Grad Norm: {'avg': 519.2357085545858, 'std': 285.20035479689926}
    Policy Loss: {'avg': 0.0018790554604493082, 'std': 0.005364197523192418}
    Total_Loss: {'avg': -0.10234183771535754, 'std': 0.004986769716907478}
    Policy Entropy: {'avg': 1.08724045753479, 'std': 0.4972095787525177}
    KL Divergence: {'avg': 0.029833097010850906, 'std': 0.22140160202980042}
    Policy Grad Norm: {'avg': 2.244261845946312, 'std': 0.5796381256590758}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.28316876137153, 'std': 22.894660873662843, 'run': -78.49453484058235, 'test_avg': -77.66368588076995, 'test_std': 6.830918582853147}
    Episode Length: {'avg': 20.24137931034483, 'std': 4.944605665884695, 'run': 20.5038830429075, 'test_avg': 20.3642578125, 'test_std': 1.4561064293288162}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 10001):
    Value Loss: {'avg': 27.36133138338725, 'std': 3.73413424870584}
    Value Grad Norm: {'avg': 819.9878438313802, 'std': 601.2156522578939}
    Policy Loss: {'avg': 0.0005163317546248436, 'std': 0.005052797862387249}
    Total_Loss: {'avg': -0.10478095663711429, 'std': 0.005300560317043003}
    Policy Entropy: {'avg': 1.0835334062576294, 'std': 0.5119154453277588}
    KL Divergence: {'avg': 0.022031618282198906, 'std': 0.20780512690544128}
    Policy Grad Norm: {'avg': 2.4212625846266747, 'std': 0.8106836283297452}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.0802254958361, 'std': 24.775884797470837, 'run': -74.18210688515634, 'test_avg': -76.54383031081943, 'test_std': 6.528729547251553}
    Episode Length: {'avg': 20.065693430656935, 'std': 5.399654462535021, 'run': 19.644458851088704, 'test_avg': 20.130859375, 'test_std': 1.3871849458434191}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4501 / 10001):
    Value Loss: {'avg': 25.05436901251475, 'std': 2.4925493092305717}
    Value Grad Norm: {'avg': 482.83606656392413, 'std': 207.6139715566028}
    Policy Loss: {'avg': 0.0032659492280799896, 'std': 0.005240984208841238}
    Total_Loss: {'avg': -0.09805504931136966, 'std': 0.00632229314223832}
    Policy Entropy: {'avg': 1.0287859439849854, 'std': 0.5065574049949646}
    KL Divergence: {'avg': 0.01963907852768898, 'std': 0.17949798703193665}
    Policy Grad Norm: {'avg': 2.268233649432659, 'std': 0.7687484216851397}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.52267644799328, 'std': 23.825161538704098, 'run': -76.99192731326389, 'test_avg': -77.2476428544774, 'test_std': 6.7872367878209}
    Episode Length: {'avg': 19.973557692307693, 'std': 5.215248798967614, 'run': 20.277787875993102, 'test_avg': 20.296875, 'test_std': 1.4408080144054585}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4601 / 10001):
    Value Loss: {'avg': 24.936347007751465, 'std': 2.4769909751879107}
    Value Grad Norm: {'avg': 648.9916143417358, 'std': 362.3341744633895}
    Policy Loss: {'avg': 0.008107511152047664, 'std': 0.005732648777213104}
    Total_Loss: {'avg': -0.09233686979860067, 'std': 0.00646634140980047}
    Policy Entropy: {'avg': 0.9725886583328247, 'std': 0.5357452630996704}
    KL Divergence: {'avg': 0.02072945609688759, 'std': 0.1999226212501526}
    Policy Grad Norm: {'avg': 2.512590065598488, 'std': 0.593773656905689}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.27507406923212, 'std': 23.67381676691021, 'run': -76.95916700623002, 'test_avg': -75.84249778237833, 'test_std': 7.102500998931624}
    Episode Length: {'avg': 20.097560975609756, 'std': 5.147601279159916, 'run': 20.204497532023254, 'test_avg': 19.9814453125, 'test_std': 1.5034619752663443}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4701 / 10001):
    Value Loss: {'avg': 24.47032419840495, 'std': 2.6996316528181747}
    Value Grad Norm: {'avg': 652.052106221517, 'std': 327.89540909940115}
    Policy Loss: {'avg': 0.0031403295579366386, 'std': 0.00547250253139664}
    Total_Loss: {'avg': -0.09429249446839094, 'std': 0.0063466945601167515}
    Policy Entropy: {'avg': 0.9530210494995117, 'std': 0.4879911243915558}
    KL Divergence: {'avg': 0.021386412903666496, 'std': 0.21756060421466827}
    Policy Grad Norm: {'avg': 2.609948121011257, 'std': 0.9417139308587306}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.66201319098072, 'std': 22.983523640237078, 'run': -77.32712011079488, 'test_avg': -76.92274372559439, 'test_std': 6.509191729108801}
    Episode Length: {'avg': 19.920398009950247, 'std': 4.974425324022328, 'run': 20.266138849996373, 'test_avg': 20.201171875, 'test_std': 1.3893282555641717}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4801 / 10001):
    Value Loss: {'avg': 23.65067712465922, 'std': 2.2848686728986483}
    Value Grad Norm: {'avg': 702.4245460828146, 'std': 458.2656249824983}
    Policy Loss: {'avg': 0.007055023103021085, 'std': 0.007030734604979312}
    Total_Loss: {'avg': -0.09621197078377008, 'std': 0.007678752396546326}
    Policy Entropy: {'avg': 1.0759434700012207, 'std': 0.5158290863037109}
    KL Divergence: {'avg': 0.015581289306282997, 'std': 0.16491279006004333}
    Policy Grad Norm: {'avg': 2.649447701871395, 'std': 0.7990671706122673}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.28100825889649, 'std': 25.637864543005808, 'run': -75.75476911054356, 'test_avg': -76.4829663648564, 'test_std': 6.142450294668486}
    Episode Length: {'avg': 19.61137440758294, 'std': 5.528526924900071, 'run': 19.972377383720836, 'test_avg': 20.0859375, 'test_std': 1.300704999642021}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4901 / 10001):
    Value Loss: {'avg': 23.35479732354482, 'std': 2.8004286189294274}
    Value Grad Norm: {'avg': 616.4690373738607, 'std': 359.5869490276456}
    Policy Loss: {'avg': 0.006403219114872627, 'std': 0.007855102093349588}
    Total_Loss: {'avg': -0.0914926752448082, 'std': 0.0070847018959083055}
    Policy Entropy: {'avg': 1.0228056907653809, 'std': 0.5364241003990173}
    KL Divergence: {'avg': 0.0324680432677269, 'std': 0.22918036580085754}
    Policy Grad Norm: {'avg': 3.713518127799034, 'std': 2.2140753774230655}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.8870432855239, 'std': 23.751079151524834, 'run': -76.78883274583812, 'test_avg': -76.21912553384838, 'test_std': 6.624971218979875}
    Episode Length: {'avg': 19.819951338199512, 'std': 5.189516945633658, 'run': 20.175065416262417, 'test_avg': 20.0830078125, 'test_std': 1.392622980409258}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5001 / 10001):
    Value Loss: {'avg': 22.25299870967865, 'std': 2.407217842120138}
    Value Grad Norm: {'avg': 912.8372284571329, 'std': 562.8102413254169}
    Policy Loss: {'avg': 0.005158674612175673, 'std': 0.00520114403124126}
    Total_Loss: {'avg': -0.09318090276792645, 'std': 0.004445836758625765}
    Policy Entropy: {'avg': 0.9660311937332153, 'std': 0.5322669148445129}
    KL Divergence: {'avg': 0.026234332472085953, 'std': 0.2237982451915741}
    Policy Grad Norm: {'avg': 2.7357759326696396, 'std': 1.0654626652513903}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.25421193345014, 'std': 24.822991121432768, 'run': -71.9583391429919, 'test_avg': -76.2294487305619, 'test_std': 7.00005299695724}
    Episode Length: {'avg': 19.466346153846153, 'std': 5.414885299178039, 'run': 19.18872617798823, 'test_avg': 20.080078125, 'test_std': 1.4702231952654279}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5101 / 10001):
    Value Loss: {'avg': 30.29244561990102, 'std': 3.442809607688624}
    Value Grad Norm: {'avg': 1231.3939040501912, 'std': 662.697552211837}
    Policy Loss: {'avg': 0.004927389352815226, 'std': 0.005851932775023961}
    Total_Loss: {'avg': -0.09279097430408001, 'std': 0.006287859722243749}
    Policy Entropy: {'avg': 0.9807649850845337, 'std': 0.5449573993682861}
    KL Divergence: {'avg': 0.021090557798743248, 'std': 0.19166186451911926}
    Policy Grad Norm: {'avg': 2.4447678178548813, 'std': 0.6791519564641115}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.44532567876008, 'std': 26.800569274838022, 'run': -73.53855966757723, 'test_avg': -76.72089330853726, 'test_std': 6.84085405375701}
    Episode Length: {'avg': 19.3006993006993, 'std': 5.795305911386355, 'run': 19.52771830413956, 'test_avg': 20.1826171875, 'test_std': 1.441858401622569}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5201 / 10001):
    Value Loss: {'avg': 24.684613188107807, 'std': 2.7635081330930835}
    Value Grad Norm: {'avg': 899.1084483464559, 'std': 478.16559556483946}
    Policy Loss: {'avg': 0.0058950629318133, 'std': 0.007563175941717668}
    Total_Loss: {'avg': -0.09665431128814816, 'std': 0.0077111784726754135}
    Policy Entropy: {'avg': 1.0338836908340454, 'std': 0.49876976013183594}
    KL Divergence: {'avg': 0.0371185727417469, 'std': 0.2480745017528534}
    Policy Grad Norm: {'avg': 2.7861799746751785, 'std': 1.1794094372819726}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.27746354418356, 'std': 22.413652135122824, 'run': -76.56633094563801, 'test_avg': -76.13396002605211, 'test_std': 7.56455629196643}
    Episode Length: {'avg': 20.18407960199005, 'std': 4.959131009740817, 'run': 20.284363991032933, 'test_avg': 20.078125, 'test_std': 1.5391219848910611}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5301 / 10001):
    Value Loss: {'avg': 27.14088996251424, 'std': 3.711001234469535}
    Value Grad Norm: {'avg': 951.704400062561, 'std': 667.5950304721488}
    Policy Loss: {'avg': 0.0033141130988951772, 'std': 0.003893263396237071}
    Total_Loss: {'avg': -0.10042839078232646, 'std': 0.005104724382823121}
    Policy Entropy: {'avg': 0.9959052205085754, 'std': 0.5070686340332031}
    KL Divergence: {'avg': 0.01628587581217289, 'std': 0.16772712767124176}
    Policy Grad Norm: {'avg': 3.144318513572216, 'std': 1.1765390663939703}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.35603545048193, 'std': 24.33918518506203, 'run': -77.84518818153312, 'test_avg': -76.35228089464616, 'test_std': 6.73899279599937}
    Episode Length: {'avg': 19.942168674698795, 'std': 5.276593472150761, 'run': 20.503331088375514, 'test_avg': 20.0927734375, 'test_std': 1.4170372796064448}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5401 / 10001):
    Value Loss: {'avg': 25.70337700843811, 'std': 2.5693202384718687}
    Value Grad Norm: {'avg': 676.6359303792318, 'std': 331.19234359349633}
    Policy Loss: {'avg': -0.0001726483751554042, 'std': 0.0051755964701116425}
    Total_Loss: {'avg': -0.10289054503664374, 'std': 0.005803439875099788}
    Policy Entropy: {'avg': 1.0216195583343506, 'std': 0.49155887961387634}
    KL Divergence: {'avg': 0.018326912075281143, 'std': 0.17044000327587128}
    Policy Grad Norm: {'avg': 2.182707577943802, 'std': 0.5078725007430167}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.72529563855848, 'std': 24.37111801603695, 'run': -74.44346275443459, 'test_avg': -76.42389101475709, 'test_std': 7.906480420865734}
    Episode Length: {'avg': 20.058536585365854, 'std': 5.290717854827756, 'run': 19.836021166904967, 'test_avg': 20.1279296875, 'test_std': 1.6136143227413893}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5501 / 10001):
    Value Loss: {'avg': 23.89015583197276, 'std': 2.476743681988701}
    Value Grad Norm: {'avg': 799.8003273010254, 'std': 461.2124795061557}
    Policy Loss: {'avg': 0.008487814862746745, 'std': 0.011319116468129617}
    Total_Loss: {'avg': -0.09603220084682107, 'std': 0.011182254240526487}
    Policy Entropy: {'avg': 1.0572121143341064, 'std': 0.5077247619628906}
    KL Divergence: {'avg': 0.029203401878476143, 'std': 0.21830736100673676}
    Policy Grad Norm: {'avg': 2.4476012885570526, 'std': 0.5560054351524844}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.50846398589714, 'std': 23.59538400407368, 'run': -75.62674403632086, 'test_avg': -76.62019154515804, 'test_std': 6.786295667079489}
    Episode Length: {'avg': 19.70316301703163, 'std': 5.1365267711034495, 'run': 19.942375788281637, 'test_avg': 20.1865234375, 'test_std': 1.4332048683852507}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5601 / 10001):
    Value Loss: {'avg': 24.09696912765503, 'std': 2.45565129084314}
    Value Grad Norm: {'avg': 873.6784880956014, 'std': 491.95573020356255}
    Policy Loss: {'avg': 0.0026459109503775835, 'std': 0.004630563008709262}
    Total_Loss: {'avg': -0.0991864437237382, 'std': 0.006616721771810247}
    Policy Entropy: {'avg': 1.0262212753295898, 'std': 0.5354439616203308}
    KL Divergence: {'avg': 0.02818400412797928, 'std': 0.19254443049430847}
    Policy Grad Norm: {'avg': 2.014403037726879, 'std': 0.40629772857685065}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.97673178143822, 'std': 24.54763241073732, 'run': -75.3546673924864, 'test_avg': -75.83612867040193, 'test_std': 6.78803154234512}
    Episode Length: {'avg': 19.7639902676399, 'std': 5.319958988545679, 'run': 19.877678215223323, 'test_avg': 19.970703125, 'test_std': 1.4242326242981638}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5701 / 10001):
    Value Loss: {'avg': 30.048659364382427, 'std': 4.235747239850031}
    Value Grad Norm: {'avg': 977.739678700765, 'std': 668.0709029075424}
    Policy Loss: {'avg': 0.0011511695629451424, 'std': 0.004090684051941552}
    Total_Loss: {'avg': -0.10078893415629864, 'std': 0.005018179755925914}
    Policy Entropy: {'avg': 0.9989149570465088, 'std': 0.5647829174995422}
    KL Divergence: {'avg': 0.022746510803699493, 'std': 0.19531100988388062}
    Policy Grad Norm: {'avg': 3.1605164036154747, 'std': 1.1348668277959237}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.43183799670643, 'std': 25.777615163690932, 'run': -73.58072518344758, 'test_avg': -75.70436763701696, 'test_std': 6.591943038752212}
    Episode Length: {'avg': 19.713603818615752, 'std': 5.608898585023064, 'run': 19.528021933483178, 'test_avg': 19.935546875, 'test_std': 1.3734885491614899}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5801 / 10001):
    Value Loss: {'avg': 27.040252725283306, 'std': 3.1732324590078}
    Value Grad Norm: {'avg': 711.255584081014, 'std': 436.86037360008663}
    Policy Loss: {'avg': 0.011116693378426135, 'std': 0.010468251895708816}
    Total_Loss: {'avg': -0.09708630619570613, 'std': 0.010760653202246936}
    Policy Entropy: {'avg': 1.0915696620941162, 'std': 0.5222355127334595}
    KL Divergence: {'avg': 0.01566576212644577, 'std': 0.1496080905199051}
    Policy Grad Norm: {'avg': 3.2692609056830406, 'std': 2.7155728742986533}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.92555528255666, 'std': 25.086514225739126, 'run': -74.03587622823315, 'test_avg': -75.96609366330894, 'test_std': 7.620188838057129}
    Episode Length: {'avg': 19.70843373493976, 'std': 5.480682501235031, 'run': 19.739034392849106, 'test_avg': 20.0400390625, 'test_std': 1.5728899551380322}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5901 / 10001):
    Value Loss: {'avg': 24.00931652386983, 'std': 2.8118532835214585}
    Value Grad Norm: {'avg': 548.4142039616903, 'std': 355.09028617823213}
    Policy Loss: {'avg': 0.001885680016130209, 'std': 0.003798517759941603}
    Total_Loss: {'avg': -0.09433813579380512, 'std': 0.0045084983301174174}
    Policy Entropy: {'avg': 0.9298113584518433, 'std': 0.5265442728996277}
    KL Divergence: {'avg': 0.017432967200875282, 'std': 0.17309439182281494}
    Policy Grad Norm: {'avg': 3.2820094004273415, 'std': 1.8793728430530203}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.88578320580613, 'std': 25.23249888312336, 'run': -70.80552996901211, 'test_avg': -76.60786785682151, 'test_std': 7.946072302479832}
    Episode Length: {'avg': 19.372037914691944, 'std': 5.473891077161549, 'run': 18.94432878407584, 'test_avg': 20.15625, 'test_std': 1.63309282880674}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6001 / 10001):
    Value Loss: {'avg': 20.510842164357502, 'std': 3.223503143906767}
    Value Grad Norm: {'avg': 455.7692189216614, 'std': 281.89927806207845}
    Policy Loss: {'avg': 0.003171169722918421, 'std': 0.004769092110987002}
    Total_Loss: {'avg': -0.08891960280016065, 'std': 0.005961294124971518}
    Policy Entropy: {'avg': 0.9249309301376343, 'std': 0.484992653131485}
    KL Divergence: {'avg': 0.019314710050821304, 'std': 0.1861935257911682}
    Policy Grad Norm: {'avg': 2.6091123148798943, 'std': 1.0789115014176176}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.43675306072475, 'std': 22.909105922225166, 'run': -72.13610738156105, 'test_avg': -76.02094393690459, 'test_std': 6.273262644135681}
    Episode Length: {'avg': 19.529691211401424, 'std': 4.969952197483108, 'run': 19.251573261734674, 'test_avg': 20.052734375, 'test_std': 1.3524978135632455}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6101 / 10001):
    Value Loss: {'avg': 21.34498969713847, 'std': 2.601510792169541}
    Value Grad Norm: {'avg': 543.9427544275919, 'std': 330.3805166203355}
    Policy Loss: {'avg': 0.006387077388353646, 'std': 0.007980425490490108}
    Total_Loss: {'avg': -0.09011106193065643, 'std': 0.007793482045828897}
    Policy Entropy: {'avg': 0.9294754266738892, 'std': 0.5312853455543518}
    KL Divergence: {'avg': 0.02987879514694214, 'std': 0.2949802279472351}
    Policy Grad Norm: {'avg': 3.5155923664569855, 'std': 1.4721690792029571}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.85904438611682, 'std': 23.93431965804603, 'run': -73.69738895673483, 'test_avg': -75.73060216638312, 'test_std': 6.539086741073742}
    Episode Length: {'avg': 19.455813953488374, 'std': 5.2554867154764535, 'run': 19.65787887854073, 'test_avg': 20.00390625, 'test_std': 1.3926370188282866}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6201 / 10001):
    Value Loss: {'avg': 23.94463308652242, 'std': 2.3975520586964816}
    Value Grad Norm: {'avg': 576.3196903864542, 'std': 348.873877473446}
    Policy Loss: {'avg': 0.0040507100347895175, 'std': 0.007418288734143936}
    Total_Loss: {'avg': -0.09023791132494807, 'std': 0.006367980666967416}
    Policy Entropy: {'avg': 0.9768860340118408, 'std': 0.5160021185874939}
    KL Divergence: {'avg': 0.027961134910583496, 'std': 0.21919642388820648}
    Policy Grad Norm: {'avg': 2.7122783437371254, 'std': 0.933662064171585}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.02394652923358, 'std': 21.544189585216905, 'run': -74.55707614178928, 'test_avg': -75.925728631952, 'test_std': 7.3029946473803244}
    Episode Length: {'avg': 20.072639225181597, 'std': 4.685204372047826, 'run': 19.765800601210326, 'test_avg': 19.962890625, 'test_std': 1.4805344539344936}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6301 / 10001):
    Value Loss: {'avg': 22.429200331370037, 'std': 2.062795122706998}
    Value Grad Norm: {'avg': 758.0558913548788, 'std': 479.34454880191817}
    Policy Loss: {'avg': 0.007299155957298353, 'std': 0.00591025117186031}
    Total_Loss: {'avg': -0.0961747383698821, 'std': 0.005903978933131546}
    Policy Entropy: {'avg': 1.0588130950927734, 'std': 0.5061976313591003}
    KL Divergence: {'avg': 0.020310118794441223, 'std': 0.18913312256336212}
    Policy Grad Norm: {'avg': 2.7395939752459526, 'std': 1.0483190208261255}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.18203341223031, 'std': 21.5472027424642, 'run': -75.62144941510407, 'test_avg': -76.12082196673617, 'test_std': 6.577926935566464}
    Episode Length: {'avg': 19.94403892944039, 'std': 4.716207210358684, 'run': 20.042808654619705, 'test_avg': 20.05859375, 'test_std': 1.401897561329264}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6401 / 10001):
    Value Loss: {'avg': 18.425636907418568, 'std': 2.0370157480821245}
    Value Grad Norm: {'avg': 504.2252782185872, 'std': 257.24121621448893}
    Policy Loss: {'avg': 0.00887224345933646, 'std': 0.00647871733689245}
    Total_Loss: {'avg': -0.08671505143865943, 'std': 0.0062651737166938655}
    Policy Entropy: {'avg': 0.938200831413269, 'std': 0.5418009757995605}
    KL Divergence: {'avg': 0.026609618216753006, 'std': 0.26246917247772217}
    Policy Grad Norm: {'avg': 2.63644477725029, 'std': 1.3382833436845918}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.3984781708894, 'std': 21.786449467085742, 'run': -75.12240920944086, 'test_avg': -75.88352395508586, 'test_std': 7.173479573151014}
    Episode Length: {'avg': 19.738095238095237, 'std': 4.7427113192346395, 'run': 19.91997139234964, 'test_avg': 20.015625, 'test_std': 1.5441895882225731}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6501 / 10001):
    Value Loss: {'avg': 20.61363919576009, 'std': 2.3853672848490093}
    Value Grad Norm: {'avg': 609.147694269816, 'std': 366.97964988494965}
    Policy Loss: {'avg': 0.006533944251714274, 'std': 0.006319375246975605}
    Total_Loss: {'avg': -0.09476270759478211, 'std': 0.007001454254219034}
    Policy Entropy: {'avg': 0.9521144032478333, 'std': 0.5245789289474487}
    KL Divergence: {'avg': 0.019095292314887047, 'std': 0.19064609706401825}
    Policy Grad Norm: {'avg': 2.8274066895246506, 'std': 1.1781730056772906}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.45540455198984, 'std': 22.970307327815945, 'run': -75.57934172360518, 'test_avg': -75.39058897141142, 'test_std': 6.5371379517660335}
    Episode Length: {'avg': 19.583535108958838, 'std': 5.0714908522311, 'run': 20.07188417962845, 'test_avg': 19.94140625, 'test_std': 1.3850782549953404}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6601 / 10001):
    Value Loss: {'avg': 19.851406296094257, 'std': 2.2739033919326417}
    Value Grad Norm: {'avg': 978.7686570485433, 'std': 475.89065781861495}
    Policy Loss: {'avg': 0.008307787007652223, 'std': 0.005254925792219009}
    Total_Loss: {'avg': -0.08722926722839475, 'std': 0.004399877178318906}
    Policy Entropy: {'avg': 0.9555176496505737, 'std': 0.5061789155006409}
    KL Divergence: {'avg': 0.02050236240029335, 'std': 0.18235521018505096}
    Policy Grad Norm: {'avg': 2.716364271938801, 'std': 0.9761986940403333}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.8155943923954, 'std': 23.504236489057746, 'run': -73.9455522147722, 'test_avg': -75.48307699803993, 'test_std': 6.2904389217197805}
    Episode Length: {'avg': 19.37037037037037, 'std': 5.118218354279646, 'run': 19.628054163939122, 'test_avg': 19.9345703125, 'test_std': 1.3208869722628247}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6701 / 10001):
    Value Loss: {'avg': 23.15366009871165, 'std': 3.6152328832964207}
    Value Grad Norm: {'avg': 980.0449625651041, 'std': 549.9682727751062}
    Policy Loss: {'avg': 0.008108627429464832, 'std': 0.005504799892997994}
    Total_Loss: {'avg': -0.08430264983326197, 'std': 0.0055663654586539}
    Policy Entropy: {'avg': 0.9441853761672974, 'std': 0.5354285836219788}
    KL Divergence: {'avg': 0.03763817995786667, 'std': 0.21627144515514374}
    Policy Grad Norm: {'avg': 2.5536939427256584, 'std': 0.9055581036876966}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.706738406483, 'std': 21.435081971845136, 'run': -73.72881304024924, 'test_avg': -76.11751256165076, 'test_std': 10.0360975454298}
    Episode Length: {'avg': 19.545238095238094, 'std': 4.661938202127256, 'run': 19.593541524496093, 'test_avg': 20.0615234375, 'test_std': 2.0556524643378276}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (6801 / 10001):
    Value Loss: {'avg': 22.272850116093952, 'std': 2.092097470489481}
    Value Grad Norm: {'avg': 961.3495680491129, 'std': 594.4937882718717}
    Policy Loss: {'avg': 0.005693313461961225, 'std': 0.006346665002334685}
    Total_Loss: {'avg': -0.09199748700484633, 'std': 0.006061259255686282}
    Policy Entropy: {'avg': 0.9525575041770935, 'std': 0.53045654296875}
    KL Divergence: {'avg': 0.01850389689207077, 'std': 0.17828699946403503}
    Policy Grad Norm: {'avg': 3.059417814016342, 'std': 2.2484540873537067}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.46191921798007, 'std': 24.441947551454863, 'run': -74.78071397233305, 'test_avg': -75.23973429089497, 'test_std': 6.531111618543464}
    Episode Length: {'avg': 19.583529411764705, 'std': 5.39526692484361, 'run': 19.883115809796127, 'test_avg': 19.89453125, 'test_std': 1.3645230733752498}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6901 / 10001):
    Value Loss: {'avg': 19.151093065738678, 'std': 1.6663206368941321}
    Value Grad Norm: {'avg': 421.4493169784546, 'std': 298.5590075518165}
    Policy Loss: {'avg': 0.006954495649551973, 'std': 0.005825849816761829}
    Total_Loss: {'avg': -0.08687324589118361, 'std': 0.00698652767695089}
    Policy Entropy: {'avg': 0.9411503076553345, 'std': 0.5157706141471863}
    KL Divergence: {'avg': 0.017205379903316498, 'std': 0.17253273725509644}
    Policy Grad Norm: {'avg': 2.7891902551054955, 'std': 0.8988682658295827}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.59144953142555, 'std': 24.282228508539962, 'run': -72.54508700207599, 'test_avg': -75.4114753096646, 'test_std': 6.740432167695308}
    Episode Length: {'avg': 19.27803738317757, 'std': 5.281760528363278, 'run': 19.272200216396506, 'test_avg': 19.9326171875, 'test_std': 1.4518141217385887}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7001 / 10001):
    Value Loss: {'avg': 20.994913895924885, 'std': 2.423690416018906}
    Value Grad Norm: {'avg': 1017.3004608154297, 'std': 534.0139779405038}
    Policy Loss: {'avg': 0.009050549153471366, 'std': 0.0064909911400005595}
    Total_Loss: {'avg': -0.07661474263295531, 'std': 0.0068711274572498095}
    Policy Entropy: {'avg': 0.8404934406280518, 'std': 0.5110687017440796}
    KL Divergence: {'avg': 0.016548439860343933, 'std': 0.16318422555923462}
    Policy Grad Norm: {'avg': 3.1856646463274956, 'std': 1.4979746431242744}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.76203923340783, 'std': 23.41790296684268, 'run': -72.7060666075212, 'test_avg': -75.27018514360624, 'test_std': 6.39189489704594}
    Episode Length: {'avg': 19.149882903981265, 'std': 5.124311227868484, 'run': 19.34092893343821, 'test_avg': 19.9140625, 'test_std': 1.3651770933083187}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7101 / 10001):
    Value Loss: {'avg': 23.516972581545513, 'std': 2.773155686167506}
    Value Grad Norm: {'avg': 995.2125968933105, 'std': 574.8864798594548}
    Policy Loss: {'avg': 0.007511962758144364, 'std': 0.009979225425508576}
    Total_Loss: {'avg': -0.08746979478746653, 'std': 0.010318295077007551}
    Policy Entropy: {'avg': 0.9821176528930664, 'std': 0.5069588422775269}
    KL Divergence: {'avg': 0.023097164928913116, 'std': 0.19599659740924835}
    Policy Grad Norm: {'avg': 2.603101685643196, 'std': 0.7971050311999063}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.11258889409962, 'std': 22.7261272412669, 'run': -72.0218743445713, 'test_avg': -75.27220938109295, 'test_std': 8.018171089280974}
    Episode Length: {'avg': 19.672985781990523, 'std': 4.96501314601303, 'run': 19.22670135888518, 'test_avg': 19.8896484375, 'test_std': 1.6377296694368728}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7201 / 10001):
    Value Loss: {'avg': 19.478651603062946, 'std': 1.6929321394329655}
    Value Grad Norm: {'avg': 729.0101591746012, 'std': 419.0845243011449}
    Policy Loss: {'avg': 0.00514589756494388, 'std': 0.007905459843638732}
    Total_Loss: {'avg': -0.08131793118081987, 'std': 0.008658620798834536}
    Policy Entropy: {'avg': 0.8879687190055847, 'std': 0.5392323732376099}
    KL Divergence: {'avg': 0.025551635771989822, 'std': 0.21862076222896576}
    Policy Grad Norm: {'avg': 3.5483484491705894, 'std': 1.7978967494890608}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.26117171021625, 'std': 24.076229332502244, 'run': -69.06057061856274, 'test_avg': -75.16394244237608, 'test_std': 7.090587514083916}
    Episode Length: {'avg': 19.048387096774192, 'std': 5.251724288043073, 'run': 18.56751383566092, 'test_avg': 19.9013671875, 'test_std': 1.517166769276977}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7301 / 10001):
    Value Loss: {'avg': 17.660062154134113, 'std': 1.9733096685858675}
    Value Grad Norm: {'avg': 341.3667842547099, 'std': 165.86037713308937}
    Policy Loss: {'avg': 0.007717211847193539, 'std': 0.009472205635939967}
    Total_Loss: {'avg': -0.07524810545146465, 'std': 0.009083112182734304}
    Policy Entropy: {'avg': 0.8304634690284729, 'std': 0.5221336483955383}
    KL Divergence: {'avg': 0.020596971735358238, 'std': 0.17879579961299896}
    Policy Grad Norm: {'avg': 4.504595659673214, 'std': 3.0875860486516524}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.87081887432173, 'std': 21.6668587479142, 'run': -73.98218316182322, 'test_avg': -75.15677208404745, 'test_std': 6.640540090470719}
    Episode Length: {'avg': 19.375886524822697, 'std': 4.748331557807233, 'run': 19.6085708404396, 'test_avg': 19.8837890625, 'test_std': 1.4083910431784814}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7401 / 10001):
    Value Loss: {'avg': 21.081881165504456, 'std': 2.5875546598048054}
    Value Grad Norm: {'avg': 448.7570242881775, 'std': 232.99653585331163}
    Policy Loss: {'avg': 0.006926296278834343, 'std': 0.005840556211504179}
    Total_Loss: {'avg': -0.08438636129721999, 'std': 0.006060634416747954}
    Policy Entropy: {'avg': 0.9335354566574097, 'std': 0.5235603451728821}
    KL Divergence: {'avg': 0.024293383583426476, 'std': 0.18297132849693298}
    Policy Grad Norm: {'avg': 2.8840978294610977, 'std': 1.4951406271023666}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.78815545953749, 'std': 24.577835304244957, 'run': -72.45688962103941, 'test_avg': -75.09401366882125, 'test_std': 8.057394817557773}
    Episode Length: {'avg': 19.13317757009346, 'std': 5.375482781731624, 'run': 19.299184201558344, 'test_avg': 19.87890625, 'test_std': 1.6568349129321658}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7501 / 10001):
    Value Loss: {'avg': 17.951875269412994, 'std': 1.7146980928516837}
    Value Grad Norm: {'avg': 552.0706156094869, 'std': 292.2690714038075}
    Policy Loss: {'avg': 0.004401836893521249, 'std': 0.0057823448718356905}
    Total_Loss: {'avg': -0.0842933189123869, 'std': 0.0059981295309544025}
    Policy Entropy: {'avg': 0.9158815741539001, 'std': 0.5451379418373108}
    KL Divergence: {'avg': 0.026548828929662704, 'std': 0.19316436350345612}
    Policy Grad Norm: {'avg': 2.37257182598114, 'std': 0.6692206709409579}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.51879546280148, 'std': 24.049204552753228, 'run': -71.46722125632941, 'test_avg': -74.95636650449659, 'test_std': 7.23767900258911}
    Episode Length: {'avg': 19.099307159353348, 'std': 5.268480021511129, 'run': 19.064208589494402, 'test_avg': 19.830078125, 'test_std': 1.5387043027809093}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7601 / 10001):
    Value Loss: {'avg': 18.292322754859924, 'std': 1.4431385145913949}
    Value Grad Norm: {'avg': 493.659720102946, 'std': 270.9201248665998}
    Policy Loss: {'avg': 0.006815900618676096, 'std': 0.005683477625211185}
    Total_Loss: {'avg': -0.07803799351677299, 'std': 0.006194888499979974}
    Policy Entropy: {'avg': 0.846514105796814, 'std': 0.49397003650665283}
    KL Divergence: {'avg': 0.023855574429035187, 'std': 0.2667546272277832}
    Policy Grad Norm: {'avg': 2.481515385210514, 'std': 0.8878648980572302}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.03602207741417, 'std': 22.266191984600166, 'run': -70.3995198994162, 'test_avg': -75.32138518298038, 'test_std': 7.315259850555071}
    Episode Length: {'avg': 19.458432304038006, 'std': 4.850869247794047, 'run': 18.867599738609954, 'test_avg': 19.9521484375, 'test_std': 1.4746077581737824}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7701 / 10001):
    Value Loss: {'avg': 20.259110788504284, 'std': 2.427103588693469}
    Value Grad Norm: {'avg': 1028.3400146166484, 'std': 580.4289129363814}
    Policy Loss: {'avg': 0.005059507268015295, 'std': 0.006244799510485139}
    Total_Loss: {'avg': -0.08293268224224448, 'std': 0.0056952543197301645}
    Policy Entropy: {'avg': 0.8467124104499817, 'std': 0.5165140628814697}
    KL Divergence: {'avg': 0.019275031983852386, 'std': 0.2077593356370926}
    Policy Grad Norm: {'avg': 2.5057462602853775, 'std': 0.617845480342745}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.71734074855836, 'std': 22.69881456139977, 'run': -71.34375524723434, 'test_avg': -75.17094481205987, 'test_std': 7.0569880738686415}
    Episode Length: {'avg': 19.368794326241133, 'std': 4.968093965295507, 'run': 19.06667389053927, 'test_avg': 19.9541015625, 'test_std': 1.5286466304987096}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7801 / 10001):
    Value Loss: {'avg': 16.135540227095287, 'std': 1.4622728789258723}
    Value Grad Norm: {'avg': 523.236424446106, 'std': 314.34837632979924}
    Policy Loss: {'avg': 0.004728278378024697, 'std': 0.005048308282605991}
    Total_Loss: {'avg': -0.07828338677063584, 'std': 0.007096388970491977}
    Policy Entropy: {'avg': 0.813246488571167, 'std': 0.49741896986961365}
    KL Divergence: {'avg': 0.018744099885225296, 'std': 0.1670835018157959}
    Policy Grad Norm: {'avg': 2.4451099932193756, 'std': 0.79086881175722}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.83796867443799, 'std': 23.570689448827196, 'run': -72.9001545231918, 'test_avg': -75.19817513638725, 'test_std': 6.634899935131126}
    Episode Length: {'avg': 18.943396226415093, 'std': 5.123162696305471, 'run': 19.37286092475168, 'test_avg': 19.93359375, 'test_std': 1.4257277387218563}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7901 / 10001):
    Value Loss: {'avg': 21.03504006067912, 'std': 3.4296979278445208}
    Value Grad Norm: {'avg': 416.1205539703369, 'std': 214.4272675286904}
    Policy Loss: {'avg': 0.005761131877079606, 'std': 0.006381026486907012}
    Total_Loss: {'avg': -0.0806109388358891, 'std': 0.006308369177538773}
    Policy Entropy: {'avg': 0.8960087895393372, 'std': 0.5421732664108276}
    KL Divergence: {'avg': 0.020931966602802277, 'std': 0.17916710674762726}
    Policy Grad Norm: {'avg': 3.0924426466226578, 'std': 1.046952744395601}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.73666880140243, 'std': 23.732388690221693, 'run': -71.547652710923, 'test_avg': -75.24410501973705, 'test_std': 7.5359300151011075}
    Episode Length: {'avg': 19.217798594847775, 'std': 5.2266531691453055, 'run': 19.14220643677822, 'test_avg': 19.98046875, 'test_std': 1.5269740601180615}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8001 / 10001):
    Value Loss: {'avg': 20.149659156799316, 'std': 1.9671521141697794}
    Value Grad Norm: {'avg': 511.95003906885785, 'std': 307.0217886779327}
    Policy Loss: {'avg': 0.002158951188903302, 'std': 0.0056954847576302986}
    Total_Loss: {'avg': -0.08565129525959492, 'std': 0.006643882689223297}
    Policy Entropy: {'avg': 0.8934295177459717, 'std': 0.517532229423523}
    KL Divergence: {'avg': 0.01770152524113655, 'std': 0.1709582507610321}
    Policy Grad Norm: {'avg': 2.3672028183937073, 'std': 0.6552984383217768}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.03111489783431, 'std': 21.57556989546943, 'run': -75.1989902211187, 'test_avg': -74.8301372176794, 'test_std': 6.480413013075613}
    Episode Length: {'avg': 19.726829268292683, 'std': 4.7347714494120785, 'run': 19.978042627761194, 'test_avg': 19.912109375, 'test_std': 1.4017601392667396}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8101 / 10001):
    Value Loss: {'avg': 17.08570917447408, 'std': 1.6509052275908234}
    Value Grad Norm: {'avg': 325.4674606323242, 'std': 162.95445301337136}
    Policy Loss: {'avg': 0.005353049607947469, 'std': 0.004382622688422845}
    Total_Loss: {'avg': -0.08154326863586903, 'std': 0.004554628240081625}
    Policy Entropy: {'avg': 0.8569951057434082, 'std': 0.5221850872039795}
    KL Divergence: {'avg': 0.01979443058371544, 'std': 0.1767868846654892}
    Policy Grad Norm: {'avg': 2.931423641741276, 'std': 1.7294799174359725}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.43626502161192, 'std': 21.668495354110455, 'run': -73.00739481318448, 'test_avg': -74.97946588637622, 'test_std': 6.893922102562529}
    Episode Length: {'avg': 19.381861575179, 'std': 4.745781231153103, 'run': 19.493584295779147, 'test_avg': 19.9365234375, 'test_std': 1.4733551552538795}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8201 / 10001):
    Value Loss: {'avg': 16.46828204393387, 'std': 1.583937181919}
    Value Grad Norm: {'avg': 482.1464327176412, 'std': 364.0990658164409}
    Policy Loss: {'avg': 0.0032682527671568096, 'std': 0.004978377264975492}
    Total_Loss: {'avg': -0.07693962333723903, 'std': 0.005365232547339825}
    Policy Entropy: {'avg': 0.7690803408622742, 'std': 0.5052585005760193}
    KL Divergence: {'avg': 0.028183463960886, 'std': 0.20537243783473969}
    Policy Grad Norm: {'avg': 2.1010462194681168, 'std': 0.38488139586825165}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.09972822654379, 'std': 24.012782838790812, 'run': -70.44426494014971, 'test_avg': -75.15576729981447, 'test_std': 6.358885559021379}
    Episode Length: {'avg': 18.848970251716246, 'std': 5.262455430188597, 'run': 18.9295665939467, 'test_avg': 19.95703125, 'test_std': 1.3463308700031495}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8301 / 10001):
    Value Loss: {'avg': 22.292690475781757, 'std': 2.7645222470666897}
    Value Grad Norm: {'avg': 1360.9202858606975, 'std': 572.668154861817}
    Policy Loss: {'avg': 0.002619906939798966, 'std': 0.006927102006573637}
    Total_Loss: {'avg': -0.08463287958875299, 'std': 0.007261088403048784}
    Policy Entropy: {'avg': 0.8884274959564209, 'std': 0.5205394625663757}
    KL Divergence: {'avg': 0.025642147287726402, 'std': 0.21380451321601868}
    Policy Grad Norm: {'avg': 2.281111352145672, 'std': 0.7273114900743334}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.79042247480186, 'std': 22.46902336521697, 'run': -71.45398319858981, 'test_avg': -74.87130622359996, 'test_std': 7.16633156335948}
    Episode Length: {'avg': 19.45990566037736, 'std': 4.9304881298556245, 'run': 19.143312932138983, 'test_avg': 19.9189453125, 'test_std': 1.5373832720354015}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8401 / 10001):
    Value Loss: {'avg': 19.750652114550274, 'std': 2.0631937194058643}
    Value Grad Norm: {'avg': 557.8138227462769, 'std': 361.3089043795112}
    Policy Loss: {'avg': 0.0014010948070790619, 'std': 0.005550985524507131}
    Total_Loss: {'avg': -0.08619202813133597, 'std': 0.006458440545963806}
    Policy Entropy: {'avg': 0.8545647263526917, 'std': 0.5635969638824463}
    KL Divergence: {'avg': 0.028359796851873398, 'std': 0.2547178566455841}
    Policy Grad Norm: {'avg': 2.926477015018463, 'std': 1.0630970077893291}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.29327125181811, 'std': 23.004557420643657, 'run': -75.24525987559404, 'test_avg': -74.9769617327365, 'test_std': 6.256923850503741}
    Episode Length: {'avg': 19.57246376811594, 'std': 5.054133546961634, 'run': 20.01347849367082, 'test_avg': 19.9306640625, 'test_std': 1.3251168685331103}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8501 / 10001):
    Value Loss: {'avg': 16.11037375529607, 'std': 1.0961770637317363}
    Value Grad Norm: {'avg': 562.9215574264526, 'std': 252.9541241915955}
    Policy Loss: {'avg': 0.006176077789859846, 'std': 0.004694447942868889}
    Total_Loss: {'avg': -0.07069143047556281, 'std': 0.005312576982436223}
    Policy Entropy: {'avg': 0.793067991733551, 'std': 0.5281355381011963}
    KL Divergence: {'avg': 0.018563026562333107, 'std': 0.18707187473773956}
    Policy Grad Norm: {'avg': 2.8887407779693604, 'std': 0.8392956764752291}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.53777645041747, 'std': 21.1527588716662, 'run': -73.3905014630274, 'test_avg': -74.4458170637754, 'test_std': 6.257843858875275}
    Episode Length: {'avg': 19.46875, 'std': 4.652747779435122, 'run': 19.66041789679326, 'test_avg': 19.859375, 'test_std': 1.343295708090739}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8601 / 10001):
    Value Loss: {'avg': 16.064187904198963, 'std': 2.2210312651397914}
    Value Grad Norm: {'avg': 372.14069684346515, 'std': 250.71857573408298}
    Policy Loss: {'avg': 0.0009391563362441957, 'std': 0.004087694489473773}
    Total_Loss: {'avg': -0.07842181669548154, 'std': 0.006112038513409734}
    Policy Entropy: {'avg': 0.7347232699394226, 'std': 0.4983067810535431}
    KL Divergence: {'avg': 0.019240625202655792, 'std': 0.1833321452140808}
    Policy Grad Norm: {'avg': 2.1363145112991333, 'std': 0.5245437129356312}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.87109054008167, 'std': 24.34938932448291, 'run': -67.90694146924683, 'test_avg': -74.8265644809932, 'test_std': 6.48965433046494}
    Episode Length: {'avg': 19.039080459770116, 'std': 5.347753988139709, 'run': 18.397356006292092, 'test_avg': 19.9375, 'test_std': 1.3947446002763373}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8701 / 10001):
    Value Loss: {'avg': 18.52098321914673, 'std': 1.8213188270204697}
    Value Grad Norm: {'avg': 446.464316368103, 'std': 262.46495738204266}
    Policy Loss: {'avg': 0.008973736956249923, 'std': 0.00846931120798982}
    Total_Loss: {'avg': -0.07884231000207365, 'std': 0.009485020996846514}
    Policy Entropy: {'avg': 0.8881532549858093, 'std': 0.5207316279411316}
    KL Divergence: {'avg': 0.02997002936899662, 'std': 0.23372262716293335}
    Policy Grad Norm: {'avg': 3.6954776123166084, 'std': 2.574526890427712}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.11825242067576, 'std': 22.882780104853932, 'run': -72.50783270996574, 'test_avg': -74.82126647807576, 'test_std': 8.567745789762167}
    Episode Length: {'avg': 19.365155131264917, 'std': 5.03949349296849, 'run': 19.465131921824277, 'test_avg': 19.90625, 'test_std': 1.7823461539499}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (8801 / 10001):
    Value Loss: {'avg': 15.438945968945822, 'std': 2.270039880579474}
    Value Grad Norm: {'avg': 358.316543896993, 'std': 188.38269333541066}
    Policy Loss: {'avg': 0.003617619047872722, 'std': 0.0074104036507173145}
    Total_Loss: {'avg': -0.07556757610291243, 'std': 0.009003728599394073}
    Policy Entropy: {'avg': 0.7851570844650269, 'std': 0.511855959892273}
    KL Divergence: {'avg': 0.021831104531884193, 'std': 0.1916562020778656}
    Policy Grad Norm: {'avg': 2.2830155566334724, 'std': 0.8540968029270629}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.29580139814794, 'std': 22.704539095548796, 'run': -71.39633090222365, 'test_avg': -74.77023049769412, 'test_std': 6.504981575423096}
    Episode Length: {'avg': 18.928899082568808, 'std': 4.997888515530222, 'run': 19.16226593350519, 'test_avg': 19.9443359375, 'test_std': 1.4016686304708386}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8901 / 10001):
    Value Loss: {'avg': 18.437426547209423, 'std': 1.5270317822502175}
    Value Grad Norm: {'avg': 528.4700444539388, 'std': 294.92050332805724}
    Policy Loss: {'avg': 0.0038007871189620346, 'std': 0.0065168674618261355}
    Total_Loss: {'avg': -0.08717956580221653, 'std': 0.007259013948561445}
    Policy Entropy: {'avg': 0.9560456275939941, 'std': 0.50698322057724}
    KL Divergence: {'avg': 0.017590906471014023, 'std': 0.15745456516742706}
    Policy Grad Norm: {'avg': 2.4018556028604507, 'std': 0.9489743530699108}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.04147491323842, 'std': 21.03720300287023, 'run': -74.8333004254199, 'test_avg': -74.68251735969285, 'test_std': 6.361435276527371}
    Episode Length: {'avg': 19.73076923076923, 'std': 4.624310279612537, 'run': 19.97398499476132, 'test_avg': 19.904296875, 'test_std': 1.3730885484429745}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9001 / 10001):
    Value Loss: {'avg': 17.1310537258784, 'std': 1.4719866085190825}
    Value Grad Norm: {'avg': 350.0995051066081, 'std': 198.47523537664898}
    Policy Loss: {'avg': 0.0011355734604876488, 'std': 0.0037473166771297356}
    Total_Loss: {'avg': -0.07890099426731467, 'std': 0.0044646901746106344}
    Policy Entropy: {'avg': 0.769355833530426, 'std': 0.520910918712616}
    KL Divergence: {'avg': 0.021172787994146347, 'std': 0.21045474708080292}
    Policy Grad Norm: {'avg': 2.529723711311817, 'std': 1.2102059660504574}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.5109986278228, 'std': 23.515822078554613, 'run': -72.5982171940811, 'test_avg': -74.70786465162563, 'test_std': 6.404194438473668}
    Episode Length: {'avg': 19.084705882352942, 'std': 5.185262053219069, 'run': 19.595618621979586, 'test_avg': 19.9375, 'test_std': 1.3678792892649556}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9101 / 10001):
    Value Loss: {'avg': 14.691140075524649, 'std': 1.240817092092274}
    Value Grad Norm: {'avg': 323.9638759295146, 'std': 184.8308972053819}
    Policy Loss: {'avg': 0.002580387459602207, 'std': 0.007901816879868353}
    Total_Loss: {'avg': -0.0736447093077004, 'std': 0.007891023562980326}
    Policy Entropy: {'avg': 0.7587776780128479, 'std': 0.4952256679534912}
    KL Divergence: {'avg': 0.03179774433374405, 'std': 0.25569748878479004}
    Policy Grad Norm: {'avg': 2.708660699427128, 'std': 1.503492008963185}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.25337256689681, 'std': 22.793100071325316, 'run': -70.19936498188687, 'test_avg': -74.77695762029767, 'test_std': 7.441662364039837}
    Episode Length: {'avg': 18.90639269406393, 'std': 4.979217562558307, 'run': 18.91304392562621, 'test_avg': 19.9033203125, 'test_std': 1.493942427111869}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9201 / 10001):
    Value Loss: {'avg': 15.443873226642609, 'std': 1.323670957303478}
    Value Grad Norm: {'avg': 358.68247095743817, 'std': 220.94504149909108}
    Policy Loss: {'avg': 0.004476592526771128, 'std': 0.007589201150631895}
    Total_Loss: {'avg': -0.07520496472716331, 'std': 0.008386343327692395}
    Policy Entropy: {'avg': 0.7929396629333496, 'std': 0.475860595703125}
    KL Divergence: {'avg': 0.019444413483142853, 'std': 0.2058471143245697}
    Policy Grad Norm: {'avg': 2.5713277235627174, 'std': 0.963686370728611}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.8034050959866, 'std': 22.84710121430142, 'run': -70.83484511458582, 'test_avg': -74.23042041402063, 'test_std': 6.331135411931458}
    Episode Length: {'avg': 19.055299539170505, 'std': 5.0240602695732, 'run': 19.076437934494553, 'test_avg': 19.8193359375, 'test_std': 1.361287142384367}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9301 / 10001):
    Value Loss: {'avg': 19.165960252285004, 'std': 1.907811357199015}
    Value Grad Norm: {'avg': 1109.7054265340169, 'std': 532.9898713412942}
    Policy Loss: {'avg': 0.005318691488355398, 'std': 0.008080345436270033}
    Total_Loss: {'avg': -0.07414245139807463, 'std': 0.007464380849599564}
    Policy Entropy: {'avg': 0.8049370646476746, 'std': 0.5258505940437317}
    KL Divergence: {'avg': 0.023266077041625977, 'std': 0.1860811710357666}
    Policy Grad Norm: {'avg': 2.839744418859482, 'std': 2.4534236845036106}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.93152467135776, 'std': 21.33138257259178, 'run': -73.47311630904915, 'test_avg': -74.765563363598, 'test_std': 9.099745547191999}
    Episode Length: {'avg': 19.375291375291376, 'std': 4.74048626162818, 'run': 19.69307623039947, 'test_avg': 19.94140625, 'test_std': 1.7947635352494036}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (9401 / 10001):
    Value Loss: {'avg': 17.562006493409474, 'std': 1.700343078046187}
    Value Grad Norm: {'avg': 330.26490147908527, 'std': 145.66884338966}
    Policy Loss: {'avg': 0.0034192343591712415, 'std': 0.003850075569277345}
    Total_Loss: {'avg': -0.08316771872341633, 'std': 0.004953556545475186}
    Policy Entropy: {'avg': 0.8649842739105225, 'std': 0.5407829284667969}
    KL Divergence: {'avg': 0.020583922043442726, 'std': 0.2043152153491974}
    Policy Grad Norm: {'avg': 2.5322658717632294, 'std': 0.78668649291686}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.63881919275926, 'std': 21.688485123313885, 'run': -74.14396319084194, 'test_avg': -74.4487149527876, 'test_std': 6.912100223222827}
    Episode Length: {'avg': 19.488151658767773, 'std': 4.794210756027331, 'run': 19.86328226636836, 'test_avg': 19.8681640625, 'test_std': 1.4846881736861435}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9501 / 10001):
    Value Loss: {'avg': 15.557484944661459, 'std': 2.264347571691449}
    Value Grad Norm: {'avg': 318.91241041819256, 'std': 212.54050340627512}
    Policy Loss: {'avg': 0.006798670277930796, 'std': 0.009248097744281508}
    Total_Loss: {'avg': -0.07250534184277058, 'std': 0.009673352466569272}
    Policy Entropy: {'avg': 0.8234984874725342, 'std': 0.5302448868751526}
    KL Divergence: {'avg': 0.027448074892163277, 'std': 0.21143770217895508}
    Policy Grad Norm: {'avg': 3.215248204767704, 'std': 2.590811868916379}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.46066456639763, 'std': 22.653470666175593, 'run': -72.14521865778843, 'test_avg': -74.41842821355593, 'test_std': 6.300292893616268}
    Episode Length: {'avg': 19.258215962441316, 'std': 5.013033773607759, 'run': 19.37271627597649, 'test_avg': 19.869140625, 'test_std': 1.337728092317198}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9601 / 10001):
    Value Loss: {'avg': 15.306984504063925, 'std': 1.0421072797749247}
    Value Grad Norm: {'avg': 263.2761352856954, 'std': 130.37671354731404}
    Policy Loss: {'avg': 0.005463407040224411, 'std': 0.006912567640468643}
    Total_Loss: {'avg': -0.07374071632511914, 'std': 0.007318544401965693}
    Policy Entropy: {'avg': 0.7895650863647461, 'std': 0.5250462889671326}
    KL Divergence: {'avg': 0.029788773506879807, 'std': 0.22189700603485107}
    Policy Grad Norm: {'avg': 2.5595160722732544, 'std': 1.0119773113492117}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.43184517360535, 'std': 21.377598729141987, 'run': -73.21718802064395, 'test_avg': -74.39059235897352, 'test_std': 7.801692624473249}
    Episode Length: {'avg': 19.264150943396228, 'std': 4.7524609053059415, 'run': 19.668255040218074, 'test_avg': 19.96875, 'test_std': 1.6895242488641589}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (9701 / 10001):
    Value Loss: {'avg': 17.06195557117462, 'std': 1.5755183120371026}
    Value Grad Norm: {'avg': 383.5185748736064, 'std': 190.01842552962205}
    Policy Loss: {'avg': 0.007321714248973876, 'std': 0.006152412623001048}
    Total_Loss: {'avg': -0.07502099452540278, 'std': 0.005490153052766489}
    Policy Entropy: {'avg': 0.8418680429458618, 'std': 0.5317133665084839}
    KL Divergence: {'avg': 0.021626416593790054, 'std': 0.18857800960540771}
    Policy Grad Norm: {'avg': 2.637487471103668, 'std': 1.201436155691394}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.60219974550773, 'std': 21.99893801012177, 'run': -70.49500067178336, 'test_avg': -74.6102405359069, 'test_std': 7.281086582787407}
    Episode Length: {'avg': 19.208920187793428, 'std': 4.846083095574907, 'run': 18.954306094744954, 'test_avg': 19.943359375, 'test_std': 1.5106118262477655}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9801 / 10001):
    Value Loss: {'avg': 14.103507101535797, 'std': 2.2741445032053345}
    Value Grad Norm: {'avg': 315.8327012062073, 'std': 189.05573864450528}
    Policy Loss: {'avg': 0.0019136864866595715, 'std': 0.0044626670023627}
    Total_Loss: {'avg': -0.07542884349822998, 'std': 0.004258942474455538}
    Policy Entropy: {'avg': 0.7706693410873413, 'std': 0.5069801211357117}
    KL Divergence: {'avg': 0.0276813767850399, 'std': 0.2088024765253067}
    Policy Grad Norm: {'avg': 1.956654503941536, 'std': 0.32132461620747643}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -69.02587403590486, 'std': 24.07313126907436, 'run': -68.77355653038023, 'test_avg': -74.43176547029594, 'test_std': 7.591245015968794}
    Episode Length: {'avg': 18.72119815668203, 'std': 5.302217816328733, 'run': 18.654150626954245, 'test_avg': 19.8642578125, 'test_std': 1.5487305272489191}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9901 / 10001):
    Value Loss: {'avg': 16.446967879931133, 'std': 1.8192506875466663}
    Value Grad Norm: {'avg': 335.2701555887858, 'std': 169.70670368679532}
    Policy Loss: {'avg': 0.006202426826348528, 'std': 0.010892283939458614}
    Total_Loss: {'avg': -0.0692354692146182, 'std': 0.010465944158422273}
    Policy Entropy: {'avg': 0.7518039345741272, 'std': 0.5062850713729858}
    KL Divergence: {'avg': 0.020867381244897842, 'std': 0.18955646455287933}
    Policy Grad Norm: {'avg': 3.1642595380544662, 'std': 1.8898233471711865}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.77446831081518, 'std': 21.108716564598033, 'run': -71.56394663993403, 'test_avg': -74.38182858474161, 'test_std': 6.314023317403188}
    Episode Length: {'avg': 19.269767441860466, 'std': 4.6517581014374345, 'run': 19.21714735990237, 'test_avg': 19.900390625, 'test_std': 1.348407569102202}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (10001 / 10001):
    Value Loss: {'avg': 16.002240876356762, 'std': 1.6658877265483805}
    Value Grad Norm: {'avg': 331.28511063257855, 'std': 229.6226754348455}
    Policy Loss: {'avg': 0.0019406408537179232, 'std': 0.011094062533480734}
    Total_Loss: {'avg': -0.07731729687657207, 'std': 0.012277240351853194}
    Policy Entropy: {'avg': 0.8427590131759644, 'std': 0.5163880586624146}
    KL Divergence: {'avg': 0.026326201856136322, 'std': 0.19967179000377655}
    Policy Grad Norm: {'avg': 3.2104652747511864, 'std': 2.2378729265303754}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -72.31422311785046, 'std': 20.84470621873499, 'run': -71.42312116163083, 'test_avg': -74.26034665817085, 'test_std': 6.303786977974044}
    Episode Length: {'avg': 19.41966426858513, 'std': 4.580104706215604, 'run': 19.2268557684407, 'test_avg': 19.8857421875, 'test_std': 1.3663191299190371}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Training took 25249.206 seconds in total.
