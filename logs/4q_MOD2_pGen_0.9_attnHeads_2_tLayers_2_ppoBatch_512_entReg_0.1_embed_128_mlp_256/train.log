
Iteration (1 / 2001):
    Value Loss: {'avg': 163.7015584309896, 'std': 1.7972997588949606}
    Value Grad Norm: {'avg': 65.91356404622395, 'std': 0.5007269567912316}
    Policy Loss: {'avg': -0.008020966003338495, 'std': 0.006525549325735307}
    Total_Loss: {'avg': -0.25424018998940784, 'std': 0.006567821052743938}
    Policy Entropy: {'avg': 2.462599754333496, 'std': 0.01991996169090271}
    KL Divergence: {'avg': 0.00663716858252883, 'std': 0.08211006969213486}
    Policy Grad Norm: {'avg': 0.5387410124142965, 'std': 0.009199611873437924}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -22.95815994400735, 'std': 6.646520724658428, 'run': -11.717623183376766, 'test_avg': -20.429575191916292, 'test_std': 7.391146744961867}
    Episode Length: {'avg': 7.75, 'std': 1.015504800579495, 'run': 5.266133573162392, 'test_avg': 7.4775390625, 'test_std': 1.0474501211449743}
    Ratio Terminated: {'avg': 0.171875, 'test_avg': 0.2841796875}

Iteration (101 / 2001):
    Value Loss: {'avg': 15.007438659667969, 'std': 0.01004605857280183}
    Value Grad Norm: {'avg': 6.2627668380737305, 'std': 0.26553682955792335}
    Policy Loss: {'avg': -7.450580596923828e-09, 'std': 0.0}
    Total_Loss: {'avg': -0.13634511828422546, 'std': 0.0}
    Policy Entropy: {'avg': 1.3634510040283203, 'std': 0.483901709318161}
    KL Divergence: {'avg': 0.015369508415460587, 'std': 0.14008353650569916}
    Policy Grad Norm: {'avg': 1.064521074295044, 'std': 0.0}
    Num PPO updates: {'avg': 1}
    Return: {'avg': -9.017016335584817, 'std': 5.025807590450561, 'run': -8.94351873778144, 'test_avg': -7.751346558739897, 'test_std': 2.767848210973216}
    Episode Length: {'avg': 5.47191011235955, 'std': 1.281588617762595, 'run': 5.45545375567281, 'test_avg': 5.212890625, 'test_std': 0.7095813602308825}
    Ratio Terminated: {'avg': 0.8876404494382022, 'test_avg': 0.970703125}

Iteration (201 / 2001):
    Value Loss: {'avg': 7.762437184651692, 'std': 0.011489652602022884}
    Value Grad Norm: {'avg': 8.782607714335123, 'std': 0.4522514519377228}
    Policy Loss: {'avg': -0.0016683486755937338, 'std': 0.0016683486755937338}
    Total_Loss: {'avg': -0.1271178536117077, 'std': 0.0023868121206760406}
    Policy Entropy: {'avg': 1.2616796493530273, 'std': 0.49310874938964844}
    KL Divergence: {'avg': 0.0214511938393116, 'std': 0.13147957623004913}
    Policy Grad Norm: {'avg': 2.203812599182129, 'std': 0.3198425769805908}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -7.943821154599797, 'std': 4.156120181199509, 'run': -7.834178132631886, 'test_avg': -7.413225992858071, 'test_std': 1.8188607448507472}
    Episode Length: {'avg': 5.2254901960784315, 'std': 1.2038081954665827, 'run': 5.197354923497645, 'test_avg': 5.091796875, 'test_std': 0.4649545233033381}
    Ratio Terminated: {'avg': 0.9215686274509803, 'test_avg': 0.9892578125}

Iteration (301 / 2001):
    Value Loss: {'avg': 8.863427797953287, 'std': 0.04568865077091384}
    Value Grad Norm: {'avg': 5.136111259460449, 'std': 0.6284597606227408}
    Policy Loss: {'avg': -0.006147108040750027, 'std': 0.004946769831000675}
    Total_Loss: {'avg': -0.13449427485466003, 'std': 0.004366259911344194}
    Policy Entropy: {'avg': 1.2777130603790283, 'std': 0.551013708114624}
    KL Divergence: {'avg': 0.012891510501503944, 'std': 0.12004076689481735}
    Policy Grad Norm: {'avg': 2.04358971118927, 'std': 0.14635484256516562}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.958966075867217, 'std': 4.197888253191432, 'run': -7.778957312314109, 'test_avg': -7.521830971525393, 'test_std': 2.440855777444247}
    Episode Length: {'avg': 5.204081632653061, 'std': 1.0875847015897329, 'run': 5.13794144475948, 'test_avg': 5.103515625, 'test_std': 0.510655353815917}
    Ratio Terminated: {'avg': 0.9489795918367347, 'test_avg': 0.982421875}

Iteration (401 / 2001):
    Value Loss: {'avg': 7.380954106648763, 'std': 0.07356332504397477}
    Value Grad Norm: {'avg': 9.044749736785889, 'std': 3.0457975370455816}
    Policy Loss: {'avg': -5.587935447692871e-09, 'std': 0.0}
    Total_Loss: {'avg': -0.1400355100631714, 'std': 0.0}
    Policy Entropy: {'avg': 1.4003551006317139, 'std': 0.6302329301834106}
    KL Divergence: {'avg': 0.07917097210884094, 'std': 0.46466055512428284}
    Policy Grad Norm: {'avg': 22.06537437438965, 'std': 0.0}
    Num PPO updates: {'avg': 1}
    Return: {'avg': -8.234910174425627, 'std': 3.8926529414494095, 'run': -8.265789464100084, 'test_avg': -7.246953889925331, 'test_std': 1.5273343718039303}
    Episode Length: {'avg': 5.4375, 'std': 1.2146029872623674, 'run': 5.442004800928587, 'test_avg': 5.076171875, 'test_std': 0.42396311214418686}
    Ratio Terminated: {'avg': 0.9375, 'test_avg': 0.9921875}

Iteration (501 / 2001):
    Value Loss: {'avg': 4.492947896321614, 'std': 0.008942300875828302}
    Value Grad Norm: {'avg': 5.213619391123454, 'std': 0.9756878310333167}
    Policy Loss: {'avg': -0.007264360164602597, 'std': 0.005835967291085723}
    Total_Loss: {'avg': -0.12822625041007996, 'std': 0.005775410741537895}
    Policy Entropy: {'avg': 1.2090885639190674, 'std': 0.686434805393219}
    KL Divergence: {'avg': 0.01744372397661209, 'std': 0.1338789165019989}
    Policy Grad Norm: {'avg': 2.3345791498819985, 'std': 0.6359330423563643}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.983530678755086, 'std': 2.9914082339836336, 'run': -6.929475350457294, 'test_avg': -7.263776708654307, 'test_std': 2.2422177877325833}
    Episode Length: {'avg': 5.0, 'std': 0.901044498412155, 'run': 4.983552449646476, 'test_avg': 5.0595703125, 'test_std': 0.4042815422062357}
    Ratio Terminated: {'avg': 0.9702970297029703, 'test_avg': 0.98828125}

Iteration (601 / 2001):
    Value Loss: {'avg': 1.0829370021820068, 'std': 0.0034618735037904246}
    Value Grad Norm: {'avg': 3.7376240889231362, 'std': 0.2844875726132869}
    Policy Loss: {'avg': -0.0039009529476364455, 'std': 0.003566895113878121}
    Total_Loss: {'avg': -0.12553584078947702, 'std': 0.002830540991476122}
    Policy Entropy: {'avg': 1.2071982622146606, 'std': 0.6596136689186096}
    KL Divergence: {'avg': 0.008502095937728882, 'std': 0.14225240051746368}
    Policy Grad Norm: {'avg': 2.8502840598424277, 'std': 2.1232652090098725}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -5.987603072070739, 'std': 2.332708874255849, 'run': -6.260841640368696, 'test_avg': -7.07740917237129, 'test_std': 1.2419337221383508}
    Episode Length: {'avg': 4.675925925925926, 'std': 0.825840802788327, 'run': 4.761458242655922, 'test_avg': 5.0498046875, 'test_std': 0.34863007702008064}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (701 / 2001):
    Value Loss: {'avg': 4.390135924021403, 'std': 0.022325087337510673}
    Value Grad Norm: {'avg': 15.53659439086914, 'std': 0.6085536913647537}
    Policy Loss: {'avg': -0.002867326606065035, 'std': 0.0028673005290329456}
    Total_Loss: {'avg': -0.12306948751211166, 'std': 0.0035646483302116394}
    Policy Entropy: {'avg': 1.2089951038360596, 'std': 0.6933667659759521}
    KL Divergence: {'avg': 0.02036624401807785, 'std': 0.1256803572177887}
    Policy Grad Norm: {'avg': 1.8673561215400696, 'std': 0.15284579992294312}
    Num PPO updates: {'avg': 2}
    Return: {'avg': -7.289352918595593, 'std': 3.383451131127304, 'run': -7.061674938488255, 'test_avg': -6.982133035635343, 'test_std': 1.1809697435451638}
    Episode Length: {'avg': 5.098039215686274, 'std': 1.004985649312902, 'run': 5.0313140473417794, 'test_avg': 5.0361328125, 'test_std': 0.3024365344346477}
    Ratio Terminated: {'avg': 0.9705882352941176, 'test_avg': 0.9970703125}

Iteration (801 / 2001):
    Value Loss: {'avg': 2.981198310852051, 'std': 0.007325483643294466}
    Value Grad Norm: {'avg': 4.121870199839274, 'std': 0.3343443364478634}
    Policy Loss: {'avg': -0.007133133398989837, 'std': 0.0059255470897487846}
    Total_Loss: {'avg': -0.13210674126942953, 'std': 0.005609554194514618}
    Policy Entropy: {'avg': 1.2350139617919922, 'std': 0.6957337856292725}
    KL Divergence: {'avg': 0.0117325559258461, 'std': 0.10835923254489899}
    Policy Grad Norm: {'avg': 5.315555493036906, 'std': 0.9888710359771473}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.840062892564329, 'std': 2.759478441841528, 'run': -6.782913929690444, 'test_avg': -6.880371350482164, 'test_std': 0.7738529669905582}
    Episode Length: {'avg': 4.97196261682243, 'std': 0.9012757720554163, 'run': 4.946288778960557, 'test_avg': 5.02734375, 'test_std': 0.21477271552955116}
    Ratio Terminated: {'avg': 0.9719626168224299, 'test_avg': 1.0}

Iteration (901 / 2001):
    Value Loss: {'avg': 1.2413376967112224, 'std': 0.08103594869522245}
    Value Grad Norm: {'avg': 9.989978472391764, 'std': 2.634996364466762}
    Policy Loss: {'avg': -0.003877432240794102, 'std': 0.003318928955696271}
    Total_Loss: {'avg': -0.12225036323070526, 'std': 0.003166222392589297}
    Policy Entropy: {'avg': 1.1814388036727905, 'std': 0.7037631869316101}
    KL Divergence: {'avg': 0.008065866306424141, 'std': 0.08579423278570175}
    Policy Grad Norm: {'avg': 1.1906262040138245, 'std': 0.2469227482345437}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.213798005220921, 'std': 2.7245141390673466, 'run': -6.417560801261835, 'test_avg': -6.707774463953683, 'test_std': 0.5928951821915908}
    Episode Length: {'avg': 4.723809523809524, 'std': 0.9206130265595864, 'run': 4.811711816211287, 'test_avg': 5.0068359375, 'test_std': 0.1208375250429108}
    Ratio Terminated: {'avg': 0.9904761904761905, 'test_avg': 1.0}

Iteration (1001 / 2001):
    Value Loss: {'avg': 1.0965267022450764, 'std': 0.00552288717248132}
    Value Grad Norm: {'avg': 2.617251714070638, 'std': 0.20536559586237954}
    Policy Loss: {'avg': -0.0020268835748235383, 'std': 0.0026094108248673107}
    Total_Loss: {'avg': -0.12093957761923473, 'std': 0.0026169107362570988}
    Policy Entropy: {'avg': 1.1889574527740479, 'std': 0.7196242809295654}
    KL Divergence: {'avg': 0.006039304193109274, 'std': 0.1242404654622078}
    Policy Grad Norm: {'avg': 3.8747220436731973, 'std': 1.9031002734743105}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.784324380250422, 'std': 1.6019605765061087, 'run': -6.735638015129619, 'test_avg': -6.765107139640141, 'test_std': 1.3520874411351924}
    Episode Length: {'avg': 4.944444444444445, 'std': 0.5905636562630362, 'run': 4.932480349926178, 'test_avg': 5.0234375, 'test_std': 0.2488989425324061}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (1101 / 2001):
    Value Loss: {'avg': 0.5773910681406657, 'std': 0.010046011951447385}
    Value Grad Norm: {'avg': 5.288980960845947, 'std': 0.48094881949980023}
    Policy Loss: {'avg': -0.0023629767820239067, 'std': 0.002808515679353196}
    Total_Loss: {'avg': -0.12049051870902379, 'std': 0.0030010596599174552}
    Policy Entropy: {'avg': 1.1836782693862915, 'std': 0.7055318355560303}
    KL Divergence: {'avg': 0.004751009866595268, 'std': 0.0703202560544014}
    Policy Grad Norm: {'avg': 1.940403938293457, 'std': 0.015748309264811335}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.488442848282341, 'std': 2.018044955881768, 'run': -6.4686709092179955, 'test_avg': -6.707858943074825, 'test_std': 0.7687995768376455}
    Episode Length: {'avg': 4.831775700934579, 'std': 0.6765219091907985, 'run': 4.8294888640673275, 'test_avg': 5.0107421875, 'test_std': 0.16202405039905293}
    Ratio Terminated: {'avg': 0.9906542056074766, 'test_avg': 0.9990234375}

Iteration (1201 / 2001):
    Value Loss: {'avg': 0.8675880432128906, 'std': 0.013988447695861859}
    Value Grad Norm: {'avg': 2.513056914011637, 'std': 0.18787309149412293}
    Policy Loss: {'avg': -0.004051261271039645, 'std': 0.0032478844597183905}
    Total_Loss: {'avg': -0.12601550668478012, 'std': 0.0039005032744638796}
    Policy Entropy: {'avg': 1.2278201580047607, 'std': 0.688794732093811}
    KL Divergence: {'avg': 0.0017663631588220596, 'std': 0.08637623488903046}
    Policy Grad Norm: {'avg': 1.0793977777163188, 'std': 0.06694128615514973}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.59926938872862, 'std': 1.8792067947750049, 'run': -6.507899049059251, 'test_avg': -6.6217310560823535, 'test_std': 0.5662375571624643}
    Episode Length: {'avg': 4.892156862745098, 'std': 0.6402643869512039, 'run': 4.884118009135409, 'test_avg': 4.9990234375, 'test_std': 0.10363992389848418}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 2001):
    Value Loss: {'avg': 0.5052209695180258, 'std': 0.009598040380806054}
    Value Grad Norm: {'avg': 6.194848378499349, 'std': 0.13735491025674107}
    Policy Loss: {'avg': -0.003104797564446926, 'std': 0.0024770185315805835}
    Total_Loss: {'avg': -0.1208779513835907, 'std': 0.0018571695729513585}
    Policy Entropy: {'avg': 1.1706628799438477, 'std': 0.6851158142089844}
    KL Divergence: {'avg': 0.00922644417732954, 'std': 0.16011470556259155}
    Policy Grad Norm: {'avg': 1.3643072843551636, 'std': 0.4891104125303592}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.160543807946748, 'std': 2.0765790778320583, 'run': -6.274546265072871, 'test_avg': -6.583639639375178, 'test_std': 0.6728840333488816}
    Episode Length: {'avg': 4.777777777777778, 'std': 0.7370277311900889, 'run': 4.808175954479219, 'test_avg': 5.001953125, 'test_std': 0.11691047986700925}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1401 / 2001):
    Value Loss: {'avg': 0.4239431619644165, 'std': 0.007342335385103077}
    Value Grad Norm: {'avg': 2.9625653425852456, 'std': 0.2469276600259365}
    Policy Loss: {'avg': 0.003385017936428388, 'std': 0.0035494743104142134}
    Total_Loss: {'avg': -0.11093603074550629, 'std': 0.0029877085254559}
    Policy Entropy: {'avg': 1.1447951793670654, 'std': 0.5975713729858398}
    KL Divergence: {'avg': 0.003468739101663232, 'std': 0.07450783997774124}
    Policy Grad Norm: {'avg': 8.741137663523356, 'std': 1.8711924684696737}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.394240049096361, 'std': 2.206137388273939, 'run': -6.234403316959178, 'test_avg': -6.605561296265471, 'test_std': 0.8016953882999021}
    Episode Length: {'avg': 4.869158878504673, 'std': 0.7245251380678244, 'run': 4.827459717065648, 'test_avg': 5.0205078125, 'test_std': 0.23084706436614014}
    Ratio Terminated: {'avg': 0.9906542056074766, 'test_avg': 0.998046875}

Iteration (1501 / 2001):
    Value Loss: {'avg': 2.5158118406931558, 'std': 0.010706557154693439}
    Value Grad Norm: {'avg': 5.565618356068929, 'std': 0.8169331930398754}
    Policy Loss: {'avg': -0.006728453561663628, 'std': 0.005100990098955837}
    Total_Loss: {'avg': -0.10948541015386581, 'std': 0.0049370097308068525}
    Policy Entropy: {'avg': 1.0251059532165527, 'std': 0.49884724617004395}
    KL Divergence: {'avg': 0.012492087669670582, 'std': 0.1606324166059494}
    Policy Grad Norm: {'avg': 3.359719157218933, 'std': 1.2672819749696687}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.226638465021973, 'std': 2.7841780908727074, 'run': -6.222213121728128, 'test_avg': -6.55578166933023, 'test_std': 0.8471005780737089}
    Episode Length: {'avg': 4.83, 'std': 0.938669270829721, 'run': 4.839660798204545, 'test_avg': 5.013671875, 'test_std': 0.18170361810922855}
    Ratio Terminated: {'avg': 0.98, 'test_avg': 0.9970703125}

Iteration (1601 / 2001):
    Value Loss: {'avg': 3.5181594689687095, 'std': 0.015780359767910795}
    Value Grad Norm: {'avg': 8.199318091074625, 'std': 0.8623081815990314}
    Policy Loss: {'avg': -0.005392315797507763, 'std': 0.0048101036630083215}
    Total_Loss: {'avg': -0.10245674103498459, 'std': 0.004685326808498299}
    Policy Entropy: {'avg': 0.9693824052810669, 'std': 0.5053223371505737}
    KL Divergence: {'avg': 0.01225446816533804, 'std': 0.12064085900783539}
    Policy Grad Norm: {'avg': 3.108785072962443, 'std': 0.2797735871479508}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.0706117093822884, 'std': 3.060397231827679, 'run': -6.055687715106945, 'test_avg': -6.599158562406956, 'test_std': 0.9156465704822897}
    Episode Length: {'avg': 4.792079207920792, 'std': 0.8480242814005488, 'run': 4.792420844817102, 'test_avg': 5.02734375, 'test_std': 0.2637514347561687}
    Ratio Terminated: {'avg': 0.9801980198019802, 'test_avg': 0.9951171875}

Iteration (1701 / 2001):
    Value Loss: {'avg': 1.7434697151184082, 'std': 0.023638978912350082}
    Value Grad Norm: {'avg': 6.841355800628662, 'std': 2.086447078554777}
    Policy Loss: {'avg': -0.006151356423894565, 'std': 0.004896426411473925}
    Total_Loss: {'avg': -0.10503396640221278, 'std': 0.005119301241624738}
    Policy Entropy: {'avg': 0.991692304611206, 'std': 0.45196405053138733}
    KL Divergence: {'avg': 0.0067429374903440475, 'std': 0.11604512482881546}
    Policy Grad Norm: {'avg': 1.854772726694743, 'std': 0.5976939643359152}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.009339582428433, 'std': 2.630252882738291, 'run': -6.206033936035329, 'test_avg': -6.571321817711578, 'test_std': 0.9341672528749279}
    Episode Length: {'avg': 4.8, 'std': 0.8552359741197582, 'run': 4.869100334456441, 'test_avg': 5.025390625, 'test_std': 0.2639466161217252}
    Ratio Terminated: {'avg': 0.9904761904761905, 'test_avg': 0.99609375}

Iteration (1801 / 2001):
    Value Loss: {'avg': 0.6214758356412252, 'std': 0.012248756395381328}
    Value Grad Norm: {'avg': 3.4398364226023355, 'std': 0.454496619851666}
    Policy Loss: {'avg': -0.004761846270412207, 'std': 0.004117649846382847}
    Total_Loss: {'avg': -0.10242779801289241, 'std': 0.0040874981825155116}
    Policy Entropy: {'avg': 0.9764052629470825, 'std': 0.432755708694458}
    KL Divergence: {'avg': 0.007987039163708687, 'std': 0.10760504007339478}
    Policy Grad Norm: {'avg': 1.8997066020965576, 'std': 0.23201451538468393}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.102412407543452, 'std': 1.8847454238878651, 'run': -6.119717474444538, 'test_avg': -6.581007646789658, 'test_std': 0.9598163640866789}
    Episode Length: {'avg': 4.844036697247707, 'std': 0.6796425386220968, 'run': 4.855361283658004, 'test_avg': 5.025390625, 'test_std': 0.24072612272478733}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (1901 / 2001):
    Value Loss: {'avg': 0.8905725081761678, 'std': 0.016131606838873762}
    Value Grad Norm: {'avg': 2.7454000314076743, 'std': 0.5241314620486607}
    Policy Loss: {'avg': -0.005259472255905469, 'std': 0.004420880176730578}
    Total_Loss: {'avg': -0.10272443791230519, 'std': 0.004357600127084249}
    Policy Entropy: {'avg': 0.9740250706672668, 'std': 0.3919406533241272}
    KL Divergence: {'avg': 0.004748713690787554, 'std': 0.07130372524261475}
    Policy Grad Norm: {'avg': 2.182390252749125, 'std': 0.6632438532939222}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.070803723708861, 'std': 2.130516137167003, 'run': -6.128388030300193, 'test_avg': -6.584025788234612, 'test_std': 1.0649631730834508}
    Episode Length: {'avg': 4.80188679245283, 'std': 0.769952354820404, 'run': 4.827348343985829, 'test_avg': 5.0283203125, 'test_std': 0.2580325026036494}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (2001 / 2001):
    Value Loss: {'avg': 0.6113277276357015, 'std': 0.012732219884780585}
    Value Grad Norm: {'avg': 4.412690083185832, 'std': 0.7193471273136759}
    Policy Loss: {'avg': -0.0036562376966079078, 'std': 0.0029542218357455213}
    Total_Loss: {'avg': -0.10218280057112376, 'std': 0.0013939624785147063}
    Policy Entropy: {'avg': 0.9689903855323792, 'std': 0.4272300899028778}
    KL Divergence: {'avg': 0.012041301466524601, 'std': 0.23474662005901337}
    Policy Grad Norm: {'avg': 2.9351374308268228, 'std': 0.36659645749663394}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.212260253473354, 'std': 2.1357559770671246, 'run': -6.145315907803149, 'test_avg': -6.576117607139167, 'test_std': 0.9598766625370395}
    Episode Length: {'avg': 4.883495145631068, 'std': 0.7796062097042613, 'run': 4.864702647541762, 'test_avg': 5.029296875, 'test_std': 0.2849086574943527}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Training took 650.611 seconds in total.
