
Iteration (1 / 1001):
    Value Loss: {'avg': 195.751220703125, 'std': 2.070883254334008}
    Value Grad Norm: {'avg': 76.50298309326172, 'std': 0.5707698104686088}
    Policy Loss: {'avg': -0.006127093297739823, 'std': 0.004995149387613825}
    Total_Loss: {'avg': -0.25227493047714233, 'std': 0.0048180278659680185}
    Policy Entropy: {'avg': 2.4592032432556152, 'std': 0.021686892956495285}
    KL Divergence: {'avg': 0.007995039224624634, 'std': 0.07317972183227539}
    Policy Grad Norm: {'avg': 0.37786397337913513, 'std': 0.003959762890179716}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -24.790748604626355, 'std': 6.134893320452801, 'run': -25.093120566988986, 'test_avg': -22.154709289926494, 'test_std': 7.066991055334668}
    Episode Length: {'avg': 7.8307692307692305, 'std': 0.8515909232675721, 'run': 7.9164444372527205, 'test_avg': 7.6328125, 'test_std': 0.8926443663877289}
    Ratio Terminated: {'avg': 0.09230769230769231, 'test_avg': 0.2197265625}

Iteration (101 / 1001):
    Value Loss: {'avg': 12.888059298197428, 'std': 0.03621223832365859}
    Value Grad Norm: {'avg': 2.6144653956095376, 'std': 0.03491464723084701}
    Policy Loss: {'avg': -0.006005602267881234, 'std': 0.00496132572120528}
    Total_Loss: {'avg': -0.14500377078851065, 'std': 0.0030268536209255487}
    Policy Entropy: {'avg': 1.3649941682815552, 'std': 0.4887903034687042}
    KL Divergence: {'avg': 0.014961590990424156, 'std': 0.12754856050014496}
    Policy Grad Norm: {'avg': 1.8891409238179524, 'std': 0.25011749936531874}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -8.926960185687818, 'std': 5.571360988351646, 'run': -8.793606736476859, 'test_avg': -8.126355556981498, 'test_std': 3.6603855825981784}
    Episode Length: {'avg': 5.442105263157894, 'std': 1.4416057529069464, 'run': 5.404523402303818, 'test_avg': 5.306640625, 'test_std': 0.8703643071149054}
    Ratio Terminated: {'avg': 0.8631578947368421, 'test_avg': 0.9462890625}

Iteration (201 / 1001):
    Value Loss: {'avg': 5.130435943603516, 'std': 0.002937528780111019}
    Value Grad Norm: {'avg': 4.204293409983317, 'std': 0.432211105141773}
    Policy Loss: {'avg': -0.003123366894821326, 'std': 0.0024123004398208265}
    Total_Loss: {'avg': -0.12094801912705104, 'std': 0.0035758374714811004}
    Policy Entropy: {'avg': 1.1942108869552612, 'std': 0.4484003782272339}
    KL Divergence: {'avg': 0.020250648260116577, 'std': 0.14712871611118317}
    Policy Grad Norm: {'avg': 1.3398855725924175, 'std': 0.25430786109755754}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.603159682211242, 'std': 3.3590006953510363, 'run': -7.574715799628464, 'test_avg': -7.29678327904107, 'test_std': 1.67910509145175}
    Episode Length: {'avg': 5.13, 'std': 0.901720577562695, 'run': 5.1284986037288025, 'test_avg': 5.0751953125, 'test_std': 0.42066952882045944}
    Ratio Terminated: {'avg': 0.97, 'test_avg': 0.9892578125}

Iteration (301 / 1001):
    Value Loss: {'avg': 3.209942181905111, 'std': 0.021373954738019358}
    Value Grad Norm: {'avg': 3.3950478235880532, 'std': 0.08994054025708825}
    Policy Loss: {'avg': 0.006208949101467927, 'std': 0.004762568444688226}
    Total_Loss: {'avg': -0.12196502337853114, 'std': 0.0032078443423955182}
    Policy Entropy: {'avg': 1.285033941268921, 'std': 0.4862171411514282}
    KL Divergence: {'avg': 0.0006042305612936616, 'std': 0.09376244992017746}
    Policy Grad Norm: {'avg': 11.319773038228353, 'std': 2.1891953144537735}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.388001212012137, 'std': 2.6438927140865776, 'run': -7.507481602813025, 'test_avg': -7.236571530083893, 'test_std': 1.3657454954614627}
    Episode Length: {'avg': 5.153061224489796, 'std': 0.8847003507048452, 'run': 5.140483749707419, 'test_avg': 5.0498046875, 'test_std': 0.35142005577802093}
    Ratio Terminated: {'avg': 0.9897959183673469, 'test_avg': 0.994140625}

Iteration (401 / 1001):
    Value Loss: {'avg': 2.264423211415609, 'std': 0.004289434918720923}
    Value Grad Norm: {'avg': 5.1470034917195635, 'std': 0.7937987827450047}
    Policy Loss: {'avg': -0.006404363239804904, 'std': 0.006506938340898356}
    Total_Loss: {'avg': -0.1298292949795723, 'std': 0.004956310247244945}
    Policy Entropy: {'avg': 1.2123364210128784, 'std': 0.5430501699447632}
    KL Divergence: {'avg': 0.02105119079351425, 'std': 0.24173201620578766}
    Policy Grad Norm: {'avg': 7.972887277603149, 'std': 4.7961709941235995}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.828474643230183, 'std': 2.4376030146073653, 'run': -7.0372883240635575, 'test_avg': -7.087905723245058, 'test_std': 1.010748090675961}
    Episode Length: {'avg': 4.9504950495049505, 'std': 0.812967155861875, 'run': 4.998180594683049, 'test_avg': 5.0263671875, 'test_std': 0.2505620360775747}
    Ratio Terminated: {'avg': 0.9801980198019802, 'test_avg': 0.9970703125}

Iteration (501 / 1001):
    Value Loss: {'avg': 5.301510651906331, 'std': 0.04415523855568083}
    Value Grad Norm: {'avg': 14.541040738423666, 'std': 1.5429473621625132}
    Policy Loss: {'avg': -0.00578446810444196, 'std': 0.004753188092453294}
    Total_Loss: {'avg': -0.1278637001911799, 'std': 0.004824902671597318}
    Policy Entropy: {'avg': 1.2221691608428955, 'std': 0.6081646084785461}
    KL Divergence: {'avg': 0.01583290472626686, 'std': 0.13065095245838165}
    Policy Grad Norm: {'avg': 2.5249027013778687, 'std': 0.9215624081823616}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -7.230425700434483, 'std': 3.6571535226280876, 'run': -7.021703887941738, 'test_avg': -7.08610801221532, 'test_std': 1.6289195939501804}
    Episode Length: {'avg': 5.072916666666667, 'std': 0.9815463105336512, 'run': 5.009979556960133, 'test_avg': 5.0419921875, 'test_std': 0.341175495440345}
    Ratio Terminated: {'avg': 0.9479166666666666, 'test_avg': 0.9873046875}

Iteration (601 / 1001):
    Value Loss: {'avg': 1.4306703408559163, 'std': 0.017440056385293834}
    Value Grad Norm: {'avg': 7.907180309295654, 'std': 0.5912938076827289}
    Policy Loss: {'avg': -0.004380352174242337, 'std': 0.003659760593961583}
    Total_Loss: {'avg': -0.12532355139652887, 'std': 0.0022309277333214376}
    Policy Entropy: {'avg': 1.1896291971206665, 'std': 0.642897367477417}
    KL Divergence: {'avg': 0.009475496597588062, 'std': 0.1987697035074234}
    Policy Grad Norm: {'avg': 3.951316316922506, 'std': 2.7314924086762935}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.485255552986359, 'std': 2.1916903788732935, 'run': -6.565470814595625, 'test_avg': -7.106811959172774, 'test_std': 1.4444927616144523}
    Episode Length: {'avg': 4.821782178217822, 'std': 0.7758232880855339, 'run': 4.856558935223588, 'test_avg': 5.060546875, 'test_std': 0.39804955838153416}
    Ratio Terminated: {'avg': 0.9900990099009901, 'test_avg': 0.994140625}

Iteration (701 / 1001):
    Value Loss: {'avg': 1.9373810688654582, 'std': 0.029468386427863643}
    Value Grad Norm: {'avg': 3.5668996969858804, 'std': 1.1896718724374036}
    Policy Loss: {'avg': -0.005416446675856908, 'std': 0.004031656575154285}
    Total_Loss: {'avg': -0.124460868537426, 'std': 0.002634796429918461}
    Policy Entropy: {'avg': 1.1774580478668213, 'std': 0.6823638677597046}
    KL Divergence: {'avg': 0.019336717203259468, 'std': 0.24890369176864624}
    Policy Grad Norm: {'avg': 2.7465425729751587, 'std': 0.7564065793727731}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.612399212140447, 'std': 2.6610003720188837, 'run': -6.646467374095921, 'test_avg': -6.953875984752813, 'test_std': 1.2372094054512557}
    Episode Length: {'avg': 4.930693069306931, 'std': 0.9361541903820051, 'run': 4.924392700798858, 'test_avg': 5.0263671875, 'test_std': 0.2619937192440686}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (801 / 1001):
    Value Loss: {'avg': 1.2884302139282227, 'std': 0.014506588900203376}
    Value Grad Norm: {'avg': 2.052574952443441, 'std': 0.017696995899612728}
    Policy Loss: {'avg': 0.0012050531804561615, 'std': 0.006911876262116777}
    Total_Loss: {'avg': -0.11730857193470001, 'std': 0.00597412722987957}
    Policy Entropy: {'avg': 1.1762394905090332, 'std': 0.6674646735191345}
    KL Divergence: {'avg': 0.011818325147032738, 'std': 0.1647198647260666}
    Policy Grad Norm: {'avg': 14.43668524424235, 'std': 5.263905197986661}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.8163733614532624, 'std': 2.0322392008866785, 'run': -6.733344687806856, 'test_avg': -6.8643987373725395, 'test_std': 1.0973807554278578}
    Episode Length: {'avg': 5.009615384615385, 'std': 0.7531369309006103, 'run': 4.963696052769714, 'test_avg': 5.0361328125, 'test_std': 0.28239884447504354}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (901 / 1001):
    Value Loss: {'avg': 1.9081953366597493, 'std': 0.012717661492572044}
    Value Grad Norm: {'avg': 2.8915692965189614, 'std': 0.1326500038586587}
    Policy Loss: {'avg': -0.007241119009753068, 'std': 0.005179978454372882}
    Total_Loss: {'avg': -0.1226809819539388, 'std': 0.00439395258056403}
    Policy Entropy: {'avg': 1.1439582109451294, 'std': 0.7011541724205017}
    KL Divergence: {'avg': 0.008268242701888084, 'std': 0.13020846247673035}
    Policy Grad Norm: {'avg': 5.057639181613922, 'std': 4.15191840940251}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.63495655565706, 'std': 2.4038090961265404, 'run': -6.583205411005493, 'test_avg': -6.848922414921532, 'test_std': 1.2990574908455768}
    Episode Length: {'avg': 4.864077669902913, 'std': 0.8010738386305348, 'run': 4.866897996795679, 'test_avg': 5.0517578125, 'test_std': 0.35390792071556526}
    Ratio Terminated: {'avg': 0.9805825242718447, 'test_avg': 0.994140625}

Iteration (1001 / 1001):
    Value Loss: {'avg': 3.980849345525106, 'std': 0.003491028016684842}
    Value Grad Norm: {'avg': 6.636967023213704, 'std': 0.534194972653837}
    Policy Loss: {'avg': -0.006728445490201314, 'std': 0.00575228117699934}
    Total_Loss: {'avg': -0.13215145468711853, 'std': 0.004413781762264276}
    Policy Entropy: {'avg': 1.2360494136810303, 'std': 0.6887035369873047}
    KL Divergence: {'avg': 0.017175594344735146, 'std': 0.15289433300495148}
    Policy Grad Norm: {'avg': 4.570708433787028, 'std': 2.5888328776863845}
    Num PPO updates: {'avg': 3}
    Return: {'avg': -6.692447567996546, 'std': 3.4808603046298523, 'run': -6.760772985588632, 'test_avg': -6.710869835165795, 'test_std': 0.9821938215944498}
    Episode Length: {'avg': 4.864077669902913, 'std': 1.0053115605488736, 'run': 4.900202939049073, 'test_avg': 5.0224609375, 'test_std': 0.23486074339195365}
    Ratio Terminated: {'avg': 0.970873786407767, 'test_avg': 0.998046875}

Training took 152.643 seconds in total.
