
Iteration (1 / 10001):
    Value Loss: {'avg': 2281.482353210449, 'std': 192.20101017501796}
    Value Grad Norm: {'avg': 496.6773859659831, 'std': 136.30143984676326}
    Policy Loss: {'avg': -0.0021321014792192727, 'std': 0.0033865225758375576}
    Total_Loss: {'avg': -0.23153885826468468, 'std': 0.00325878941911999}
    Policy Entropy: {'avg': 2.293102502822876, 'std': 0.014252734370529652}
    KL Divergence: {'avg': 0.00685111852362752, 'std': 0.06978929787874222}
    Policy Grad Norm: {'avg': 0.14976660069078207, 'std': 0.031620093400015925}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -158.10482288674325, 'std': 46.30539982080272, 'run': -127.36612603464842, 'test_avg': -192.33701239228347, 'test_std': 10.28616742384998}
    Episode Length: {'avg': 36.73103448275862, 'std': 7.5404702793190355, 'run': 30.998031785991778, 'test_avg': 39.9501953125, 'test_std': 0.6734791612240333}
    Ratio Terminated: {'avg': 0.22758620689655173, 'test_avg': 0.005859375}

Iteration (101 / 10001):
    Value Loss: {'avg': 270.16314856211346, 'std': 35.002959378935316}
    Value Grad Norm: {'avg': 956.286340713501, 'std': 523.2820139070436}
    Policy Loss: {'avg': -0.006183349420704569, 'std': 0.007307377073015862}
    Total_Loss: {'avg': -0.2049130890518427, 'std': 0.007177090832630914}
    Policy Entropy: {'avg': 2.0014662742614746, 'std': 0.2723762094974518}
    KL Divergence: {'avg': 0.011226349510252476, 'std': 0.14244094491004944}
    Policy Grad Norm: {'avg': 2.4591729318102202, 'std': 0.8263041798930614}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -131.0041896881561, 'std': 42.42246061896745, 'run': -126.29807420746366, 'test_avg': -118.54508723942922, 'test_std': 16.101200236172783}
    Episode Length: {'avg': 33.3780487804878, 'std': 9.28015661300218, 'run': 32.379996979206055, 'test_avg': 30.86328125, 'test_std': 3.9650400197726174}
    Ratio Terminated: {'avg': 0.7317073170731707, 'test_avg': 0.9541015625}

Iteration (201 / 10001):
    Value Loss: {'avg': 181.15747801462808, 'std': 18.36666734205795}
    Value Grad Norm: {'avg': 1175.517764409383, 'std': 628.0375015017976}
    Policy Loss: {'avg': -0.005765991266040753, 'std': 0.007472650608561508}
    Total_Loss: {'avg': -0.18796988390386105, 'std': 0.0070292134406745215}
    Policy Entropy: {'avg': 1.7790348529815674, 'std': 0.32806992530822754}
    KL Divergence: {'avg': 0.014819091185927391, 'std': 0.1860722154378891}
    Policy Grad Norm: {'avg': 2.5176962365706763, 'std': 0.8361078886460664}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -117.61578008001257, 'std': 35.43844945679035, 'run': -119.32202624291868, 'test_avg': -107.19270645807441, 'test_std': 13.992397278620826}
    Episode Length: {'avg': 30.072519083969464, 'std': 7.703380376609676, 'run': 30.412552977341573, 'test_avg': 27.6259765625, 'test_std': 3.168101052791827}
    Ratio Terminated: {'avg': 0.9618320610687023, 'test_avg': 1.0}

Iteration (301 / 10001):
    Value Loss: {'avg': 150.72955640157065, 'std': 18.15029906393174}
    Value Grad Norm: {'avg': 1260.9285961786907, 'std': 575.442001453375}
    Policy Loss: {'avg': -0.005406657689794277, 'std': 0.008379547922073245}
    Total_Loss: {'avg': -0.17673468682914972, 'std': 0.008406593334856011}
    Policy Entropy: {'avg': 1.7233210802078247, 'std': 0.3628692328929901}
    KL Divergence: {'avg': 0.024293355643749237, 'std': 0.22003738582134247}
    Policy Grad Norm: {'avg': 3.257402613759041, 'std': 1.2048484685349503}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -109.02900747727519, 'std': 32.8563885337265, 'run': -106.74413693939061, 'test_avg': -99.48221187896681, 'test_std': 12.378942510401313}
    Episode Length: {'avg': 27.779310344827586, 'std': 7.14332962595633, 'run': 27.353825263077418, 'test_avg': 25.458984375, 'test_std': 2.8326151068413545}
    Ratio Terminated: {'avg': 0.9793103448275862, 'test_avg': 1.0}

Iteration (401 / 10001):
    Value Loss: {'avg': 121.67804718017578, 'std': 14.352915811160948}
    Value Grad Norm: {'avg': 1038.6911141077678, 'std': 582.957492140728}
    Policy Loss: {'avg': -0.004603192617651075, 'std': 0.008721944621771864}
    Total_Loss: {'avg': -0.1719540236517787, 'std': 0.008864646075642444}
    Policy Entropy: {'avg': 1.730034351348877, 'std': 0.35004299879074097}
    KL Divergence: {'avg': 0.010652745142579079, 'std': 0.14117871224880219}
    Policy Grad Norm: {'avg': 2.3541165068745613, 'std': 0.6415268848798277}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -104.0396441088185, 'std': 32.12978832507051, 'run': -104.06010834634752, 'test_avg': -97.53957842141708, 'test_std': 13.147699120036272}
    Episode Length: {'avg': 26.779935275080906, 'std': 7.077709116575275, 'run': 26.82318150639559, 'test_avg': 25.0107421875, 'test_std': 2.939640482764468}
    Ratio Terminated: {'avg': 0.9902912621359223, 'test_avg': 0.998046875}

Iteration (501 / 10001):
    Value Loss: {'avg': 110.52951224644978, 'std': 11.391125285072036}
    Value Grad Norm: {'avg': 1040.765571276347, 'std': 480.0344047963055}
    Policy Loss: {'avg': -0.006427677416165049, 'std': 0.008541548490634219}
    Total_Loss: {'avg': -0.16383634600788355, 'std': 0.008862360176550153}
    Policy Entropy: {'avg': 1.5611029863357544, 'std': 0.4157117009162903}
    KL Divergence: {'avg': 0.010165908373892307, 'std': 0.1668921262025833}
    Policy Grad Norm: {'avg': 2.600178303817908, 'std': 0.7175724828733954}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -98.65211554359668, 'std': 29.99875222587895, 'run': -99.51200840758699, 'test_avg': -93.44041073187289, 'test_std': 11.380167796276028}
    Episode Length: {'avg': 25.246200607902736, 'std': 6.602720667654783, 'run': 25.381322090594463, 'test_avg': 24.021484375, 'test_std': 2.6316002112081653}
    Ratio Terminated: {'avg': 0.9969604863221885, 'test_avg': 0.9990234375}

Iteration (601 / 10001):
    Value Loss: {'avg': 91.4624212582906, 'std': 7.987782165336914}
    Value Grad Norm: {'avg': 936.9583940505981, 'std': 595.0329408773192}
    Policy Loss: {'avg': -0.001388927164953202, 'std': 0.006915171398854366}
    Total_Loss: {'avg': -0.15240334812551737, 'std': 0.0075860545088231235}
    Policy Entropy: {'avg': 1.5105068683624268, 'std': 0.40673282742500305}
    KL Divergence: {'avg': 0.01795177534222603, 'std': 0.1727524697780609}
    Policy Grad Norm: {'avg': 3.284469723701477, 'std': 0.8800383990304487}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -97.99050328018386, 'std': 29.63792593440672, 'run': -96.27341311400383, 'test_avg': -91.54421349301485, 'test_std': 10.258221020826467}
    Episode Length: {'avg': 25.226114649681527, 'std': 6.534802922450156, 'run': 24.77918747101051, 'test_avg': 23.51953125, 'test_std': 2.339289375061033}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (701 / 10001):
    Value Loss: {'avg': 73.58645351727803, 'std': 6.958578466267302}
    Value Grad Norm: {'avg': 822.7569739023844, 'std': 518.5680777331144}
    Policy Loss: {'avg': 0.0018291090236743912, 'std': 0.008987356082485085}
    Total_Loss: {'avg': -0.1423040432855487, 'std': 0.008096382893536026}
    Policy Entropy: {'avg': 1.372155785560608, 'std': 0.4341381788253784}
    KL Divergence: {'avg': 0.023264970630407333, 'std': 0.22867140173912048}
    Policy Grad Norm: {'avg': 3.770620319992304, 'std': 1.409958191442117}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -93.6598041290247, 'std': 29.03788969088393, 'run': -95.08730058756292, 'test_avg': -89.69308744638357, 'test_std': 9.732954754991496}
    Episode Length: {'avg': 24.136904761904763, 'std': 6.263010833873388, 'run': 24.46233229169954, 'test_avg': 23.080078125, 'test_std': 2.177977845134446}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 10001):
    Value Loss: {'avg': 84.92026122411092, 'std': 11.253711141040448}
    Value Grad Norm: {'avg': 1022.3492139180502, 'std': 593.0986815428413}
    Policy Loss: {'avg': -0.006360447926757236, 'std': 0.008330071262931945}
    Total_Loss: {'avg': -0.15360808838158846, 'std': 0.009097835222502952}
    Policy Entropy: {'avg': 1.5136088132858276, 'std': 0.40547022223472595}
    KL Divergence: {'avg': 0.013645272701978683, 'std': 0.18881671130657196}
    Policy Grad Norm: {'avg': 3.8985579361518226, 'std': 1.4079143751162877}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -93.48428899001549, 'std': 30.326508510186674, 'run': -93.85322754481436, 'test_avg': -87.57451861008386, 'test_std': 8.865677656588892}
    Episode Length: {'avg': 24.18421052631579, 'std': 6.65599908292782, 'run': 24.2697606734019, 'test_avg': 22.455078125, 'test_std': 1.9803560665058404}
    Ratio Terminated: {'avg': 0.9970760233918129, 'test_avg': 1.0}

Iteration (901 / 10001):
    Value Loss: {'avg': 81.41306893030803, 'std': 7.421575319588372}
    Value Grad Norm: {'avg': 1003.7313200632731, 'std': 564.167344442441}
    Policy Loss: {'avg': -0.0053240353978859884, 'std': 0.010863197247939882}
    Total_Loss: {'avg': -0.15406258528431258, 'std': 0.010741520272976318}
    Policy Entropy: {'avg': 1.5299980640411377, 'std': 0.38100796937942505}
    KL Divergence: {'avg': 0.017163222655653954, 'std': 0.16587813198566437}
    Policy Grad Norm: {'avg': 3.0530722041924796, 'std': 1.04574018208282}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -91.68430565793152, 'std': 30.357091192823578, 'run': -90.83956947555896, 'test_avg': -86.1587203159439, 'test_std': 8.480635961807279}
    Episode Length: {'avg': 23.6231884057971, 'std': 6.549480451294939, 'run': 23.426879026426125, 'test_avg': 22.0966796875, 'test_std': 1.8586339676022556}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1001 / 10001):
    Value Loss: {'avg': 77.08873120943706, 'std': 10.320841833198786}
    Value Grad Norm: {'avg': 986.9983208974203, 'std': 597.5707558859572}
    Policy Loss: {'avg': -0.0022833638067822903, 'std': 0.00803784259909789}
    Total_Loss: {'avg': -0.14564387639984488, 'std': 0.00792646587322091}
    Policy Entropy: {'avg': 1.4232592582702637, 'std': 0.4416794776916504}
    KL Divergence: {'avg': 0.018957993015646935, 'std': 0.1984703689813614}
    Policy Grad Norm: {'avg': 3.32130354270339, 'std': 1.1951797627564729}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -89.0019754960367, 'std': 29.87619820571474, 'run': -89.67105250038291, 'test_avg': -85.8381748110134, 'test_std': 8.548095195935568}
    Episode Length: {'avg': 23.0, 'std': 6.529080730404241, 'run': 23.136392719597286, 'test_avg': 22.041015625, 'test_std': 1.8750722235438984}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 10001):
    Value Loss: {'avg': 64.75207877159119, 'std': 8.830210559998545}
    Value Grad Norm: {'avg': 1577.1263133684795, 'std': 1121.5768697192261}
    Policy Loss: {'avg': -0.002535491861635819, 'std': 0.008759029293788693}
    Total_Loss: {'avg': -0.13738420326262712, 'std': 0.007568877392166136}
    Policy Entropy: {'avg': 1.338590145111084, 'std': 0.4463806450366974}
    KL Divergence: {'avg': 0.01953909359872341, 'std': 0.17808060348033905}
    Policy Grad Norm: {'avg': 4.025317911058664, 'std': 1.8454210644848963}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -88.99165239170995, 'std': 27.696744497556143, 'run': -89.51449739603643, 'test_avg': -84.38580636102016, 'test_std': 8.20206374019847}
    Episode Length: {'avg': 23.16056338028169, 'std': 6.0968354496003965, 'run': 23.234591124116484, 'test_avg': 21.779296875, 'test_std': 1.8092970335506644}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 10001):
    Value Loss: {'avg': 57.6732493241628, 'std': 6.026245998156286}
    Value Grad Norm: {'avg': 659.2868741353353, 'std': 284.5292429610725}
    Policy Loss: {'avg': 0.0012753737100865692, 'std': 0.009968138448374578}
    Total_Loss: {'avg': -0.13712043943814933, 'std': 0.010672999953560004}
    Policy Entropy: {'avg': 1.3410437107086182, 'std': 0.47003406286239624}
    KL Divergence: {'avg': 0.01932573691010475, 'std': 0.20716692507266998}
    Policy Grad Norm: {'avg': 5.230622723698616, 'std': 2.6356771344047263}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -88.30056297218677, 'std': 26.715148349744318, 'run': -89.7256021978636, 'test_avg': -84.53912468933572, 'test_std': 7.9701968214509}
    Episode Length: {'avg': 22.794520547945204, 'std': 5.777990607041278, 'run': 23.05107065501854, 'test_avg': 21.7431640625, 'test_std': 1.7476133693436018}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 10001):
    Value Loss: {'avg': 67.04957167307536, 'std': 8.161886196924682}
    Value Grad Norm: {'avg': 776.4452978769938, 'std': 382.64351273217284}
    Policy Loss: {'avg': 0.00455558838439174, 'std': 0.005449162811862032}
    Total_Loss: {'avg': -0.13005954213440418, 'std': 0.004744245393984518}
    Policy Entropy: {'avg': 1.3811123371124268, 'std': 0.42603302001953125}
    KL Divergence: {'avg': 0.02127579227089882, 'std': 0.18963190913200378}
    Policy Grad Norm: {'avg': 3.6213448643684387, 'std': 1.4208084972657926}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -88.39156135977589, 'std': 28.1873309536789, 'run': -88.85936342519706, 'test_avg': -83.57973338570906, 'test_std': 8.473236583907674}
    Episode Length: {'avg': 22.95108695652174, 'std': 6.2212642809406615, 'run': 23.110306380683568, 'test_avg': 21.548828125, 'test_std': 1.8806058370134302}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 10001):
    Value Loss: {'avg': 48.66348687807719, 'std': 5.977184743597637}
    Value Grad Norm: {'avg': 871.7041912078857, 'std': 513.427998587849}
    Policy Loss: {'avg': -0.003494505028356798, 'std': 0.009062766320178573}
    Total_Loss: {'avg': -0.1357409011106938, 'std': 0.008601723063879418}
    Policy Entropy: {'avg': 1.2778159379959106, 'std': 0.4775030314922333}
    KL Divergence: {'avg': 0.01570543274283409, 'std': 0.17421361804008484}
    Policy Grad Norm: {'avg': 3.2781957760453224, 'std': 1.105518448918103}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -87.26890725059023, 'std': 24.242208779370994, 'run': -86.48600376342928, 'test_avg': -82.67237873982785, 'test_std': 7.880505912184605}
    Episode Length: {'avg': 22.634285714285713, 'std': 5.257155279488429, 'run': 22.391203255858315, 'test_avg': 21.376953125, 'test_std': 1.716332417264422}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 10001):
    Value Loss: {'avg': 51.27570311228434, 'std': 6.751217871853928}
    Value Grad Norm: {'avg': 1055.4007399876912, 'std': 672.0990957488369}
    Policy Loss: {'avg': 0.004536714084679261, 'std': 0.0057841968892496905}
    Total_Loss: {'avg': -0.1231252416037023, 'std': 0.00650207597770783}
    Policy Entropy: {'avg': 1.220566749572754, 'std': 0.49122974276542664}
    KL Divergence: {'avg': 0.01736508682370186, 'std': 0.19611221551895142}
    Policy Grad Norm: {'avg': 3.2014743387699127, 'std': 0.8911016919866593}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.21926476169227, 'std': 28.773159208190545, 'run': -84.02352903896787, 'test_avg': -83.09655764879204, 'test_std': 8.02536593544777}
    Episode Length: {'avg': 21.454068241469816, 'std': 6.251182815997116, 'run': 21.830425050077576, 'test_avg': 21.4677734375, 'test_std': 1.7519343448512656}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 10001):
    Value Loss: {'avg': 41.62595625718435, 'std': 5.571789458259034}
    Value Grad Norm: {'avg': 1046.962270418803, 'std': 675.2952699920049}
    Policy Loss: {'avg': 0.0049639018543530256, 'std': 0.006798456124875771}
    Total_Loss: {'avg': -0.11299086827784777, 'std': 0.00704254411249346}
    Policy Entropy: {'avg': 1.1918506622314453, 'std': 0.48407578468322754}
    KL Divergence: {'avg': 0.01827573962509632, 'std': 0.18054990470409393}
    Policy Grad Norm: {'avg': 2.944928526878357, 'std': 0.7499374785413107}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.11848757355382, 'std': 26.091376586787675, 'run': -81.80623964267131, 'test_avg': -82.68202203411258, 'test_std': 8.438123398016998}
    Episode Length: {'avg': 21.43766578249337, 'std': 5.648122418921259, 'run': 21.34429338262088, 'test_avg': 21.4208984375, 'test_std': 1.8449659055955638}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 10001):
    Value Loss: {'avg': 51.97942026456197, 'std': 6.264917116882406}
    Value Grad Norm: {'avg': 692.8210808436075, 'std': 356.7390615603935}
    Policy Loss: {'avg': 0.0013275880774017423, 'std': 0.005992673261583894}
    Total_Loss: {'avg': -0.12521774601191282, 'std': 0.00590800521977296}
    Policy Entropy: {'avg': 1.2596032619476318, 'std': 0.47874534130096436}
    KL Divergence: {'avg': 0.016968587413430214, 'std': 0.1735060214996338}
    Policy Grad Norm: {'avg': 3.500136613845825, 'std': 1.116123439510543}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.68217454868292, 'std': 25.418902308803986, 'run': -83.01276842339556, 'test_avg': -81.50609332793066, 'test_std': 7.714369635144766}
    Episode Length: {'avg': 21.986449864498645, 'std': 5.562391194227707, 'run': 21.650903736249024, 'test_avg': 21.0263671875, 'test_std': 1.6495406811968414}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 10001):
    Value Loss: {'avg': 44.64372420310974, 'std': 5.417928454962602}
    Value Grad Norm: {'avg': 1114.2389181454976, 'std': 672.7174568529716}
    Policy Loss: {'avg': 0.0013025908847339451, 'std': 0.007539535327929607}
    Total_Loss: {'avg': -0.12040813150815666, 'std': 0.007562576939600011}
    Policy Entropy: {'avg': 1.2353384494781494, 'std': 0.4470711946487427}
    KL Divergence: {'avg': 0.02967921830713749, 'std': 0.20729050040245056}
    Policy Grad Norm: {'avg': 4.011279705911875, 'std': 2.0340744805600406}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -81.0278840639893, 'std': 27.041972327139664, 'run': -80.74053688823886, 'test_avg': -82.68207468222981, 'test_std': 9.193329272753568}
    Episode Length: {'avg': 21.154450261780106, 'std': 5.833170950394934, 'run': 21.101483002425667, 'test_avg': 21.4072265625, 'test_std': 1.9533591168278386}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1901 / 10001):
    Value Loss: {'avg': 48.93697198232015, 'std': 5.347711130538253}
    Value Grad Norm: {'avg': 1006.4122505187988, 'std': 482.05838446174295}
    Policy Loss: {'avg': -0.0034607281268108636, 'std': 0.008905537335480378}
    Total_Loss: {'avg': -0.1286023820284754, 'std': 0.008228821607803386}
    Policy Entropy: {'avg': 1.2844786643981934, 'std': 0.5002984404563904}
    KL Divergence: {'avg': 0.017444781959056854, 'std': 0.1688200831413269}
    Policy Grad Norm: {'avg': 3.2446451485157013, 'std': 1.2187960133889055}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -83.3818489368223, 'std': 27.3892982472919, 'run': -84.59864687777979, 'test_avg': -82.01410056328774, 'test_std': 9.509615626324107}
    Episode Length: {'avg': 21.702412868632706, 'std': 5.972225219365589, 'run': 21.97187880353606, 'test_avg': 21.1728515625, 'test_std': 1.9526637638982571}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (2001 / 10001):
    Value Loss: {'avg': 38.27780854701996, 'std': 7.634034462987273}
    Value Grad Norm: {'avg': 840.4645220438639, 'std': 672.4705584243452}
    Policy Loss: {'avg': -0.004464474157430232, 'std': 0.007780361087405653}
    Total_Loss: {'avg': -0.12387949996627867, 'std': 0.0072730811393321385}
    Policy Entropy: {'avg': 1.201371431350708, 'std': 0.4834210276603699}
    KL Divergence: {'avg': 0.01791650801897049, 'std': 0.1925549954175949}
    Policy Grad Norm: {'avg': 3.2430093809962273, 'std': 1.0956288462696877}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -81.31382028791104, 'std': 25.349585618923555, 'run': -83.57285492641007, 'test_avg': -80.58283042390997, 'test_std': 7.564722223618313}
    Episode Length: {'avg': 21.212598425196852, 'std': 5.493441455268702, 'run': 21.702599522808885, 'test_avg': 20.9345703125, 'test_std': 1.636562294412789}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 10001):
    Value Loss: {'avg': 38.84266300996145, 'std': 4.093698106215387}
    Value Grad Norm: {'avg': 847.788646697998, 'std': 378.2100562037544}
    Policy Loss: {'avg': 0.008182435296475887, 'std': 0.007196265943720593}
    Total_Loss: {'avg': -0.10677215736359358, 'std': 0.007640256340845283}
    Policy Entropy: {'avg': 1.1637227535247803, 'std': 0.4847472906112671}
    KL Divergence: {'avg': 0.017640527337789536, 'std': 0.18842655420303345}
    Policy Grad Norm: {'avg': 3.621349185705185, 'std': 1.3254211357402808}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.43520745513507, 'std': 25.89140851938053, 'run': -78.31424927178053, 'test_avg': -79.84343340363637, 'test_std': 7.668696255489241}
    Episode Length: {'avg': 20.638242894056848, 'std': 5.68177511776083, 'run': 20.58604499650233, 'test_avg': 20.830078125, 'test_std': 1.6478067791450806}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 10001):
    Value Loss: {'avg': 37.210856874783836, 'std': 4.963684351821305}
    Value Grad Norm: {'avg': 699.7037223180135, 'std': 388.3298988755709}
    Policy Loss: {'avg': -0.002827785889773319, 'std': 0.00969021995346794}
    Total_Loss: {'avg': -0.1149476976133883, 'std': 0.009725235380774912}
    Policy Entropy: {'avg': 1.1427981853485107, 'std': 0.5037375688552856}
    KL Divergence: {'avg': 0.018460862338542938, 'std': 0.18151314556598663}
    Policy Grad Norm: {'avg': 4.413762552042802, 'std': 2.1540180105202595}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -78.6959518465769, 'std': 26.436603431939698, 'run': -78.94737167536935, 'test_avg': -79.93938357428658, 'test_std': 7.051810557310866}
    Episode Length: {'avg': 20.605063291139242, 'std': 5.73339978522866, 'run': 20.63748210880311, 'test_avg': 20.724609375, 'test_std': 1.520799749691625}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 10001):
    Value Loss: {'avg': 37.50528760751089, 'std': 5.887191381849849}
    Value Grad Norm: {'avg': 747.9397961298624, 'std': 513.9524302236963}
    Policy Loss: {'avg': 0.0016311255167238414, 'std': 0.0061388980479539475}
    Total_Loss: {'avg': -0.11539857694879174, 'std': 0.005835533365159486}
    Policy Entropy: {'avg': 1.2115460634231567, 'std': 0.45878705382347107}
    KL Divergence: {'avg': 0.016237594187259674, 'std': 0.1593932956457138}
    Policy Grad Norm: {'avg': 3.2574351876974106, 'std': 1.4559290884220422}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.45364780994298, 'std': 28.322191319510445, 'run': -76.77912660569955, 'test_avg': -79.75660373867723, 'test_std': 7.45992976387708}
    Episode Length: {'avg': 20.627791563275434, 'std': 6.175306772398361, 'run': 20.31415791466048, 'test_avg': 20.658203125, 'test_std': 1.591104143744285}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2401 / 10001):
    Value Loss: {'avg': 44.309711615244545, 'std': 5.951216723743087}
    Value Grad Norm: {'avg': 917.4551277160645, 'std': 675.2815368709647}
    Policy Loss: {'avg': -0.005258661098196171, 'std': 0.00793178045761923}
    Total_Loss: {'avg': -0.12902548536658287, 'std': 0.008943788901860655}
    Policy Entropy: {'avg': 1.2811390161514282, 'std': 0.45202794671058655}
    KL Divergence: {'avg': 0.01555983629077673, 'std': 0.16544783115386963}
    Policy Grad Norm: {'avg': 3.2689963653683662, 'std': 1.019880394647175}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -80.81171739571435, 'std': 27.36582307355565, 'run': -84.6030877602255, 'test_avg': -79.53822735750055, 'test_std': 7.76381896109466}
    Episode Length: {'avg': 21.104325699745548, 'std': 5.981890109166466, 'run': 21.944681959274643, 'test_avg': 20.7138671875, 'test_std': 1.6627710910136848}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 10001):
    Value Loss: {'avg': 34.1634806394577, 'std': 3.2374858785131377}
    Value Grad Norm: {'avg': 725.861977895101, 'std': 460.61605491338173}
    Policy Loss: {'avg': 0.005798239697469398, 'std': 0.007572651934270673}
    Total_Loss: {'avg': -0.10279035149142146, 'std': 0.006649284041757816}
    Policy Entropy: {'avg': 1.136106252670288, 'std': 0.47579482197761536}
    KL Divergence: {'avg': 0.019366521388292313, 'std': 0.17613723874092102}
    Policy Grad Norm: {'avg': 3.195310428738594, 'std': 1.0110619668611673}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.76081000165547, 'std': 23.52041285292901, 'run': -78.40192744433296, 'test_avg': -79.38776248397937, 'test_std': 7.057493760444416}
    Episode Length: {'avg': 21.065989847715738, 'std': 5.137768053194388, 'run': 20.501100695245444, 'test_avg': 20.6513671875, 'test_std': 1.5060224432419127}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 10001):
    Value Loss: {'avg': 32.58874976634979, 'std': 4.296268514914488}
    Value Grad Norm: {'avg': 688.7739082972208, 'std': 433.2620470938014}
    Policy Loss: {'avg': 0.005542373575735837, 'std': 0.00668812332816261}
    Total_Loss: {'avg': -0.11000918503850698, 'std': 0.007354473648458594}
    Policy Entropy: {'avg': 1.0980496406555176, 'std': 0.4956200420856476}
    KL Divergence: {'avg': 0.018465502187609673, 'std': 0.19579578936100006}
    Policy Grad Norm: {'avg': 4.3841119185090065, 'std': 1.7831518443105048}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.48184036570386, 'std': 25.74527444596135, 'run': -79.57052491966157, 'test_avg': -79.09813041261388, 'test_std': 6.955983176295008}
    Episode Length: {'avg': 20.52173913043478, 'std': 5.551794073611105, 'run': 20.751097617291506, 'test_avg': 20.6376953125, 'test_std': 1.4923584525560631}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 10001):
    Value Loss: {'avg': 39.75056207180023, 'std': 6.170669944322087}
    Value Grad Norm: {'avg': 727.6023019154867, 'std': 381.06696340079503}
    Policy Loss: {'avg': 0.0038926074048504233, 'std': 0.006007125005004434}
    Total_Loss: {'avg': -0.10755892749875784, 'std': 0.007419439884481041}
    Policy Entropy: {'avg': 1.0857861042022705, 'std': 0.5005255937576294}
    KL Divergence: {'avg': 0.018882127478718758, 'std': 0.16458766162395477}
    Policy Grad Norm: {'avg': 3.6973499059677124, 'std': 1.1721189165119779}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.66720128214217, 'std': 22.839611106624147, 'run': -79.30236228496041, 'test_avg': -78.86319075249662, 'test_std': 6.880716879887403}
    Episode Length: {'avg': 21.11139896373057, 'std': 5.021768634561561, 'run': 20.814235878421528, 'test_avg': 20.529296875, 'test_std': 1.446682996760256}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 10001):
    Value Loss: {'avg': 42.07197674115499, 'std': 4.191385394623101}
    Value Grad Norm: {'avg': 731.2330617904663, 'std': 440.4267349712948}
    Policy Loss: {'avg': 0.0009978004381991923, 'std': 0.008808550520622021}
    Total_Loss: {'avg': -0.12244385154917836, 'std': 0.008002590442799724}
    Policy Entropy: {'avg': 1.245981216430664, 'std': 0.4644020199775696}
    KL Divergence: {'avg': 0.015273282304406166, 'std': 0.1513996124267578}
    Policy Grad Norm: {'avg': 5.1282386258244514, 'std': 2.231045020240813}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -81.57373496855493, 'std': 25.457095352857543, 'run': -80.93217727516776, 'test_avg': -78.50975654570198, 'test_std': 8.117956585353603}
    Episode Length: {'avg': 21.295629820051413, 'std': 5.52046963714481, 'run': 21.17032180845634, 'test_avg': 20.5009765625, 'test_std': 1.776033761313586}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2901 / 10001):
    Value Loss: {'avg': 33.80042167504629, 'std': 3.22510182444353}
    Value Grad Norm: {'avg': 765.9634482065836, 'std': 383.6203883464287}
    Policy Loss: {'avg': 0.0032355799339711666, 'std': 0.003947108934480971}
    Total_Loss: {'avg': -0.10980122303590178, 'std': 0.0049928028952031895}
    Policy Entropy: {'avg': 1.1113730669021606, 'std': 0.5221322178840637}
    KL Divergence: {'avg': 0.015766780823469162, 'std': 0.1767815351486206}
    Policy Grad Norm: {'avg': 3.383342295885086, 'std': 0.9614948592660175}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.75618821846453, 'std': 27.06717436063116, 'run': -77.64577147434674, 'test_avg': -78.28365644851344, 'test_std': 7.1413164840644665}
    Episode Length: {'avg': 20.280701754385966, 'std': 5.9011407510906215, 'run': 20.49234208452233, 'test_avg': 20.4697265625, 'test_std': 1.5248788128838087}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 10001):
    Value Loss: {'avg': 33.172668973604836, 'std': 5.589704107288117}
    Value Grad Norm: {'avg': 588.4937286376953, 'std': 325.8755615795682}
    Policy Loss: {'avg': 0.0035901245137210935, 'std': 0.005006062200701586}
    Total_Loss: {'avg': -0.10751148173585534, 'std': 0.0057066200638113745}
    Policy Entropy: {'avg': 1.0738357305526733, 'std': 0.5235376358032227}
    KL Divergence: {'avg': 0.019914545118808746, 'std': 0.19190214574337006}
    Policy Grad Norm: {'avg': 3.9299484491348267, 'std': 1.2702499876023698}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.43438863104612, 'std': 24.692263227008013, 'run': -77.39613171226082, 'test_avg': -78.14160190849404, 'test_std': 8.171455126763655}
    Episode Length: {'avg': 20.56543209876543, 'std': 5.3609276996565605, 'run': 20.411089399159632, 'test_avg': 20.365234375, 'test_std': 1.6320168048517023}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3101 / 10001):
    Value Loss: {'avg': 28.03179856141408, 'std': 2.8670399324799973}
    Value Grad Norm: {'avg': 675.8905197779337, 'std': 397.8132353089635}
    Policy Loss: {'avg': 0.006068837101338431, 'std': 0.006058002961837893}
    Total_Loss: {'avg': -0.09966474818065763, 'std': 0.006053889781789924}
    Policy Entropy: {'avg': 1.0329753160476685, 'std': 0.4958711564540863}
    KL Divergence: {'avg': 0.016313038766384125, 'std': 0.16861604154109955}
    Policy Grad Norm: {'avg': 3.584720201790333, 'std': 1.1850640673613848}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.44043370582365, 'std': 25.35154715385117, 'run': -75.26504710710788, 'test_avg': -77.85794920274222, 'test_std': 7.05208354263213}
    Episode Length: {'avg': 19.948655256723715, 'std': 5.432835459099682, 'run': 19.913112865159324, 'test_avg': 20.3837890625, 'test_std': 1.4987530293565285}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 10001):
    Value Loss: {'avg': 29.66854993502299, 'std': 3.2929344385098167}
    Value Grad Norm: {'avg': 941.9311183293661, 'std': 532.0783642027485}
    Policy Loss: {'avg': -0.004937765101203695, 'std': 0.008337926510709118}
    Total_Loss: {'avg': -0.11024958407506347, 'std': 0.008649262491019867}
    Policy Entropy: {'avg': 1.103661060333252, 'std': 0.5221222639083862}
    KL Divergence: {'avg': 0.01711958646774292, 'std': 0.18660268187522888}
    Policy Grad Norm: {'avg': 3.3601085245609283, 'std': 1.105580271576206}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -76.4015075714714, 'std': 25.744688978973425, 'run': -74.10997015156184, 'test_avg': -77.68897829584631, 'test_std': 8.162903861455927}
    Episode Length: {'avg': 20.11576354679803, 'std': 5.655016325234717, 'run': 19.58218308626124, 'test_avg': 20.3134765625, 'test_std': 1.6864504906053968}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (3301 / 10001):
    Value Loss: {'avg': 33.692359964052834, 'std': 4.185929640643}
    Value Grad Norm: {'avg': 988.1866370836893, 'std': 605.6600599015667}
    Policy Loss: {'avg': 0.004264090064680204, 'std': 0.007980759659223478}
    Total_Loss: {'avg': -0.10545104276388884, 'std': 0.007847481497386202}
    Policy Entropy: {'avg': 1.1470062732696533, 'std': 0.5128532648086548}
    KL Divergence: {'avg': 0.023069746792316437, 'std': 0.18611089885234833}
    Policy Grad Norm: {'avg': 3.0163949355483055, 'std': 0.8888958056056868}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.2686114986936, 'std': 23.28816568514495, 'run': -79.94713837686389, 'test_avg': -78.42428068063683, 'test_std': 7.568495390860273}
    Episode Length: {'avg': 20.53, 'std': 5.063506690032116, 'run': 20.890796346548758, 'test_avg': 20.4951171875, 'test_std': 1.626794557755247}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 10001):
    Value Loss: {'avg': 30.303278009096783, 'std': 3.7713242294005975}
    Value Grad Norm: {'avg': 628.7095448176066, 'std': 319.5305608514441}
    Policy Loss: {'avg': 0.0065489755070302635, 'std': 0.005627556933208753}
    Total_Loss: {'avg': -0.10079595074057579, 'std': 0.006144752386613205}
    Policy Entropy: {'avg': 1.0182218551635742, 'std': 0.5109877586364746}
    KL Divergence: {'avg': 0.018364258110523224, 'std': 0.20575366914272308}
    Policy Grad Norm: {'avg': 3.699096381664276, 'std': 1.1456988485822823}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.56101222216013, 'std': 26.47448401335626, 'run': -73.34338606012678, 'test_avg': -78.08131355332273, 'test_std': 7.222155995529942}
    Episode Length: {'avg': 19.914634146341463, 'std': 5.73096258784022, 'run': 19.449130818121567, 'test_avg': 20.447265625, 'test_std': 1.540834907020658}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 10001):
    Value Loss: {'avg': 31.459847807884216, 'std': 3.698955847141435}
    Value Grad Norm: {'avg': 932.9748358726501, 'std': 586.4123525720712}
    Policy Loss: {'avg': 0.006531415245262906, 'std': 0.00593581016722243}
    Total_Loss: {'avg': -0.10225446429103613, 'std': 0.0075090224157151565}
    Policy Entropy: {'avg': 1.0845401287078857, 'std': 0.47920554876327515}
    KL Divergence: {'avg': 0.018857745453715324, 'std': 0.22580602765083313}
    Policy Grad Norm: {'avg': 4.156386360526085, 'std': 1.8203883280212525}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.3813018267896, 'std': 26.034022621292216, 'run': -77.4216476383169, 'test_avg': -78.03550173527319, 'test_std': 7.701400099557307}
    Episode Length: {'avg': 19.85096153846154, 'std': 5.59849731199068, 'run': 20.2515521220747, 'test_avg': 20.408203125, 'test_std': 1.6115340777471119}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3601 / 10001):
    Value Loss: {'avg': 40.23366538683573, 'std': 5.940945246821013}
    Value Grad Norm: {'avg': 1515.8421688079834, 'std': 762.2088740092537}
    Policy Loss: {'avg': 0.004613670986145735, 'std': 0.00962523411293738}
    Total_Loss: {'avg': -0.10952558415010571, 'std': 0.006858117857637144}
    Policy Entropy: {'avg': 1.134859561920166, 'std': 0.49204757809638977}
    KL Divergence: {'avg': 0.022979414090514183, 'std': 0.24331113696098328}
    Policy Grad Norm: {'avg': 8.775403037667274, 'std': 6.7255723905617915}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -80.97130863683101, 'std': 23.454029874806572, 'run': -82.62749190998399, 'test_avg': -77.98659405291373, 'test_std': 8.11728592477867}
    Episode Length: {'avg': 21.165, 'std': 5.066830863567483, 'run': 21.497438248946228, 'test_avg': 20.4169921875, 'test_std': 1.6749954337442132}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3701 / 10001):
    Value Loss: {'avg': 26.80408489704132, 'std': 4.02419060819128}
    Value Grad Norm: {'avg': 732.3377695083618, 'std': 321.66907142197834}
    Policy Loss: {'avg': 0.0016535601462237537, 'std': 0.004692361812406167}
    Total_Loss: {'avg': -0.10427585290744901, 'std': 0.004634615911121334}
    Policy Entropy: {'avg': 1.0884082317352295, 'std': 0.5099897384643555}
    KL Divergence: {'avg': 0.01696138083934784, 'std': 0.16332383453845978}
    Policy Grad Norm: {'avg': 3.4568795263767242, 'std': 1.435258791716249}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.48202030113218, 'std': 26.116731121061495, 'run': -75.81410408368824, 'test_avg': -77.16549595744925, 'test_std': 7.436212218042524}
    Episode Length: {'avg': 19.659367396593673, 'std': 5.650465914412243, 'run': 19.933514818475814, 'test_avg': 20.18359375, 'test_std': 1.5211671785050247}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3801 / 10001):
    Value Loss: {'avg': 27.49847408135732, 'std': 3.3519594771794865}
    Value Grad Norm: {'avg': 760.6684894561768, 'std': 443.1964722238179}
    Policy Loss: {'avg': 0.0074584798130672425, 'std': 0.007834174407716426}
    Total_Loss: {'avg': -0.09111066721379757, 'std': 0.008235969744512739}
    Policy Entropy: {'avg': 1.0196378231048584, 'std': 0.4907033443450928}
    KL Divergence: {'avg': 0.020981676876544952, 'std': 0.1781173199415207}
    Policy Grad Norm: {'avg': 4.442642144858837, 'std': 3.054356569552689}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.93870989899224, 'std': 24.10815929505788, 'run': -74.7637271346396, 'test_avg': -77.60738610059913, 'test_std': 8.274067172114549}
    Episode Length: {'avg': 19.564903846153847, 'std': 5.1911184312898815, 'run': 19.724344638235554, 'test_avg': 20.3310546875, 'test_std': 1.718685357005254}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3901 / 10001):
    Value Loss: {'avg': 27.100595633188885, 'std': 3.258717602835529}
    Value Grad Norm: {'avg': 774.7092924118042, 'std': 509.8986925282865}
    Policy Loss: {'avg': 0.0022940177586860955, 'std': 0.0066143755400690845}
    Total_Loss: {'avg': -0.10227211285382509, 'std': 0.00660716946332865}
    Policy Entropy: {'avg': 1.029106855392456, 'std': 0.49788856506347656}
    KL Divergence: {'avg': 0.015495161525905132, 'std': 0.1717441827058792}
    Policy Grad Norm: {'avg': 5.759754061698914, 'std': 5.4026360902691035}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.89985228530657, 'std': 23.783485947204934, 'run': -77.22666591615739, 'test_avg': -77.22584665562874, 'test_std': 7.455113914604609}
    Episode Length: {'avg': 20.03, 'std': 5.1719532093784455, 'run': 20.310358838870602, 'test_avg': 20.251953125, 'test_std': 1.591295933446301}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4001 / 10001):
    Value Loss: {'avg': 28.76234261194865, 'std': 4.1990479190411545}
    Value Grad Norm: {'avg': 652.7663847605387, 'std': 328.88333212642533}
    Policy Loss: {'avg': -0.0048876568107516505, 'std': 0.008918123394357512}
    Total_Loss: {'avg': -0.11023340909741819, 'std': 0.00942303844055895}
    Policy Entropy: {'avg': 1.0425398349761963, 'std': 0.510391116142273}
    KL Divergence: {'avg': 0.025537092238664627, 'std': 0.20250433683395386}
    Policy Grad Norm: {'avg': 3.9768407866358757, 'std': 1.8923169072278716}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.89517977182712, 'std': 25.862194605365207, 'run': -75.53929843629987, 'test_avg': -77.21998052838953, 'test_std': 6.896298229851626}
    Episode Length: {'avg': 19.819477434679335, 'std': 5.621953972843314, 'run': 19.94424522362262, 'test_avg': 20.2529296875, 'test_std': 1.4447815615798647}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 10001):
    Value Loss: {'avg': 30.549020369847614, 'std': 3.522353994789372}
    Value Grad Norm: {'avg': 1223.5284646352131, 'std': 588.9967546061696}
    Policy Loss: {'avg': -0.0012402376742102206, 'std': 0.00888475632987675}
    Total_Loss: {'avg': -0.10668397671543062, 'std': 0.008964441000876283}
    Policy Entropy: {'avg': 1.066899299621582, 'std': 0.5177420973777771}
    KL Divergence: {'avg': 0.022146187722682953, 'std': 0.17781324684619904}
    Policy Grad Norm: {'avg': 3.61982911080122, 'std': 1.6522031681622944}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.50998196253512, 'std': 24.326747025335766, 'run': -74.34945641588587, 'test_avg': -77.70140704854052, 'test_std': 9.63940130913051}
    Episode Length: {'avg': 19.79064039408867, 'std': 5.298295207159628, 'run': 19.79299461086779, 'test_avg': 20.40234375, 'test_std': 1.8916537425850264}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (4201 / 10001):
    Value Loss: {'avg': 23.333996534347534, 'std': 2.7800366803428465}
    Value Grad Norm: {'avg': 536.8923222223917, 'std': 266.4473436097342}
    Policy Loss: {'avg': 0.0025906936498358846, 'std': 0.006098732188176317}
    Total_Loss: {'avg': -0.09758362732827663, 'std': 0.006974445395927654}
    Policy Entropy: {'avg': 0.9874675273895264, 'std': 0.5097628831863403}
    KL Divergence: {'avg': 0.01938260719180107, 'std': 0.17088274657726288}
    Policy Grad Norm: {'avg': 3.7801331728696823, 'std': 1.4189071392360673}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.59923372534539, 'std': 25.57726997635757, 'run': -74.9673380562223, 'test_avg': -76.50238707671664, 'test_std': 6.848134203085556}
    Episode Length: {'avg': 19.553956834532375, 'std': 5.5896950344783995, 'run': 19.822693402261503, 'test_avg': 20.14453125, 'test_std': 1.4706136364706528}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4301 / 10001):
    Value Loss: {'avg': 27.763838132222492, 'std': 2.9702711328212335}
    Value Grad Norm: {'avg': 740.5543664296468, 'std': 421.2168780592443}
    Policy Loss: {'avg': 0.0063042883994057775, 'std': 0.006227753228689214}
    Total_Loss: {'avg': -0.10620751418173313, 'std': 0.006249900169331882}
    Policy Entropy: {'avg': 1.0802268981933594, 'std': 0.4962558150291443}
    KL Divergence: {'avg': 0.018312320113182068, 'std': 0.18425484001636505}
    Policy Grad Norm: {'avg': 4.3297911286354065, 'std': 1.7077128132738706}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.44438866084546, 'std': 23.49505690733067, 'run': -75.18518989712551, 'test_avg': -77.05426819161897, 'test_std': 6.940122549787476}
    Episode Length: {'avg': 20.57037037037037, 'std': 5.079915534547245, 'run': 19.955603917994317, 'test_avg': 20.2294921875, 'test_std': 1.463444318509066}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 10001):
    Value Loss: {'avg': 26.941851019859314, 'std': 2.801170199356987}
    Value Grad Norm: {'avg': 522.5590133666992, 'std': 304.64135914043106}
    Policy Loss: {'avg': 0.005953387895715423, 'std': 0.005560723564908677}
    Total_Loss: {'avg': -0.09787596017122269, 'std': 0.004955411241165452}
    Policy Entropy: {'avg': 1.0235135555267334, 'std': 0.49670326709747314}
    KL Divergence: {'avg': 0.01809716410934925, 'std': 0.18261922895908356}
    Policy Grad Norm: {'avg': 3.309441678225994, 'std': 0.8544427740935135}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.90905953142679, 'std': 23.76995141312681, 'run': -74.5465477184544, 'test_avg': -77.19920728116159, 'test_std': 7.870879214768371}
    Episode Length: {'avg': 19.759708737864077, 'std': 5.127313866731966, 'run': 19.678457410114913, 'test_avg': 20.24609375, 'test_std': 1.6007762933061376}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4501 / 10001):
    Value Loss: {'avg': 25.431983709335327, 'std': 2.9877531220083986}
    Value Grad Norm: {'avg': 592.9012249310812, 'std': 375.90018986454356}
    Policy Loss: {'avg': -0.005405422314652242, 'std': 0.007328311427483467}
    Total_Loss: {'avg': -0.103583944728598, 'std': 0.0078581034698299}
    Policy Entropy: {'avg': 0.9865725040435791, 'std': 0.5263218879699707}
    KL Divergence: {'avg': 0.023738978430628777, 'std': 0.2098233699798584}
    Policy Grad Norm: {'avg': 3.5288169980049133, 'std': 1.2182220234530023}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.33552171701353, 'std': 25.71884862992475, 'run': -72.48956961297942, 'test_avg': -77.00491749497758, 'test_std': 7.3066279350076515}
    Episode Length: {'avg': 19.483568075117372, 'std': 5.60608006968445, 'run': 19.223903200807285, 'test_avg': 20.23828125, 'test_std': 1.573045468477767}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4601 / 10001):
    Value Loss: {'avg': 28.643959363301594, 'std': 2.8853747221049675}
    Value Grad Norm: {'avg': 694.7188812891642, 'std': 417.43765853386583}
    Policy Loss: {'avg': -0.00563608123047743, 'std': 0.007772847384166993}
    Total_Loss: {'avg': -0.11084400536492467, 'std': 0.00856734143869876}
    Policy Entropy: {'avg': 1.0688347816467285, 'std': 0.5071775913238525}
    KL Divergence: {'avg': 0.01791849359869957, 'std': 0.17873206734657288}
    Policy Grad Norm: {'avg': 3.760032471269369, 'std': 1.9196736919164132}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -75.00238678491372, 'std': 25.15116115347783, 'run': -74.80701109185051, 'test_avg': -76.30490200782725, 'test_std': 6.563406073771098}
    Episode Length: {'avg': 19.914634146341463, 'std': 5.528200914760243, 'run': 19.915278766557723, 'test_avg': 20.08203125, 'test_std': 1.391628631863917}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4701 / 10001):
    Value Loss: {'avg': 21.590654492378235, 'std': 2.4329318837893235}
    Value Grad Norm: {'avg': 509.2791922887166, 'std': 256.2786882781188}
    Policy Loss: {'avg': 0.003963096911320463, 'std': 0.00501580556969169}
    Total_Loss: {'avg': -0.0870961812324822, 'std': 0.005996753770640359}
    Policy Entropy: {'avg': 0.8654399514198303, 'std': 0.5489416718482971}
    KL Divergence: {'avg': 0.017683539539575577, 'std': 0.18482421338558197}
    Policy Grad Norm: {'avg': 3.554943710565567, 'std': 0.9431355204312922}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.18004554273332, 'std': 20.075668490215936, 'run': -74.64581165312038, 'test_avg': -76.36773518719252, 'test_std': 6.744333051482278}
    Episode Length: {'avg': 20.058823529411764, 'std': 4.366929035850279, 'run': 19.758718873368434, 'test_avg': 20.0888671875, 'test_std': 1.430319391075238}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4801 / 10001):
    Value Loss: {'avg': 24.090319673220318, 'std': 2.4455933038427777}
    Value Grad Norm: {'avg': 373.3927199045817, 'std': 175.31344537993164}
    Policy Loss: {'avg': 7.139213266782463e-05, 'std': 0.005047639434495899}
    Total_Loss: {'avg': -0.09634307259693742, 'std': 0.0063417031417560095}
    Policy Entropy: {'avg': 0.947308361530304, 'std': 0.5152506232261658}
    KL Divergence: {'avg': 0.022412288933992386, 'std': 0.1954895406961441}
    Policy Grad Norm: {'avg': 3.4664749801158905, 'std': 1.119945199861002}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.19721478277371, 'std': 25.72137588644852, 'run': -74.06917345826751, 'test_avg': -76.70613547253413, 'test_std': 6.9476065365299915}
    Episode Length: {'avg': 19.644391408114558, 'std': 5.543065142048702, 'run': 19.6537631548244, 'test_avg': 20.1640625, 'test_std': 1.4558735766177466}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4901 / 10001):
    Value Loss: {'avg': 20.56769108772278, 'std': 1.8379533665102328}
    Value Grad Norm: {'avg': 500.5644006729126, 'std': 304.90524792927744}
    Policy Loss: {'avg': 0.003309694933705032, 'std': 0.004126373821826854}
    Total_Loss: {'avg': -0.08503507357090712, 'std': 0.004765196885633872}
    Policy Entropy: {'avg': 0.9129573106765747, 'std': 0.5461025238037109}
    KL Divergence: {'avg': 0.018441293388605118, 'std': 0.1642168164253235}
    Policy Grad Norm: {'avg': 3.2009789645671844, 'std': 0.7472638746243104}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.03410124093914, 'std': 23.310557584858092, 'run': -73.83378940798288, 'test_avg': -76.22599330739914, 'test_std': 6.941969331893848}
    Episode Length: {'avg': 19.441314553990612, 'std': 5.084504874738895, 'run': 19.62845781701777, 'test_avg': 20.0673828125, 'test_std': 1.4791356831202436}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5001 / 10001):
    Value Loss: {'avg': 22.47511621316274, 'std': 1.6758159990334598}
    Value Grad Norm: {'avg': 451.96269575754803, 'std': 179.99506744918907}
    Policy Loss: {'avg': 0.0020331412088125944, 'std': 0.005160316144932389}
    Total_Loss: {'avg': -0.0994356544688344, 'std': 0.004828783060604874}
    Policy Entropy: {'avg': 1.0428881645202637, 'std': 0.5141990184783936}
    KL Divergence: {'avg': 0.017279114574193954, 'std': 0.15437184274196625}
    Policy Grad Norm: {'avg': 3.164663791656494, 'std': 0.665037813028135}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.19836509799337, 'std': 22.027467287951634, 'run': -76.8343696493756, 'test_avg': -76.3148557714677, 'test_std': 6.763368666453363}
    Episode Length: {'avg': 20.059405940594058, 'std': 4.776327314725243, 'run': 20.160938237538286, 'test_avg': 20.0537109375, 'test_std': 1.4176778363552387}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5101 / 10001):
    Value Loss: {'avg': 24.297212560971577, 'std': 2.1956458797797684}
    Value Grad Norm: {'avg': 563.9343493779501, 'std': 311.027800589005}
    Policy Loss: {'avg': -0.0030879545665811747, 'std': 0.007301171422220376}
    Total_Loss: {'avg': -0.09877913841046393, 'std': 0.007933252346240377}
    Policy Entropy: {'avg': 0.9571791887283325, 'std': 0.5293275117874146}
    KL Divergence: {'avg': 0.016354383900761604, 'std': 0.15205799043178558}
    Policy Grad Norm: {'avg': 3.896782122552395, 'std': 1.5035690523338079}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.07081612389085, 'std': 23.397326347376364, 'run': -76.27079099876886, 'test_avg': -75.95691501204621, 'test_std': 8.984531809230718}
    Episode Length: {'avg': 19.556603773584907, 'std': 5.0638939984867655, 'run': 20.02425994596687, 'test_avg': 19.9814453125, 'test_std': 1.7882667337597535}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (5201 / 10001):
    Value Loss: {'avg': 27.929425319035847, 'std': 2.7377965736302783}
    Value Grad Norm: {'avg': 844.4888633092245, 'std': 365.78084908921625}
    Policy Loss: {'avg': 0.004935650969855487, 'std': 0.005746227086990217}
    Total_Loss: {'avg': -0.09907945059239864, 'std': 0.0059799188622133535}
    Policy Entropy: {'avg': 1.0063223838806152, 'std': 0.4847002923488617}
    KL Divergence: {'avg': 0.019895220175385475, 'std': 0.18152952194213867}
    Policy Grad Norm: {'avg': 4.0000885128974915, 'std': 1.9524948285697785}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.23778112656963, 'std': 22.0973731535418, 'run': -79.88876361497447, 'test_avg': -75.8145098587579, 'test_std': 6.888962754618064}
    Episode Length: {'avg': 20.08641975308642, 'std': 4.822779104722001, 'run': 20.85934736286617, 'test_avg': 19.990234375, 'test_std': 1.4947506924461882}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5301 / 10001):
    Value Loss: {'avg': 26.42817787329356, 'std': 2.9589593908331}
    Value Grad Norm: {'avg': 580.2242379188538, 'std': 299.18283576128715}
    Policy Loss: {'avg': 0.0036743603413924575, 'std': 0.008683751953785488}
    Total_Loss: {'avg': -0.09685704484581947, 'std': 0.008113144331849145}
    Policy Entropy: {'avg': 1.0166287422180176, 'std': 0.5298271179199219}
    KL Divergence: {'avg': 0.017750829458236694, 'std': 0.16905714571475983}
    Policy Grad Norm: {'avg': 3.865398555994034, 'std': 1.0281861112323192}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.82994645490378, 'std': 25.22216531611239, 'run': -74.66597080631348, 'test_avg': -76.1473789088082, 'test_std': 6.592676563551322}
    Episode Length: {'avg': 19.554761904761904, 'std': 5.514427068671015, 'run': 19.71579408606352, 'test_avg': 20.021484375, 'test_std': 1.3931779037979533}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5401 / 10001):
    Value Loss: {'avg': 21.390052596728008, 'std': 2.9012909264833455}
    Value Grad Norm: {'avg': 414.7546151479085, 'std': 217.70031104579135}
    Policy Loss: {'avg': 0.002632160671055317, 'std': 0.005178123654806323}
    Total_Loss: {'avg': -0.09121064888313413, 'std': 0.004846380800739463}
    Policy Entropy: {'avg': 0.9238229990005493, 'std': 0.5273836851119995}
    KL Divergence: {'avg': 0.016871465370059013, 'std': 0.16640567779541016}
    Policy Grad Norm: {'avg': 3.29847851395607, 'std': 0.98473055354485}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.13574317912527, 'std': 21.30083127755627, 'run': -72.9501867612022, 'test_avg': -75.95169300373718, 'test_std': 6.82051075741942}
    Episode Length: {'avg': 19.81081081081081, 'std': 4.608621456127441, 'run': 19.348707050357547, 'test_avg': 20.0, 'test_std': 1.4584077361972543}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5501 / 10001):
    Value Loss: {'avg': 26.448471705118816, 'std': 2.903599866364176}
    Value Grad Norm: {'avg': 730.3839737574259, 'std': 408.9467220542162}
    Policy Loss: {'avg': 0.0009247270063497126, 'std': 0.005245621569973805}
    Total_Loss: {'avg': -0.09579301811754704, 'std': 0.0056507311294822825}
    Policy Entropy: {'avg': 0.9731712937355042, 'std': 0.5304324626922607}
    KL Divergence: {'avg': 0.019003314897418022, 'std': 0.19294755160808563}
    Policy Grad Norm: {'avg': 3.6163453608751297, 'std': 1.3932305041289594}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.4214757471669, 'std': 22.946577786290216, 'run': -75.63522336219141, 'test_avg': -76.03597393778256, 'test_std': 8.495329821945248}
    Episode Length: {'avg': 19.929095354523227, 'std': 4.980387884973925, 'run': 19.957171476476102, 'test_avg': 19.99609375, 'test_std': 1.6845994675919074}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (5601 / 10001):
    Value Loss: {'avg': 30.258503158887226, 'std': 5.714681107149108}
    Value Grad Norm: {'avg': 590.0322411855062, 'std': 302.7914386039822}
    Policy Loss: {'avg': -0.004056828562170267, 'std': 0.009543004644425956}
    Total_Loss: {'avg': -0.11060023424215615, 'std': 0.009803547613082239}
    Policy Entropy: {'avg': 1.1075772047042847, 'std': 0.501236081123352}
    KL Divergence: {'avg': 0.023930571973323822, 'std': 0.1755591183900833}
    Policy Grad Norm: {'avg': 3.3657288439571857, 'std': 1.4006289164216963}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.36436834574741, 'std': 23.965011022923196, 'run': -73.98840137586846, 'test_avg': -76.6259962451174, 'test_std': 10.46857655064561}
    Episode Length: {'avg': 19.673076923076923, 'std': 5.215900814027731, 'run': 19.542759968327967, 'test_avg': 20.1201171875, 'test_std': 2.0893670509910627}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (5701 / 10001):
    Value Loss: {'avg': 21.504474878311157, 'std': 2.4849709946501646}
    Value Grad Norm: {'avg': 579.8515162467957, 'std': 331.4730975884433}
    Policy Loss: {'avg': -0.0009970310638891533, 'std': 0.008249354400332125}
    Total_Loss: {'avg': -0.09825438656844199, 'std': 0.0083839949790542}
    Policy Entropy: {'avg': 0.9952044486999512, 'std': 0.5471745133399963}
    KL Divergence: {'avg': 0.02157389000058174, 'std': 0.1622147560119629}
    Policy Grad Norm: {'avg': 3.976908218115568, 'std': 2.156507953401706}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.09821389958663, 'std': 23.365463186901746, 'run': -73.60765820962293, 'test_avg': -75.77977381055894, 'test_std': 6.561669157700214}
    Episode Length: {'avg': 19.635491606714627, 'std': 5.067551999882418, 'run': 19.531233777384934, 'test_avg': 19.97265625, 'test_std': 1.3825200520556429}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5801 / 10001):
    Value Loss: {'avg': 23.09409809112549, 'std': 3.557217692889933}
    Value Grad Norm: {'avg': 822.6961026191711, 'std': 327.73466623690433}
    Policy Loss: {'avg': 0.006053218443412334, 'std': 0.00686610224693135}
    Total_Loss: {'avg': -0.08905338682234287, 'std': 0.006319462089063088}
    Policy Entropy: {'avg': 0.964300274848938, 'std': 0.5241547226905823}
    KL Divergence: {'avg': 0.017821133136749268, 'std': 0.17611274123191833}
    Policy Grad Norm: {'avg': 3.354021869599819, 'std': 1.3764311007010572}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.48783296600047, 'std': 20.82205395261307, 'run': -76.33363579168221, 'test_avg': -75.7691869134814, 'test_std': 6.903129067494596}
    Episode Length: {'avg': 19.899755501222494, 'std': 4.541816029932939, 'run': 20.10137513852028, 'test_avg': 19.9619140625, 'test_std': 1.4501867634428147}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5901 / 10001):
    Value Loss: {'avg': 23.481197396914165, 'std': 2.493212336900918}
    Value Grad Norm: {'avg': 442.8029034932454, 'std': 231.8471031659066}
    Policy Loss: {'avg': -0.003356372020789422, 'std': 0.008362647403456408}
    Total_Loss: {'avg': -0.10125256166793406, 'std': 0.008007491338243015}
    Policy Entropy: {'avg': 0.974962592124939, 'std': 0.5047280192375183}
    KL Divergence: {'avg': 0.02233363315463066, 'std': 0.1974181979894638}
    Policy Grad Norm: {'avg': 3.8763555735349655, 'std': 1.6747384130631098}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.1270876528946, 'std': 24.646362128306393, 'run': -73.89711256603024, 'test_avg': -75.68525314572526, 'test_std': 7.503017188756666}
    Episode Length: {'avg': 19.623222748815166, 'std': 5.354957931488659, 'run': 19.578869410514, 'test_avg': 19.923828125, 'test_std': 1.5026209503593992}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6001 / 10001):
    Value Loss: {'avg': 24.1834819316864, 'std': 1.9431479739428454}
    Value Grad Norm: {'avg': 475.0193042755127, 'std': 202.93634613538947}
    Policy Loss: {'avg': 0.003371904051164165, 'std': 0.006512804775085766}
    Total_Loss: {'avg': -0.0902489423751831, 'std': 0.006474158823085504}
    Policy Entropy: {'avg': 0.9319456815719604, 'std': 0.5670410394668579}
    KL Divergence: {'avg': 0.022761207073926926, 'std': 0.23245017230510712}
    Policy Grad Norm: {'avg': 3.871237874031067, 'std': 1.7561551766022463}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.5335655347417, 'std': 27.016080935427464, 'run': -72.55853539833292, 'test_avg': -75.92581145662277, 'test_std': 6.986140393785339}
    Episode Length: {'avg': 18.85354691075515, 'std': 5.892365421199936, 'run': 19.32491732180592, 'test_avg': 20.0029296875, 'test_std': 1.4813262147248838}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6101 / 10001):
    Value Loss: {'avg': 26.759651223818462, 'std': 3.1198204457916843}
    Value Grad Norm: {'avg': 382.15552520751953, 'std': 161.6803795219634}
    Policy Loss: {'avg': -0.0016913772997213528, 'std': 0.007915501985272314}
    Total_Loss: {'avg': -0.10906747123226523, 'std': 0.008792862733233061}
    Policy Entropy: {'avg': 1.0421769618988037, 'std': 0.540507435798645}
    KL Divergence: {'avg': 0.02535366266965866, 'std': 0.21182632446289062}
    Policy Grad Norm: {'avg': 3.7989614009857178, 'std': 1.6212675386696753}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.87004278141849, 'std': 25.763179327596216, 'run': -75.06857922562156, 'test_avg': -76.55049005833, 'test_std': 10.367061670028985}
    Episode Length: {'avg': 19.81367924528302, 'std': 5.572481379718114, 'run': 19.878819888862523, 'test_avg': 20.1298828125, 'test_std': 1.9832613966689034}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (6201 / 10001):
    Value Loss: {'avg': 27.179731408754986, 'std': 2.8508954136576516}
    Value Grad Norm: {'avg': 381.43434047698975, 'std': 188.1543817374728}
    Policy Loss: {'avg': -0.006617700113565661, 'std': 0.007564843381850975}
    Total_Loss: {'avg': -0.1107776528224349, 'std': 0.009536326461254444}
    Policy Entropy: {'avg': 1.0389986038208008, 'std': 0.5203390717506409}
    KL Divergence: {'avg': 0.021010201424360275, 'std': 0.19693706929683685}
    Policy Grad Norm: {'avg': 3.912640579044819, 'std': 1.5888930632403433}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.62706123927093, 'std': 26.384917204895252, 'run': -73.15254002585759, 'test_avg': -75.83963612136583, 'test_std': 7.758681727155242}
    Episode Length: {'avg': 19.501187648456057, 'std': 5.725562426330246, 'run': 19.408009167401346, 'test_avg': 19.962890625, 'test_std': 1.5645579708937312}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6301 / 10001):
    Value Loss: {'avg': 19.90223999818166, 'std': 1.6577700770211334}
    Value Grad Norm: {'avg': 480.0419101715088, 'std': 296.5678710317442}
    Policy Loss: {'avg': -0.004262067130184732, 'std': 0.009529848385637238}
    Total_Loss: {'avg': -0.09379711863584816, 'std': 0.009996564618919393}
    Policy Entropy: {'avg': 0.9019750356674194, 'std': 0.528195858001709}
    KL Divergence: {'avg': 0.019847728312015533, 'std': 0.17899039387702942}
    Policy Grad Norm: {'avg': 4.002099249511957, 'std': 2.1827545738006426}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.24509908513221, 'std': 20.912372050729857, 'run': -73.23025797218791, 'test_avg': -75.60387372023655, 'test_std': 6.965652531020428}
    Episode Length: {'avg': 19.60774818401937, 'std': 4.561247229131194, 'run': 19.401880814712268, 'test_avg': 19.943359375, 'test_std': 1.4699844691695247}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6401 / 10001):
    Value Loss: {'avg': 20.264953136444092, 'std': 1.9552856452197966}
    Value Grad Norm: {'avg': 518.1498381296793, 'std': 317.9722597842863}
    Policy Loss: {'avg': -0.002743477452895604, 'std': 0.007515395968654008}
    Total_Loss: {'avg': -0.09792743530124426, 'std': 0.00899527130737638}
    Policy Entropy: {'avg': 0.9848060607910156, 'std': 0.5440869331359863}
    KL Divergence: {'avg': 0.026257380843162537, 'std': 0.21822962164878845}
    Policy Grad Norm: {'avg': 3.6467251256108284, 'std': 1.3533237965689435}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.7016397502504, 'std': 22.831480720144476, 'run': -73.04283669322209, 'test_avg': -75.35469780240254, 'test_std': 6.4070709075473005}
    Episode Length: {'avg': 19.797619047619047, 'std': 4.987555374808388, 'run': 19.475740730454028, 'test_avg': 19.884765625, 'test_std': 1.342805752452066}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6501 / 10001):
    Value Loss: {'avg': 26.340844472249348, 'std': 2.765590245726056}
    Value Grad Norm: {'avg': 476.65677785873413, 'std': 291.25943770758204}
    Policy Loss: {'avg': -0.004820821704925038, 'std': 0.007688493852580775}
    Total_Loss: {'avg': -0.11597738415002823, 'std': 0.007885367005661474}
    Policy Entropy: {'avg': 1.1380424499511719, 'std': 0.5233435034751892}
    KL Divergence: {'avg': 0.01554851047694683, 'std': 0.1786850243806839}
    Policy Grad Norm: {'avg': 4.573299776762724, 'std': 2.5460498702552194}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -76.95391023774097, 'std': 23.810072729476385, 'run': -77.15398456013004, 'test_avg': -76.08505313735523, 'test_std': 6.3975573246921025}
    Episode Length: {'avg': 20.33252427184466, 'std': 5.1594583177796896, 'run': 20.423318424061275, 'test_avg': 20.048828125, 'test_std': 1.3432261310773344}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6601 / 10001):
    Value Loss: {'avg': 19.528463502724964, 'std': 2.1524118566433237}
    Value Grad Norm: {'avg': 565.8255216280619, 'std': 352.2071966964802}
    Policy Loss: {'avg': -0.0008687302688485943, 'std': 0.006634966269665794}
    Total_Loss: {'avg': -0.09779603080824018, 'std': 0.0075860151238352665}
    Policy Entropy: {'avg': 0.9547951221466064, 'std': 0.5182876586914062}
    KL Divergence: {'avg': 0.017866145819425583, 'std': 0.1673918068408966}
    Policy Grad Norm: {'avg': 5.029803991317749, 'std': 3.7694307209294218}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.17265749022934, 'std': 23.300202534428024, 'run': -74.52149844843515, 'test_avg': -75.38822524076826, 'test_std': 6.580692548099398}
    Episode Length: {'avg': 19.407925407925408, 'std': 5.0317437679612995, 'run': 19.716701829857378, 'test_avg': 19.9130859375, 'test_std': 1.377577360165209}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6701 / 10001):
    Value Loss: {'avg': 21.179410417874653, 'std': 1.7018883921200538}
    Value Grad Norm: {'avg': 405.9239870707194, 'std': 195.95574932930882}
    Policy Loss: {'avg': -0.0038514442567247897, 'std': 0.007456208270843617}
    Total_Loss: {'avg': -0.10023920051753521, 'std': 0.008253064786430626}
    Policy Entropy: {'avg': 0.993405282497406, 'std': 0.5039506554603577}
    KL Divergence: {'avg': 0.022765353322029114, 'std': 0.17730428278446198}
    Policy Grad Norm: {'avg': 4.738382313400507, 'std': 2.1739330622288033}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -76.89201112921468, 'std': 19.48797089157427, 'run': -77.35454021079111, 'test_avg': -75.89058323416481, 'test_std': 8.812128273502223}
    Episode Length: {'avg': 20.241895261845386, 'std': 4.228963238645845, 'run': 20.33039633697114, 'test_avg': 19.9970703125, 'test_std': 1.7519495867264996}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (6801 / 10001):
    Value Loss: {'avg': 18.799961984157562, 'std': 1.4380013478781504}
    Value Grad Norm: {'avg': 411.4275369644165, 'std': 230.28074264835328}
    Policy Loss: {'avg': 0.00267142488155514, 'std': 0.004758666468518976}
    Total_Loss: {'avg': -0.08890614565461874, 'std': 0.005072067931501008}
    Policy Entropy: {'avg': 0.9288705587387085, 'std': 0.5471963882446289}
    KL Divergence: {'avg': 0.015362787991762161, 'std': 0.1516353189945221}
    Policy Grad Norm: {'avg': 3.4628819078207016, 'std': 1.2847429008054359}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.1921594171054, 'std': 21.05196932547234, 'run': -73.46990648446263, 'test_avg': -75.58325731790113, 'test_std': 7.275443367815093}
    Episode Length: {'avg': 19.640287769784173, 'std': 4.5749928032514395, 'run': 19.472385464120556, 'test_avg': 19.9384765625, 'test_std': 1.544624000894128}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6901 / 10001):
    Value Loss: {'avg': 20.035120050112408, 'std': 1.7461530437701522}
    Value Grad Norm: {'avg': 393.75411621729535, 'std': 278.0477183709975}
    Policy Loss: {'avg': 0.00533893246029038, 'std': 0.005947456061914968}
    Total_Loss: {'avg': -0.09167347801849246, 'std': 0.006407204108800829}
    Policy Entropy: {'avg': 0.9420982599258423, 'std': 0.5292184948921204}
    KL Divergence: {'avg': 0.016204671934247017, 'std': 0.17953413724899292}
    Policy Grad Norm: {'avg': 4.525941580533981, 'std': 2.4086743162881827}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.58075614288823, 'std': 24.036205724844848, 'run': -73.47659035170847, 'test_avg': -75.06225121379495, 'test_std': 6.708442800898603}
    Episode Length: {'avg': 19.292978208232444, 'std': 5.2601912238424875, 'run': 19.438172510961998, 'test_avg': 19.8046875, 'test_std': 1.4138466686114692}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7001 / 10001):
    Value Loss: {'avg': 24.558956265449524, 'std': 2.085072885034398}
    Value Grad Norm: {'avg': 642.4265027046204, 'std': 352.1059583941762}
    Policy Loss: {'avg': 0.0023219925787998363, 'std': 0.004910154200012974}
    Total_Loss: {'avg': -0.09785341145470738, 'std': 0.005612528378215586}
    Policy Entropy: {'avg': 0.9896248579025269, 'std': 0.5282832384109497}
    KL Divergence: {'avg': 0.018754370510578156, 'std': 0.15848495066165924}
    Policy Grad Norm: {'avg': 3.9151571840047836, 'std': 1.325707232474122}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.95875775920574, 'std': 26.17529186815119, 'run': -70.25373589582837, 'test_avg': -75.684312287741, 'test_std': 6.682899169267649}
    Episode Length: {'avg': 19.24532710280374, 'std': 5.739932400161549, 'run': 18.87346652475982, 'test_avg': 19.95703125, 'test_std': 1.414251325445176}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7101 / 10001):
    Value Loss: {'avg': 21.290823181470234, 'std': 2.152254819838156}
    Value Grad Norm: {'avg': 498.6730016072591, 'std': 249.28526596928236}
    Policy Loss: {'avg': -0.00453437196847517, 'std': 0.008615191094201476}
    Total_Loss: {'avg': -0.10099914483726025, 'std': 0.009181113270842282}
    Policy Entropy: {'avg': 0.9717897176742554, 'std': 0.5028681755065918}
    KL Divergence: {'avg': 0.01616688072681427, 'std': 0.1547977477312088}
    Policy Grad Norm: {'avg': 3.49743228033185, 'std': 1.432382011722257}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.04056003771933, 'std': 24.24020034639934, 'run': -73.55340552598835, 'test_avg': -75.30617182628843, 'test_std': 6.490638800273398}
    Episode Length: {'avg': 19.43230403800475, 'std': 5.312406638013359, 'run': 19.54784958949194, 'test_avg': 19.849609375, 'test_std': 1.3610226522406266}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7201 / 10001):
    Value Loss: {'avg': 19.848322868347168, 'std': 1.7705348378120769}
    Value Grad Norm: {'avg': 412.0793113708496, 'std': 194.6674367564599}
    Policy Loss: {'avg': 0.00362240377580747, 'std': 0.005601763493207574}
    Total_Loss: {'avg': -0.0853269575163722, 'std': 0.006124696382685352}
    Policy Entropy: {'avg': 0.8826777935028076, 'std': 0.5308709144592285}
    KL Divergence: {'avg': 0.016244564205408096, 'std': 0.18671737611293793}
    Policy Grad Norm: {'avg': 3.9902158677577972, 'std': 1.3605234771752281}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.57149897652391, 'std': 23.598343378706286, 'run': -72.48596486702242, 'test_avg': -75.32676295835046, 'test_std': 7.62934943413208}
    Episode Length: {'avg': 19.330188679245282, 'std': 5.160118651029454, 'run': 19.303694952372577, 'test_avg': 19.888671875, 'test_std': 1.5268778761197583}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7301 / 10001):
    Value Loss: {'avg': 18.251001477241516, 'std': 1.299643925875094}
    Value Grad Norm: {'avg': 253.07441663742065, 'std': 121.78880451524924}
    Policy Loss: {'avg': 0.005823510349728167, 'std': 0.006387120765141046}
    Total_Loss: {'avg': -0.08656388847157359, 'std': 0.007700840789050336}
    Policy Entropy: {'avg': 0.9282892942428589, 'std': 0.5203834176063538}
    KL Divergence: {'avg': 0.018761858344078064, 'std': 0.17962272465229034}
    Policy Grad Norm: {'avg': 4.192386597394943, 'std': 2.587730988557866}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.10359470298731, 'std': 22.613515990907107, 'run': -70.32463044267158, 'test_avg': -75.57379644316056, 'test_std': 6.920400782063165}
    Episode Length: {'avg': 19.46043165467626, 'std': 4.916959619521517, 'run': 18.88833866896714, 'test_avg': 19.9091796875, 'test_std': 1.4672711008322226}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7401 / 10001):
    Value Loss: {'avg': 26.156572858492535, 'std': 4.767211780858652}
    Value Grad Norm: {'avg': 812.3615287144979, 'std': 355.05675631886805}
    Policy Loss: {'avg': 0.0034368500928394496, 'std': 0.005807363679572777}
    Total_Loss: {'avg': -0.09330953378230333, 'std': 0.006429247353686379}
    Policy Entropy: {'avg': 0.9572122097015381, 'std': 0.5237551331520081}
    KL Divergence: {'avg': 0.018994895741343498, 'std': 0.1756935715675354}
    Policy Grad Norm: {'avg': 5.029739692807198, 'std': 2.114293111714166}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.18678031087262, 'std': 24.469022863131578, 'run': -75.25306043753623, 'test_avg': -75.4444689176998, 'test_std': 6.398354457425144}
    Episode Length: {'avg': 19.38443396226415, 'std': 5.303598205453001, 'run': 19.842894336766047, 'test_avg': 19.8798828125, 'test_std': 1.3600844362638262}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7501 / 10001):
    Value Loss: {'avg': 20.484102368354797, 'std': 1.9272568830262855}
    Value Grad Norm: {'avg': 373.14642508824664, 'std': 203.70562794584913}
    Policy Loss: {'avg': -0.005853356589796022, 'std': 0.007964464621070037}
    Total_Loss: {'avg': -0.10310622653923929, 'std': 0.008551123237851373}
    Policy Entropy: {'avg': 0.9633502960205078, 'std': 0.4947080612182617}
    KL Divergence: {'avg': 0.021511055529117584, 'std': 0.17531561851501465}
    Policy Grad Norm: {'avg': 3.863724362105131, 'std': 1.4146035840050506}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.19539889117979, 'std': 24.869647204244956, 'run': -72.8410527817537, 'test_avg': -75.45640156874173, 'test_std': 7.811665192042874}
    Episode Length: {'avg': 19.475728155339805, 'std': 5.3880390009367085, 'run': 19.371039514149654, 'test_avg': 19.9501953125, 'test_std': 1.6928329969619056}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7601 / 10001):
    Value Loss: {'avg': 18.279983898003895, 'std': 1.6189946227054128}
    Value Grad Norm: {'avg': 331.94445673624676, 'std': 157.67245454627113}
    Policy Loss: {'avg': 0.002579559833975509, 'std': 0.005838489106465277}
    Total_Loss: {'avg': -0.08927607303485274, 'std': 0.007268094215005671}
    Policy Entropy: {'avg': 0.9135143756866455, 'std': 0.5279274582862854}
    KL Divergence: {'avg': 0.023179499432444572, 'std': 0.19855928421020508}
    Policy Grad Norm: {'avg': 3.816972315311432, 'std': 0.9661054341186683}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.86453543066136, 'std': 23.235065997912134, 'run': -72.44755385151595, 'test_avg': -75.02078592964067, 'test_std': 6.593601112844961}
    Episode Length: {'avg': 19.38388625592417, 'std': 5.0952562331887705, 'run': 19.26448027384083, 'test_avg': 19.8564453125, 'test_std': 1.4002990267070734}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7701 / 10001):
    Value Loss: {'avg': 20.998518188794453, 'std': 1.5162112181663068}
    Value Grad Norm: {'avg': 635.8002344767252, 'std': 309.3724985990896}
    Policy Loss: {'avg': 0.0017583700828254223, 'std': 0.0044336038821299086}
    Total_Loss: {'avg': -0.09374144487082958, 'std': 0.003696567918946936}
    Policy Entropy: {'avg': 0.9609813690185547, 'std': 0.5129293203353882}
    KL Divergence: {'avg': 0.01680990681052208, 'std': 0.15918827056884766}
    Policy Grad Norm: {'avg': 3.5342700481414795, 'std': 1.601541262105733}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.86206352059524, 'std': 24.61573313710836, 'run': -72.60242595641292, 'test_avg': -75.28661312454199, 'test_std': 6.704525257927549}
    Episode Length: {'avg': 19.137440758293838, 'std': 5.362682278747617, 'run': 19.298932118248764, 'test_avg': 19.8974609375, 'test_std': 1.4087593577902584}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7801 / 10001):
    Value Loss: {'avg': 18.80379009246826, 'std': 1.4930421975546595}
    Value Grad Norm: {'avg': 405.156489054362, 'std': 205.34597104424944}
    Policy Loss: {'avg': -0.0008985159656731412, 'std': 0.01435368547406231}
    Total_Loss: {'avg': -0.08932488085702062, 'std': 0.014421348421890728}
    Policy Entropy: {'avg': 0.9929500818252563, 'std': 0.521854043006897}
    KL Divergence: {'avg': 0.026801273226737976, 'std': 0.19147655367851257}
    Policy Grad Norm: {'avg': 5.474306240677834, 'std': 11.070976810716413}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.60660473004893, 'std': 19.92085792229662, 'run': -73.05710363343364, 'test_avg': -75.40857478827866, 'test_std': 6.286313866243171}
    Episode Length: {'avg': 19.768496420047732, 'std': 4.338467595884071, 'run': 19.448319518427496, 'test_avg': 19.92578125, 'test_std': 1.3376895948419565}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7901 / 10001):
    Value Loss: {'avg': 18.2095449368159, 'std': 1.4602898958200627}
    Value Grad Norm: {'avg': 320.40325593948364, 'std': 176.26937432231722}
    Policy Loss: {'avg': -0.0003178152983309701, 'std': 0.008367260980600432}
    Total_Loss: {'avg': -0.08831983408890665, 'std': 0.008682882960370262}
    Policy Entropy: {'avg': 0.9075487852096558, 'std': 0.5185843110084534}
    KL Divergence: {'avg': 0.0181790292263031, 'std': 0.16528652608394623}
    Policy Grad Norm: {'avg': 3.964344337582588, 'std': 1.4378618660445766}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -69.52297245594006, 'std': 24.615280638123902, 'run': -68.60702122441924, 'test_avg': -74.95176123177933, 'test_std': 6.39914248521997}
    Episode Length: {'avg': 18.679545454545455, 'std': 5.415847098412993, 'run': 18.471087100700544, 'test_avg': 19.8369140625, 'test_std': 1.3534405840264085}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8001 / 10001):
    Value Loss: {'avg': 19.395527799924213, 'std': 3.148096746926934}
    Value Grad Norm: {'avg': 281.9555074373881, 'std': 137.48893876842203}
    Policy Loss: {'avg': 0.007250368478707969, 'std': 0.006721294557042808}
    Total_Loss: {'avg': -0.08324518846347928, 'std': 0.006497114558441353}
    Policy Entropy: {'avg': 0.930651068687439, 'std': 0.5516519546508789}
    KL Divergence: {'avg': 0.028295766562223434, 'std': 0.2123797982931137}
    Policy Grad Norm: {'avg': 3.122017741203308, 'std': 1.0841143687638344}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.09573943087857, 'std': 23.351005247174403, 'run': -72.93991926326521, 'test_avg': -75.0832747625849, 'test_std': 7.407405878053469}
    Episode Length: {'avg': 19.392344497607656, 'std': 5.095653345752375, 'run': 19.401994425928063, 'test_avg': 19.8564453125, 'test_std': 1.4914788765506461}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8101 / 10001):
    Value Loss: {'avg': 19.428409775098164, 'std': 1.4579613173477963}
    Value Grad Norm: {'avg': 381.84923696517944, 'std': 219.0806381762454}
    Policy Loss: {'avg': -0.003113545637461357, 'std': 0.008554143170146293}
    Total_Loss: {'avg': -0.09828655072487891, 'std': 0.008418077203909117}
    Policy Entropy: {'avg': 0.9476507902145386, 'std': 0.5531780123710632}
    KL Divergence: {'avg': 0.018746495246887207, 'std': 0.15692465007305145}
    Policy Grad Norm: {'avg': 4.024820700287819, 'std': 1.848276970994017}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.84066670033042, 'std': 20.262095799391293, 'run': -75.32860089885158, 'test_avg': -75.51987180720556, 'test_std': 6.529831795929923}
    Episode Length: {'avg': 19.78743961352657, 'std': 4.4176016746117135, 'run': 19.909288479277688, 'test_avg': 19.9287109375, 'test_std': 1.3813051100563811}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8201 / 10001):
    Value Loss: {'avg': 18.627417127291363, 'std': 1.4980819870235726}
    Value Grad Norm: {'avg': 369.59763447443646, 'std': 236.38218089302984}
    Policy Loss: {'avg': 0.006035899568814784, 'std': 0.0049811639728967435}
    Total_Loss: {'avg': -0.08498245710507035, 'std': 0.004070672988231745}
    Policy Entropy: {'avg': 0.8992337584495544, 'std': 0.5409260988235474}
    KL Divergence: {'avg': 0.01798222027719021, 'std': 0.16763976216316223}
    Policy Grad Norm: {'avg': 5.318983554840088, 'std': 1.7512166328141174}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.0572392694899, 'std': 22.817583014241126, 'run': -73.05041802937303, 'test_avg': -74.61846554067372, 'test_std': 6.446354509275762}
    Episode Length: {'avg': 19.397163120567377, 'std': 4.972091519649921, 'run': 19.4130244885909, 'test_avg': 19.71875, 'test_std': 1.3603624287299323}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8301 / 10001):
    Value Loss: {'avg': 22.061606407165527, 'std': 2.13829110266103}
    Value Grad Norm: {'avg': 232.7858829498291, 'std': 106.22699679710485}
    Policy Loss: {'avg': 0.0035831774002872407, 'std': 0.003980277809553144}
    Total_Loss: {'avg': -0.09612224576994777, 'std': 0.0041231911859725525}
    Policy Entropy: {'avg': 0.9740744829177856, 'std': 0.5322518944740295}
    KL Divergence: {'avg': 0.015225035138428211, 'std': 0.16527952253818512}
    Policy Grad Norm: {'avg': 5.3154482543468475, 'std': 2.3724751603209957}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.55336614723578, 'std': 24.399075136560327, 'run': -72.72585238505351, 'test_avg': -75.42421238286175, 'test_std': 8.272750634476894}
    Episode Length: {'avg': 19.613138686131386, 'std': 5.324846284999065, 'run': 19.453800999886678, 'test_avg': 19.951171875, 'test_std': 1.6722571390814824}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (8401 / 10001):
    Value Loss: {'avg': 20.58584996064504, 'std': 2.0257785352136435}
    Value Grad Norm: {'avg': 527.4761091868082, 'std': 357.81864120323934}
    Policy Loss: {'avg': 0.004239696645527147, 'std': 0.004905220192621138}
    Total_Loss: {'avg': -0.0883036688901484, 'std': 0.004960730146705437}
    Policy Entropy: {'avg': 0.8959851861000061, 'std': 0.5165539979934692}
    KL Divergence: {'avg': 0.016391701996326447, 'std': 0.15312907099723816}
    Policy Grad Norm: {'avg': 3.738223075866699, 'std': 1.289480782725881}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.9646178761631, 'std': 23.22234061537546, 'run': -73.18581075557724, 'test_avg': -75.24487185155033, 'test_std': 8.391359535888842}
    Episode Length: {'avg': 19.45774647887324, 'std': 5.086514306034369, 'run': 19.51084452393409, 'test_avg': 19.8720703125, 'test_std': 1.644189939622595}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (8501 / 10001):
    Value Loss: {'avg': 19.159337719281513, 'std': 2.0809358352734044}
    Value Grad Norm: {'avg': 237.22340885798135, 'std': 145.72961138385995}
    Policy Loss: {'avg': 0.003907090402208269, 'std': 0.005978775562377153}
    Total_Loss: {'avg': -0.08632777072489262, 'std': 0.005889602878059696}
    Policy Entropy: {'avg': 0.8893837928771973, 'std': 0.5293759703636169}
    KL Divergence: {'avg': 0.018305649980902672, 'std': 0.20316831767559052}
    Policy Grad Norm: {'avg': 4.625516772270203, 'std': 1.5095926603136922}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.22719604897878, 'std': 22.884983256570017, 'run': -72.17186762557083, 'test_avg': -75.55066470048044, 'test_std': 7.084407668548929}
    Episode Length: {'avg': 19.27358490566038, 'std': 4.998175174299087, 'run': 19.24186812674005, 'test_avg': 19.953125, 'test_std': 1.4940474337767862}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8601 / 10001):
    Value Loss: {'avg': 19.85352822144826, 'std': 2.045261451977105}
    Value Grad Norm: {'avg': 396.2424090703328, 'std': 210.68301606133483}
    Policy Loss: {'avg': 0.002816416905261576, 'std': 0.006305678563154095}
    Total_Loss: {'avg': -0.09040026413276792, 'std': 0.007907027075171415}
    Policy Entropy: {'avg': 1.009589433670044, 'std': 0.5177689790725708}
    KL Divergence: {'avg': 0.016778241842985153, 'std': 0.15876424312591553}
    Policy Grad Norm: {'avg': 3.4741856679320335, 'std': 1.4471197997733416}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.25789019080457, 'std': 23.34701380144485, 'run': -74.52060032878745, 'test_avg': -74.73675487049888, 'test_std': 6.701598034786377}
    Episode Length: {'avg': 19.479713603818617, 'std': 5.1150434609800435, 'run': 19.744292040511134, 'test_avg': 19.7958984375, 'test_std': 1.4205325989519066}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8701 / 10001):
    Value Loss: {'avg': 15.973982771237692, 'std': 1.487945894117133}
    Value Grad Norm: {'avg': 406.7187542915344, 'std': 202.91549114303407}
    Policy Loss: {'avg': 0.0034616558405105025, 'std': 0.003643072384206336}
    Total_Loss: {'avg': -0.07711465563625097, 'std': 0.004315566089596995}
    Policy Entropy: {'avg': 0.767708957195282, 'std': 0.5421360731124878}
    KL Divergence: {'avg': 0.01540890708565712, 'std': 0.15666115283966064}
    Policy Grad Norm: {'avg': 3.5503885447978973, 'std': 1.3339479267965555}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.70792837332982, 'std': 21.450706837282834, 'run': -70.98446769976493, 'test_avg': -74.95314418512315, 'test_std': 7.022037909010537}
    Episode Length: {'avg': 19.147196261682243, 'std': 4.663370546003375, 'run': 18.98295246832402, 'test_avg': 19.8271484375, 'test_std': 1.5118042283448305}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8801 / 10001):
    Value Loss: {'avg': 16.89560196797053, 'std': 1.667492672697824}
    Value Grad Norm: {'avg': 251.0156488418579, 'std': 152.17610074627333}
    Policy Loss: {'avg': -0.0029290235979715362, 'std': 0.009576111634589662}
    Total_Loss: {'avg': -0.09577694186009467, 'std': 0.009773841804071393}
    Policy Entropy: {'avg': 0.9385024905204773, 'std': 0.5086178779602051}
    KL Divergence: {'avg': 0.019389107823371887, 'std': 0.16656193137168884}
    Policy Grad Norm: {'avg': 4.808246735483408, 'std': 2.751822289919343}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.74079119854255, 'std': 20.49526036180135, 'run': -74.81056574150675, 'test_avg': -74.58160731427617, 'test_std': 6.188702804948048}
    Episode Length: {'avg': 19.56872037914692, 'std': 4.478888632938662, 'run': 19.7656997555815, 'test_avg': 19.736328125, 'test_std': 1.299342003605665}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8901 / 10001):
    Value Loss: {'avg': 17.850238541762035, 'std': 2.055746627059788}
    Value Grad Norm: {'avg': 272.72101577123004, 'std': 150.6593790262233}
    Policy Loss: {'avg': 0.005616984621156007, 'std': 0.006210945204396891}
    Total_Loss: {'avg': -0.07820914080366492, 'std': 0.0075884703891503525}
    Policy Entropy: {'avg': 0.8385202884674072, 'std': 0.5453168749809265}
    KL Divergence: {'avg': 0.016923055052757263, 'std': 0.17708642780780792}
    Policy Grad Norm: {'avg': 4.992287769913673, 'std': 2.676331055085362}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -69.75842859633728, 'std': 25.677377497469696, 'run': -68.73972208050691, 'test_avg': -74.466391016372, 'test_std': 6.599921820794942}
    Episode Length: {'avg': 18.70945945945946, 'std': 5.626417793347149, 'run': 18.483921550496202, 'test_avg': 19.7666015625, 'test_std': 1.4433365795518933}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9001 / 10001):
    Value Loss: {'avg': 16.882894416650135, 'std': 1.638288163449429}
    Value Grad Norm: {'avg': 281.42269643147785, 'std': 125.36857082096182}
    Policy Loss: {'avg': 0.005509900423930958, 'std': 0.006396724504706467}
    Total_Loss: {'avg': -0.08235998684540391, 'std': 0.006651118715747354}
    Policy Entropy: {'avg': 0.8901529312133789, 'std': 0.5037753582000732}
    KL Divergence: {'avg': 0.022301647812128067, 'std': 0.1639704704284668}
    Policy Grad Norm: {'avg': 4.276163727045059, 'std': 2.6955488921996222}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.79656661987488, 'std': 22.97832150734475, 'run': -69.2853168142161, 'test_avg': -74.91015068756265, 'test_std': 6.288298550844072}
    Episode Length: {'avg': 19.156028368794328, 'std': 4.995435772020965, 'run': 18.60482486846478, 'test_avg': 19.8818359375, 'test_std': 1.3674159267880042}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9101 / 10001):
    Value Loss: {'avg': 22.2960927883784, 'std': 2.740324199463712}
    Value Grad Norm: {'avg': 345.709401289622, 'std': 180.76957192556972}
    Policy Loss: {'avg': -0.005716078187106177, 'std': 0.008496604617940195}
    Total_Loss: {'avg': -0.10227655177004635, 'std': 0.008877683613836531}
    Policy Entropy: {'avg': 0.987130880355835, 'std': 0.5125039219856262}
    KL Divergence: {'avg': 0.023768283426761627, 'std': 0.18979796767234802}
    Policy Grad Norm: {'avg': 3.89799702167511, 'std': 1.5485023911263873}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -73.44248629000036, 'std': 23.83782185390143, 'run': -70.89649271152612, 'test_avg': -74.65780423922727, 'test_std': 6.713621737957497}
    Episode Length: {'avg': 19.5, 'std': 5.207664298114891, 'run': 18.942243431778923, 'test_avg': 19.7958984375, 'test_std': 1.4198449702995952}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9201 / 10001):
    Value Loss: {'avg': 16.976646701494854, 'std': 1.9335662112409469}
    Value Grad Norm: {'avg': 465.88956387837726, 'std': 271.6553568220103}
    Policy Loss: {'avg': 0.008479242329485714, 'std': 0.009838344664339239}
    Total_Loss: {'avg': -0.07363502122461796, 'std': 0.010981548389891783}
    Policy Entropy: {'avg': 0.8194454908370972, 'std': 0.5282226204872131}
    KL Divergence: {'avg': 0.017738888040184975, 'std': 0.18011455237865448}
    Policy Grad Norm: {'avg': 5.053797036409378, 'std': 3.4837574237726745}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.11846981505619, 'std': 21.12532906942343, 'run': -75.00308016940944, 'test_avg': -74.06826596222137, 'test_std': 7.422933973871445}
    Episode Length: {'avg': 19.4478672985782, 'std': 4.6125609156302545, 'run': 19.855071179834376, 'test_avg': 19.685546875, 'test_std': 1.5138507958771017}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9301 / 10001):
    Value Loss: {'avg': 16.514627635478973, 'std': 1.0935419700728934}
    Value Grad Norm: {'avg': 286.4450117746989, 'std': 170.99618256013983}
    Policy Loss: {'avg': 0.006104183732531965, 'std': 0.006596047069069283}
    Total_Loss: {'avg': -0.08175988867878914, 'std': 0.0074133705114963495}
    Policy Entropy: {'avg': 0.8833351731300354, 'std': 0.5210360288619995}
    KL Divergence: {'avg': 0.01954483427107334, 'std': 0.1777300089597702}
    Policy Grad Norm: {'avg': 4.810327544808388, 'std': 1.8858935638817589}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.40498489451515, 'std': 23.7650960649239, 'run': -71.62212368549638, 'test_avg': -74.87912290352396, 'test_std': 7.136036303946591}
    Episode Length: {'avg': 19.045766590389015, 'std': 5.160376378382936, 'run': 19.11244155558412, 'test_avg': 19.84765625, 'test_std': 1.5136857358236344}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9401 / 10001):
    Value Loss: {'avg': 16.64402099450429, 'std': 1.25681988949066}
    Value Grad Norm: {'avg': 303.6279902458191, 'std': 192.60132973584427}
    Policy Loss: {'avg': 0.0023980029218364507, 'std': 0.006704575062844119}
    Total_Loss: {'avg': -0.09371934225782752, 'std': 0.006930808533778988}
    Policy Entropy: {'avg': 0.9472494721412659, 'std': 0.5420588850975037}
    KL Divergence: {'avg': 0.02358066476881504, 'std': 0.19230471551418304}
    Policy Grad Norm: {'avg': 3.701880432665348, 'std': 1.5594892913000933}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.93854741894697, 'std': 20.87170104576571, 'run': -75.81424895804072, 'test_avg': -74.56759733076498, 'test_std': 6.075755683733774}
    Episode Length: {'avg': 19.87409200968523, 'std': 4.573704393083516, 'run': 20.0575137931432, 'test_avg': 19.7822265625, 'test_std': 1.268779449872764}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9501 / 10001):
    Value Loss: {'avg': 20.305582125981648, 'std': 2.2273728012059255}
    Value Grad Norm: {'avg': 523.65576171875, 'std': 232.9043210279788}
    Policy Loss: {'avg': 0.0032887893612496555, 'std': 0.0045152827773553205}
    Total_Loss: {'avg': -0.08940725633874536, 'std': 0.004646384039346511}
    Policy Entropy: {'avg': 0.9577224254608154, 'std': 0.5420653820037842}
    KL Divergence: {'avg': 0.016994137316942215, 'std': 0.16578181087970734}
    Policy Grad Norm: {'avg': 3.8981787264347076, 'std': 1.5595580757676477}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.79404651518074, 'std': 23.46682586877133, 'run': -73.38694999174662, 'test_avg': -74.85962607317397, 'test_std': 6.686695917651491}
    Episode Length: {'avg': 19.211764705882352, 'std': 5.130976555707979, 'run': 19.583562341659086, 'test_avg': 19.826171875, 'test_std': 1.4062703449049134}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9601 / 10001):
    Value Loss: {'avg': 18.47319296995799, 'std': 2.2951370446906214}
    Value Grad Norm: {'avg': 325.22020228703815, 'std': 178.56305908818388}
    Policy Loss: {'avg': 0.002568963580415584, 'std': 0.004768772973027335}
    Total_Loss: {'avg': -0.08824861003085971, 'std': 0.005524733937815548}
    Policy Entropy: {'avg': 0.8879016637802124, 'std': 0.5017650127410889}
    KL Divergence: {'avg': 0.01868642307817936, 'std': 0.17266038060188293}
    Policy Grad Norm: {'avg': 3.497856453061104, 'std': 1.252978665811111}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.51699871959784, 'std': 21.145619275698234, 'run': -73.76167531364034, 'test_avg': -74.89490665062772, 'test_std': 9.168695341531683}
    Episode Length: {'avg': 19.549397590361444, 'std': 4.630110292838564, 'run': 19.56926707076047, 'test_avg': 19.80078125, 'test_std': 1.7697985449334164}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (9701 / 10001):
    Value Loss: {'avg': 18.27841281890869, 'std': 1.6889113780192329}
    Value Grad Norm: {'avg': 488.220201810201, 'std': 201.05238048371046}
    Policy Loss: {'avg': 0.0024496125988662243, 'std': 0.004148673381684287}
    Total_Loss: {'avg': -0.08400063868612051, 'std': 0.005078601813928639}
    Policy Entropy: {'avg': 0.8868832588195801, 'std': 0.5209497809410095}
    KL Divergence: {'avg': 0.021592222154140472, 'std': 0.17844322323799133}
    Policy Grad Norm: {'avg': 4.145980939269066, 'std': 1.4677218599634676}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.10687320609527, 'std': 22.120901106593436, 'run': -71.83444136999755, 'test_avg': -74.7772131043015, 'test_std': 6.495770086658835}
    Episode Length: {'avg': 19.38479809976247, 'std': 4.827096595139643, 'run': 19.12501149561331, 'test_avg': 19.78125, 'test_std': 1.371088185530019}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9801 / 10001):
    Value Loss: {'avg': 17.593108733495075, 'std': 1.623843895968657}
    Value Grad Norm: {'avg': 254.77681159973145, 'std': 131.4665931677482}
    Policy Loss: {'avg': -0.002725697217101697, 'std': 0.008652553096120157}
    Total_Loss: {'avg': -0.08791005541570485, 'std': 0.009041746368876238}
    Policy Entropy: {'avg': 0.8865868449211121, 'std': 0.5209853649139404}
    KL Divergence: {'avg': 0.016304753720760345, 'std': 0.16640804708003998}
    Policy Grad Norm: {'avg': 4.502379722893238, 'std': 2.0644052933988206}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -69.60928449803136, 'std': 24.226426340277968, 'run': -69.336771638764, 'test_avg': -74.27493883831518, 'test_std': 6.488226690531416}
    Episode Length: {'avg': 18.65366972477064, 'std': 5.263406675896553, 'run': 18.587194336381877, 'test_avg': 19.703125, 'test_std': 1.3649311738600596}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9901 / 10001):
    Value Loss: {'avg': 17.522783120473225, 'std': 1.5877123599585155}
    Value Grad Norm: {'avg': 289.39536269505817, 'std': 129.02627021517495}
    Policy Loss: {'avg': -0.0021916349651291966, 'std': 0.009967432370157731}
    Total_Loss: {'avg': -0.09148355037905276, 'std': 0.009604540894451024}
    Policy Entropy: {'avg': 0.9370332956314087, 'std': 0.5449934601783752}
    KL Divergence: {'avg': 0.0168388020247221, 'std': 0.14774538576602936}
    Policy Grad Norm: {'avg': 4.420291654765606, 'std': 1.9933077030054789}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -72.60272941356988, 'std': 23.371495589310367, 'run': -72.02536708240842, 'test_avg': -74.82929739619993, 'test_std': 7.451463221333788}
    Episode Length: {'avg': 19.31924882629108, 'std': 5.129446922117226, 'run': 19.14021636829301, 'test_avg': 19.8212890625, 'test_std': 1.5855474885092125}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (10001 / 10001):
    Value Loss: {'avg': 17.406944036483765, 'std': 1.9110802722780724}
    Value Grad Norm: {'avg': 329.6989024480184, 'std': 185.32085694664298}
    Policy Loss: {'avg': 0.0016357818385586143, 'std': 0.003950864685220162}
    Total_Loss: {'avg': -0.08845644164830446, 'std': 0.005053756741531788}
    Policy Entropy: {'avg': 0.9210463166236877, 'std': 0.5443239808082581}
    KL Divergence: {'avg': 0.01589992642402649, 'std': 0.15432113409042358}
    Policy Grad Norm: {'avg': 4.471485182642937, 'std': 1.3914950922787241}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.5577004545001, 'std': 22.122012222855503, 'run': -72.74327550012539, 'test_avg': -74.87567262540784, 'test_std': 5.992237090668517}
    Episode Length: {'avg': 19.345971563981042, 'std': 4.816413522730395, 'run': 19.410398699039643, 'test_avg': 19.8046875, 'test_std': 1.2812261811810395}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Training took 17272.457 seconds in total.
