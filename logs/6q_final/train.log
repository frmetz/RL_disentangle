
Iteration (1 / 4000):
    Value Loss: {'avg': 3639.1480812355326, 'std': 376.2032460639852}
    Value Grad Norm: {'avg': 433.0876090014422, 'std': 420.8374025566395}
    Policy Loss: {'avg': -0.00040028023154095366, 'std': 0.002907981811877689}
    Total_Loss: {'avg': -0.27079023476000186, 'std': 0.002970052309446467}
    Policy Entropy: {'avg': 2.7035887241363525, 'std': 0.007445620372891426}
    KL Divergence: {'avg': 0.0012942025205120444, 'std': 0.04924577847123146}
    Policy Grad Norm: {'avg': 0.04553682975884941, 'std': 0.04317018063250208}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -47.52531148563509, 'std': 97.34977064789801, 'run': -83.0734845450845, 'test_avg': -301.9318098110002, 'test_std': 17.045724055912338}
    Episode Length: {'avg': 12.141765114662961, 'std': 17.937135996391092, 'run': 18.547565717933463, 'test_avg': 56.8076171875, 'test_std': 2.922351329144836}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (101 / 4000):
    Value Loss: {'avg': 1182.073580819589, 'std': 121.44572370407339}
    Value Grad Norm: {'avg': 11743.964008246528, 'std': 8092.4570111117}
    Policy Loss: {'avg': -0.004637544453833942, 'std': 0.007813539210701189}
    Total_Loss: {'avg': -0.2500534991423289, 'std': 0.007649981776154141}
    Policy Entropy: {'avg': 2.444894790649414, 'std': 0.21181099116802216}
    KL Divergence: {'avg': 0.008201837539672852, 'std': 0.13879825174808502}
    Policy Grad Norm: {'avg': 0.7158422375166857, 'std': 0.19767581019000194}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -76.24849986152769, 'std': 121.28553121582245, 'run': -82.36610393725718, 'test_avg': -301.7629867490148, 'test_std': 17.0621887800988}
    Episode Length: {'avg': 17.40967987804878, 'std': 22.018220992855095, 'run': 18.689231549144502, 'test_avg': 56.857421875, 'test_std': 2.878256239161393}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (201 / 4000):
    Value Loss: {'avg': 938.0073346173322, 'std': 132.76728416754847}
    Value Grad Norm: {'avg': 24190.552759693288, 'std': 19869.163947920635}
    Policy Loss: {'avg': -0.0012793062039202561, 'std': 0.010954528805133323}
    Total_Loss: {'avg': -0.24400079482131534, 'std': 0.01057367672516208}
    Policy Entropy: {'avg': 2.4253392219543457, 'std': 0.29387226700782776}
    KL Divergence: {'avg': 0.009798377752304077, 'std': 0.16056041419506073}
    Policy Grad Norm: {'avg': 0.8277070725405657, 'std': 0.23993253259387423}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -76.25119527917192, 'std': 124.06565420282145, 'run': -71.86987866672209, 'test_avg': -300.86575841372974, 'test_std': 16.178730931158405}
    Episode Length: {'avg': 17.313807531380753, 'std': 22.429349869306524, 'run': 16.53039770730448, 'test_avg': 56.57421875, 'test_std': 2.7529031861197804}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (301 / 4000):
    Value Loss: {'avg': 693.7307759602865, 'std': 87.54195631328152}
    Value Grad Norm: {'avg': 20549.645299840857, 'std': 12348.048564965866}
    Policy Loss: {'avg': -0.0018618403399294173, 'std': 0.009542422361197978}
    Total_Loss: {'avg': -0.2439251388664599, 'std': 0.009633785749050565}
    Policy Entropy: {'avg': 2.4097976684570312, 'std': 0.33288446068763733}
    KL Divergence: {'avg': 0.010462252423167229, 'std': 0.1654280573129654}
    Policy Grad Norm: {'avg': 0.8529672684492888, 'std': 0.24950198736680154}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -75.5747402184935, 'std': 122.9107312014299, 'run': -72.26080106860802, 'test_avg': -302.1065960947496, 'test_std': 17.312711840983745}
    Episode Length: {'avg': 17.23405823811279, 'std': 22.25278136091408, 'run': 16.738854908699132, 'test_avg': 56.8486328125, 'test_std': 2.9539992234339434}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (401 / 4000):
    Value Loss: {'avg': 657.0730699327257, 'std': 95.73560474622857}
    Value Grad Norm: {'avg': 23021.096676070603, 'std': 17338.012776329248}
    Policy Loss: {'avg': -0.004738496847588707, 'std': 0.009682326501952603}
    Total_Loss: {'avg': -0.2483971037246563, 'std': 0.008967208465515523}
    Policy Entropy: {'avg': 2.414288282394409, 'std': 0.23735947906970978}
    KL Divergence: {'avg': 0.010817188769578934, 'std': 0.15993787348270416}
    Policy Grad Norm: {'avg': 0.8669282871263998, 'std': 0.21715696964622794}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -74.7215318590869, 'std': 121.79612479099471, 'run': -78.49179883304238, 'test_avg': -300.60080253211083, 'test_std': 18.373602806101083}
    Episode Length: {'avg': 17.036460311431828, 'std': 22.022297334172627, 'run': 17.709630963630225, 'test_avg': 56.607421875, 'test_std': 3.0407684950965086}
    Ratio Terminated: {'avg': 0.9996202050892518, 'test_avg': 0.9990234375}

Iteration (501 / 4000):
    Value Loss: {'avg': 633.4867144549335, 'std': 98.52056523774465}
    Value Grad Norm: {'avg': 27587.02995695891, 'std': 17996.448404216288}
    Policy Loss: {'avg': -0.0037199110517071353, 'std': 0.009563373772313262}
    Total_Loss: {'avg': -0.24353606149002358, 'std': 0.009696589040790855}
    Policy Entropy: {'avg': 2.4074361324310303, 'std': 0.2747288644313812}
    KL Divergence: {'avg': 0.011318620294332504, 'std': 0.16917192935943604}
    Policy Grad Norm: {'avg': 0.9441023199646561, 'std': 0.3355129678722613}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -73.78684868656002, 'std': 121.97650216894523, 'run': -76.95084544145801, 'test_avg': -300.893262450731, 'test_std': 16.7554036227324}
    Episode Length: {'avg': 16.82588320115357, 'std': 22.136130099882028, 'run': 17.242005512157917, 'test_avg': 56.712890625, 'test_std': 2.841102793245452}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (601 / 4000):
    Value Loss: {'avg': 444.21471738462094, 'std': 67.95643602235153}
    Value Grad Norm: {'avg': 25043.60372721354, 'std': 18107.81103357129}
    Policy Loss: {'avg': -0.0035315461698229664, 'std': 0.009402931144524193}
    Total_Loss: {'avg': -0.2371541632546319, 'std': 0.008624318614384952}
    Policy Entropy: {'avg': 2.3118786811828613, 'std': 0.34873417019844055}
    KL Divergence: {'avg': 0.016724973917007446, 'std': 0.22623853385448456}
    Policy Grad Norm: {'avg': 1.0835790406774592, 'std': 0.38478994978984826}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -73.50393701076047, 'std': 120.16932542444573, 'run': -88.48261886370918, 'test_avg': -302.33799710817675, 'test_std': 21.74022944188313}
    Episode Length: {'avg': 16.88295537673738, 'std': 21.76705954854969, 'run': 19.691631568584413, 'test_avg': 56.9130859375, 'test_std': 3.5310100372612574}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (701 / 4000):
    Value Loss: {'avg': 430.1247856987847, 'std': 61.24886234047011}
    Value Grad Norm: {'avg': 21819.31030635127, 'std': 14697.778733390176}
    Policy Loss: {'avg': -0.00437328754061902, 'std': 0.010214006940240232}
    Total_Loss: {'avg': -0.23576475591571242, 'std': 0.010045874273385672}
    Policy Entropy: {'avg': 2.286020278930664, 'std': 0.35574808716773987}
    KL Divergence: {'avg': 0.013690216466784477, 'std': 0.1786474883556366}
    Policy Grad Norm: {'avg': 1.205611068672604, 'std': 0.34811432804848463}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -76.67182739788065, 'std': 127.94309793419968, 'run': -81.50669765543968, 'test_avg': -301.8734130955432, 'test_std': 17.14443474049098}
    Episode Length: {'avg': 17.330492775101888, 'std': 23.134697483572044, 'run': 18.415177187351265, 'test_avg': 56.80078125, 'test_std': 2.923396892255384}
    Ratio Terminated: {'avg': 0.9996294924045943, 'test_avg': 1.0}

Iteration (801 / 4000):
    Value Loss: {'avg': 448.58153528284146, 'std': 71.17487807546979}
    Value Grad Norm: {'avg': 32672.11228660301, 'std': 19167.640696429495}
    Policy Loss: {'avg': -0.0021249103359878064, 'std': 0.010286039475522554}
    Total_Loss: {'avg': -0.23690079119470384, 'std': 0.00950098558667518}
    Policy Entropy: {'avg': 2.361931085586548, 'std': 0.3155480623245239}
    KL Divergence: {'avg': 0.013910483568906784, 'std': 0.1867877095937729}
    Policy Grad Norm: {'avg': 1.1619226764749597, 'std': 0.34111890708652925}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -79.72730235849075, 'std': 127.92241444121959, 'run': -72.64038622984711, 'test_avg': -300.61625018543975, 'test_std': 16.579812922609587}
    Episode Length: {'avg': 17.97975866095757, 'std': 23.191041909629085, 'run': 16.41255229727784, 'test_avg': 56.6318359375, 'test_std': 2.8353588680418387}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (901 / 4000):
    Value Loss: {'avg': 352.61216046368634, 'std': 60.188296889547836}
    Value Grad Norm: {'avg': 22509.77528030961, 'std': 16160.984527860537}
    Policy Loss: {'avg': -0.005519848596304655, 'std': 0.009612493454379225}
    Total_Loss: {'avg': -0.23460626513869673, 'std': 0.009329715071127348}
    Policy Entropy: {'avg': 2.273930311203003, 'std': 0.2784268260002136}
    KL Divergence: {'avg': 0.011589243076741695, 'std': 0.15765972435474396}
    Policy Grad Norm: {'avg': 1.2927698656364723, 'std': 0.4212923264323487}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -73.62823131051763, 'std': 120.37414769495932, 'run': -62.95229673731357, 'test_avg': -300.8635213770575, 'test_std': 16.88973930280828}
    Episode Length: {'avg': 16.875186289120716, 'std': 21.779763945317026, 'run': 14.882478296852518, 'test_avg': 56.58203125, 'test_std': 2.867706335039109}
    Ratio Terminated: {'avg': 0.9996274217585693, 'test_avg': 1.0}

Iteration (1001 / 4000):
    Value Loss: {'avg': 292.95852412471066, 'std': 45.40924077029555}
    Value Grad Norm: {'avg': 26876.91719563802, 'std': 15014.919385234689}
    Policy Loss: {'avg': -0.0003565013977802462, 'std': 0.007571782616042482}
    Total_Loss: {'avg': -0.2242193682326211, 'std': 0.007130498735280191}
    Policy Entropy: {'avg': 2.1529064178466797, 'std': 0.365357905626297}
    KL Divergence: {'avg': 0.015348982997238636, 'std': 0.17831631004810333}
    Policy Grad Norm: {'avg': 1.498039232359992, 'std': 0.4883262309353887}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -72.23763145956602, 'std': 121.11281029334684, 'run': -63.867709142893055, 'test_avg': -301.34803876226863, 'test_std': 17.78590027814099}
    Episode Length: {'avg': 16.541756659467243, 'std': 21.95442999674968, 'run': 14.882293597673666, 'test_avg': 56.72265625, 'test_std': 3.0367595507935654}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 4000):
    Value Loss: {'avg': 248.77874620225694, 'std': 37.64807998328999}
    Value Grad Norm: {'avg': 22948.003584346065, 'std': 14527.342387846993}
    Policy Loss: {'avg': -0.004727842789833192, 'std': 0.009797724014481566}
    Total_Loss: {'avg': -0.22431203226248422, 'std': 0.009510232331733339}
    Policy Entropy: {'avg': 2.213850498199463, 'std': 0.332631915807724}
    KL Divergence: {'avg': 0.014229112304747105, 'std': 0.17319902777671814}
    Policy Grad Norm: {'avg': 1.5944718091576189, 'std': 0.59932674002321}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -73.65252207867573, 'std': 122.49411535491622, 'run': -80.10686057151935, 'test_avg': -299.7513281248307, 'test_std': 16.183058095259007}
    Episode Length: {'avg': 16.83798477709315, 'std': 22.1758645090872, 'run': 18.12074473714037, 'test_avg': 56.482421875, 'test_std': 2.756328583373449}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 4000):
    Value Loss: {'avg': 224.48642713758682, 'std': 49.70888146006063}
    Value Grad Norm: {'avg': 20879.882741970487, 'std': 18994.243340151836}
    Policy Loss: {'avg': -0.003931637335982587, 'std': 0.009912262438013611}
    Total_Loss: {'avg': -0.2200486810119064, 'std': 0.009166210794093792}
    Policy Entropy: {'avg': 2.2100560665130615, 'std': 0.3163752853870392}
    KL Divergence: {'avg': 0.01500706933438778, 'std': 0.18228642642498016}
    Policy Grad Norm: {'avg': 1.8358273616543523, 'std': 0.6054656488507079}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -70.89785966839658, 'std': 118.71782951525579, 'run': -70.64972334412452, 'test_avg': -298.88525045906556, 'test_std': 17.028753349979013}
    Episode Length: {'avg': 16.36896675008938, 'std': 21.611127663036, 'run': 16.244783134012344, 'test_avg': 56.3837890625, 'test_std': 2.907790401319423}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 4000):
    Value Loss: {'avg': 223.3898846661603, 'std': 36.84180759051131}
    Value Grad Norm: {'avg': 16801.31085792824, 'std': 9679.36799489391}
    Policy Loss: {'avg': -0.006297221997131904, 'std': 0.008909111482847978}
    Total_Loss: {'avg': -0.22591628984168724, 'std': 0.008992385479111183}
    Policy Entropy: {'avg': 2.1807861328125, 'std': 0.3286972939968109}
    KL Divergence: {'avg': 0.016727615147829056, 'std': 0.17815637588500977}
    Policy Grad Norm: {'avg': 1.5380372921625773, 'std': 0.5097230135874278}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -71.60150337757494, 'std': 118.94500833764624, 'run': -79.42064081182421, 'test_avg': -298.578570032626, 'test_std': 15.859189024899452}
    Episode Length: {'avg': 16.47318496898942, 'std': 21.557414063211468, 'run': 17.78380347053601, 'test_avg': 56.306640625, 'test_std': 2.676524617316196}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 4000):
    Value Loss: {'avg': 205.0634408456308, 'std': 53.01145810290682}
    Value Grad Norm: {'avg': 20211.923489945024, 'std': 16411.262076099927}
    Policy Loss: {'avg': -0.004635915091192281, 'std': 0.009914445099332814}
    Total_Loss: {'avg': -0.21727368930975596, 'std': 0.00996748673241498}
    Policy Entropy: {'avg': 2.1128768920898438, 'std': 0.2910594642162323}
    KL Divergence: {'avg': 0.01385213527828455, 'std': 0.16824933886528015}
    Policy Grad Norm: {'avg': 1.70691776893757, 'std': 0.5528672904110649}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -72.05208172618302, 'std': 119.87721511936307, 'run': -72.1791709244644, 'test_avg': -298.9833997267932, 'test_std': 18.601154013224885}
    Episode Length: {'avg': 16.568990042674255, 'std': 21.765869244923312, 'run': 16.335911743154416, 'test_avg': 56.44140625, 'test_std': 3.0927214791282025}
    Ratio Terminated: {'avg': 0.9996443812233285, 'test_avg': 0.9990234375}

Iteration (1501 / 4000):
    Value Loss: {'avg': 169.42485741509333, 'std': 30.16037469263189}
    Value Grad Norm: {'avg': 13643.782268156829, 'std': 8432.900741427276}
    Policy Loss: {'avg': -0.0035790926604359237, 'std': 0.0093929311346154}
    Total_Loss: {'avg': -0.215011626040494, 'std': 0.008942181611063681}
    Policy Entropy: {'avg': 2.1014485359191895, 'std': 0.358805775642395}
    KL Divergence: {'avg': 0.013512623496353626, 'std': 0.23132021725177765}
    Policy Grad Norm: {'avg': 1.9200203555601614, 'std': 0.6105025631139895}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -73.5392330422963, 'std': 123.73261262734916, 'run': -52.959099511159636, 'test_avg': -299.2688822579794, 'test_std': 16.373337647548972}
    Episode Length: {'avg': 16.827573794096473, 'std': 22.37675957942776, 'run': 13.35698026782175, 'test_avg': 56.373046875, 'test_std': 2.781688184188288}
    Ratio Terminated: {'avg': 0.9996400287976962, 'test_avg': 1.0}

Iteration (1601 / 4000):
    Value Loss: {'avg': 192.5752107973452, 'std': 59.90854353680306}
    Value Grad Norm: {'avg': 9515.255759006077, 'std': 6919.723511114128}
    Policy Loss: {'avg': -0.002536824635333485, 'std': 0.01159982572545347}
    Total_Loss: {'avg': -0.21004858646127914, 'std': 0.010991312784597869}
    Policy Entropy: {'avg': 2.0636401176452637, 'std': 0.37887564301490784}
    KL Divergence: {'avg': 0.013382374309003353, 'std': 0.16318047046661377}
    Policy Grad Norm: {'avg': 1.9574618679505806, 'std': 0.6493731501305072}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -75.13464275217996, 'std': 121.67206860546278, 'run': -82.817766282215, 'test_avg': -298.86273676781997, 'test_std': 16.03000185441079}
    Episode Length: {'avg': 17.277216174183515, 'std': 22.090329059873383, 'run': 18.727122621243453, 'test_avg': 56.3330078125, 'test_std': 2.6942945244189556}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 4000):
    Value Loss: {'avg': 160.50642231128833, 'std': 24.582063898567117}
    Value Grad Norm: {'avg': 14300.804370117188, 'std': 10902.878523274396}
    Policy Loss: {'avg': -0.002714893586623172, 'std': 0.008696283783492362}
    Total_Loss: {'avg': -0.21064403454462688, 'std': 0.008615088866904628}
    Policy Entropy: {'avg': 2.078667402267456, 'std': 0.3400703966617584}
    KL Divergence: {'avg': 0.01876337267458439, 'std': 0.1801685094833374}
    Policy Grad Norm: {'avg': 2.1744733267360266, 'std': 0.7601441371045516}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -74.70581210071416, 'std': 125.46314940944292, 'run': -69.27333465522281, 'test_avg': -301.8112551138805, 'test_std': 22.378477332880408}
    Episode Length: {'avg': 16.959709618874772, 'std': 22.664863055808354, 'run': 16.016321683601358, 'test_avg': 56.7109375, 'test_std': 3.634475425848103}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (1801 / 4000):
    Value Loss: {'avg': 135.78909239592375, 'std': 23.19429375157113}
    Value Grad Norm: {'avg': 7885.474040617766, 'std': 5025.564806271021}
    Policy Loss: {'avg': 0.00660210560179419, 'std': 0.006072152570253233}
    Total_Loss: {'avg': -0.19410899248388078, 'std': 0.005246320889761839}
    Policy Entropy: {'avg': 2.001816511154175, 'std': 0.37107744812965393}
    KL Divergence: {'avg': 0.016707424074411392, 'std': 0.19641253352165222}
    Policy Grad Norm: {'avg': 2.0978714333640203, 'std': 0.5243349625178366}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -72.10238225775174, 'std': 119.87689661065143, 'run': -72.28352107235753, 'test_avg': -300.37067001924095, 'test_std': 17.25723524804807}
    Episode Length: {'avg': 16.650344577439245, 'std': 21.77473064157425, 'run': 16.766071285242397, 'test_avg': 56.58984375, 'test_std': 2.9187791712608093}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 4000):
    Value Loss: {'avg': 136.38457183837892, 'std': 21.23289062954506}
    Value Grad Norm: {'avg': 8824.838110351562, 'std': 6141.8755505848085}
    Policy Loss: {'avg': -0.0011088256258517503, 'std': 0.008001522235045069}
    Total_Loss: {'avg': -0.2005685622493426, 'std': 0.007563964382837253}
    Policy Entropy: {'avg': 2.016129970550537, 'std': 0.292706698179245}
    KL Divergence: {'avg': 0.018431194126605988, 'std': 0.16600044071674347}
    Policy Grad Norm: {'avg': 2.3452644652790493, 'std': 0.7514285158645052}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -75.46099174504276, 'std': 123.09344825574738, 'run': -84.13653961839026, 'test_avg': -299.5403758069543, 'test_std': 17.467542759150295}
    Episode Length: {'avg': 17.155127730470195, 'std': 22.211963994545304, 'run': 18.768024757423476, 'test_avg': 56.3701171875, 'test_std': 2.9591498703203745}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 4000):
    Value Loss: {'avg': 140.87019517686633, 'std': 21.473056325804727}
    Value Grad Norm: {'avg': 9995.359710467303, 'std': 7872.819764440188}
    Policy Loss: {'avg': -0.0023190120338565773, 'std': 0.008747640588953687}
    Total_Loss: {'avg': -0.19812513308392632, 'std': 0.009444128556161177}
    Policy Entropy: {'avg': 1.9553308486938477, 'std': 0.4885586202144623}
    KL Divergence: {'avg': 0.01667024940252304, 'std': 0.18253418803215027}
    Policy Grad Norm: {'avg': 2.410594579908583, 'std': 0.7470452954019261}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -73.22334790974584, 'std': 119.6058581435591, 'run': -73.4331000784536, 'test_avg': -300.8111421738647, 'test_std': 16.74111183673809}
    Episode Length: {'avg': 16.844444444444445, 'std': 21.734344443646364, 'run': 16.81847678313653, 'test_avg': 56.669921875, 'test_std': 2.8628195771645277}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 4000):
    Value Loss: {'avg': 138.57148126672814, 'std': 16.710524341594546}
    Value Grad Norm: {'avg': 7813.8558973524305, 'std': 4702.689935834934}
    Policy Loss: {'avg': -0.005291376373282185, 'std': 0.010380971128580602}
    Total_Loss: {'avg': -0.20716347804775945, 'std': 0.010446591617824753}
    Policy Entropy: {'avg': 2.000589609146118, 'std': 0.40117916464805603}
    KL Divergence: {'avg': 0.010657236911356449, 'std': 0.16022461652755737}
    Policy Grad Norm: {'avg': 2.5972875127085935, 'std': 0.9755985835533215}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -71.29401885500289, 'std': 120.79683110535895, 'run': -63.62848727641193, 'test_avg': -299.11334492932735, 'test_std': 17.91431549137651}
    Episode Length: {'avg': 16.38383102694829, 'std': 21.921576454215554, 'run': 15.053548928140518, 'test_avg': 56.365234375, 'test_std': 2.9701316429273565}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2201 / 4000):
    Value Loss: {'avg': 127.89500885009765, 'std': 17.706222689223207}
    Value Grad Norm: {'avg': 5573.672463650174, 'std': 3093.441868527766}
    Policy Loss: {'avg': -0.0074714534019154535, 'std': 0.011612439906787179}
    Total_Loss: {'avg': -0.20480964294186346, 'std': 0.010831795017731736}
    Policy Entropy: {'avg': 1.9552927017211914, 'std': 0.41989532113075256}
    KL Divergence: {'avg': 0.01445283368229866, 'std': 0.1671646237373352}
    Policy Grad Norm: {'avg': 2.2453662594159445, 'std': 0.6498460269076491}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -73.26178206678918, 'std': 121.09850657193307, 'run': -79.22070504718153, 'test_avg': -298.7554258290012, 'test_std': 16.957940174097327}
    Episode Length: {'avg': 16.759292674124865, 'std': 21.966843294736034, 'run': 17.744617911698544, 'test_avg': 56.287109375, 'test_std': 2.8979366723217246}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 4000):
    Value Loss: {'avg': 153.7471060293692, 'std': 27.255873906345236}
    Value Grad Norm: {'avg': 7413.930357530382, 'std': 5229.166813853964}
    Policy Loss: {'avg': -0.0010210030091305573, 'std': 0.008350284222748127}
    Total_Loss: {'avg': -0.1979185735185941, 'std': 0.00877419179723442}
    Policy Entropy: {'avg': 1.918487548828125, 'std': 0.493857204914093}
    KL Divergence: {'avg': 0.017335759475827217, 'std': 0.18702629208564758}
    Policy Grad Norm: {'avg': 2.335445561673906, 'std': 0.8066225895413244}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -73.30744587820227, 'std': 122.74684086405196, 'run': -72.40934237450819, 'test_avg': -299.5038398657525, 'test_std': 17.08634078704666}
    Episode Length: {'avg': 16.737033006891547, 'std': 22.216679099831296, 'run': 16.591306011697377, 'test_avg': 56.396484375, 'test_std': 2.9213364048635104}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2401 / 4000):
    Value Loss: {'avg': 186.8045777497468, 'std': 44.02560047776251}
    Value Grad Norm: {'avg': 7617.737232349537, 'std': 5366.615761603125}
    Policy Loss: {'avg': 0.006505303938562672, 'std': 0.00956644011426032}
    Total_Loss: {'avg': -0.19035911526944901, 'std': 0.007469614808494254}
    Policy Entropy: {'avg': 1.97284996509552, 'std': 0.4448730945587158}
    KL Divergence: {'avg': 0.015005274675786495, 'std': 0.1783052384853363}
    Policy Grad Norm: {'avg': 2.5323035346137153, 'std': 1.0639105780732}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -73.83771022314771, 'std': 120.5754599954852, 'run': -96.11502259940237, 'test_avg': -298.45733760165103, 'test_std': 18.300632581196634}
    Episode Length: {'avg': 16.95593726661688, 'std': 21.87756002813643, 'run': 21.19600479737975, 'test_avg': 56.228515625, 'test_std': 3.0421080247306898}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2501 / 4000):
    Value Loss: {'avg': 156.60099509910302, 'std': 19.898313882375483}
    Value Grad Norm: {'avg': 8027.152114981192, 'std': 5759.294545546348}
    Policy Loss: {'avg': -0.0029488566348812094, 'std': 0.01006428996302608}
    Total_Loss: {'avg': -0.19037214705237634, 'std': 0.010059369889502089}
    Policy Entropy: {'avg': 1.9327609539031982, 'std': 0.46042874455451965}
    KL Divergence: {'avg': 0.017786983400583267, 'std': 0.19910527765750885}
    Policy Grad Norm: {'avg': 3.1386813561121625, 'std': 1.1394436019032308}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -76.42143149139163, 'std': 123.83376477956232, 'run': -76.0504252278204, 'test_avg': -299.7180034204937, 'test_std': 17.23578236439943}
    Episode Length: {'avg': 17.376773711725168, 'std': 22.395294796529836, 'run': 17.5465048307643, 'test_avg': 56.400390625, 'test_std': 2.9278164598232777}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 4000):
    Value Loss: {'avg': 138.96130568892866, 'std': 22.040300461723277}
    Value Grad Norm: {'avg': 5360.391696506076, 'std': 3658.3626674964758}
    Policy Loss: {'avg': 0.006446227276076873, 'std': 0.007783128171783445}
    Total_Loss: {'avg': -0.18284838696320851, 'std': 0.006549021970441695}
    Policy Entropy: {'avg': 1.9206668138504028, 'std': 0.47345244884490967}
    KL Divergence: {'avg': 0.015447393991053104, 'std': 0.18369942903518677}
    Policy Grad Norm: {'avg': 2.9323818233278063, 'std': 0.9137585104822008}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -73.67191580447778, 'std': 122.22183938897724, 'run': -74.76166902141571, 'test_avg': -299.574500803396, 'test_std': 16.786552283163434}
    Episode Length: {'avg': 16.837468536497664, 'std': 22.118185831407388, 'run': 16.836738297254534, 'test_avg': 56.4501953125, 'test_std': 2.866744254045524}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 4000):
    Value Loss: {'avg': 140.4164862173575, 'std': 18.610036749002322}
    Value Grad Norm: {'avg': 5989.076989293982, 'std': 3560.87221239443}
    Policy Loss: {'avg': -0.0036396741177196854, 'std': 0.009955348999725918}
    Total_Loss: {'avg': -0.18917548292213016, 'std': 0.010201366124409406}
    Policy Entropy: {'avg': 1.878056287765503, 'std': 0.5168825387954712}
    KL Divergence: {'avg': 0.013354684226214886, 'std': 0.16949263215065002}
    Policy Grad Norm: {'avg': 2.8017358788737545, 'std': 0.9413521580989894}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -81.1101020686564, 'std': 127.3841277779217, 'run': -80.23542891968151, 'test_avg': -298.6857217939831, 'test_std': 16.621262892883703}
    Episode Length: {'avg': 18.13750985027581, 'std': 23.012596415857868, 'run': 18.000163822930713, 'test_avg': 56.30859375, 'test_std': 2.8357518663417887}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 4000):
    Value Loss: {'avg': 172.979372660319, 'std': 25.4119764596688}
    Value Grad Norm: {'avg': 7754.125557906539, 'std': 5019.73315814599}
    Policy Loss: {'avg': -0.00022713607177138329, 'std': 0.008459413301410097}
    Total_Loss: {'avg': -0.19236771845155293, 'std': 0.009026343316798333}
    Policy Entropy: {'avg': 1.9538626670837402, 'std': 0.5028359293937683}
    KL Divergence: {'avg': 0.019444651901721954, 'std': 0.19614802300930023}
    Policy Grad Norm: {'avg': 2.8124012185467615, 'std': 1.491358008529884}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -72.18993663912052, 'std': 120.87031442686582, 'run': -73.84925211463572, 'test_avg': -298.77517828433884, 'test_std': 18.131525461461322}
    Episode Length: {'avg': 16.542764345001803, 'std': 21.89171278290374, 'run': 16.94891804506561, 'test_avg': 56.2666015625, 'test_std': 3.0016625883620827}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2901 / 4000):
    Value Loss: {'avg': 127.99820720531322, 'std': 18.13654387628782}
    Value Grad Norm: {'avg': 5279.05129937066, 'std': 2810.381506011955}
    Policy Loss: {'avg': 0.004055925965723064, 'std': 0.006392078284772874}
    Total_Loss: {'avg': -0.17981957329644097, 'std': 0.006938681767222257}
    Policy Entropy: {'avg': 1.7914397716522217, 'std': 0.5389619469642639}
    KL Divergence: {'avg': 0.016014592722058296, 'std': 0.19310100376605988}
    Policy Grad Norm: {'avg': 2.647780746883816, 'std': 0.7076600826894123}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -78.86649042024025, 'std': 125.90647758806796, 'run': -79.11813560461383, 'test_avg': -298.95461409710083, 'test_std': 18.238842706094925}
    Episode Length: {'avg': 17.893880712625872, 'std': 22.755587862670147, 'run': 18.034548652791436, 'test_avg': 56.3134765625, 'test_std': 3.0382287615094397}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3001 / 4000):
    Value Loss: {'avg': 158.67944912380642, 'std': 22.497403532475893}
    Value Grad Norm: {'avg': 6210.740069806135, 'std': 3252.4141746082814}
    Policy Loss: {'avg': 0.0026880837769971953, 'std': 0.006209070824529555}
    Total_Loss: {'avg': -0.1850290166007148, 'std': 0.005387816831610636}
    Policy Entropy: {'avg': 1.8361181020736694, 'std': 0.5333572626113892}
    KL Divergence: {'avg': 0.0212290920317173, 'std': 0.2333546131849289}
    Policy Grad Norm: {'avg': 3.1318586826324464, 'std': 1.371922654799344}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -73.31963178479158, 'std': 121.83506982055577, 'run': -78.29556972150394, 'test_avg': -298.85483193625583, 'test_std': 17.876772614614474}
    Episode Length: {'avg': 16.70990391722099, 'std': 22.156662474490744, 'run': 17.42653096854263, 'test_avg': 56.408203125, 'test_std': 2.9585963029349296}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3101 / 4000):
    Value Loss: {'avg': 129.53308664957683, 'std': 17.340828148167166}
    Value Grad Norm: {'avg': 4754.9708251953125, 'std': 2635.888260460597}
    Policy Loss: {'avg': 0.0066973376812206374, 'std': 0.010333441495529963}
    Total_Loss: {'avg': -0.17866306338045332, 'std': 0.009596498747347531}
    Policy Entropy: {'avg': 1.8750529289245605, 'std': 0.4849720001220703}
    KL Divergence: {'avg': 0.01778574474155903, 'std': 0.17416463792324066}
    Policy Grad Norm: {'avg': 2.3890971236758762, 'std': 0.9109675226042516}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -73.8572196492589, 'std': 121.70023764298155, 'run': -71.52277430274826, 'test_avg': -298.6780501979779, 'test_std': 18.418209637529063}
    Episode Length: {'avg': 16.89263466471235, 'std': 22.085492486347565, 'run': 16.283548199503354, 'test_avg': 56.291015625, 'test_std': 3.05727828811933}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3201 / 4000):
    Value Loss: {'avg': 176.32692633734808, 'std': 22.193872247488184}
    Value Grad Norm: {'avg': 5150.236107494213, 'std': 2505.3261442699186}
    Policy Loss: {'avg': -0.005294457916170359, 'std': 0.009777458540227532}
    Total_Loss: {'avg': -0.19974235362476772, 'std': 0.009553157071011347}
    Policy Entropy: {'avg': 1.9928678274154663, 'std': 0.46339309215545654}
    KL Divergence: {'avg': 0.014529315754771233, 'std': 0.17683957517147064}
    Policy Grad Norm: {'avg': 2.99864630345945, 'std': 1.5596764822769804}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -67.5030439796258, 'std': 116.76082452893037, 'run': -63.29944961835044, 'test_avg': -298.8965377032589, 'test_std': 16.028181390786923}
    Episode Length: {'avg': 15.811731647348086, 'std': 21.15327083300974, 'run': 14.7723428916777, 'test_avg': 56.294921875, 'test_std': 2.7205334656361946}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 4000):
    Value Loss: {'avg': 140.1832955819589, 'std': 21.96382624076183}
    Value Grad Norm: {'avg': 4592.335345232928, 'std': 2249.53035988275}
    Policy Loss: {'avg': 0.0015321009068025482, 'std': 0.009330565542258352}
    Total_Loss: {'avg': -0.19297376688983706, 'std': 0.008878031927348418}
    Policy Entropy: {'avg': 1.9990054368972778, 'std': 0.4503389596939087}
    KL Divergence: {'avg': 0.015830278396606445, 'std': 0.18663935363292694}
    Policy Grad Norm: {'avg': 3.004184134138955, 'std': 1.5997118206209007}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -76.23914568696128, 'std': 123.85249384259939, 'run': -66.13693187104488, 'test_avg': -297.5138720810953, 'test_std': 18.169035123791677}
    Episode Length: {'avg': 17.27160968113715, 'std': 22.363831970172335, 'run': 15.336456991129957, 'test_avg': 56.09375, 'test_std': 2.9782741961579022}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3401 / 4000):
    Value Loss: {'avg': 119.65201732494214, 'std': 18.04236744419042}
    Value Grad Norm: {'avg': 5781.661875180845, 'std': 4713.084330355417}
    Policy Loss: {'avg': 0.0036952279922035005, 'std': 0.007550754913108323}
    Total_Loss: {'avg': -0.17408299181196424, 'std': 0.008150381567407381}
    Policy Entropy: {'avg': 1.764510989189148, 'std': 0.5615777969360352}
    KL Divergence: {'avg': 0.015289515256881714, 'std': 0.18323814868927002}
    Policy Grad Norm: {'avg': 3.0204433812035454, 'std': 1.6345314718963313}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -77.64379315746457, 'std': 126.66414250652518, 'run': -82.1982936077427, 'test_avg': -298.1339456573695, 'test_std': 15.942143647566999}
    Episode Length: {'avg': 17.463660081997762, 'std': 22.89024198443192, 'run': 18.518685084496983, 'test_avg': 56.1064453125, 'test_std': 2.6960977046366064}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 4000):
    Value Loss: {'avg': 134.1810188010887, 'std': 20.24917944127645}
    Value Grad Norm: {'avg': 6682.531009024161, 'std': 3430.539755491146}
    Policy Loss: {'avg': 0.006090206342438857, 'std': 0.0063660583760588385}
    Total_Loss: {'avg': -0.1809882915682263, 'std': 0.005995893379752675}
    Policy Entropy: {'avg': 1.852658987045288, 'std': 0.4682367146015167}
    KL Divergence: {'avg': 0.01551148109138012, 'std': 0.1666249781847}
    Policy Grad Norm: {'avg': 3.3042491965823704, 'std': 1.9653217537388579}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -70.50995273467443, 'std': 119.03531608196535, 'run': -86.09070324041002, 'test_avg': -298.4126341034918, 'test_std': 16.634162982597925}
    Episode Length: {'avg': 16.315959741193385, 'std': 21.60445403151436, 'run': 19.214779616596733, 'test_avg': 56.22265625, 'test_std': 2.847908082143091}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3601 / 4000):
    Value Loss: {'avg': 119.92597729718244, 'std': 16.853269533633917}
    Value Grad Norm: {'avg': 5350.141871473525, 'std': 3204.0597504310226}
    Policy Loss: {'avg': 0.005161672251092063, 'std': 0.005552702049175966}
    Total_Loss: {'avg': -0.1773282915353775, 'std': 0.005681846949847595}
    Policy Entropy: {'avg': 1.8074405193328857, 'std': 0.48953354358673096}
    KL Divergence: {'avg': 0.016067976132035255, 'std': 0.16047824919223785}
    Policy Grad Norm: {'avg': 2.478857398033142, 'std': 0.5998745283455296}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -78.11110098319334, 'std': 123.958746604955, 'run': -83.12302297094104, 'test_avg': -297.4566567555063, 'test_std': 15.995006372524955}
    Episode Length: {'avg': 17.65551330798479, 'std': 22.395952029821512, 'run': 18.630115973618214, 'test_avg': 56.06640625, 'test_std': 2.738164227171361}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3701 / 4000):
    Value Loss: {'avg': 129.6459008110894, 'std': 16.98546923782191}
    Value Grad Norm: {'avg': 3874.3015073423035, 'std': 1997.287271647421}
    Policy Loss: {'avg': 0.0019296778107268943, 'std': 0.009050947522083923}
    Total_Loss: {'avg': -0.1776484527521663, 'std': 0.008985937984242786}
    Policy Entropy: {'avg': 1.8085120916366577, 'std': 0.5265792012214661}
    KL Divergence: {'avg': 0.01669972762465477, 'std': 0.18318291008472443}
    Policy Grad Norm: {'avg': 4.1834594594107735, 'std': 4.11621530067089}
    Num PPO updates: {'avg': 90}
    Return: {'avg': -72.23018716842978, 'std': 121.0087622170593, 'run': -52.10137600102946, 'test_avg': -297.90969639304063, 'test_std': 17.948396337804738}
    Episode Length: {'avg': 16.646757053865883, 'std': 21.909215679630464, 'run': 12.870471109848582, 'test_avg': 56.1787109375, 'test_std': 2.963366154108849}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3801 / 4000):
    Value Loss: {'avg': 129.56463990388093, 'std': 20.146224281646383}
    Value Grad Norm: {'avg': 4986.071227575231, 'std': 2558.443069515776}
    Policy Loss: {'avg': 0.008290124343087275, 'std': 0.006108000940742773}
    Total_Loss: {'avg': -0.169968577226003, 'std': 0.006727010045107502}
    Policy Entropy: {'avg': 1.751476764678955, 'std': 0.5133870244026184}
    KL Divergence: {'avg': 0.01701391488313675, 'std': 0.17906281352043152}
    Policy Grad Norm: {'avg': 3.1357423014110988, 'std': 1.0896256355566367}
    Num PPO updates: {'avg': 45}
    Return: {'avg': -74.42522043912008, 'std': 123.62225979449919, 'run': -72.49135027984445, 'test_avg': -298.74411163388856, 'test_std': 16.86375174144615}
    Episode Length: {'avg': 16.944322344322345, 'std': 22.37570910326902, 'run': 16.821706271194724, 'test_avg': 56.3798828125, 'test_std': 2.85407219797732}
    Ratio Terminated: {'avg': 0.9992673992673993, 'test_avg': 1.0}

Iteration (3901 / 4000):
    Value Loss: {'avg': 111.25749602141204, 'std': 18.87438667383961}
    Value Grad Norm: {'avg': 3595.055050998264, 'std': 1519.173353759348}
    Policy Loss: {'avg': -0.006810805184283742, 'std': 0.011133830083543819}
    Total_Loss: {'avg': -0.18599243307555163, 'std': 0.01055457701960052}
    Policy Entropy: {'avg': 1.769775629043579, 'std': 0.5217330455780029}
    KL Divergence: {'avg': 0.015904057770967484, 'std': 0.18195365369319916}
    Policy Grad Norm: {'avg': 3.0186930117783723, 'std': 1.1282605399401089}
    Num PPO updates: {'avg': 135}
    Return: {'avg': -76.68746187098138, 'std': 124.45613678673506, 'run': -84.03975613608544, 'test_avg': -297.9244917293374, 'test_std': 16.584853133029892}
    Episode Length: {'avg': 17.37101669195751, 'std': 22.527265099567366, 'run': 18.716499516291556, 'test_avg': 56.08984375, 'test_std': 2.7890925899987504}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Training took 161238.517 seconds in total.
