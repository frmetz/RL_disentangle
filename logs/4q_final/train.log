
Iteration (1 / 4000):
    Value Loss: {'avg': 59.99036852518717, 'std': 7.337767018392657}
    Value Grad Norm: {'avg': 29.159387747446697, 'std': 2.451975536795317}
    Policy Loss: {'avg': -0.016570610615114372, 'std': 0.01120889719653703}
    Total_Loss: {'avg': -0.19250949720541635, 'std': 0.010491854652861511}
    Policy Entropy: {'avg': 1.7518270015716553, 'std': 0.055656179785728455}
    KL Divergence: {'avg': 0.013851141557097435, 'std': 0.15622231364250183}
    Policy Grad Norm: {'avg': 0.4130570913354556, 'std': 0.06580300181095994}
    Num PPO updates: {'avg': 12}
    Return: {'avg': -2.9569113468155455, 'std': 4.710634688332056, 'run': -1.8428083759531382, 'test_avg': -41.05271997821194, 'test_std': 18.465847437098475}
    Episode Length: {'avg': 2.9577464788732395, 'std': 2.5311391396321423, 'run': 2.19212728072507, 'test_avg': 13.931640625, 'test_std': 3.908526192294176}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.2412109375}

Iteration (101 / 4000):
    Value Loss: {'avg': 17.888949712117512, 'std': 1.9507739005606508}
    Value Grad Norm: {'avg': 19.365074078241985, 'std': 4.743946771838957}
    Policy Loss: {'avg': -0.0048546078614890575, 'std': 0.006166268731526486}
    Total_Loss: {'avg': -0.1120811179280281, 'std': 0.006093752801059397}
    Policy Entropy: {'avg': 1.0817099809646606, 'std': 0.48490163683891296}
    KL Divergence: {'avg': 0.021771326661109924, 'std': 0.20762421190738678}
    Policy Grad Norm: {'avg': 3.8063566088676453, 'std': 0.6412966980157352}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -3.329318326286413, 'std': 7.028093672599861, 'run': -3.4229548991421965, 'test_avg': -13.178948191957815, 'test_std': 5.861155783098527}
    Episode Length: {'avg': 3.223684210526316, 'std': 2.7725092387987416, 'run': 3.2689476493344904, 'test_avg': 7.2890625, 'test_std': 1.9824517008224312}
    Ratio Terminated: {'avg': 0.993421052631579, 'test_avg': 1.0}

Iteration (201 / 4000):
    Value Loss: {'avg': 13.556373516718546, 'std': 1.7799112177319856}
    Value Grad Norm: {'avg': 30.182912190755207, 'std': 9.619854079692232}
    Policy Loss: {'avg': -0.0004931364674121141, 'std': 0.0060434325284704675}
    Total_Loss: {'avg': -0.09309399779886007, 'std': 0.007054951335417664}
    Policy Entropy: {'avg': 1.0589306354522705, 'std': 0.48264428973197937}
    KL Divergence: {'avg': 0.030760768800973892, 'std': 0.2355043888092041}
    Policy Grad Norm: {'avg': 4.518581181764603, 'std': 1.797001007205217}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -3.4558034459091442, 'std': 7.228170302139552, 'run': -3.7496354418284605, 'test_avg': -12.104565523463254, 'test_std': 5.977004462809555}
    Episode Length: {'avg': 3.4014084507042255, 'std': 2.7579842076244834, 'run': 3.4648866621508128, 'test_avg': 6.90625, 'test_std': 2.0651025246945975}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (301 / 4000):
    Value Loss: {'avg': 11.056433518727621, 'std': 2.230823067962346}
    Value Grad Norm: {'avg': 22.495517174402874, 'std': 6.207265006112786}
    Policy Loss: {'avg': -0.007184043992310762, 'std': 0.005331591340462624}
    Total_Loss: {'avg': -0.0844473596662283, 'std': 0.0052069395850591555}
    Policy Entropy: {'avg': 0.7820176482200623, 'std': 0.5189329981803894}
    KL Divergence: {'avg': 0.04148184508085251, 'std': 0.26841551065444946}
    Policy Grad Norm: {'avg': 2.1759417355060577, 'std': 0.2801965006534305}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.853932070023856, 'std': 5.991227680557696, 'run': -1.5629355469891748, 'test_avg': -10.915155251050825, 'test_std': 5.3269285256290875}
    Episode Length: {'avg': 2.727272727272727, 'std': 2.517888251859514, 'run': 2.627787166963125, 'test_avg': 6.4736328125, 'test_std': 1.778036598729998}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (401 / 4000):
    Value Loss: {'avg': 7.83301321665446, 'std': 1.6253331804789264}
    Value Grad Norm: {'avg': 15.520336310068766, 'std': 5.330858376254676}
    Policy Loss: {'avg': 0.004735495895147324, 'std': 0.005895967920319583}
    Total_Loss: {'avg': -0.058377426117658615, 'std': 0.004683304467299702}
    Policy Entropy: {'avg': 0.6632547378540039, 'std': 0.4931095838546753}
    KL Divergence: {'avg': 0.017138978466391563, 'std': 0.17473267018795013}
    Policy Grad Norm: {'avg': 3.581491708755493, 'std': 0.6318941955210065}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -2.1400004835459088, 'std': 4.571819970016681, 'run': -2.2185556128201434, 'test_avg': -9.499239161822878, 'test_std': 5.264113501809993}
    Episode Length: {'avg': 2.8125, 'std': 1.9897642905173922, 'run': 2.850681153314262, 'test_avg': 6.037109375, 'test_std': 1.8568364613737822}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (501 / 4000):
    Value Loss: {'avg': 4.694403390089671, 'std': 0.9891885432806721}
    Value Grad Norm: {'avg': 14.424073139826456, 'std': 4.04724594343187}
    Policy Loss: {'avg': 0.008484782185405493, 'std': 0.005913268163577535}
    Total_Loss: {'avg': -0.05141321197152138, 'std': 0.009382685846759196}
    Policy Entropy: {'avg': 0.6124346256256104, 'std': 0.4973963499069214}
    KL Divergence: {'avg': 0.022541191428899765, 'std': 0.16239583492279053}
    Policy Grad Norm: {'avg': 4.473985433578491, 'std': 0.5841248052643777}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.6913997943432895, 'std': 4.779385853783277, 'run': -1.4433582461934855, 'test_avg': -7.763317379770694, 'test_std': 3.324576266000292}
    Episode Length: {'avg': 2.680628272251309, 'std': 2.0279697693453644, 'run': 2.601993847706534, 'test_avg': 5.4140625, 'test_std': 1.161910762964932}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (601 / 4000):
    Value Loss: {'avg': 5.914683977762858, 'std': 0.969964644423878}
    Value Grad Norm: {'avg': 14.804672161738077, 'std': 2.349308559455719}
    Policy Loss: {'avg': 0.002999500371515751, 'std': 0.015174909973562687}
    Total_Loss: {'avg': -0.06772703491151333, 'std': 0.012893054887867747}
    Policy Entropy: {'avg': 0.7396677732467651, 'std': 0.5364035964012146}
    KL Divergence: {'avg': 0.04108055680990219, 'std': 0.25259992480278015}
    Policy Grad Norm: {'avg': 4.237308621406555, 'std': 1.2225281858605355}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -2.0525046818372705, 'std': 6.396803923925264, 'run': -1.7845765046550812, 'test_avg': -8.546086078985816, 'test_std': 4.846623617224902}
    Episode Length: {'avg': 2.7474747474747474, 'std': 2.6830686274233315, 'run': 2.646797711793957, 'test_avg': 5.6728515625, 'test_std': 1.7928365687762253}
    Ratio Terminated: {'avg': 0.9949494949494949, 'test_avg': 0.98828125}

Iteration (701 / 4000):
    Value Loss: {'avg': 5.440707763036092, 'std': 0.8762004392514529}
    Value Grad Norm: {'avg': 18.401321013768513, 'std': 5.22820514475892}
    Policy Loss: {'avg': 0.0020148702897131443, 'std': 0.010223767134444771}
    Total_Loss: {'avg': -0.056450034491717815, 'std': 0.007853185834824705}
    Policy Entropy: {'avg': 0.6086477041244507, 'std': 0.5534706711769104}
    KL Divergence: {'avg': 0.03117467649281025, 'std': 0.25696951150894165}
    Policy Grad Norm: {'avg': 5.873382151126862, 'std': 1.460871004706143}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -2.006586297221963, 'std': 5.387728610507733, 'run': -2.1602331329861872, 'test_avg': -8.819907413307632, 'test_std': 4.54375555983437}
    Episode Length: {'avg': 2.7357512953367875, 'std': 2.1516631909685096, 'run': 2.7785381257290207, 'test_avg': 5.748046875, 'test_std': 1.568425045325002}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9931640625}

Iteration (801 / 4000):
    Value Loss: {'avg': 9.483388106028238, 'std': 1.6430264906574894}
    Value Grad Norm: {'avg': 22.83728535970052, 'std': 5.06039897244272}
    Policy Loss: {'avg': -0.007940459763631225, 'std': 0.01043789690007802}
    Total_Loss: {'avg': -0.06611037300899625, 'std': 0.010203816854885894}
    Policy Entropy: {'avg': 0.5522579550743103, 'std': 0.49350112676620483}
    KL Divergence: {'avg': 0.02690727636218071, 'std': 0.24761265516281128}
    Policy Grad Norm: {'avg': 3.7870292961597443, 'std': 1.1353230711772948}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.4453424177450176, 'std': 4.458290983048411, 'run': -1.453351356585802, 'test_avg': -7.985718353458651, 'test_std': 3.3258116156122774}
    Episode Length: {'avg': 2.5052631578947366, 'std': 1.9486766587152435, 'run': 2.515042849649849, 'test_avg': 5.4453125, 'test_std': 1.0874539771152387}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (901 / 4000):
    Value Loss: {'avg': 2.9145152866840363, 'std': 0.612153509580485}
    Value Grad Norm: {'avg': 10.822450598080954, 'std': 2.574722555706353}
    Policy Loss: {'avg': 0.005680488422513008, 'std': 0.005351366521577436}
    Total_Loss: {'avg': -0.04333110153675079, 'std': 0.006343619318140647}
    Policy Entropy: {'avg': 0.474076509475708, 'std': 0.48685958981513977}
    KL Divergence: {'avg': 0.021180594339966774, 'std': 0.16117718815803528}
    Policy Grad Norm: {'avg': 4.157487213611603, 'std': 1.3539752794095141}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.9310201916593133, 'std': 4.2269732540039175, 'run': -1.5205332816395147, 'test_avg': -7.438798424907109, 'test_std': 2.982448289465001}
    Episode Length: {'avg': 2.7967914438502675, 'std': 1.8619150552809525, 'run': 2.593372686173489, 'test_avg': 5.298828125, 'test_std': 1.04046948619793}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1001 / 4000):
    Value Loss: {'avg': 2.0781285564104715, 'std': 0.3983853380700147}
    Value Grad Norm: {'avg': 9.810664296150208, 'std': 2.984874442888509}
    Policy Loss: {'avg': 0.0013854673597961664, 'std': 0.0028133840755434074}
    Total_Loss: {'avg': -0.04824353661388159, 'std': 0.006972410654793261}
    Policy Entropy: {'avg': 0.4642421007156372, 'std': 0.4738965332508087}
    KL Divergence: {'avg': 0.031228769570589066, 'std': 0.17887818813323975}
    Policy Grad Norm: {'avg': 3.5969103574752808, 'std': 0.6421262278988031}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.6207862608785233, 'std': 4.349456196301104, 'run': -1.431840084198304, 'test_avg': -8.015680177962462, 'test_std': 3.7232739922917006}
    Episode Length: {'avg': 2.6789473684210527, 'std': 1.9377357778083002, 'run': 2.58733581266508, 'test_avg': 5.490234375, 'test_std': 1.3418963754956488}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1101 / 4000):
    Value Loss: {'avg': 2.8349662721157074, 'std': 0.8495963985578644}
    Value Grad Norm: {'avg': 8.785415569941202, 'std': 2.107032694825693}
    Policy Loss: {'avg': 0.0008915138896554708, 'std': 0.014725172733184133}
    Total_Loss: {'avg': -0.0494597009383142, 'std': 0.016252891425186537}
    Policy Entropy: {'avg': 0.521018385887146, 'std': 0.47460073232650757}
    KL Divergence: {'avg': 0.042128436267375946, 'std': 0.26243460178375244}
    Policy Grad Norm: {'avg': 5.3709109127521515, 'std': 2.6530800763334135}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.29078423660758, 'std': 3.777015166173994, 'run': -1.3276978782732634, 'test_avg': -7.745792534704417, 'test_std': 4.222511084164222}
    Episode Length: {'avg': 2.6354166666666665, 'std': 1.6369419638629696, 'run': 2.65401774390244, 'test_avg': 5.4130859375, 'test_std': 1.55129250811694}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9873046875}

Iteration (1201 / 4000):
    Value Loss: {'avg': 2.946720709403356, 'std': 0.8638729381163622}
    Value Grad Norm: {'avg': 12.450327515602112, 'std': 4.003615443591154}
    Policy Loss: {'avg': 0.006818046327680349, 'std': 0.01124837119112298}
    Total_Loss: {'avg': -0.045091642532497644, 'std': 0.012216516334106326}
    Policy Entropy: {'avg': 0.4940851926803589, 'std': 0.4934525191783905}
    KL Divergence: {'avg': 0.0352378785610199, 'std': 0.30081814527511597}
    Policy Grad Norm: {'avg': 4.907890260219574, 'std': 0.6273405150285534}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.4118746420457444, 'std': 4.535342972960336, 'run': -1.3846211316735517, 'test_avg': -7.191122745143984, 'test_std': 2.452048652961195}
    Episode Length: {'avg': 2.5073170731707317, 'std': 1.932064514892944, 'run': 2.5129982376096325, 'test_avg': 5.19921875, 'test_std': 0.8381523666067152}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 4000):
    Value Loss: {'avg': 1.9142117301623027, 'std': 0.8515649402866136}
    Value Grad Norm: {'avg': 8.058953205744425, 'std': 2.4552176278473983}
    Policy Loss: {'avg': -0.006538027198985219, 'std': 0.010836871339343369}
    Total_Loss: {'avg': -0.05446131061762571, 'std': 0.010664885523453188}
    Policy Entropy: {'avg': 0.4488812983036041, 'std': 0.4929569661617279}
    KL Divergence: {'avg': 0.030918430536985397, 'std': 0.17696990072727203}
    Policy Grad Norm: {'avg': 2.709481567144394, 'std': 1.1129102845307244}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.379232269845846, 'std': 3.7485772161062463, 'run': -1.1820344350629628, 'test_avg': -7.134066722637242, 'test_std': 2.9857459472504337}
    Episode Length: {'avg': 2.6146341463414635, 'std': 1.6682926829268292, 'run': 2.5110850907593254, 'test_avg': 5.205078125, 'test_std': 1.11844164472112}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (1401 / 4000):
    Value Loss: {'avg': 6.937733670075734, 'std': 1.7389733063336632}
    Value Grad Norm: {'avg': 21.678870995839436, 'std': 5.942095737759902}
    Policy Loss: {'avg': -0.004803827963769436, 'std': 0.00525376769249891}
    Total_Loss: {'avg': -0.052459802478551865, 'std': 0.00740166050344102}
    Policy Entropy: {'avg': 0.5219993591308594, 'std': 0.516492486000061}
    KL Divergence: {'avg': 0.04016513749957085, 'std': 0.3719443380832672}
    Policy Grad Norm: {'avg': 6.173788368701935, 'std': 4.975878437151155}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -2.2355017181035306, 'std': 5.431971438292335, 'run': -2.2074047994797006, 'test_avg': -7.359500564022173, 'test_std': 2.4920075902461596}
    Episode Length: {'avg': 2.9414893617021276, 'std': 2.202943368298282, 'run': 2.889655452269146, 'test_avg': 5.2568359375, 'test_std': 0.8288335108503372}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 4000):
    Value Loss: {'avg': 3.366970717906952, 'std': 0.6753762367155559}
    Value Grad Norm: {'avg': 15.531262795130411, 'std': 5.0574823249423115}
    Policy Loss: {'avg': 0.002813565544784069, 'std': 0.004631481260780954}
    Total_Loss: {'avg': -0.04542152304202318, 'std': 0.007651854452561822}
    Policy Entropy: {'avg': 0.40560561418533325, 'std': 0.49949154257774353}
    KL Divergence: {'avg': 0.05224602669477463, 'std': 0.3680949807167053}
    Policy Grad Norm: {'avg': 4.021892428398132, 'std': 1.0031597153629561}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -2.027339704872972, 'std': 5.70536082934253, 'run': -1.7200694580012768, 'test_avg': -7.26941419634386, 'test_std': 2.4369318702738356}
    Episode Length: {'avg': 2.8226600985221677, 'std': 2.3040078205545105, 'run': 2.6927782038036656, 'test_avg': 5.21484375, 'test_std': 0.804488370385761}
    Ratio Terminated: {'avg': 0.9950738916256158, 'test_avg': 1.0}

Iteration (1601 / 4000):
    Value Loss: {'avg': 1.8555210928122203, 'std': 0.5621413404624047}
    Value Grad Norm: {'avg': 8.576942364374796, 'std': 1.7289566078515977}
    Policy Loss: {'avg': -0.003235402866266668, 'std': 0.012475115501172463}
    Total_Loss: {'avg': -0.04942127806134522, 'std': 0.013545239307115877}
    Policy Entropy: {'avg': 0.44757145643234253, 'std': 0.5131681561470032}
    KL Divergence: {'avg': 0.049305059015750885, 'std': 0.3355092704296112}
    Policy Grad Norm: {'avg': 2.5366730988025665, 'std': 1.5858113141662482}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.0561004032370975, 'std': 3.530086716657154, 'run': -0.9334885623924817, 'test_avg': -7.120497166583434, 'test_std': 2.1140906660378325}
    Episode Length: {'avg': 2.5, 'std': 1.6043096720426278, 'run': 2.443750570364557, 'test_avg': 5.1611328125, 'test_std': 0.6661552215781543}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 4000):
    Value Loss: {'avg': 1.1089799751838048, 'std': 0.2927593376246342}
    Value Grad Norm: {'avg': 8.571913401285807, 'std': 2.7118056328286544}
    Policy Loss: {'avg': -0.0027115767588838935, 'std': 0.002155207435781573}
    Total_Loss: {'avg': -0.05233038775622845, 'std': 0.0012205322202735326}
    Policy Entropy: {'avg': 0.49101102352142334, 'std': 0.5582215189933777}
    KL Divergence: {'avg': 0.021439112722873688, 'std': 0.17722880840301514}
    Policy Grad Norm: {'avg': 4.278962701559067, 'std': 2.7033649880397146}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.4763869065788753, 'std': 4.457473237765843, 'run': -1.2422659689816813, 'test_avg': -7.28997120395017, 'test_std': 2.6658767880933936}
    Episode Length: {'avg': 2.5318181818181817, 'std': 1.9385764138657764, 'run': 2.463830551576761, 'test_avg': 5.248046875, 'test_std': 0.9359341578352264}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 4000):
    Value Loss: {'avg': 4.30365123351415, 'std': 1.3330584558994387}
    Value Grad Norm: {'avg': 13.285486618677774, 'std': 2.932778658051771}
    Policy Loss: {'avg': -3.78522090613842e-05, 'std': 0.0036645230359640887}
    Total_Loss: {'avg': -0.04699626285582781, 'std': 0.003983032127932319}
    Policy Entropy: {'avg': 0.4940480887889862, 'std': 0.487522691488266}
    KL Divergence: {'avg': 0.016338348388671875, 'std': 0.19201603531837463}
    Policy Grad Norm: {'avg': 2.8719615936279297, 'std': 1.0433795321221178}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.569953400134583, 'std': 4.0485518551992, 'run': -1.469798906604948, 'test_avg': -7.273824844018075, 'test_std': 3.246008867121211}
    Episode Length: {'avg': 2.740740740740741, 'std': 1.7821814946504704, 'run': 2.6866149171325486, 'test_avg': 5.2490234375, 'test_std': 1.22055116241626}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9931640625}

Iteration (1901 / 4000):
    Value Loss: {'avg': 1.2283468395471573, 'std': 0.16998274342068254}
    Value Grad Norm: {'avg': 8.918460607528687, 'std': 2.3064189250675997}
    Policy Loss: {'avg': -0.007665844983421266, 'std': 0.014016242374574621}
    Total_Loss: {'avg': -0.05368945514783263, 'std': 0.014361314280575856}
    Policy Entropy: {'avg': 0.44269314408302307, 'std': 0.5270942449569702}
    KL Divergence: {'avg': 0.04962575435638428, 'std': 0.32352012395858765}
    Policy Grad Norm: {'avg': 3.8543726205825806, 'std': 2.522009510605285}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.204435054191076, 'std': 4.040591382742796, 'run': -1.4818190971399492, 'test_avg': -7.2681680334756384, 'test_std': 2.6165298427201167}
    Episode Length: {'avg': 2.5320197044334973, 'std': 1.7483868313182316, 'run': 2.6492215573017637, 'test_avg': 5.2392578125, 'test_std': 0.9272259091816378}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 4000):
    Value Loss: {'avg': 1.8679577708244324, 'std': 0.535369664520377}
    Value Grad Norm: {'avg': 10.310856103897095, 'std': 2.0149823263971305}
    Policy Loss: {'avg': 0.0029454142786562443, 'std': 0.003719393465333762}
    Total_Loss: {'avg': -0.05097215808928013, 'std': 0.001890639026782593}
    Policy Entropy: {'avg': 0.5124509930610657, 'std': 0.5503860712051392}
    KL Divergence: {'avg': 0.020130105316638947, 'std': 0.1660122126340866}
    Policy Grad Norm: {'avg': 5.845386385917664, 'std': 3.2215844437370142}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.0172181166049084, 'std': 4.146584249237876, 'run': -1.2880907056727353, 'test_avg': -7.109344813563767, 'test_std': 1.8693532340440293}
    Episode Length: {'avg': 2.3285714285714287, 'std': 1.8183306989137715, 'run': 2.4313172975193087, 'test_avg': 5.15625, 'test_std': 0.609975665498223}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 4000):
    Value Loss: {'avg': 0.6357966139912605, 'std': 0.14004302527141754}
    Value Grad Norm: {'avg': 5.383234441280365, 'std': 1.9908153049410136}
    Policy Loss: {'avg': -0.003961634240113199, 'std': 0.01089221572770162}
    Total_Loss: {'avg': -0.051519148983061314, 'std': 0.011135752959271316}
    Policy Entropy: {'avg': 0.4091242253780365, 'std': 0.49506866931915283}
    KL Divergence: {'avg': 0.04723944514989853, 'std': 0.24488374590873718}
    Policy Grad Norm: {'avg': 2.6510395854711533, 'std': 0.667649281671494}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.366698081016691, 'std': 3.757983422299276, 'run': -1.1548387538226457, 'test_avg': -7.051274633242881, 'test_std': 2.2787648093473507}
    Episode Length: {'avg': 2.551219512195122, 'std': 1.7260022823402246, 'run': 2.4703320541398166, 'test_avg': 5.1474609375, 'test_std': 0.8354530713401089}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (2201 / 4000):
    Value Loss: {'avg': 1.6269464641809464, 'std': 0.8375145780708197}
    Value Grad Norm: {'avg': 10.409304141998291, 'std': 3.5961056201224886}
    Policy Loss: {'avg': -0.002278244122862816, 'std': 0.004434389384944181}
    Total_Loss: {'avg': -0.043333107605576515, 'std': 0.0026110168277787026}
    Policy Entropy: {'avg': 0.4538295567035675, 'std': 0.524711012840271}
    KL Divergence: {'avg': 0.03415576368570328, 'std': 0.28450796008110046}
    Policy Grad Norm: {'avg': 2.3151892721652985, 'std': 0.8204451305815831}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.3645963765355735, 'std': 3.6231832801050854, 'run': -1.3064474110218396, 'test_avg': -7.2229852268981105, 'test_std': 2.378632301727232}
    Episode Length: {'avg': 2.616915422885572, 'std': 1.6443820953275357, 'run': 2.6261696292972556, 'test_avg': 5.21875, 'test_std': 0.8131007394536055}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 4000):
    Value Loss: {'avg': 1.1768881728251774, 'std': 0.31755957361039605}
    Value Grad Norm: {'avg': 6.975214123725891, 'std': 1.3040115324427315}
    Policy Loss: {'avg': 0.003129060845822096, 'std': 0.004415492449200178}
    Total_Loss: {'avg': -0.045104511082172394, 'std': 0.004544880432306192}
    Policy Entropy: {'avg': 0.4729822874069214, 'std': 0.5041165947914124}
    KL Divergence: {'avg': 0.02335556223988533, 'std': 0.1427605003118515}
    Policy Grad Norm: {'avg': 2.7674800753593445, 'std': 1.2711732156015962}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.1679331748518174, 'std': 3.8901086460086214, 'run': -0.7192343328525482, 'test_avg': -7.426286785576616, 'test_std': 3.3042376539958496}
    Episode Length: {'avg': 2.4688995215311005, 'std': 1.7334975112422357, 'run': 2.271453215520921, 'test_avg': 5.30078125, 'test_std': 1.1798103723261792}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (2401 / 4000):
    Value Loss: {'avg': 1.8806020220120747, 'std': 0.9559065002300601}
    Value Grad Norm: {'avg': 9.083809971809387, 'std': 2.9643382568346888}
    Policy Loss: {'avg': 0.002045396249741316, 'std': 0.015990990371992243}
    Total_Loss: {'avg': -0.04555815830826759, 'std': 0.018246413543718375}
    Policy Entropy: {'avg': 0.539178192615509, 'std': 0.5023414492607117}
    KL Divergence: {'avg': 0.028967056423425674, 'std': 0.18727433681488037}
    Policy Grad Norm: {'avg': 3.8150221407413483, 'std': 1.8111588258943787}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -0.7158126343930254, 'std': 3.303866142322634, 'run': -0.7828220330069059, 'test_avg': -7.274970579261533, 'test_std': 2.696243514343448}
    Episode Length: {'avg': 2.3317535545023698, 'std': 1.5219986410753568, 'run': 2.384793088137188, 'test_avg': 5.2421875, 'test_std': 0.9343371125261749}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 4000):
    Value Loss: {'avg': 1.5161301344633102, 'std': 0.45088638314672896}
    Value Grad Norm: {'avg': 13.95513657728831, 'std': 5.950445077476562}
    Policy Loss: {'avg': -0.0033438457176089287, 'std': 0.0075361272365242786}
    Total_Loss: {'avg': -0.054764289408922195, 'std': 0.004822833088239665}
    Policy Entropy: {'avg': 0.4869958460330963, 'std': 0.5166608691215515}
    KL Divergence: {'avg': 0.031064841896295547, 'std': 0.1918574571609497}
    Policy Grad Norm: {'avg': 3.6149488389492035, 'std': 1.0743425627356353}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.1477557089205528, 'std': 4.160944946223096, 'run': -1.0110340694440232, 'test_avg': -6.884656071318787, 'test_std': 1.598552968723022}
    Episode Length: {'avg': 2.4074074074074074, 'std': 1.8561062241964188, 'run': 2.3429840608710983, 'test_avg': 5.103515625, 'test_std': 0.5201293256305198}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 4000):
    Value Loss: {'avg': 1.399774208664894, 'std': 0.3577800792382385}
    Value Grad Norm: {'avg': 7.2831199169158936, 'std': 2.145068188863194}
    Policy Loss: {'avg': 0.0029276544228196144, 'std': 0.004137993092959396}
    Total_Loss: {'avg': -0.046523382887244225, 'std': 0.005927924505299532}
    Policy Entropy: {'avg': 0.4059143662452698, 'std': 0.5241338610649109}
    KL Divergence: {'avg': 0.01639433205127716, 'std': 0.10802529752254486}
    Policy Grad Norm: {'avg': 4.8284289836883545, 'std': 2.4431475884440457}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -0.796382336872366, 'std': 3.4119208504655707, 'run': -0.9243378452459459, 'test_avg': -7.174653356455224, 'test_std': 2.3902672434030503}
    Episode Length: {'avg': 2.2883720930232556, 'std': 1.5732072561646502, 'run': 2.3113739491197123, 'test_avg': 5.220703125, 'test_std': 0.8362637177441302}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 4000):
    Value Loss: {'avg': 0.6136782094836235, 'std': 0.21459126523888014}
    Value Grad Norm: {'avg': 4.72714759906133, 'std': 1.914560858211614}
    Policy Loss: {'avg': -0.006514617707580328, 'std': 0.013725737192169903}
    Total_Loss: {'avg': -0.05063642840832472, 'std': 0.013940708920570638}
    Policy Entropy: {'avg': 0.4174204170703888, 'std': 0.5268949270248413}
    KL Divergence: {'avg': 0.03267904371023178, 'std': 0.19227296113967896}
    Policy Grad Norm: {'avg': 1.7591873854398727, 'std': 0.8558913073194856}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.0730236073277486, 'std': 3.534694715933057, 'run': -1.2531395653728608, 'test_avg': -6.846957762813101, 'test_std': 1.545061933556151}
    Episode Length: {'avg': 2.4950980392156863, 'std': 1.61639137241563, 'run': 2.5880456599636723, 'test_avg': 5.099609375, 'test_std': 0.4998435729426851}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 4000):
    Value Loss: {'avg': 0.808962307870388, 'std': 0.2957592403185233}
    Value Grad Norm: {'avg': 8.012988150119781, 'std': 3.889998960315868}
    Policy Loss: {'avg': -0.008401491213589907, 'std': 0.00924344705805664}
    Total_Loss: {'avg': -0.04884060053154826, 'std': 0.008364955989013337}
    Policy Entropy: {'avg': 0.44639167189598083, 'std': 0.542338490486145}
    KL Divergence: {'avg': 0.0572417713701725, 'std': 0.37598758935928345}
    Policy Grad Norm: {'avg': 3.4232834950089455, 'std': 3.826765616664802}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.081744302457766, 'std': 3.9783782518114457, 'run': -1.0044478407667579, 'test_avg': -6.796036956348061, 'test_std': 1.27720921445031}
    Episode Length: {'avg': 2.600985221674877, 'std': 1.6971140426244862, 'run': 2.591919937904005, 'test_avg': 5.0693359375, 'test_std': 0.39784226179604915}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 4000):
    Value Loss: {'avg': 0.6420451253652573, 'std': 0.16770192745835588}
    Value Grad Norm: {'avg': 5.485066930452983, 'std': 1.391167834156633}
    Policy Loss: {'avg': -0.01073958061169833, 'std': 0.010429325925705517}
    Total_Loss: {'avg': -0.05529583618044853, 'std': 0.009907131848665507}
    Policy Entropy: {'avg': 0.45540547370910645, 'std': 0.5073566436767578}
    KL Divergence: {'avg': 0.04666862264275551, 'std': 0.2710496187210083}
    Policy Grad Norm: {'avg': 2.6368279606103897, 'std': 1.9231860355336896}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.6542854062720107, 'std': 3.713357451232324, 'run': -1.4691018867609942, 'test_avg': -6.95025941825118, 'test_std': 2.490240326715244}
    Episode Length: {'avg': 2.683937823834197, 'std': 1.709043618342836, 'run': 2.560252392327471, 'test_avg': 5.130859375, 'test_std': 0.8503588648180305}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (3001 / 4000):
    Value Loss: {'avg': 1.185367301106453, 'std': 0.38610852888504044}
    Value Grad Norm: {'avg': 7.735939542452495, 'std': 2.658100691318258}
    Policy Loss: {'avg': -0.01007591630332172, 'std': 0.011280670626398499}
    Total_Loss: {'avg': -0.06264483230188489, 'std': 0.01196052978291204}
    Policy Entropy: {'avg': 0.4581807553768158, 'std': 0.5387292504310608}
    KL Divergence: {'avg': 0.04056544229388237, 'std': 0.2162148505449295}
    Policy Grad Norm: {'avg': 3.837973892688751, 'std': 1.9542824855050376}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -0.7648274792270303, 'std': 3.9196917251243852, 'run': -0.8481483787589346, 'test_avg': -6.987271792298058, 'test_std': 2.041532167321306}
    Episode Length: {'avg': 2.220720720720721, 'std': 1.700800930410719, 'run': 2.293020685275685, 'test_avg': 5.1435546875, 'test_std': 0.7028801385704232}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3101 / 4000):
    Value Loss: {'avg': 1.1800664216279984, 'std': 0.4022733584747408}
    Value Grad Norm: {'avg': 8.252190113067627, 'std': 2.769828252659863}
    Policy Loss: {'avg': -0.007706258678808808, 'std': 0.008761686282214865}
    Total_Loss: {'avg': -0.06247975630685687, 'std': 0.008201279833122486}
    Policy Entropy: {'avg': 0.6133750081062317, 'std': 0.5598047971725464}
    KL Divergence: {'avg': 0.02656799554824829, 'std': 0.24948137998580933}
    Policy Grad Norm: {'avg': 2.3909712433815002, 'std': 1.390866501856571}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.1623850513589635, 'std': 3.9560098994311046, 'run': -1.2878518998877266, 'test_avg': -6.788642156434435, 'test_std': 1.5485803412903754}
    Episode Length: {'avg': 2.4312796208530805, 'std': 1.7248580606516923, 'run': 2.4871174220096246, 'test_avg': 5.060546875, 'test_std': 0.48638302902931796}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 4000):
    Value Loss: {'avg': 0.8996715297301611, 'std': 0.21705496135467944}
    Value Grad Norm: {'avg': 6.397281964619954, 'std': 1.1938573530875}
    Policy Loss: {'avg': -0.003074776381254196, 'std': 0.0025529870274337654}
    Total_Loss: {'avg': -0.05410144943743944, 'std': 0.007263411036017919}
    Policy Entropy: {'avg': 0.4948067367076874, 'std': 0.6048999428749084}
    KL Divergence: {'avg': 0.02937222272157669, 'std': 0.2425035685300827}
    Policy Grad Norm: {'avg': 3.124648839235306, 'std': 1.2134027118216282}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.029684861793711, 'std': 3.468749308499923, 'run': -1.3348125841780314, 'test_avg': -6.84557392694569, 'test_std': 1.5698496159836972}
    Episode Length: {'avg': 2.378640776699029, 'std': 1.601676941926313, 'run': 2.5252992188208045, 'test_avg': 5.0771484375, 'test_std': 0.5066985603801422}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 4000):
    Value Loss: {'avg': 1.7391242384910583, 'std': 0.528450911061567}
    Value Grad Norm: {'avg': 9.750977714856466, 'std': 3.363419355935468}
    Policy Loss: {'avg': -0.0005208910442888737, 'std': 0.0028866876837038004}
    Total_Loss: {'avg': -0.050533706322312355, 'std': 0.003584951761729866}
    Policy Entropy: {'avg': 0.5185587406158447, 'std': 0.5216290950775146}
    KL Divergence: {'avg': 0.022421278059482574, 'std': 0.16723641753196716}
    Policy Grad Norm: {'avg': 4.452509760856628, 'std': 2.6588669348959257}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -0.794992851795053, 'std': 4.376099249308549, 'run': -0.8519926622920702, 'test_avg': -6.892957096377485, 'test_std': 1.7175657578578376}
    Episode Length: {'avg': 2.3689320388349513, 'std': 1.918182246634456, 'run': 2.3930851935963617, 'test_avg': 5.09765625, 'test_std': 0.5557181226448689}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 4000):
    Value Loss: {'avg': 0.41997794558604556, 'std': 0.07102166544059296}
    Value Grad Norm: {'avg': 4.466952582200368, 'std': 1.5040832408092786}
    Policy Loss: {'avg': -0.0021590562537312508, 'std': 0.0027545898716195977}
    Total_Loss: {'avg': -0.04992958530783653, 'std': 0.004957507962162926}
    Policy Entropy: {'avg': 0.44689875841140747, 'std': 0.49806922674179077}
    KL Divergence: {'avg': 0.017535515129566193, 'std': 0.19020406901836395}
    Policy Grad Norm: {'avg': 3.1151224970817566, 'std': 1.1685611691198365}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -0.5947927441130166, 'std': 3.1033873638612457, 'run': -0.7325432183396952, 'test_avg': -6.793365405788791, 'test_std': 1.4895605153804543}
    Episode Length: {'avg': 2.1904761904761907, 'std': 1.488220773925673, 'run': 2.2647707761448186, 'test_avg': 5.0712890625, 'test_std': 0.47782455678613994}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 4000):
    Value Loss: {'avg': 2.0848366022109985, 'std': 0.9107474346275252}
    Value Grad Norm: {'avg': 23.682052214940388, 'std': 14.504922467504889}
    Policy Loss: {'avg': -0.010851832339540124, 'std': 0.01586619809392166}
    Total_Loss: {'avg': -0.058713842649012804, 'std': 0.016881777556167495}
    Policy Entropy: {'avg': 0.4437354803085327, 'std': 0.5253762006759644}
    KL Divergence: {'avg': 0.0440022274851799, 'std': 0.24125978350639343}
    Policy Grad Norm: {'avg': 4.414578422904015, 'std': 5.15326668480796}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.2239389228701505, 'std': 4.531974506197791, 'run': -1.0768575552861313, 'test_avg': -7.0549992369049095, 'test_std': 2.075277310396079}
    Episode Length: {'avg': 2.4832535885167464, 'std': 1.9370368871552346, 'run': 2.4463203129029036, 'test_avg': 5.14453125, 'test_std': 0.6779229069543509}
    Ratio Terminated: {'avg': 0.9952153110047847, 'test_avg': 1.0}

Iteration (3601 / 4000):
    Value Loss: {'avg': 0.4937588845690091, 'std': 0.1149548126585058}
    Value Grad Norm: {'avg': 4.176620781421661, 'std': 1.1034124666894227}
    Policy Loss: {'avg': 8.66549089550972e-05, 'std': 0.0020973788107344596}
    Total_Loss: {'avg': -0.041705078445374966, 'std': 0.0028750863310253983}
    Policy Entropy: {'avg': 0.3992687463760376, 'std': 0.4620082378387451}
    KL Divergence: {'avg': 0.035428643226623535, 'std': 0.29168036580085754}
    Policy Grad Norm: {'avg': 7.1952885389328, 'std': 4.744590419408811}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -0.8058996946306114, 'std': 3.300621032669441, 'run': -0.7869079563691447, 'test_avg': -6.879873742826021, 'test_std': 1.8929424062070868}
    Episode Length: {'avg': 2.3636363636363638, 'std': 1.5317432861164606, 'run': 2.384407802729883, 'test_avg': 5.1064453125, 'test_std': 0.6102937472617406}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3701 / 4000):
    Value Loss: {'avg': 1.5413431177536647, 'std': 0.6537884543120897}
    Value Grad Norm: {'avg': 9.22815509637197, 'std': 2.6652901872808425}
    Policy Loss: {'avg': 0.002786957658827305, 'std': 0.009385538654451136}
    Total_Loss: {'avg': -0.04872750397771597, 'std': 0.012687310131574195}
    Policy Entropy: {'avg': 0.5344623327255249, 'std': 0.5257587432861328}
    KL Divergence: {'avg': 0.018060192465782166, 'std': 0.12651588022708893}
    Policy Grad Norm: {'avg': 5.4925039410591125, 'std': 3.5646635969375025}
    Num PPO updates: {'avg': 4}
    Return: {'avg': -1.3695708745260142, 'std': 3.978998174895472, 'run': -1.4848004770797152, 'test_avg': -6.766462145263807, 'test_std': 1.2932828297272583}
    Episode Length: {'avg': 2.618556701030928, 'std': 1.7902559799059787, 'run': 2.694859807935042, 'test_avg': 5.072265625, 'test_std': 0.4426618963084121}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3801 / 4000):
    Value Loss: {'avg': 1.9072202046712239, 'std': 0.8802380274589763}
    Value Grad Norm: {'avg': 10.779222011566162, 'std': 2.9195794255558423}
    Policy Loss: {'avg': -0.012124403147026896, 'std': 0.011163117207278252}
    Total_Loss: {'avg': -0.06151337921619415, 'std': 0.012936275612031074}
    Policy Entropy: {'avg': 0.5016540288925171, 'std': 0.4984782040119171}
    KL Divergence: {'avg': 0.054191578179597855, 'std': 0.20332758128643036}
    Policy Grad Norm: {'avg': 1.5174433812499046, 'std': 0.4230829213035026}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -0.8123429875464849, 'std': 3.6031482549269938, 'run': -0.967317241850995, 'test_avg': -6.857114506970728, 'test_std': 1.5621700036946826}
    Episode Length: {'avg': 2.311320754716981, 'std': 1.638932047281698, 'run': 2.369645848410288, 'test_avg': 5.0927734375, 'test_std': 0.5155648861146709}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 4000):
    Value Loss: {'avg': 0.9390070289373398, 'std': 0.24064009580224355}
    Value Grad Norm: {'avg': 6.131392776966095, 'std': 1.995560891730011}
    Policy Loss: {'avg': -0.006871042773127556, 'std': 0.012916982047758659}
    Total_Loss: {'avg': -0.05942170787602663, 'std': 0.013458966248948557}
    Policy Entropy: {'avg': 0.4728825092315674, 'std': 0.5531182885169983}
    KL Divergence: {'avg': 0.02723044343292713, 'std': 0.25000447034835815}
    Policy Grad Norm: {'avg': 4.247353971004486, 'std': 2.350054365269716}
    Num PPO updates: {'avg': 8}
    Return: {'avg': -1.4197464262984731, 'std': 3.793798774471523, 'run': -1.244096537730179, 'test_avg': -6.724818993010934, 'test_std': 1.3234493273814731}
    Episode Length: {'avg': 2.545, 'std': 1.7285760035358584, 'run': 2.4343164268056805, 'test_avg': 5.0576171875, 'test_std': 0.4302985268445499}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Training took 2769.428 seconds in total.
