
Iteration (1 / 5000):
    Value Loss: {'avg': 102.30512603123982, 'std': 24.68847968200715}
    Value Grad Norm: {'avg': 68.58446939786275, 'std': 7.873725942334724}
    Policy Loss: {'avg': -0.004662720583534489, 'std': 0.008397168638870663}
    Total_Loss: {'avg': -0.18343516221890846, 'std': 0.008418867794772071}
    Policy Entropy: {'avg': 1.7868268489837646, 'std': 0.00582090113312006}
    KL Divergence: {'avg': 0.005728662945330143, 'std': 0.08673404157161713}
    Policy Grad Norm: {'avg': 0.22597092110663652, 'std': 0.08625276838965061}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -10.76669090441779, 'std': 5.698940301942607, 'run': -1.5881488396126864, 'test_avg': -37.18175071585369, 'test_std': 9.941969776595473}
    Episode Length: {'avg': 6.391304347826087, 'std': 1.811536230956492, 'run': 2.928921527153062, 'test_avg': 11.564453125, 'test_std': 1.4596614058327824}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.09375}

Iteration (101 / 5000):
    Value Loss: {'avg': 1.4458382154504459, 'std': 0.6073330454216426}
    Value Grad Norm: {'avg': 9.949901252985, 'std': 4.995464726152602}
    Policy Loss: {'avg': 0.02538753382395953, 'std': 0.043648722809838066}
    Total_Loss: {'avg': -0.025291288504377007, 'std': 0.04272805041602223}
    Policy Entropy: {'avg': 0.5590220093727112, 'std': 0.5307059288024902}
    KL Divergence: {'avg': 0.04451350122690201, 'std': 0.2530445158481598}
    Policy Grad Norm: {'avg': 2.108313988894224, 'std': 1.3834463495947436}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.142700686924194, 'std': 2.804221649173598, 'run': -7.042564818154973, 'test_avg': -6.673973477809341, 'test_std': 0.7955377621316495}
    Episode Length: {'avg': 5.134292565947242, 'std': 1.0041635342979744, 'run': 5.099226345509562, 'test_avg': 5.009765625, 'test_std': 0.2117227138697201}
    Ratio Terminated: {'avg': 0.9952038369304557, 'test_avg': 1.0}

Iteration (201 / 5000):
    Value Loss: {'avg': 2.0698783484598002, 'std': 0.8361187899297231}
    Value Grad Norm: {'avg': 11.25301738580068, 'std': 3.586069049854295}
    Policy Loss: {'avg': 0.004776657820912078, 'std': 0.03601971963912358}
    Total_Loss: {'avg': -0.0426746744196862, 'std': 0.03520509003153356}
    Policy Entropy: {'avg': 0.5269895792007446, 'std': 0.4908542335033417}
    KL Divergence: {'avg': 0.06514847278594971, 'std': 0.45229196548461914}
    Policy Grad Norm: {'avg': 7.862531770020723, 'std': 19.720395251186634}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.608613157676646, 'std': 2.1524614900986436, 'run': -6.50372989579835, 'test_avg': -6.71308086134921, 'test_std': 1.1606860029044077}
    Episode Length: {'avg': 4.975369458128079, 'std': 0.7620197665313121, 'run': 4.921087627527162, 'test_avg': 5.052734375, 'test_std': 0.43878421313141996}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (301 / 5000):
    Value Loss: {'avg': 1.2964662096152704, 'std': 0.7180680564646976}
    Value Grad Norm: {'avg': 11.79693133632342, 'std': 6.213887489745098}
    Policy Loss: {'avg': -0.0028514162404462695, 'std': 0.01323707953064295}
    Total_Loss: {'avg': -0.048940002801828086, 'std': 0.015341790427237005}
    Policy Entropy: {'avg': 0.46638211607933044, 'std': 0.5318260788917542}
    KL Divergence: {'avg': 0.0366806760430336, 'std': 0.40880510210990906}
    Policy Grad Norm: {'avg': 1.6259405836462975, 'std': 0.6201052889147084}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.596076488706525, 'std': 2.09679337992632, 'run': -6.552793210998758, 'test_avg': -6.6763355888040605, 'test_std': 1.3051259774333517}
    Episode Length: {'avg': 4.980295566502463, 'std': 0.6873995484733955, 'run': 4.969978998501901, 'test_avg': 5.0390625, 'test_std': 0.3982842842665902}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (401 / 5000):
    Value Loss: {'avg': 1.4753497044245403, 'std': 0.6582065127478344}
    Value Grad Norm: {'avg': 12.04988663395246, 'std': 4.4877689406936385}
    Policy Loss: {'avg': -0.0023840053472667933, 'std': 0.015607489758898021}
    Total_Loss: {'avg': -0.05046019225846976, 'std': 0.015915884550466577}
    Policy Entropy: {'avg': 0.42641401290893555, 'std': 0.4673369526863098}
    KL Divergence: {'avg': 0.03565147891640663, 'std': 0.35652974247932434}
    Policy Grad Norm: {'avg': 3.673571590334177, 'std': 3.3143445034991923}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.735992428008634, 'std': 2.1892974053734515, 'run': -6.937336587503297, 'test_avg': -6.622538317678384, 'test_std': 0.722502681210819}
    Episode Length: {'avg': 5.012224938875305, 'std': 0.773868564912331, 'run': 5.089290904851341, 'test_avg': 5.0185546875, 'test_std': 0.17300046552474171}
    Ratio Terminated: {'avg': 0.9975550122249389, 'test_avg': 1.0}

Iteration (501 / 5000):
    Value Loss: {'avg': 0.9846644786496958, 'std': 0.41705857825241127}
    Value Grad Norm: {'avg': 10.31171977519989, 'std': 3.6913531078836312}
    Policy Loss: {'avg': 0.0024543593754060566, 'std': 0.011807872013005422}
    Total_Loss: {'avg': -0.040282475179992616, 'std': 0.015055328579206216}
    Policy Entropy: {'avg': 0.36548277735710144, 'std': 0.5148851871490479}
    KL Divergence: {'avg': 0.03226754069328308, 'std': 0.3640056252479553}
    Policy Grad Norm: {'avg': 2.3149055391550064, 'std': 1.5602027560794978}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.452266429551684, 'std': 1.9037985455546516, 'run': -6.292570940381039, 'test_avg': -6.641471961273055, 'test_std': 0.8859828646589356}
    Episode Length: {'avg': 4.9225181598062955, 'std': 0.6809774009572795, 'run': 4.867650030912845, 'test_avg': 5.0244140625, 'test_std': 0.25075987727753835}
    Ratio Terminated: {'avg': 0.9975786924939467, 'test_avg': 1.0}

Iteration (601 / 5000):
    Value Loss: {'avg': 5.330451731880506, 'std': 1.6012070112078183}
    Value Grad Norm: {'avg': 33.28631462653478, 'std': 13.23660498141468}
    Policy Loss: {'avg': 8.776492904871702e-06, 'std': 0.009339940482986671}
    Total_Loss: {'avg': -0.05895233456976712, 'std': 0.011328451855770107}
    Policy Entropy: {'avg': 0.5653014183044434, 'std': 0.61026930809021}
    KL Divergence: {'avg': 0.06730153411626816, 'std': 0.6047778129577637}
    Policy Grad Norm: {'avg': 3.0504360627382994, 'std': 2.8092278866401115}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.339269149957864, 'std': 4.064935522925315, 'run': -7.53155907487302, 'test_avg': -7.591504482581855, 'test_std': 3.9671977977945465}
    Episode Length: {'avg': 5.238693467336684, 'std': 1.4753622505538546, 'run': 5.304458259046684, 'test_avg': 5.396484375, 'test_std': 1.466763065522465}
    Ratio Terminated: {'avg': 0.9673366834170855, 'test_avg': 0.9560546875}

Iteration (701 / 5000):
    Value Loss: {'avg': 0.7570497958610455, 'std': 0.47492136139747826}
    Value Grad Norm: {'avg': 8.619260559479395, 'std': 4.280339884476194}
    Policy Loss: {'avg': 0.0006011087680235505, 'std': 0.015368838808204076}
    Total_Loss: {'avg': -0.040728831896558404, 'std': 0.015597021850889015}
    Policy Entropy: {'avg': 0.42480355501174927, 'std': 0.4816809296607971}
    KL Divergence: {'avg': 0.05953288823366165, 'std': 0.5066401958465576}
    Policy Grad Norm: {'avg': 4.495064051821828, 'std': 7.409765535779172}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.493987223183869, 'std': 1.70286757829554, 'run': -6.54279812891556, 'test_avg': -6.638637688218296, 'test_std': 1.0751686500681767}
    Episode Length: {'avg': 4.941463414634146, 'std': 0.5686850942889123, 'run': 4.970640805297075, 'test_avg': 5.037109375, 'test_std': 0.34600093104948343}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 5000):
    Value Loss: {'avg': 2.8904505521059036, 'std': 1.0645453309266781}
    Value Grad Norm: {'avg': 28.94779521226883, 'std': 12.897370447581261}
    Policy Loss: {'avg': 0.004832477250602096, 'std': 0.01586328305821807}
    Total_Loss: {'avg': -0.04351175110787153, 'std': 0.015736082296223072}
    Policy Entropy: {'avg': 0.5160963535308838, 'std': 0.4881516695022583}
    KL Divergence: {'avg': 0.15031978487968445, 'std': 1.0306432247161865}
    Policy Grad Norm: {'avg': 3.9211809188127518, 'std': 4.655142848297803}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.992847378604915, 'std': 3.041629369370368, 'run': -7.080515686883352, 'test_avg': -6.844335754060559, 'test_std': 2.2078623266130193}
    Episode Length: {'avg': 5.159090909090909, 'std': 1.1688046132946128, 'run': 5.218127331551142, 'test_avg': 5.115234375, 'test_std': 0.8468705856377109}
    Ratio Terminated: {'avg': 0.9848484848484849, 'test_avg': 0.986328125}

Iteration (901 / 5000):
    Value Loss: {'avg': 1.661567259579897, 'std': 0.8529512964002408}
    Value Grad Norm: {'avg': 20.06365442276001, 'std': 9.196908164696971}
    Policy Loss: {'avg': 0.0025855667190626264, 'std': 0.012968958290767097}
    Total_Loss: {'avg': -0.038258601794950664, 'std': 0.01339819190130125}
    Policy Entropy: {'avg': 0.40514668822288513, 'std': 0.4767313301563263}
    KL Divergence: {'avg': 0.06704331934452057, 'std': 0.6525707244873047}
    Policy Grad Norm: {'avg': 2.783068347722292, 'std': 2.645803492502601}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.614835822464895, 'std': 2.4042414827117584, 'run': -6.762167706545339, 'test_avg': -6.767671059063236, 'test_std': 1.791992215284083}
    Episode Length: {'avg': 4.9975, 'std': 0.8499963235214608, 'run': 5.052194459037383, 'test_avg': 5.076171875, 'test_std': 0.6570371720526811}
    Ratio Terminated: {'avg': 0.995, 'test_avg': 0.9921875}

Iteration (1001 / 5000):
    Value Loss: {'avg': 5.163666605949402, 'std': 1.5448701183740317}
    Value Grad Norm: {'avg': 25.14876115322113, 'std': 8.711954504319342}
    Policy Loss: {'avg': -0.03723609785083681, 'std': 0.015857991194348307}
    Total_Loss: {'avg': -0.09556926786899567, 'std': 0.011897445695844985}
    Policy Entropy: {'avg': 0.635730504989624, 'std': 0.515449047088623}
    KL Divergence: {'avg': 0.033435117453336716, 'std': 0.22454485297203064}
    Policy Grad Norm: {'avg': 1.9845609702169895, 'std': 1.7076840880908442}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -10.00552905237183, 'std': 6.791752950968682, 'run': -8.636819582611954, 'test_avg': -6.836684393517768, 'test_std': 2.019472284921083}
    Episode Length: {'avg': 5.826829268292683, 'std': 1.6488760976752712, 'run': 5.507921587005224, 'test_avg': 5.09375, 'test_std': 0.6782042004440846}
    Ratio Terminated: {'avg': 0.9902439024390244, 'test_avg': 0.994140625}

Iteration (1101 / 5000):
    Value Loss: {'avg': 0.45595489007731277, 'std': 0.19301686042093147}
    Value Grad Norm: {'avg': 9.272446230053902, 'std': 4.634008752775628}
    Policy Loss: {'avg': 0.01495206297840923, 'std': 0.021293699118241884}
    Total_Loss: {'avg': -0.026340210577473044, 'std': 0.02152201577675796}
    Policy Entropy: {'avg': 0.42016470432281494, 'std': 0.470329225063324}
    KL Divergence: {'avg': 0.0212648194283247, 'std': 0.2253246009349823}
    Policy Grad Norm: {'avg': 3.6473712511360645, 'std': 3.987526186572162}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.413493405551175, 'std': 2.0894957773753218, 'run': -6.286504421101115, 'test_avg': -6.561255799897481, 'test_std': 0.6920627164108842}
    Episode Length: {'avg': 4.92018779342723, 'std': 0.7239795878385441, 'run': 4.867606245657861, 'test_avg': 5.0126953125, 'test_std': 0.16780685784713134}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 5000):
    Value Loss: {'avg': 2.019616807500521, 'std': 0.8601074838970753}
    Value Grad Norm: {'avg': 34.370365957419075, 'std': 14.267340067296983}
    Policy Loss: {'avg': 0.005407642340287566, 'std': 0.01198343367730664}
    Total_Loss: {'avg': -0.04150925704743713, 'std': 0.0113440238736048}
    Policy Entropy: {'avg': 0.5504488945007324, 'std': 0.4960714280605316}
    KL Divergence: {'avg': 0.0966913104057312, 'std': 0.5230079889297485}
    Policy Grad Norm: {'avg': 2.9297329001128674, 'std': 6.227031852598365}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.887656135908828, 'std': 3.4239946896668525, 'run': -6.809972744414769, 'test_avg': -6.692551166502076, 'test_std': 1.5081771584565244}
    Episode Length: {'avg': 5.110849056603773, 'std': 1.281020832556015, 'run': 5.113996653335889, 'test_avg': 5.0546875, 'test_std': 0.5237871966206792}
    Ratio Terminated: {'avg': 0.9787735849056604, 'test_avg': 0.99609375}

Iteration (1301 / 5000):
    Value Loss: {'avg': 0.6600065897218883, 'std': 0.3733779704568068}
    Value Grad Norm: {'avg': 6.716670056184133, 'std': 3.1084009480567163}
    Policy Loss: {'avg': 0.011252552969381213, 'std': 0.019346207089009547}
    Total_Loss: {'avg': -0.03114664857275784, 'std': 0.018195472850252133}
    Policy Entropy: {'avg': 0.5866920351982117, 'std': 0.6732229590415955}
    KL Divergence: {'avg': 0.2766602635383606, 'std': 0.7449526190757751}
    Policy Grad Norm: {'avg': 2.631546229124069, 'std': 1.578005490848805}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.339113376445843, 'std': 1.904289599617476, 'run': -6.350402844238165, 'test_avg': -12.501873610348097, 'test_std': 5.4534837168263595}
    Episode Length: {'avg': 4.899014778325123, 'std': 0.6600112066359551, 'run': 4.88755824580709, 'test_avg': 6.4580078125, 'test_std': 1.1022855942036822}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9853515625}

Iteration (1401 / 5000):
    Value Loss: {'avg': 1.2032702161620061, 'std': 0.6517166171200046}
    Value Grad Norm: {'avg': 15.943386842807135, 'std': 8.212180729916163}
    Policy Loss: {'avg': 0.0038279234431684017, 'std': 0.025073075506652047}
    Total_Loss: {'avg': -0.043999734334647655, 'std': 0.025886012447729267}
    Policy Entropy: {'avg': 0.42593055963516235, 'std': 0.5407970547676086}
    KL Divergence: {'avg': 0.06840837001800537, 'std': 0.6131879091262817}
    Policy Grad Norm: {'avg': 2.483682993799448, 'std': 1.6241664413091281}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.818103455853827, 'std': 2.6079348336819854, 'run': -6.827396114072244, 'test_avg': -6.617147961641589, 'test_std': 0.8641409694226915}
    Episode Length: {'avg': 5.056470588235294, 'std': 0.876684537645505, 'run': 5.03884375786334, 'test_avg': 5.0302734375, 'test_std': 0.3452545531661148}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 5000):
    Value Loss: {'avg': 0.5105598475784063, 'std': 0.20898969340845056}
    Value Grad Norm: {'avg': 6.723786229888598, 'std': 3.052680692541515}
    Policy Loss: {'avg': 0.0079223369830288, 'std': 0.01898459807344277}
    Total_Loss: {'avg': -0.030000997125171125, 'std': 0.01928569983721334}
    Policy Entropy: {'avg': 0.4163060188293457, 'std': 0.45891132950782776}
    KL Divergence: {'avg': 0.03024650737643242, 'std': 0.2941005527973175}
    Policy Grad Norm: {'avg': 2.8333138413727283, 'std': 1.9366346385659554}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.402105241331967, 'std': 1.857116703016741, 'run': -6.207375417840195, 'test_avg': -6.609927891928237, 'test_std': 0.9032996326405325}
    Episode Length: {'avg': 4.930288461538462, 'std': 0.633553708382585, 'run': 4.857881135394836, 'test_avg': 5.0234375, 'test_std': 0.25662605790088816}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 5000):
    Value Loss: {'avg': 0.6279604205240806, 'std': 0.33487424726118126}
    Value Grad Norm: {'avg': 8.524997060497602, 'std': 2.978029583971776}
    Policy Loss: {'avg': 0.026371481362730265, 'std': 0.10250735249593278}
    Total_Loss: {'avg': -0.014026819728314877, 'std': 0.10188794039463003}
    Policy Entropy: {'avg': 0.4238938093185425, 'std': 0.4820886254310608}
    KL Divergence: {'avg': 0.05408431589603424, 'std': 0.526436448097229}
    Policy Grad Norm: {'avg': 15.239844849333167, 'std': 51.408154212551075}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.592999927557662, 'std': 1.8915637220484918, 'run': -6.637077737144397, 'test_avg': -6.629618412864898, 'test_std': 1.2227259265706703}
    Episode Length: {'avg': 4.966507177033493, 'std': 0.617780989046247, 'run': 4.9862198783239124, 'test_avg': 5.0361328125, 'test_std': 0.461044040587057}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (1701 / 5000):
    Value Loss: {'avg': 0.5848846295848489, 'std': 0.3336302965107094}
    Value Grad Norm: {'avg': 10.907579054435095, 'std': 10.475835113105786}
    Policy Loss: {'avg': 0.01593753683846444, 'std': 0.035807938232494244}
    Total_Loss: {'avg': -0.017805167008191347, 'std': 0.03459094942621439}
    Policy Entropy: {'avg': 0.4001791477203369, 'std': 0.40826869010925293}
    KL Divergence: {'avg': 0.043084029108285904, 'std': 0.3993709087371826}
    Policy Grad Norm: {'avg': 2.85169942304492, 'std': 2.332723599841361}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.184248542974013, 'std': 2.444905109421967, 'run': -6.1198612155108725, 'test_avg': -6.632827077990175, 'test_std': 1.1740381426703057}
    Episode Length: {'avg': 4.869158878504673, 'std': 0.8492339830312908, 'run': 4.854864952611264, 'test_avg': 5.0458984375, 'test_std': 0.45804737302495097}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (1801 / 5000):
    Value Loss: {'avg': 0.3933206520353754, 'std': 0.2481052683831896}
    Value Grad Norm: {'avg': 7.591513628760974, 'std': 5.74022952639318}
    Policy Loss: {'avg': 0.00572224473580718, 'std': 0.016495852671514537}
    Total_Loss: {'avg': -0.028500486398115754, 'std': 0.017646525400310364}
    Policy Entropy: {'avg': 0.32063713669776917, 'std': 0.43659713864326477}
    KL Divergence: {'avg': 0.023103563115000725, 'std': 0.3590249717235565}
    Policy Grad Norm: {'avg': 1.6895363330841064, 'std': 0.745728925892494}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.296311411050212, 'std': 1.7453724836875022, 'run': -6.470413839795632, 'test_avg': -6.569039776803287, 'test_std': 0.7491809266157867}
    Episode Length: {'avg': 4.880095923261391, 'std': 0.623298251419967, 'run': 4.938392702436656, 'test_avg': 5.009765625, 'test_std': 0.22513525394384457}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 5000):
    Value Loss: {'avg': 0.3039455811182658, 'std': 0.2108611443972362}
    Value Grad Norm: {'avg': 4.362133527795474, 'std': 1.7556883534058285}
    Policy Loss: {'avg': 0.008108407841064036, 'std': 0.016142553483888142}
    Total_Loss: {'avg': -0.02383556088898331, 'std': 0.017217975239807528}
    Policy Entropy: {'avg': 0.29941168427467346, 'std': 0.3786626160144806}
    KL Divergence: {'avg': 0.05591953918337822, 'std': 0.7231307029724121}
    Policy Grad Norm: {'avg': 3.105428235605359, 'std': 2.656873294013238}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.341872323370316, 'std': 1.5703697788453859, 'run': -6.340255960746912, 'test_avg': -6.720699530056329, 'test_std': 1.501547949172026}
    Episode Length: {'avg': 4.902147971360382, 'std': 0.5591249274968794, 'run': 4.901139787826041, 'test_avg': 5.0703125, 'test_std': 0.5633132142456362}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (2001 / 5000):
    Value Loss: {'avg': 0.9628481355806192, 'std': 0.4852971197292832}
    Value Grad Norm: {'avg': 10.630255152781805, 'std': 4.210867781744376}
    Policy Loss: {'avg': 0.005289357795845717, 'std': 0.0233286063669894}
    Total_Loss: {'avg': -0.02963203634135425, 'std': 0.02427044638574318}
    Policy Entropy: {'avg': 0.38627225160598755, 'std': 0.44039180874824524}
    KL Divergence: {'avg': 0.045033399015665054, 'std': 0.4745272099971771}
    Policy Grad Norm: {'avg': 4.325021028518677, 'std': 7.649997051268229}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.340712129008536, 'std': 2.0568333777994727, 'run': -6.288132571876357, 'test_avg': -6.56437594706253, 'test_std': 0.8922357174266613}
    Episode Length: {'avg': 4.90307328605201, 'std': 0.74221890306466, 'run': 4.884668828680311, 'test_avg': 5.0166015625, 'test_std': 0.27371463355575015}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 5000):
    Value Loss: {'avg': 0.9081750313440958, 'std': 0.48855147845787417}
    Value Grad Norm: {'avg': 22.7064568400383, 'std': 14.842526905893797}
    Policy Loss: {'avg': 0.0052603320218622684, 'std': 0.007269664418673322}
    Total_Loss: {'avg': -0.03160345321521163, 'std': 0.008647816182211183}
    Policy Entropy: {'avg': 0.36928337812423706, 'std': 0.4217941164970398}
    KL Divergence: {'avg': 0.04889535903930664, 'std': 0.5277251601219177}
    Policy Grad Norm: {'avg': 3.9476657174527645, 'std': 4.278866630634584}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.230251445676514, 'std': 2.13329976474397, 'run': -6.243027409275985, 'test_avg': -6.609475758758846, 'test_std': 0.8800878885998167}
    Episode Length: {'avg': 4.868235294117647, 'std': 0.7860866236813827, 'run': 4.879197504085182, 'test_avg': 5.0185546875, 'test_std': 0.27358917389359055}
    Ratio Terminated: {'avg': 0.9976470588235294, 'test_avg': 0.9990234375}

Iteration (2201 / 5000):
    Value Loss: {'avg': 0.4776084553450346, 'std': 0.32122647778453917}
    Value Grad Norm: {'avg': 6.36890119065841, 'std': 3.526773456359136}
    Policy Loss: {'avg': 0.005817743600346148, 'std': 0.016676217500929517}
    Total_Loss: {'avg': -0.03357623633928597, 'std': 0.016012110322448217}
    Policy Entropy: {'avg': 0.3639832139015198, 'std': 0.47168397903442383}
    KL Divergence: {'avg': 0.03162499889731407, 'std': 0.425964891910553}
    Policy Grad Norm: {'avg': 5.244484215974808, 'std': 10.00940782549337}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.369707545461212, 'std': 1.7695219051105675, 'run': -6.401924127551322, 'test_avg': -6.600884959231735, 'test_std': 0.8428958144351504}
    Episode Length: {'avg': 4.892768079800499, 'std': 0.616459659911181, 'run': 4.912771211206189, 'test_avg': 5.01953125, 'test_std': 0.24923589282733236}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 5000):
    Value Loss: {'avg': 0.5221730275079608, 'std': 0.3291040712966854}
    Value Grad Norm: {'avg': 10.82988353073597, 'std': 6.740194085332865}
    Policy Loss: {'avg': 0.004401603015139699, 'std': 0.017309237582541905}
    Total_Loss: {'avg': -0.03424501058179885, 'std': 0.018076583095865302}
    Policy Entropy: {'avg': 0.37606754899024963, 'std': 0.4717981815338135}
    KL Divergence: {'avg': 0.02803240716457367, 'std': 0.3056196868419647}
    Policy Grad Norm: {'avg': 3.0124887079000473, 'std': 3.908180189640959}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.452223268321082, 'std': 2.0359601124268685, 'run': -6.362576173296284, 'test_avg': -6.591649961729097, 'test_std': 0.8405633211475042}
    Episode Length: {'avg': 4.946987951807229, 'std': 0.6745524798320824, 'run': 4.915829449126498, 'test_avg': 5.0224609375, 'test_std': 0.31635651374141344}
    Ratio Terminated: {'avg': 0.9975903614457832, 'test_avg': 0.9990234375}

Iteration (2401 / 5000):
    Value Loss: {'avg': 0.6012958446517587, 'std': 0.4544648487077684}
    Value Grad Norm: {'avg': 11.282884816328684, 'std': 7.383831810862827}
    Policy Loss: {'avg': 0.0013813099940307438, 'std': 0.011458732280064604}
    Total_Loss: {'avg': -0.03878644353244454, 'std': 0.01280372898611742}
    Policy Entropy: {'avg': 0.4086737036705017, 'std': 0.491176575422287}
    KL Divergence: {'avg': 0.01730981096625328, 'std': 0.1641393005847931}
    Policy Grad Norm: {'avg': 2.5042630061507225, 'std': 2.1937313060186687}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.229096982431731, 'std': 2.2445436994261287, 'run': -6.300269425056353, 'test_avg': -6.6989847787757295, 'test_std': 1.5487347038419714}
    Episode Length: {'avg': 4.844705882352941, 'std': 0.8199721490755133, 'run': 4.868437435070698, 'test_avg': 5.0703125, 'test_std': 0.6034871807617375}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (2501 / 5000):
    Value Loss: {'avg': 0.4803292296516399, 'std': 0.347421654471617}
    Value Grad Norm: {'avg': 5.331556166211764, 'std': 2.079195313303282}
    Policy Loss: {'avg': 0.009143650793703273, 'std': 0.031059559782512996}
    Total_Loss: {'avg': -0.02690587460529059, 'std': 0.030351751176574574}
    Policy Entropy: {'avg': 0.3423778712749481, 'std': 0.4030027687549591}
    KL Divergence: {'avg': 0.03198707103729248, 'std': 0.3743644058704376}
    Policy Grad Norm: {'avg': 1.9947380274534225, 'std': 1.3455595380455392}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.521003039367337, 'std': 1.2941297291053515, 'run': -6.602293083825489, 'test_avg': -6.595698428277128, 'test_std': 0.8926392761942118}
    Episode Length: {'avg': 4.958024691358025, 'std': 0.45619580957554573, 'run': 4.983902148544589, 'test_avg': 5.015625, 'test_std': 0.3089643739575811}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (2601 / 5000):
    Value Loss: {'avg': 0.5922879215019444, 'std': 0.3886467977761573}
    Value Grad Norm: {'avg': 8.826968237757683, 'std': 7.8842138135273565}
    Policy Loss: {'avg': 0.008858096087351441, 'std': 0.012927591719182322}
    Total_Loss: {'avg': -0.02717105799820274, 'std': 0.013753052310339887}
    Policy Entropy: {'avg': 0.37325364351272583, 'std': 0.47597503662109375}
    KL Divergence: {'avg': 0.022731449455022812, 'std': 0.30021700263023376}
    Policy Grad Norm: {'avg': 2.965812299400568, 'std': 1.6737430893886487}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.24073407377479, 'std': 2.194060075190884, 'run': -6.227429162124411, 'test_avg': -6.598393681633752, 'test_std': 0.9266467885235573}
    Episode Length: {'avg': 4.854368932038835, 'std': 0.7746940140116363, 'run': 4.832595279664517, 'test_avg': 5.0224609375, 'test_std': 0.27684642635696255}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 5000):
    Value Loss: {'avg': 1.1429398500670989, 'std': 0.687255267570214}
    Value Grad Norm: {'avg': 29.214073518912, 'std': 16.1141589521664}
    Policy Loss: {'avg': 0.0018805049476213753, 'std': 0.01864736851298893}
    Total_Loss: {'avg': -0.04123468929901719, 'std': 0.01807647161342657}
    Policy Entropy: {'avg': 0.43455109000205994, 'std': 0.5322234034538269}
    KL Divergence: {'avg': 0.08665146678686142, 'std': 0.8922314643859863}
    Policy Grad Norm: {'avg': 3.234831130132079, 'std': 5.360242041452975}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.267259552245939, 'std': 2.1168312566422043, 'run': -6.281431315758413, 'test_avg': -6.639475660767559, 'test_std': 1.109284876286368}
    Episode Length: {'avg': 4.860975609756098, 'std': 0.794916178670703, 'run': 4.854484039688694, 'test_avg': 5.037109375, 'test_std': 0.3488119397140949}
    Ratio Terminated: {'avg': 0.9975609756097561, 'test_avg': 0.9990234375}

Iteration (2801 / 5000):
    Value Loss: {'avg': 0.6630544131621718, 'std': 0.4077543733666409}
    Value Grad Norm: {'avg': 16.0746634354194, 'std': 14.886617340203616}
    Policy Loss: {'avg': -0.0009261249215342104, 'std': 0.014009054761302417}
    Total_Loss: {'avg': -0.0380227193236351, 'std': 0.014965246483853221}
    Policy Entropy: {'avg': 0.3645908832550049, 'std': 0.4409656226634979}
    KL Divergence: {'avg': 0.017359565943479538, 'std': 0.2372502237558365}
    Policy Grad Norm: {'avg': 2.8771488927304745, 'std': 4.159186108885736}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.5051929579396015, 'std': 1.7515313104211847, 'run': -6.438705122957204, 'test_avg': -6.698826923236503, 'test_std': 1.5349077784245415}
    Episode Length: {'avg': 4.9640287769784175, 'std': 0.6164422399082566, 'run': 4.94872684539307, 'test_avg': 5.064453125, 'test_std': 0.5374146859527886}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (2901 / 5000):
    Value Loss: {'avg': 0.46918635349720716, 'std': 0.3369530884752686}
    Value Grad Norm: {'avg': 5.3028601706027985, 'std': 1.857143474299355}
    Policy Loss: {'avg': 0.008770641637966037, 'std': 0.02711831581644688}
    Total_Loss: {'avg': -0.027053373400121927, 'std': 0.02479409441123343}
    Policy Entropy: {'avg': 0.31911298632621765, 'std': 0.44144555926322937}
    KL Divergence: {'avg': 0.02712559886276722, 'std': 0.3500451147556305}
    Policy Grad Norm: {'avg': 2.8693235516548157, 'std': 3.233343790461459}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.215243251571911, 'std': 1.8445018890914409, 'run': -6.4081347978244745, 'test_avg': -6.60359703035283, 'test_std': 0.6995741471514713}
    Episode Length: {'avg': 4.864406779661017, 'std': 0.6789943775883945, 'run': 4.9473604035993475, 'test_avg': 5.009765625, 'test_std': 0.18195537246357793}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 5000):
    Value Loss: {'avg': 0.35333741394182044, 'std': 0.3381001259784455}
    Value Grad Norm: {'avg': 6.424316431085269, 'std': 3.9767410922843447}
    Policy Loss: {'avg': 0.004025615577120334, 'std': 0.015507291357546357}
    Total_Loss: {'avg': -0.02988296328112483, 'std': 0.014316634402274228}
    Policy Entropy: {'avg': 0.4144021272659302, 'std': 0.45604053139686584}
    KL Divergence: {'avg': 0.023203950375318527, 'std': 0.37808752059936523}
    Policy Grad Norm: {'avg': 1.936165638267994, 'std': 1.1395426178364179}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.261710240553346, 'std': 2.3899495583073085, 'run': -6.250154303700514, 'test_avg': -6.571384527069313, 'test_std': 0.769717014123744}
    Episode Length: {'avg': 4.873536299765808, 'std': 0.8056750703229798, 'run': 4.869654619295636, 'test_avg': 5.0166015625, 'test_std': 0.19940774965521926}
    Ratio Terminated: {'avg': 0.9976580796252927, 'test_avg': 1.0}

Iteration (3101 / 5000):
    Value Loss: {'avg': 0.5371582298539579, 'std': 0.39642005664373253}
    Value Grad Norm: {'avg': 7.772143051028252, 'std': 4.3430479731835305}
    Policy Loss: {'avg': -0.002342165942536667, 'std': 0.008927422358043747}
    Total_Loss: {'avg': -0.04086280398769304, 'std': 0.008773985199797179}
    Policy Entropy: {'avg': 0.37813645601272583, 'std': 0.45749080181121826}
    KL Divergence: {'avg': 0.021059639751911163, 'std': 0.18906643986701965}
    Policy Grad Norm: {'avg': 1.8904123352840543, 'std': 1.7722177936971781}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.101458154005448, 'std': 2.030984794879311, 'run': -5.961464239109005, 'test_avg': -6.587640414348611, 'test_std': 1.1315432267072103}
    Episode Length: {'avg': 4.801418439716312, 'std': 0.7521743877198781, 'run': 4.755345507290148, 'test_avg': 5.029296875, 'test_std': 0.4087914420768057}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (3201 / 5000):
    Value Loss: {'avg': 0.25127986414978903, 'std': 0.16065409543739387}
    Value Grad Norm: {'avg': 5.082885143657525, 'std': 3.123815070849256}
    Policy Loss: {'avg': 0.01833527348935604, 'std': 0.05922035048392372}
    Total_Loss: {'avg': -0.019167431048117578, 'std': 0.059647243023012476}
    Policy Entropy: {'avg': 0.31532248854637146, 'std': 0.4351683557033539}
    KL Divergence: {'avg': 0.01752358302474022, 'std': 0.2487259805202484}
    Policy Grad Norm: {'avg': 2.7615387439727783, 'std': 4.641536947323842}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.482089658810114, 'std': 1.4357483779983717, 'run': -6.478075893251991, 'test_avg': -6.584323683109687, 'test_std': 0.7314341955476521}
    Episode Length: {'avg': 4.945945945945946, 'std': 0.5025996565543763, 'run': 4.943574027399041, 'test_avg': 5.0078125, 'test_std': 0.16517480087395292}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 5000):
    Value Loss: {'avg': 0.5309656234458089, 'std': 0.565490859434817}
    Value Grad Norm: {'avg': 10.715197776754698, 'std': 10.865533760731815}
    Policy Loss: {'avg': 0.00019579066429287195, 'std': 0.03282040809673801}
    Total_Loss: {'avg': -0.03761980787385255, 'std': 0.03233416454425339}
    Policy Entropy: {'avg': 0.39427661895751953, 'std': 0.44961321353912354}
    KL Divergence: {'avg': 0.07278188318014145, 'std': 0.37090542912483215}
    Policy Grad Norm: {'avg': 1.9147887178696692, 'std': 3.6229002205519345}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.354972746196282, 'std': 1.705944149388519, 'run': -6.3619086478787725, 'test_avg': -6.571767493923574, 'test_std': 0.860665995724101}
    Episode Length: {'avg': 4.896385542168675, 'std': 0.6102430452277211, 'run': 4.904246102651762, 'test_avg': 5.0185546875, 'test_std': 0.27358917389359055}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3401 / 5000):
    Value Loss: {'avg': 0.30495135268817347, 'std': 0.18929107112003016}
    Value Grad Norm: {'avg': 4.522162189086278, 'std': 1.50467464065647}
    Policy Loss: {'avg': -0.0006469819636549801, 'std': 0.01587091629369396}
    Total_Loss: {'avg': -0.039210154849570245, 'std': 0.016858849100565745}
    Policy Entropy: {'avg': 0.42857640981674194, 'std': 0.5047038197517395}
    KL Divergence: {'avg': 0.02759900875389576, 'std': 0.2747640013694763}
    Policy Grad Norm: {'avg': 2.8024841472506523, 'std': 5.678529724760793}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.39136266067047, 'std': 1.577312106563903, 'run': -6.4106476605485465, 'test_avg': -6.59237808790931, 'test_std': 1.0278567430422092}
    Episode Length: {'avg': 4.9352517985611515, 'std': 0.5567372373621061, 'run': 4.936987719935114, 'test_avg': 5.029296875, 'test_std': 0.32343537703107617}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 5000):
    Value Loss: {'avg': 0.21813129090393582, 'std': 0.11395282204652125}
    Value Grad Norm: {'avg': 4.522299913068612, 'std': 2.2625907776195824}
    Policy Loss: {'avg': 0.00967119901906699, 'std': 0.020817002794797815}
    Total_Loss: {'avg': -0.022344529046677053, 'std': 0.019243870597736558}
    Policy Entropy: {'avg': 0.37292763590812683, 'std': 0.47403430938720703}
    KL Divergence: {'avg': 0.026746422052383423, 'std': 0.26039236783981323}
    Policy Grad Norm: {'avg': 2.8503962345421314, 'std': 2.0143891370520626}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.229038130341962, 'std': 1.7713845896172498, 'run': -6.267972442626304, 'test_avg': -6.53490897622396, 'test_std': 0.704838533044071}
    Episode Length: {'avg': 4.878281622911694, 'std': 0.6641023204664455, 'run': 4.902472213525744, 'test_avg': 5.0107421875, 'test_std': 0.1845651454303191}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3601 / 5000):
    Value Loss: {'avg': 2.0790600453813872, 'std': 1.303242249480514}
    Value Grad Norm: {'avg': 22.954470331470173, 'std': 16.253658291285003}
    Policy Loss: {'avg': -0.00575782626401633, 'std': 0.013219039078230285}
    Total_Loss: {'avg': -0.04832951514981687, 'std': 0.01397748725517028}
    Policy Entropy: {'avg': 0.4137633442878723, 'std': 0.47386372089385986}
    KL Divergence: {'avg': 0.05569647252559662, 'std': 0.5459325909614563}
    Policy Grad Norm: {'avg': 2.997315337881446, 'std': 2.2818809127891133}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.508750274643579, 'std': 2.0130512818049473, 'run': -6.598797647367809, 'test_avg': -6.784523269686136, 'test_std': 1.864166387676433}
    Episode Length: {'avg': 4.962121212121212, 'std': 0.7791989835816603, 'run': 4.992401010748801, 'test_avg': 5.0869140625, 'test_std': 0.653464810253579}
    Ratio Terminated: {'avg': 0.9974747474747475, 'test_avg': 0.994140625}

Iteration (3701 / 5000):
    Value Loss: {'avg': 0.6024917725784084, 'std': 0.6828551911580276}
    Value Grad Norm: {'avg': 7.817079151670138, 'std': 5.309659364266193}
    Policy Loss: {'avg': 7.595401257276535e-06, 'std': 0.0061605945538459154}
    Total_Loss: {'avg': -0.034909790265373886, 'std': 0.007707600056452361}
    Policy Entropy: {'avg': 0.3187016546726227, 'std': 0.46214863657951355}
    KL Divergence: {'avg': 0.029240615665912628, 'std': 0.30501851439476013}
    Policy Grad Norm: {'avg': 2.8775607869029045, 'std': 2.610048984682737}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.228079298638481, 'std': 1.7029426345143235, 'run': -6.125288973447821, 'test_avg': -6.528712130297208, 'test_std': 0.515606041281928}
    Episode Length: {'avg': 4.863414634146341, 'std': 0.6253803126063355, 'run': 4.836289738198279, 'test_avg': 5.0029296875, 'test_std': 0.06981568184263721}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3801 / 5000):
    Value Loss: {'avg': 4.407646586497624, 'std': 1.469833933152345}
    Value Grad Norm: {'avg': 28.197296857833862, 'std': 23.16165907317328}
    Policy Loss: {'avg': -0.025124596315436065, 'std': 0.026964569342618407}
    Total_Loss: {'avg': -0.0948051055893302, 'std': 0.019373089570651373}
    Policy Entropy: {'avg': 0.5954973697662354, 'std': 0.3825436532497406}
    KL Divergence: {'avg': 0.14866213500499725, 'std': 0.7604406476020813}
    Policy Grad Norm: {'avg': 1.9480146393179893, 'std': 1.4343148649719861}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -7.53025466160511, 'std': 2.8683090836813325, 'run': -8.004401793306148, 'test_avg': -6.535941497189924, 'test_std': 0.5073787541716116}
    Episode Length: {'avg': 5.422857142857143, 'std': 1.1703688586535967, 'run': 5.6419054872208045, 'test_avg': 4.998046875, 'test_std': 0.08836676582705952}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 5000):
    Value Loss: {'avg': 0.19276729466704032, 'std': 0.11724416784055514}
    Value Grad Norm: {'avg': 3.4314139460523925, 'std': 1.5009247796518281}
    Policy Loss: {'avg': 0.002176036301534623, 'std': 0.005963961775410858}
    Total_Loss: {'avg': -0.0326784229837358, 'std': 0.005564720657329437}
    Policy Entropy: {'avg': 0.4122745096683502, 'std': 0.5257906317710876}
    KL Divergence: {'avg': 0.02849961817264557, 'std': 0.669553279876709}
    Policy Grad Norm: {'avg': 1.9824926443397999, 'std': 2.018831936197432}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.214419874815409, 'std': 1.9062837967809485, 'run': -5.960045677076705, 'test_avg': -6.531219930737279, 'test_std': 0.5225749399314639}
    Episode Length: {'avg': 4.869047619047619, 'std': 0.699995950749545, 'run': 4.760095895131375, 'test_avg': 5.0009765625, 'test_std': 0.08267396098944088}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4001 / 5000):
    Value Loss: {'avg': 0.39099184966956574, 'std': 0.3162469453605276}
    Value Grad Norm: {'avg': 12.024453148245811, 'std': 11.066156410478708}
    Policy Loss: {'avg': -0.000770244630984962, 'std': 0.008051937985413423}
    Total_Loss: {'avg': -0.036996181472204626, 'std': 0.00834622779397079}
    Policy Entropy: {'avg': 0.36988094449043274, 'std': 0.4184255301952362}
    KL Divergence: {'avg': 0.04197673499584198, 'std': 0.541299045085907}
    Policy Grad Norm: {'avg': 2.280145797878504, 'std': 2.994771650343718}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.360061396138152, 'std': 1.5918693818209444, 'run': -6.3855260234107805, 'test_avg': -6.555820715788286, 'test_std': 0.5503424312703541}
    Episode Length: {'avg': 4.913253012048193, 'std': 0.5784839105628473, 'run': 4.918908667764101, 'test_avg': 5.0078125, 'test_std': 0.10797089813347854}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 5000):
    Value Loss: {'avg': 0.2838484618502359, 'std': 0.1629613487121111}
    Value Grad Norm: {'avg': 4.843919078509013, 'std': 2.221824439277116}
    Policy Loss: {'avg': -0.0032574873184785247, 'std': 0.011843876001655403}
    Total_Loss: {'avg': -0.03826649289112538, 'std': 0.013258981112961699}
    Policy Entropy: {'avg': 0.4574683904647827, 'std': 0.4800008535385132}
    KL Divergence: {'avg': 0.05200325325131416, 'std': 0.42863911390304565}
    Policy Grad Norm: {'avg': 2.203095719218254, 'std': 1.4994447068856367}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.398530014323199, 'std': 1.7998484668369918, 'run': -6.5068018966054, 'test_avg': -6.640747823526908, 'test_std': 1.0838274490896191}
    Episode Length: {'avg': 4.933491686460807, 'std': 0.6319629097419838, 'run': 4.9729053388909445, 'test_avg': 5.0361328125, 'test_std': 0.33897692747566144}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4201 / 5000):
    Value Loss: {'avg': 0.27286464953795075, 'std': 0.16237180830265355}
    Value Grad Norm: {'avg': 3.8917556727925935, 'std': 1.4612843046278219}
    Policy Loss: {'avg': 0.0022603090619668365, 'std': 0.015251964718539674}
    Total_Loss: {'avg': -0.03399864211678505, 'std': 0.016524822059294345}
    Policy Entropy: {'avg': 0.3395705819129944, 'std': 0.43733125925064087}
    KL Divergence: {'avg': 0.02180316485464573, 'std': 0.2563978433609009}
    Policy Grad Norm: {'avg': 1.8951069302856922, 'std': 1.1710645121158292}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.164658278997726, 'std': 1.9317998858523617, 'run': -5.999324306458525, 'test_avg': -6.549172497718246, 'test_std': 0.7567669715515489}
    Episode Length: {'avg': 4.850779510022272, 'std': 0.7203720691258075, 'run': 4.8090656570570145, 'test_avg': 5.0107421875, 'test_std': 0.2046382000207069}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4301 / 5000):
    Value Loss: {'avg': 0.5818793655683597, 'std': 0.42524974488342504}
    Value Grad Norm: {'avg': 10.751413971185684, 'std': 5.948468590909969}
    Policy Loss: {'avg': -0.007403661526041105, 'std': 0.012148925430186116}
    Total_Loss: {'avg': -0.04706964088836685, 'std': 0.014084371511851391}
    Policy Entropy: {'avg': 0.4757683575153351, 'std': 0.4670897424221039}
    KL Divergence: {'avg': 0.02578211948275566, 'std': 0.26402971148490906}
    Policy Grad Norm: {'avg': 1.65268009994179, 'std': 1.268653176651657}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.443361253921486, 'std': 2.0934948549389967, 'run': -6.402775525853083, 'test_avg': -6.525489472631307, 'test_std': 0.485091013040276}
    Episode Length: {'avg': 4.9170616113744074, 'std': 0.7221892014213007, 'run': 4.901301075132631, 'test_avg': 5.001953125, 'test_std': 0.062469474967654204}
    Ratio Terminated: {'avg': 0.9976303317535545, 'test_avg': 1.0}

Iteration (4401 / 5000):
    Value Loss: {'avg': 0.26223139837384224, 'std': 0.18026603311551817}
    Value Grad Norm: {'avg': 4.527904788653056, 'std': 2.093229570082524}
    Policy Loss: {'avg': -0.0027418932877480984, 'std': 0.0079454997571933}
    Total_Loss: {'avg': -0.037376966211013496, 'std': 0.00912369462599134}
    Policy Entropy: {'avg': 0.29866600036621094, 'std': 0.47583484649658203}
    KL Divergence: {'avg': 0.03092072531580925, 'std': 0.3870202302932739}
    Policy Grad Norm: {'avg': 2.109018100425601, 'std': 2.255583509960914}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.328378905219145, 'std': 1.8422672766785149, 'run': -6.436985933409948, 'test_avg': -6.530329680567107, 'test_std': 0.5178389992194122}
    Episode Length: {'avg': 4.901204819277108, 'std': 0.6853886376028478, 'run': 4.966428656225133, 'test_avg': 5.0087890625, 'test_std': 0.10327119579229774}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4501 / 5000):
    Value Loss: {'avg': 0.24420257083450755, 'std': 0.11665175889989843}
    Value Grad Norm: {'avg': 5.681497280796369, 'std': 4.715983643203066}
    Policy Loss: {'avg': -0.0028786944458261132, 'std': 0.014777370180497162}
    Total_Loss: {'avg': -0.041193130309693515, 'std': 0.014603495729301702}
    Policy Entropy: {'avg': 0.38793328404426575, 'std': 0.4650280773639679}
    KL Divergence: {'avg': 0.016295021399855614, 'std': 0.19172166287899017}
    Policy Grad Norm: {'avg': 2.01898505538702, 'std': 1.9681384014894128}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -6.453558497403259, 'std': 1.6910402910799398, 'run': -6.380341020009082, 'test_avg': -6.524072094834992, 'test_std': 0.6239519581685261}
    Episode Length: {'avg': 4.949880668257757, 'std': 0.5861314742373741, 'run': 4.921593345718296, 'test_avg': 5.0087890625, 'test_std': 0.1429355270056087}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4601 / 5000):
    Value Loss: {'avg': 0.34879549592733383, 'std': 0.414613841248525}
    Value Grad Norm: {'avg': 4.09279066324234, 'std': 2.535216096038317}
    Policy Loss: {'avg': -0.00184253987390548, 'std': 0.011758257671703683}
    Total_Loss: {'avg': -0.03839074831921607, 'std': 0.011034121805537204}
    Policy Entropy: {'avg': 0.3337504267692566, 'std': 0.41891345381736755}
    KL Divergence: {'avg': 0.019180238246917725, 'std': 0.23403508961200714}
    Policy Grad Norm: {'avg': 2.0448827017098665, 'std': 1.2442719666698845}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.249784350382818, 'std': 1.9097208268350843, 'run': -6.378664744683936, 'test_avg': -6.547445201722439, 'test_std': 0.6981026562124463}
    Episode Length: {'avg': 4.8631090487238975, 'std': 0.6793668300207965, 'run': 4.917645548322907, 'test_avg': 5.0107421875, 'test_std': 0.1845651454303191}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4701 / 5000):
    Value Loss: {'avg': 0.19382644025608897, 'std': 0.1228111670949767}
    Value Grad Norm: {'avg': 2.678539179265499, 'std': 0.8640171735843528}
    Policy Loss: {'avg': 0.002424414793495089, 'std': 0.007101824309769025}
    Total_Loss: {'avg': -0.031609398080036044, 'std': 0.008344296839933952}
    Policy Entropy: {'avg': 0.3880506157875061, 'std': 0.4873698353767395}
    KL Divergence: {'avg': 0.031675178557634354, 'std': 0.38073915243148804}
    Policy Grad Norm: {'avg': 1.5996450074017048, 'std': 0.7265623417911528}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.327451070137773, 'std': 1.549621388805621, 'run': -6.235353353961412, 'test_avg': -6.671825281751808, 'test_std': 1.1441954819635258}
    Episode Length: {'avg': 4.918072289156626, 'std': 0.5622983340372126, 'run': 4.883494768711568, 'test_avg': 5.0419921875, 'test_std': 0.32354592979817387}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4801 / 5000):
    Value Loss: {'avg': 1.0933904473980267, 'std': 0.8203170621218754}
    Value Grad Norm: {'avg': 20.314851840337116, 'std': 12.196692707260985}
    Policy Loss: {'avg': 0.002146280836313963, 'std': 0.011693353230025025}
    Total_Loss: {'avg': -0.0368388332426548, 'std': 0.0128147175587531}
    Policy Entropy: {'avg': 0.37994566559791565, 'std': 0.4547131359577179}
    KL Divergence: {'avg': 0.03588947653770447, 'std': 0.3766344487667084}
    Policy Grad Norm: {'avg': 2.9499738961458206, 'std': 3.550906853558803}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.623595271851247, 'std': 2.5057620414771327, 'run': -6.616631290920768, 'test_avg': -6.520759332939633, 'test_std': 0.49333090966135457}
    Episode Length: {'avg': 5.055555555555555, 'std': 1.08316299911988, 'run': 5.041174197340274, 'test_avg': 5.0009765625, 'test_std': 0.05411777735350551}
    Ratio Terminated: {'avg': 0.9927536231884058, 'test_avg': 1.0}

Iteration (4901 / 5000):
    Value Loss: {'avg': 1.1600870887438457, 'std': 0.7956288000421156}
    Value Grad Norm: {'avg': 25.907859692970913, 'std': 16.053771845813735}
    Policy Loss: {'avg': 0.004839282191824168, 'std': 0.027641642946092906}
    Total_Loss: {'avg': -0.033023320604115725, 'std': 0.027068064744041304}
    Policy Entropy: {'avg': 0.3524722456932068, 'std': 0.4339098632335663}
    KL Divergence: {'avg': 0.062287140637636185, 'std': 0.5753783583641052}
    Policy Grad Norm: {'avg': 2.8522587548941374, 'std': 4.783606089762799}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -6.334731879835703, 'std': 2.9470406510481086, 'run': -6.387882914407, 'test_avg': -6.661569066398041, 'test_std': 1.1567042561999146}
    Episode Length: {'avg': 4.910377358490566, 'std': 1.1016650558751597, 'run': 4.9301378112760785, 'test_avg': 5.0615234375, 'test_std': 0.4387526970152817}
    Ratio Terminated: {'avg': 0.9929245283018868, 'test_avg': 0.998046875}

Training took 8284.468 seconds in total.
