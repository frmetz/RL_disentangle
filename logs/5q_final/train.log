
Iteration (1 / 10000):
    Value Loss: {'avg': 885.6465749740601, 'std': 183.68364616629776}
    Value Grad Norm: {'avg': 142.17411101361117, 'std': 132.80522315900103}
    Policy Loss: {'avg': -0.002535296616163881, 'std': 0.007310263332286712}
    Total_Loss: {'avg': -0.23232503367277482, 'std': 0.007323213137025984}
    Policy Entropy: {'avg': 2.299391984939575, 'std': 0.0054315198212862015}
    KL Divergence: {'avg': 0.00316316494718194, 'std': 0.08331896364688873}
    Policy Grad Norm: {'avg': 0.14826246323840073, 'std': 0.05881269003507195}
    Num PPO updates: {'avg': 192}
    Return: {'avg': -44.76373604261505, 'std': 55.21584592049778, 'run': -53.42007142026052, 'test_avg': -183.06439234438736, 'test_std': 12.644824168506037}
    Episode Length: {'avg': 15.287769784172662, 'std': 13.658692265463639, 'run': 17.450646421851335, 'test_avg': 39.970703125, 'test_std': 0.5422762839321248}
    Ratio Terminated: {'avg': 0.8609112709832134, 'test_avg': 0.00390625}

Iteration (101 / 10000):
    Value Loss: {'avg': 161.3178040186564, 'std': 25.154957557464098}
    Value Grad Norm: {'avg': 3767.2631158828735, 'std': 2571.8118259648068}
    Policy Loss: {'avg': 0.00027151815811521374, 'std': 0.014511180108934646}
    Total_Loss: {'avg': -0.1903409124352038, 'std': 0.014503336968843336}
    Policy Entropy: {'avg': 1.9394365549087524, 'std': 0.2446417510509491}
    KL Divergence: {'avg': 0.01546353567391634, 'std': 0.17391610145568848}
    Policy Grad Norm: {'avg': 2.005265240557492, 'std': 0.8122207126020147}
    Num PPO updates: {'avg': 128}
    Return: {'avg': -32.289509828446725, 'std': 54.29577723214535, 'run': -30.54291587819261, 'test_avg': -110.96952545539423, 'test_std': 14.395335136999918}
    Episode Length: {'avg': 10.270100502512562, 'std': 12.638624714076531, 'run': 9.894451964515499, 'test_avg': 28.7060546875, 'test_std': 3.250979789349555}
    Ratio Terminated: {'avg': 0.9673366834170855, 'test_avg': 0.9970703125}

Iteration (201 / 10000):
    Value Loss: {'avg': 117.85286470254262, 'std': 19.52515508713853}
    Value Grad Norm: {'avg': 3104.2087666193643, 'std': 2220.7856437333594}
    Policy Loss: {'avg': 0.012267454745597206, 'std': 0.017038507120411814}
    Total_Loss: {'avg': -0.1557584748370573, 'std': 0.016603681748464244}
    Policy Entropy: {'avg': 1.5831125974655151, 'std': 0.45811647176742554}
    KL Divergence: {'avg': 0.019690141081809998, 'std': 0.19248974323272705}
    Policy Grad Norm: {'avg': 1.944206427782774, 'std': 0.7158006485263979}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -28.9467633393174, 'std': 47.34221482743624, 'run': -34.085910661869804, 'test_avg': -101.76345388289657, 'test_std': 13.630570183382229}
    Episode Length: {'avg': 9.330296127562642, 'std': 11.068548791493225, 'run': 10.635829120862713, 'test_avg': 26.2392578125, 'test_std': 3.069886156139624}
    Ratio Terminated: {'avg': 0.9977220956719818, 'test_avg': 0.998046875}

Iteration (301 / 10000):
    Value Loss: {'avg': 100.58970367908478, 'std': 17.090694165632335}
    Value Grad Norm: {'avg': 2058.873882293701, 'std': 1152.6911752466763}
    Policy Loss: {'avg': 0.004443649377208203, 'std': 0.013495200700621901}
    Total_Loss: {'avg': -0.1673632739111781, 'std': 0.012840491380581878}
    Policy Entropy: {'avg': 1.6919255256652832, 'std': 0.36586177349090576}
    KL Divergence: {'avg': 0.01672210544347763, 'std': 0.19650599360466003}
    Policy Grad Norm: {'avg': 1.5975613398477435, 'std': 0.4678611199811886}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -26.63690118330644, 'std': 46.593633809709935, 'run': -25.562624508844234, 'test_avg': -99.5038140268762, 'test_std': 13.491171927770923}
    Episode Length: {'avg': 8.835706462212487, 'std': 10.861437154121798, 'run': 8.604635817290205, 'test_avg': 25.666015625, 'test_std': 3.2112742894769766}
    Ratio Terminated: {'avg': 0.9945235487404163, 'test_avg': 0.9931640625}

Iteration (401 / 10000):
    Value Loss: {'avg': 76.55562561750412, 'std': 13.327238269104257}
    Value Grad Norm: {'avg': 2297.8003985087075, 'std': 1552.1077367041455}
    Policy Loss: {'avg': -0.0010757565978565253, 'std': 0.015249929103805722}
    Total_Loss: {'avg': -0.15904142381623387, 'std': 0.014554861899972439}
    Policy Entropy: {'avg': 1.629302740097046, 'std': 0.35009878873825073}
    KL Divergence: {'avg': 0.015170646831393242, 'std': 0.18356621265411377}
    Policy Grad Norm: {'avg': 1.6309037818573415, 'std': 0.41612878815507054}
    Num PPO updates: {'avg': 128}
    Return: {'avg': -26.845409238502747, 'std': 45.52700881431171, 'run': -27.963202463133477, 'test_avg': -98.03615008119992, 'test_std': 13.045414562225588}
    Episode Length: {'avg': 8.763333333333334, 'std': 10.812060652602515, 'run': 8.944260920250333, 'test_avg': 25.4287109375, 'test_std': 3.054005422321295}
    Ratio Terminated: {'avg': 0.9988888888888889, 'test_avg': 0.9951171875}

Iteration (501 / 10000):
    Value Loss: {'avg': 69.40488386154175, 'std': 12.260088876316555}
    Value Grad Norm: {'avg': 1449.2547839482625, 'std': 723.6362843648084}
    Policy Loss: {'avg': 0.005525592059711926, 'std': 0.013998233017241016}
    Total_Loss: {'avg': -0.14881033159326762, 'std': 0.012644697915064335}
    Policy Entropy: {'avg': 1.5498006343841553, 'std': 0.4380313456058502}
    KL Divergence: {'avg': 0.02333858236670494, 'std': 0.22178027033805847}
    Policy Grad Norm: {'avg': 1.9152497928589582, 'std': 0.6173390969497641}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -23.314925911395726, 'std': 43.40005976255387, 'run': -24.555750586842354, 'test_avg': -95.32089801715959, 'test_std': 13.000346392896992}
    Episode Length: {'avg': 7.939901477832512, 'std': 10.16975783263937, 'run': 8.168392251640231, 'test_avg': 24.7578125, 'test_std': 3.018487550056112}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (601 / 10000):
    Value Loss: {'avg': 58.503867169221245, 'std': 10.898091431425284}
    Value Grad Norm: {'avg': 1596.047125339508, 'std': 1061.9572918803767}
    Policy Loss: {'avg': 0.011754217048292048, 'std': 0.013222051953546853}
    Total_Loss: {'avg': -0.13613405369687825, 'std': 0.01362537441762246}
    Policy Entropy: {'avg': 1.473093032836914, 'std': 0.3771362900733948}
    KL Divergence: {'avg': 0.03165735304355621, 'std': 0.2367953360080719}
    Policy Grad Norm: {'avg': 1.9075683634728193, 'std': 0.6215891133488343}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -23.306804529747353, 'std': 42.364778284801, 'run': -27.04555071065583, 'test_avg': -91.76476323413536, 'test_std': 11.226301408923936}
    Episode Length: {'avg': 7.923001949317738, 'std': 10.04031431062477, 'run': 8.813660795342042, 'test_avg': 23.84765625, 'test_std': 2.650956927570861}
    Ratio Terminated: {'avg': 0.9990253411306043, 'test_avg': 0.9990234375}

Iteration (701 / 10000):
    Value Loss: {'avg': 47.77973658839861, 'std': 9.077075087917182}
    Value Grad Norm: {'avg': 1007.9995829264323, 'std': 573.5287242317473}
    Policy Loss: {'avg': 0.0058378698013257235, 'std': 0.01503491792687068}
    Total_Loss: {'avg': -0.13217802392318845, 'std': 0.014865279696612827}
    Policy Entropy: {'avg': 1.3173590898513794, 'std': 0.5250901579856873}
    KL Divergence: {'avg': 0.02852380834519863, 'std': 0.24229934811592102}
    Policy Grad Norm: {'avg': 2.6470884289592505, 'std': 1.083118640621328}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -22.04358387566654, 'std': 40.57877691536207, 'run': -21.191485249219852, 'test_avg': -88.86481049585831, 'test_std': 9.99028856562445}
    Episode Length: {'avg': 7.606392694063927, 'std': 9.516117318204305, 'run': 7.457857859339106, 'test_avg': 23.0576171875, 'test_std': 2.262033918225938}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 10000):
    Value Loss: {'avg': 45.17373372117678, 'std': 9.244110615668408}
    Value Grad Norm: {'avg': 1089.4374111493428, 'std': 684.7029267701412}
    Policy Loss: {'avg': 0.008909760028473102, 'std': 0.013915358882827532}
    Total_Loss: {'avg': -0.1234389488818124, 'std': 0.01586278192794449}
    Policy Entropy: {'avg': 1.2965906858444214, 'std': 0.41816428303718567}
    KL Divergence: {'avg': 0.017230898141860962, 'std': 0.18144288659095764}
    Policy Grad Norm: {'avg': 3.3530187159776688, 'std': 1.3782130465128066}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -23.243076435124582, 'std': 41.007131705123975, 'run': -24.815740109123798, 'test_avg': -89.30750934340979, 'test_std': 10.075283331254525}
    Episode Length: {'avg': 7.8869731800766285, 'std': 9.579605113645359, 'run': 8.264919371398399, 'test_avg': 23.1328125, 'test_std': 2.2767372959662584}
    Ratio Terminated: {'avg': 0.9990421455938697, 'test_avg': 1.0}

Iteration (901 / 10000):
    Value Loss: {'avg': 40.80127663413683, 'std': 7.805380818884105}
    Value Grad Norm: {'avg': 790.9354786872864, 'std': 428.6154856191317}
    Policy Loss: {'avg': 0.006471550805144943, 'std': 0.01696339693885948}
    Total_Loss: {'avg': -0.13596679200418293, 'std': 0.01699455371352629}
    Policy Entropy: {'avg': 1.450846791267395, 'std': 0.468185693025589}
    KL Divergence: {'avg': 0.032215096056461334, 'std': 0.226134791970253}
    Policy Grad Norm: {'avg': 2.356756780296564, 'std': 0.9766073665387455}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -22.573320124973538, 'std': 40.297917060885084, 'run': -19.146925246675632, 'test_avg': -86.57636863134282, 'test_std': 8.86870514212793}
    Episode Length: {'avg': 7.707749766573296, 'std': 9.427076528483852, 'run': 6.852586353462529, 'test_avg': 22.3544921875, 'test_std': 1.9395954736752365}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1001 / 10000):
    Value Loss: {'avg': 46.19682548443476, 'std': 8.159670033936434}
    Value Grad Norm: {'avg': 871.5279003779093, 'std': 462.7145835000114}
    Policy Loss: {'avg': 0.009779160456673708, 'std': 0.014304533714670135}
    Total_Loss: {'avg': -0.12047423946205527, 'std': 0.014423882557430651}
    Policy Entropy: {'avg': 1.3018790483474731, 'std': 0.4893106520175934}
    KL Divergence: {'avg': 0.019636597484350204, 'std': 0.20939843356609344}
    Policy Grad Norm: {'avg': 3.5387186221778393, 'std': 2.190913576382525}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -21.930610605045718, 'std': 40.0802538988888, 'run': -21.866892664869084, 'test_avg': -86.1187493731855, 'test_std': 9.088416202255301}
    Episode Length: {'avg': 7.516187050359712, 'std': 9.371226273241552, 'run': 7.469047031845064, 'test_avg': 22.396484375, 'test_std': 1.9943835552322575}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 10000):
    Value Loss: {'avg': 41.042991856733956, 'std': 7.626085082563757}
    Value Grad Norm: {'avg': 697.2415585517883, 'std': 309.6557442004573}
    Policy Loss: {'avg': 0.008713154413271695, 'std': 0.015821155084530095}
    Total_Loss: {'avg': -0.1245171616319567, 'std': 0.015789785036958243}
    Policy Entropy: {'avg': 1.3041317462921143, 'std': 0.5575929880142212}
    KL Divergence: {'avg': 0.026204314082860947, 'std': 0.22599484026432037}
    Policy Grad Norm: {'avg': 3.2295164987444878, 'std': 1.5678285071356342}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -20.96120978136546, 'std': 38.176096080520665, 'run': -23.195085697897373, 'test_avg': -84.06600949949102, 'test_std': 8.15743483565296}
    Episode Length: {'avg': 7.270318021201414, 'std': 8.902856307326198, 'run': 7.888617535278801, 'test_avg': 21.7646484375, 'test_std': 1.797426620067926}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 10000):
    Value Loss: {'avg': 34.4464750289917, 'std': 7.3286953310438685}
    Value Grad Norm: {'avg': 707.282106479009, 'std': 323.4765748092697}
    Policy Loss: {'avg': 0.010641398694133386, 'std': 0.017159439539793268}
    Total_Loss: {'avg': -0.11505115544423461, 'std': 0.016738137585934006}
    Policy Entropy: {'avg': 1.2922472953796387, 'std': 0.5006888508796692}
    KL Divergence: {'avg': 0.055250994861125946, 'std': 0.2948179841041565}
    Policy Grad Norm: {'avg': 3.069632031954825, 'std': 1.5339192818379408}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -21.354613870598794, 'std': 38.01219287202961, 'run': -17.864578680354114, 'test_avg': -83.88650247196352, 'test_std': 8.283871489712308}
    Episode Length: {'avg': 7.312888888888889, 'std': 8.88613717407869, 'run': 6.524582396474898, 'test_avg': 21.826171875, 'test_std': 1.8368670768346262}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 10000):
    Value Loss: {'avg': 34.011460373799004, 'std': 6.545206850535928}
    Value Grad Norm: {'avg': 588.3862419128418, 'std': 233.09834105904235}
    Policy Loss: {'avg': 0.013597061129985377, 'std': 0.020647350594779592}
    Total_Loss: {'avg': -0.10567871248349547, 'std': 0.02121100230171249}
    Policy Entropy: {'avg': 1.192408561706543, 'std': 0.4827146828174591}
    KL Divergence: {'avg': 0.03485344350337982, 'std': 0.2558845579624176}
    Policy Grad Norm: {'avg': 2.9771399116143584, 'std': 1.6210866453223973}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -20.784066204969438, 'std': 37.121913410291185, 'run': -23.22123074623137, 'test_avg': -82.13747110067047, 'test_std': 8.043253903285294}
    Episode Length: {'avg': 7.2491071428571425, 'std': 8.590874472532242, 'run': 7.844683493067466, 'test_avg': 21.27734375, 'test_std': 1.7369025431312886}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 10000):
    Value Loss: {'avg': 39.69127133488655, 'std': 7.489018143707341}
    Value Grad Norm: {'avg': 687.8615601857504, 'std': 289.88682574028616}
    Policy Loss: {'avg': 0.009837438614340499, 'std': 0.015657145243216344}
    Total_Loss: {'avg': -0.11710790416691452, 'std': 0.01596511935457176}
    Policy Entropy: {'avg': 1.1960837841033936, 'std': 0.5521442294120789}
    KL Divergence: {'avg': 0.037410613149404526, 'std': 0.24151718616485596}
    Policy Grad Norm: {'avg': 2.6715137604624033, 'std': 1.2626071996201074}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.6188618138754, 'std': 37.36399077562484, 'run': -20.303112164555444, 'test_avg': -81.79810099092614, 'test_std': 7.743369319084646}
    Episode Length: {'avg': 6.94585448392555, 'std': 8.74717912890628, 'run': 7.100587939428463, 'test_avg': 21.337890625, 'test_std': 1.7096605805062914}
    Ratio Terminated: {'avg': 0.9991539763113367, 'test_avg': 1.0}

Iteration (1501 / 10000):
    Value Loss: {'avg': 36.74514150619507, 'std': 7.400670421483343}
    Value Grad Norm: {'avg': 705.5103782018026, 'std': 279.6666328405881}
    Policy Loss: {'avg': 0.008802265569102019, 'std': 0.016590582336921435}
    Total_Loss: {'avg': -0.11876015132293105, 'std': 0.015881247631500995}
    Policy Entropy: {'avg': 1.1792250871658325, 'std': 0.5146951079368591}
    KL Divergence: {'avg': 0.023120658472180367, 'std': 0.2279302328824997}
    Policy Grad Norm: {'avg': 2.6927696391940117, 'std': 1.0156978092370168}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -21.290150125401453, 'std': 38.688738432632064, 'run': -19.886597799963486, 'test_avg': -82.94884409492988, 'test_std': 8.465809545275837}
    Episode Length: {'avg': 7.341092211280215, 'std': 9.053063695824994, 'run': 7.096078716801831, 'test_avg': 21.619140625, 'test_std': 1.9119956554539055}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 10000):
    Value Loss: {'avg': 31.785634418328602, 'std': 5.951670764532576}
    Value Grad Norm: {'avg': 654.9716038703918, 'std': 274.3857720949023}
    Policy Loss: {'avg': 0.00848247081739828, 'std': 0.014785022963954455}
    Total_Loss: {'avg': -0.11281652154866606, 'std': 0.01601593589448483}
    Policy Entropy: {'avg': 1.2083154916763306, 'std': 0.5558474063873291}
    KL Divergence: {'avg': 0.03303508460521698, 'std': 0.25464266538619995}
    Policy Grad Norm: {'avg': 2.6451246328651905, 'std': 0.9308578597300665}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -23.319619052308706, 'std': 39.06159887905603, 'run': -22.649058749054298, 'test_avg': -81.49238127853131, 'test_std': 7.673797552977494}
    Episode Length: {'avg': 7.807400379506642, 'std': 9.12094063886006, 'run': 7.5791016530035185, 'test_avg': 21.2802734375, 'test_std': 1.7186254282803841}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 10000):
    Value Loss: {'avg': 36.966757506132126, 'std': 7.101166257137441}
    Value Grad Norm: {'avg': 799.1392062505087, 'std': 349.12060446908527}
    Policy Loss: {'avg': 0.005277895703329705, 'std': 0.012385213701464904}
    Total_Loss: {'avg': -0.12111887836363167, 'std': 0.013616476422107966}
    Policy Entropy: {'avg': 1.3294167518615723, 'std': 0.5361849069595337}
    KL Divergence: {'avg': 0.02131463959813118, 'std': 0.18364809453487396}
    Policy Grad Norm: {'avg': 2.8229076974093914, 'std': 1.1725961492477963}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -22.311584451355905, 'std': 38.64905937437466, 'run': -21.289004657579174, 'test_avg': -80.41278707415051, 'test_std': 7.63205067371171}
    Episode Length: {'avg': 7.628494138863841, 'std': 9.058120100342009, 'run': 7.485895880740335, 'test_avg': 21.0458984375, 'test_std': 1.67787846578203}
    Ratio Terminated: {'avg': 0.9990982867448152, 'test_avg': 1.0}

Iteration (1801 / 10000):
    Value Loss: {'avg': 29.98191209634145, 'std': 6.572046729339986}
    Value Grad Norm: {'avg': 559.7602163950602, 'std': 210.07285221037353}
    Policy Loss: {'avg': 0.009414615124114789, 'std': 0.015985765412903082}
    Total_Loss: {'avg': -0.1095953636104241, 'std': 0.016029485900173786}
    Policy Entropy: {'avg': 1.2253360748291016, 'std': 0.5437732338905334}
    KL Divergence: {'avg': 0.042717695236206055, 'std': 0.2841043174266815}
    Policy Grad Norm: {'avg': 3.0620648749172688, 'std': 1.3938233588054278}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.983914659401233, 'std': 35.4920052681346, 'run': -17.482917696736717, 'test_avg': -80.54858594453859, 'test_std': 7.982508845445242}
    Episode Length: {'avg': 6.76, 'std': 8.291489612850034, 'run': 6.3173575482625655, 'test_avg': 20.923828125, 'test_std': 1.6280196084381122}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1901 / 10000):
    Value Loss: {'avg': 31.237943122784298, 'std': 6.212160129200206}
    Value Grad Norm: {'avg': 593.2097454865774, 'std': 255.98831870765522}
    Policy Loss: {'avg': 0.005014428752474487, 'std': 0.014475362400532167}
    Total_Loss: {'avg': -0.11812144867144525, 'std': 0.014295755331084526}
    Policy Entropy: {'avg': 1.2874853610992432, 'std': 0.49450069665908813}
    KL Divergence: {'avg': 0.03344929218292236, 'std': 0.28201672434806824}
    Policy Grad Norm: {'avg': 2.507481040433049, 'std': 0.8293529413718514}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -23.237748519824095, 'std': 38.51000408082656, 'run': -23.98414663200351, 'test_avg': -81.96936756754266, 'test_std': 9.177812039137203}
    Episode Length: {'avg': 7.867549668874172, 'std': 9.078208334232993, 'run': 7.973175205781228, 'test_avg': 21.501953125, 'test_std': 2.080413705324673}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 10000):
    Value Loss: {'avg': 33.402742053071655, 'std': 6.8864599284561425}
    Value Grad Norm: {'avg': 571.6584742863973, 'std': 175.1501611324109}
    Policy Loss: {'avg': 0.00812298351956997, 'std': 0.017553325940738985}
    Total_Loss: {'avg': -0.12026732799131423, 'std': 0.017575337707264466}
    Policy Entropy: {'avg': 1.2033973932266235, 'std': 0.5571504831314087}
    KL Divergence: {'avg': 0.0549764558672905, 'std': 0.3559300899505615}
    Policy Grad Norm: {'avg': 3.392710005864501, 'std': 2.5703788830039374}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -20.38361144281349, 'std': 37.74042455171348, 'run': -18.20867303077661, 'test_avg': -96.52820020029432, 'test_std': 34.60508482859073}
    Episode Length: {'avg': 7.118838028169014, 'std': 8.731567953781932, 'run': 6.721393821163547, 'test_avg': 24.724609375, 'test_std': 7.73804141909709}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.8017578125}

Iteration (2101 / 10000):
    Value Loss: {'avg': 25.70758192737897, 'std': 5.0426587287296885}
    Value Grad Norm: {'avg': 516.8522657553355, 'std': 196.44625868881488}
    Policy Loss: {'avg': 0.009744562790729105, 'std': 0.014596669989527317}
    Total_Loss: {'avg': -0.10622939537279308, 'std': 0.014658885678736834}
    Policy Entropy: {'avg': 1.059802532196045, 'std': 0.6031503081321716}
    KL Divergence: {'avg': 0.031309328973293304, 'std': 0.2673969268798828}
    Policy Grad Norm: {'avg': 3.354214834049344, 'std': 1.5357807094899798}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.43235956898058, 'std': 34.94783167097225, 'run': -18.939749754674057, 'test_avg': -79.8827136086311, 'test_std': 7.555319753312102}
    Episode Length: {'avg': 6.651465798045603, 'std': 8.155593360581587, 'run': 6.724108609806658, 'test_avg': 20.84375, 'test_std': 1.58884047736077}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 10000):
    Value Loss: {'avg': 33.98532028992971, 'std': 7.061705125041295}
    Value Grad Norm: {'avg': 611.5838863054911, 'std': 223.56729550001367}
    Policy Loss: {'avg': 0.004361416715255473, 'std': 0.01540072866553764}
    Total_Loss: {'avg': -0.1170578186865896, 'std': 0.015229007514807064}
    Policy Entropy: {'avg': 1.2937710285186768, 'std': 0.5726233124732971}
    KL Divergence: {'avg': 0.028978435322642326, 'std': 0.26419785618782043}
    Policy Grad Norm: {'avg': 2.303832817822695, 'std': 1.1459824644964072}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.55808537504692, 'std': 36.80973794207128, 'run': -19.283128343529135, 'test_avg': -80.51865962742835, 'test_std': 7.664244238400196}
    Episode Length: {'avg': 6.894028595458368, 'std': 8.514206581446425, 'run': 6.745611896928157, 'test_avg': 21.048828125, 'test_std': 1.693149857280502}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 10000):
    Value Loss: {'avg': 30.03934832413991, 'std': 7.060397200514439}
    Value Grad Norm: {'avg': 704.0291163126627, 'std': 358.8195203532113}
    Policy Loss: {'avg': 0.004257251319359057, 'std': 0.014770103209485208}
    Total_Loss: {'avg': -0.11415931163355708, 'std': 0.014575215858442727}
    Policy Entropy: {'avg': 1.2417829036712646, 'std': 0.5443622469902039}
    KL Divergence: {'avg': 0.018500927835702896, 'std': 0.16827818751335144}
    Policy Grad Norm: {'avg': 3.060440448112786, 'std': 1.4751252360876659}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.23593929526761, 'std': 36.013911800138416, 'run': -23.89166798455221, 'test_avg': -79.5490659501154, 'test_std': 8.182357500474241}
    Episode Length: {'avg': 6.906542056074766, 'std': 8.48556771792377, 'run': 7.961758313281786, 'test_avg': 20.7802734375, 'test_std': 1.7341811613069533}
    Ratio Terminated: {'avg': 0.9991503823279524, 'test_avg': 0.9990234375}

Iteration (2401 / 10000):
    Value Loss: {'avg': 27.589961389700573, 'std': 6.534924738759238}
    Value Grad Norm: {'avg': 606.2390882174174, 'std': 274.7992976963344}
    Policy Loss: {'avg': 0.0033985234040301293, 'std': 0.014935895424080876}
    Total_Loss: {'avg': -0.11884014518000185, 'std': 0.014917479943896408}
    Policy Entropy: {'avg': 1.1488044261932373, 'std': 0.5606665015220642}
    KL Divergence: {'avg': 0.023522237315773964, 'std': 0.21940818428993225}
    Policy Grad Norm: {'avg': 2.3066196776926517, 'std': 0.9093318342552972}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.570600544129235, 'std': 34.79374550505924, 'run': -16.555212866738405, 'test_avg': -79.94841844659021, 'test_std': 7.701032612428953}
    Episode Length: {'avg': 6.442457231726283, 'std': 8.157910883349656, 'run': 6.1972529581341576, 'test_avg': 21.0087890625, 'test_std': 1.7027439076033632}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 10000):
    Value Loss: {'avg': 28.282847344875336, 'std': 5.651426259947768}
    Value Grad Norm: {'avg': 576.4281602700552, 'std': 205.17768537199458}
    Policy Loss: {'avg': 0.0034814389364328235, 'std': 0.013085537146211761}
    Total_Loss: {'avg': -0.11455411440692842, 'std': 0.01297451484115648}
    Policy Entropy: {'avg': 1.1518583297729492, 'std': 0.5585851669311523}
    KL Divergence: {'avg': 0.022714979946613312, 'std': 0.1922997236251831}
    Policy Grad Norm: {'avg': 2.627863137051463, 'std': 1.1873258712152575}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.419754709905785, 'std': 35.413085741342805, 'run': -19.45690092889285, 'test_avg': -80.21075954111447, 'test_std': 9.995678764976764}
    Episode Length: {'avg': 6.708809135399674, 'std': 8.325604919570974, 'run': 7.046170979337247, 'test_avg': 21.0419921875, 'test_std': 2.100314879652326}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (2601 / 10000):
    Value Loss: {'avg': 21.179502720634144, 'std': 4.813988725553959}
    Value Grad Norm: {'avg': 456.2094456354777, 'std': 199.1394366577696}
    Policy Loss: {'avg': 0.009374110188218765, 'std': 0.015740381748336335}
    Total_Loss: {'avg': -0.10123335651587695, 'std': 0.016545745279979682}
    Policy Entropy: {'avg': 1.1185578107833862, 'std': 0.6064175367355347}
    KL Divergence: {'avg': 0.0286771971732378, 'std': 0.2142898291349411}
    Policy Grad Norm: {'avg': 2.674207117408514, 'std': 1.1343746883662835}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -20.054807852133933, 'std': 35.38186462687139, 'run': -17.561609300820326, 'test_avg': -79.27652344350835, 'test_std': 7.004874840838421}
    Episode Length: {'avg': 7.064069264069264, 'std': 8.2128217187485, 'run': 6.545956431095851, 'test_avg': 20.7265625, 'test_std': 1.4991656208017012}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 10000):
    Value Loss: {'avg': 23.739331796765327, 'std': 5.5066404730550556}
    Value Grad Norm: {'avg': 425.90605815251666, 'std': 155.477984796984}
    Policy Loss: {'avg': 0.005708598531782627, 'std': 0.015189447061886066}
    Total_Loss: {'avg': -0.10231251979712397, 'std': 0.01620275632325791}
    Policy Entropy: {'avg': 1.1181461811065674, 'std': 0.5360054969787598}
    KL Divergence: {'avg': 0.024938728660345078, 'std': 0.21202974021434784}
    Policy Grad Norm: {'avg': 2.8966056536883116, 'std': 1.5236799890669588}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.900107418870945, 'std': 34.61227350149051, 'run': -20.165599493145173, 'test_avg': -78.8048379631958, 'test_std': 7.182588825775653}
    Episode Length: {'avg': 6.738626964433416, 'std': 8.098106372244036, 'run': 7.0177284554455355, 'test_avg': 20.7021484375, 'test_std': 1.5706522559803964}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 10000):
    Value Loss: {'avg': 21.655371795097988, 'std': 4.355007677346879}
    Value Grad Norm: {'avg': 520.9383125305176, 'std': 227.69154069317457}
    Policy Loss: {'avg': 0.010869182195165195, 'std': 0.01422052608709234}
    Total_Loss: {'avg': -0.1023348392918706, 'std': 0.01526890899342346}
    Policy Entropy: {'avg': 1.1399714946746826, 'std': 0.4830567240715027}
    KL Divergence: {'avg': 0.03146357089281082, 'std': 0.20031967759132385}
    Policy Grad Norm: {'avg': 2.6418300047516823, 'std': 1.176502643933337}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -21.217003333642037, 'std': 36.165266143201855, 'run': -19.222339186402603, 'test_avg': -79.05816527494918, 'test_std': 7.135550749180185}
    Episode Length: {'avg': 7.267618198037466, 'std': 8.45746636554608, 'run': 6.722950407702333, 'test_avg': 20.7216796875, 'test_std': 1.5212295573482335}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 10000):
    Value Loss: {'avg': 21.15367624660333, 'std': 4.468305182477727}
    Value Grad Norm: {'avg': 433.60356998443604, 'std': 147.3541015162837}
    Policy Loss: {'avg': 0.005588015788816847, 'std': 0.013996664793982993}
    Total_Loss: {'avg': -0.10555303911678493, 'std': 0.014387246501865892}
    Policy Entropy: {'avg': 1.2316006422042847, 'std': 0.5568247437477112}
    KL Divergence: {'avg': 0.020012732595205307, 'std': 0.1845443695783615}
    Policy Grad Norm: {'avg': 2.9050189200788736, 'std': 1.0644397812298878}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.027868875167286, 'std': 35.207199941098075, 'run': -17.063851517597683, 'test_avg': -78.38574806595628, 'test_std': 6.9005797437902165}
    Episode Length: {'avg': 6.767536704730832, 'std': 8.215329440425458, 'run': 6.2709458237002575, 'test_avg': 20.55078125, 'test_std': 1.4893368959535105}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 10000):
    Value Loss: {'avg': 27.978143115838368, 'std': 5.5024260394311515}
    Value Grad Norm: {'avg': 569.6601835091909, 'std': 265.43933498219025}
    Policy Loss: {'avg': 0.009357703631394543, 'std': 0.016706869559530484}
    Total_Loss: {'avg': -0.10276584513485432, 'std': 0.017610012859863508}
    Policy Entropy: {'avg': 1.0590709447860718, 'std': 0.536712110042572}
    KL Divergence: {'avg': 0.020658792927861214, 'std': 0.21476531028747559}
    Policy Grad Norm: {'avg': 2.7450767159461975, 'std': 1.0108320683905727}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -21.50654104863917, 'std': 37.10275700864608, 'run': -21.984578995078447, 'test_avg': -78.61318751180457, 'test_std': 7.44057014555776}
    Episode Length: {'avg': 7.314005352363961, 'std': 8.711321809468686, 'run': 7.4301356765818465, 'test_avg': 20.5791015625, 'test_std': 1.574824138692971}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3101 / 10000):
    Value Loss: {'avg': 23.606968755523365, 'std': 4.536361995931489}
    Value Grad Norm: {'avg': 429.3981331189473, 'std': 156.7759521872926}
    Policy Loss: {'avg': 0.0036525978066492826, 'std': 0.01699960893331595}
    Total_Loss: {'avg': -0.10814014635980129, 'std': 0.015493065055889387}
    Policy Entropy: {'avg': 1.106186866760254, 'std': 0.545824408531189}
    KL Divergence: {'avg': 0.02406216226518154, 'std': 0.20716102421283722}
    Policy Grad Norm: {'avg': 3.2682360373437405, 'std': 2.0834374508718927}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.716327268450915, 'std': 35.654550097449466, 'run': -21.940734662619715, 'test_avg': -78.33477078846562, 'test_std': 7.583109387370701}
    Episode Length: {'avg': 6.982112436115843, 'std': 8.26254785588764, 'run': 7.509270251367912, 'test_avg': 20.6396484375, 'test_std': 1.6405596038863717}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 10000):
    Value Loss: {'avg': 25.309842487176258, 'std': 5.8268125572404195}
    Value Grad Norm: {'avg': 480.7664747238159, 'std': 185.1727581892125}
    Policy Loss: {'avg': 0.0038866317772772163, 'std': 0.014947376763354274}
    Total_Loss: {'avg': -0.10454834718257189, 'std': 0.01533901231573822}
    Policy Entropy: {'avg': 1.1434977054595947, 'std': 0.5289644598960876}
    KL Divergence: {'avg': 0.023663459345698357, 'std': 0.19231955707073212}
    Policy Grad Norm: {'avg': 2.782957447692752, 'std': 1.1051555984518788}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.16655850203825, 'std': 34.19359307584507, 'run': -16.535061324071865, 'test_avg': -78.54636382801404, 'test_std': 7.699570574453863}
    Episode Length: {'avg': 6.5792, 'std': 8.019608928121121, 'run': 6.277038099792968, 'test_avg': 20.720703125, 'test_std': 1.667743462171336}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 10000):
    Value Loss: {'avg': 18.479017540812492, 'std': 3.9501496951359263}
    Value Grad Norm: {'avg': 475.6392599741618, 'std': 229.9711334323591}
    Policy Loss: {'avg': 0.010526696656597778, 'std': 0.029339185340558703}
    Total_Loss: {'avg': -0.09290173812769353, 'std': 0.029539836765120543}
    Policy Entropy: {'avg': 1.0931990146636963, 'std': 0.6111937165260315}
    KL Divergence: {'avg': 0.0244353748857975, 'std': 0.20805372297763824}
    Policy Grad Norm: {'avg': 3.286357307806611, 'std': 2.385577945309885}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.15894658659045, 'std': 33.84228222200006, 'run': -13.311674173703212, 'test_avg': -78.25958087796232, 'test_std': 7.098893743729078}
    Episode Length: {'avg': 6.5369340746624305, 'std': 7.957543843640052, 'run': 5.5060091697967035, 'test_avg': 20.5400390625, 'test_std': 1.5137257424890815}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 10000):
    Value Loss: {'avg': 17.34723012149334, 'std': 3.792057498556429}
    Value Grad Norm: {'avg': 355.4587826728821, 'std': 126.50061567644478}
    Policy Loss: {'avg': 0.010220403906714637, 'std': 0.027364592095360168}
    Total_Loss: {'avg': -0.09288982907310128, 'std': 0.027932692716415814}
    Policy Entropy: {'avg': 1.0358721017837524, 'std': 0.5258687734603882}
    KL Divergence: {'avg': 0.03337138146162033, 'std': 0.264366090297699}
    Policy Grad Norm: {'avg': 3.2340518664568663, 'std': 3.235914037977822}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.98549078197563, 'std': 33.59295442985539, 'run': -20.01367582488122, 'test_avg': -78.65085096786433, 'test_std': 7.329731157665885}
    Episode Length: {'avg': 6.529223378702962, 'std': 7.855030737282242, 'run': 6.963162513335002, 'test_avg': 20.5283203125, 'test_std': 1.5616180982877672}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 10000):
    Value Loss: {'avg': 28.88303458193938, 'std': 6.857509180636318}
    Value Grad Norm: {'avg': 605.8957789738973, 'std': 264.9031438485018}
    Policy Loss: {'avg': 0.0057887465809471905, 'std': 0.01480921806152698}
    Total_Loss: {'avg': -0.11102793272584677, 'std': 0.015418309922897206}
    Policy Entropy: {'avg': 1.1025395393371582, 'std': 0.5470916032791138}
    KL Divergence: {'avg': 0.02152785286307335, 'std': 0.224988654255867}
    Policy Grad Norm: {'avg': 3.4397067865356803, 'std': 3.046770047792968}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.349710874166966, 'std': 34.05375280531851, 'run': -19.90544828075953, 'test_avg': -78.69294467037457, 'test_std': 9.287246099208936}
    Episode Length: {'avg': 6.421800947867299, 'std': 8.02478183222753, 'run': 7.0570068357090685, 'test_avg': 20.802734375, 'test_std': 2.0879472630297347}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3601 / 10000):
    Value Loss: {'avg': 21.234074210127194, 'std': 4.372565646644039}
    Value Grad Norm: {'avg': 447.7174415588379, 'std': 187.26702644647716}
    Policy Loss: {'avg': 0.01220536936307326, 'std': 0.015053262684322142}
    Total_Loss: {'avg': -0.10239845816977322, 'std': 0.014814407091958592}
    Policy Entropy: {'avg': 1.0837078094482422, 'std': 0.5420058965682983}
    KL Divergence: {'avg': 0.0401226170361042, 'std': 0.29949119687080383}
    Policy Grad Norm: {'avg': 3.227691311389208, 'std': 1.7615623185989058}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.40906100426966, 'std': 33.782467169899526, 'run': -18.02668886829504, 'test_avg': -79.39084238609107, 'test_std': 14.323988300802409}
    Episode Length: {'avg': 6.692619626926196, 'std': 7.899947274588959, 'run': 6.590005685869684, 'test_avg': 20.798828125, 'test_std': 2.636240552701704}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.98828125}

Iteration (3701 / 10000):
    Value Loss: {'avg': 18.513488451639812, 'std': 4.212806636927147}
    Value Grad Norm: {'avg': 364.1215142409007, 'std': 130.86057065142674}
    Policy Loss: {'avg': 0.009038310905452818, 'std': 0.012876257219220158}
    Total_Loss: {'avg': -0.09019830456236377, 'std': 0.012647783575433611}
    Policy Entropy: {'avg': 0.8751912117004395, 'std': 0.5886551737785339}
    KL Divergence: {'avg': 0.024068128317594528, 'std': 0.20817042887210846}
    Policy Grad Norm: {'avg': 3.1408035764470696, 'std': 1.3570899592634356}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.110443741639966, 'std': 34.375150871803896, 'run': -21.35514733261249, 'test_avg': -77.96744166181966, 'test_std': 7.676665097660025}
    Episode Length: {'avg': 6.8144416456759025, 'std': 8.035604627701693, 'run': 7.36722929426272, 'test_avg': 20.4697265625, 'test_std': 1.5628316908681925}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3801 / 10000):
    Value Loss: {'avg': 21.954649319251377, 'std': 4.261895915408548}
    Value Grad Norm: {'avg': 382.9064576625824, 'std': 134.83997254610503}
    Policy Loss: {'avg': 0.005532965064048767, 'std': 0.01710727687420172}
    Total_Loss: {'avg': -0.10115259361919016, 'std': 0.017045623256160842}
    Policy Entropy: {'avg': 1.0550956726074219, 'std': 0.5263367295265198}
    KL Divergence: {'avg': 0.029105599969625473, 'std': 0.21826939284801483}
    Policy Grad Norm: {'avg': 2.8241265136748552, 'std': 1.081384335917648}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.544197295525738, 'std': 34.752608446369656, 'run': -19.015484083849767, 'test_avg': -77.52349066726984, 'test_std': 6.836436426912867}
    Episode Length: {'avg': 6.92274678111588, 'std': 8.11383850515966, 'run': 6.833408737601135, 'test_avg': 20.4228515625, 'test_std': 1.4663894839336882}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 10000):
    Value Loss: {'avg': 21.139427095651627, 'std': 4.6632395924273515}
    Value Grad Norm: {'avg': 394.5561529795329, 'std': 130.4947426688499}
    Policy Loss: {'avg': 0.005977303080726415, 'std': 0.01848249367617896}
    Total_Loss: {'avg': -0.09937783516943455, 'std': 0.01849133367397496}
    Policy Entropy: {'avg': 1.0452510118484497, 'std': 0.5949341654777527}
    KL Divergence: {'avg': 0.02689765952527523, 'std': 0.22430506348609924}
    Policy Grad Norm: {'avg': 2.9640168752521276, 'std': 1.443120972931516}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.821118415020557, 'std': 33.47369962036797, 'run': -18.439214288274584, 'test_avg': -77.374177772852, 'test_std': 7.29586505788393}
    Episode Length: {'avg': 6.506533435818601, 'std': 7.865275774068495, 'run': 6.672498004931439, 'test_avg': 20.3896484375, 'test_std': 1.530781265450361}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4001 / 10000):
    Value Loss: {'avg': 20.250483497977257, 'std': 4.086636399542201}
    Value Grad Norm: {'avg': 414.4603439172109, 'std': 165.1443237202678}
    Policy Loss: {'avg': 0.009384265344124287, 'std': 0.013124931620245108}
    Total_Loss: {'avg': -0.09433369117323309, 'std': 0.012695245601763223}
    Policy Entropy: {'avg': 1.0076632499694824, 'std': 0.5500083565711975}
    KL Divergence: {'avg': 0.028495872393250465, 'std': 0.25218772888183594}
    Policy Grad Norm: {'avg': 2.936874732375145, 'std': 1.195310961367231}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.604938853576794, 'std': 35.22322963381143, 'run': -21.78973586366919, 'test_avg': -77.92545297440584, 'test_std': 8.225729856269849}
    Episode Length: {'avg': 6.898319327731093, 'std': 8.222672930167976, 'run': 7.433503209073234, 'test_avg': 20.5185546875, 'test_std': 1.6995080460450245}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4101 / 10000):
    Value Loss: {'avg': 21.087880238890648, 'std': 4.165375032336915}
    Value Grad Norm: {'avg': 419.8968340555827, 'std': 161.36851372570672}
    Policy Loss: {'avg': 0.0029481999881681986, 'std': 0.010215431617074019}
    Total_Loss: {'avg': -0.10828907683026046, 'std': 0.01154513822837757}
    Policy Entropy: {'avg': 1.114976406097412, 'std': 0.5517789125442505}
    KL Divergence: {'avg': 0.022901330143213272, 'std': 0.20024973154067993}
    Policy Grad Norm: {'avg': 3.182400284335017, 'std': 1.7849379516521902}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.817846611753033, 'std': 34.74070875487529, 'run': -20.39505654964164, 'test_avg': -76.88643662560223, 'test_std': 6.964448824273927}
    Episode Length: {'avg': 6.7435064935064934, 'std': 8.158084392261246, 'run': 7.187969467540962, 'test_avg': 20.2978515625, 'test_std': 1.4882860559100555}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4201 / 10000):
    Value Loss: {'avg': 17.576521133383114, 'std': 3.403919804057529}
    Value Grad Norm: {'avg': 368.6811270713806, 'std': 154.0943492957356}
    Policy Loss: {'avg': 0.00887212881934829, 'std': 0.02783786187610462}
    Total_Loss: {'avg': -0.09091863199137151, 'std': 0.025917637010582105}
    Policy Entropy: {'avg': 1.0220831632614136, 'std': 0.5873069763183594}
    KL Divergence: {'avg': 0.024838274344801903, 'std': 0.24375441670417786}
    Policy Grad Norm: {'avg': 3.1492762453854084, 'std': 3.0280325139250017}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.494790743507846, 'std': 33.29292565434754, 'run': -15.464191684054743, 'test_avg': -77.23238800736114, 'test_std': 7.85900909513905}
    Episode Length: {'avg': 6.412083656080558, 'std': 7.81440265419923, 'run': 5.8868045308310055, 'test_avg': 20.3486328125, 'test_std': 1.613704154902112}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4301 / 10000):
    Value Loss: {'avg': 21.244699329137802, 'std': 4.616835932818572}
    Value Grad Norm: {'avg': 367.2307658990224, 'std': 124.11137656851439}
    Policy Loss: {'avg': 0.0026380172494100407, 'std': 0.011881291623311986}
    Total_Loss: {'avg': -0.10106032330077142, 'std': 0.013434387428720116}
    Policy Entropy: {'avg': 1.034287452697754, 'std': 0.5834673643112183}
    KL Divergence: {'avg': 0.023650532588362694, 'std': 0.20956651866436005}
    Policy Grad Norm: {'avg': 3.588575765490532, 'std': 2.127527113921427}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.882046426925648, 'std': 33.93513827142745, 'run': -15.03695335233235, 'test_avg': -78.00025101501541, 'test_std': 7.51759043549154}
    Episode Length: {'avg': 6.5107057890563045, 'std': 7.958810771166465, 'run': 5.766794503156564, 'test_avg': 20.5234375, 'test_std': 1.607914233904828}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 10000):
    Value Loss: {'avg': 22.28525861601035, 'std': 4.293401777069135}
    Value Grad Norm: {'avg': 409.86096596717834, 'std': 152.6921851306016}
    Policy Loss: {'avg': 0.003416354360524565, 'std': 0.01429104518005166}
    Total_Loss: {'avg': -0.11193198466207832, 'std': 0.014523157972308113}
    Policy Entropy: {'avg': 1.2107138633728027, 'std': 0.5351058840751648}
    KL Divergence: {'avg': 0.02438884973526001, 'std': 0.2235879898071289}
    Policy Grad Norm: {'avg': 2.465603619813919, 'std': 1.9213371654248668}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.57271359253217, 'std': 34.85724429281688, 'run': -16.12174556051104, 'test_avg': -77.62925722685472, 'test_std': 7.182881682445043}
    Episode Length: {'avg': 6.66011466011466, 'std': 8.13622487824718, 'run': 6.056861181064794, 'test_avg': 20.3359375, 'test_std': 1.5189035094744334}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4501 / 10000):
    Value Loss: {'avg': 22.78277662396431, 'std': 4.590228504832381}
    Value Grad Norm: {'avg': 440.0483275254567, 'std': 206.86330855650235}
    Policy Loss: {'avg': 0.006936075631529093, 'std': 0.015889920703159578}
    Total_Loss: {'avg': -0.09858746570535004, 'std': 0.01754555425107815}
    Policy Entropy: {'avg': 1.0339505672454834, 'std': 0.46678054332733154}
    KL Divergence: {'avg': 0.028674762696027756, 'std': 0.21805328130722046}
    Policy Grad Norm: {'avg': 2.9627199564129114, 'std': 2.3171859799747225}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.96593254909749, 'std': 34.785189014974556, 'run': -17.708593674217326, 'test_avg': -77.33634296959146, 'test_std': 6.993034009958895}
    Episode Length: {'avg': 6.7724252491694354, 'std': 8.144543682281105, 'run': 6.507760571397693, 'test_avg': 20.3984375, 'test_std': 1.4761904293124752}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4601 / 10000):
    Value Loss: {'avg': 19.875164672732353, 'std': 4.796648204681441}
    Value Grad Norm: {'avg': 323.3791803518931, 'std': 114.93892924704308}
    Policy Loss: {'avg': 0.009658205664891284, 'std': 0.020039461736442332}
    Total_Loss: {'avg': -0.0909046443994157, 'std': 0.019851441938953288}
    Policy Entropy: {'avg': 0.9811049699783325, 'std': 0.5761493444442749}
    KL Divergence: {'avg': 0.05679821968078613, 'std': 0.32139527797698975}
    Policy Grad Norm: {'avg': 3.2706138901412487, 'std': 2.647042304181343}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.46560595745056, 'std': 32.91652422901632, 'run': -19.554535494139, 'test_avg': -90.48334682689331, 'test_std': 33.904740846126}
    Episode Length: {'avg': 6.445505171042164, 'std': 7.7499976700392414, 'run': 6.885088278579362, 'test_avg': 23.126953125, 'test_std': 6.824208408603355}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.865234375}

Iteration (4701 / 10000):
    Value Loss: {'avg': 19.822144642472267, 'std': 4.117284722093234}
    Value Grad Norm: {'avg': 363.9179068406423, 'std': 133.35347358171725}
    Policy Loss: {'avg': 0.007071012485539541, 'std': 0.01400033214886378}
    Total_Loss: {'avg': -0.09260562143754214, 'std': 0.014029066119584748}
    Policy Entropy: {'avg': 0.9991077184677124, 'std': 0.5929862856864929}
    KL Divergence: {'avg': 0.03392137587070465, 'std': 0.25063779950141907}
    Policy Grad Norm: {'avg': 2.6608894634991884, 'std': 1.3191747691051054}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.234633112658113, 'std': 33.5331229006967, 'run': -15.854342932702309, 'test_avg': -76.99701717072863, 'test_std': 10.094804374094043}
    Episode Length: {'avg': 6.563346613545817, 'std': 7.877180413720209, 'run': 5.920443477953781, 'test_avg': 20.322265625, 'test_std': 1.9358996272904645}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (4801 / 10000):
    Value Loss: {'avg': 17.77051381270091, 'std': 3.6012659057797403}
    Value Grad Norm: {'avg': 389.6356822649638, 'std': 184.02332991855096}
    Policy Loss: {'avg': 0.008735317744140048, 'std': 0.015353757086166724}
    Total_Loss: {'avg': -0.08681389241246507, 'std': 0.01647015846707378}
    Policy Entropy: {'avg': 1.0046977996826172, 'std': 0.5267457962036133}
    KL Divergence: {'avg': 0.022188574075698853, 'std': 0.18052296340465546}
    Policy Grad Norm: {'avg': 3.690116750076413, 'std': 2.907119460031545}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.218081408434845, 'std': 33.40580257700263, 'run': -17.809201163598985, 'test_avg': -76.56812174324634, 'test_std': 6.997632225133294}
    Episode Length: {'avg': 6.655227454110135, 'std': 7.832904701169434, 'run': 6.628217316258128, 'test_avg': 20.248046875, 'test_std': 1.4614165637499579}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4901 / 10000):
    Value Loss: {'avg': 19.928642561038334, 'std': 4.33047167333944}
    Value Grad Norm: {'avg': 388.26180211702984, 'std': 146.1717109973769}
    Policy Loss: {'avg': 0.006501584968646057, 'std': 0.012120058613751997}
    Total_Loss: {'avg': -0.09961512580048293, 'std': 0.012362083145127864}
    Policy Entropy: {'avg': 0.9829157590866089, 'std': 0.5169147849082947}
    KL Divergence: {'avg': 0.02619013749063015, 'std': 0.22885160148143768}
    Policy Grad Norm: {'avg': 3.0899300947785378, 'std': 1.3811951794028137}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.54592273110732, 'std': 34.088382887863226, 'run': -21.068034776631592, 'test_avg': -76.74521465986803, 'test_std': 8.070613835107153}
    Episode Length: {'avg': 6.6994266994266995, 'std': 7.996758638940875, 'run': 7.269413423096943, 'test_avg': 20.255859375, 'test_std': 1.632484220513206}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5001 / 10000):
    Value Loss: {'avg': 19.2582735568285, 'std': 4.3016706792052455}
    Value Grad Norm: {'avg': 324.00373522440594, 'std': 113.83985473875018}
    Policy Loss: {'avg': 0.003611970489146188, 'std': 0.010175944672460807}
    Total_Loss: {'avg': -0.09121502144262195, 'std': 0.010719619035860065}
    Policy Entropy: {'avg': 1.0177123546600342, 'std': 0.5784642100334167}
    KL Divergence: {'avg': 0.025811588391661644, 'std': 0.2210453748703003}
    Policy Grad Norm: {'avg': 2.98684861138463, 'std': 1.0904541508136236}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.852010839815975, 'std': 33.802415917199866, 'run': -19.434527088094736, 'test_avg': -76.41196014341884, 'test_std': 7.162751628404768}
    Episode Length: {'avg': 6.744732576985413, 'std': 7.95125907492776, 'run': 6.73730171828208, 'test_avg': 20.197265625, 'test_std': 1.5039506385494703}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5101 / 10000):
    Value Loss: {'avg': 25.325078805287678, 'std': 6.228795189671907}
    Value Grad Norm: {'avg': 465.5576949119568, 'std': 210.49722986431757}
    Policy Loss: {'avg': 0.0013060745332040824, 'std': 0.01354756504767252}
    Total_Loss: {'avg': -0.1077063181437552, 'std': 0.013416730807013513}
    Policy Entropy: {'avg': 1.1573108434677124, 'std': 0.5043809413909912}
    KL Divergence: {'avg': 0.016833990812301636, 'std': 0.15766121447086334}
    Policy Grad Norm: {'avg': 2.9261175990104675, 'std': 1.7451029541593768}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.41593773742179, 'std': 34.576329793602085, 'run': -17.410561366050967, 'test_avg': -76.36572209658064, 'test_std': 6.72099196283849}
    Episode Length: {'avg': 6.701214574898786, 'std': 8.108712172700828, 'run': 6.497299077485913, 'test_avg': 20.23828125, 'test_std': 1.445581689458758}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5201 / 10000):
    Value Loss: {'avg': 17.816443731387455, 'std': 3.5677270241726076}
    Value Grad Norm: {'avg': 316.95573774973553, 'std': 115.14256862384613}
    Policy Loss: {'avg': 0.006671108145383187, 'std': 0.014115497767160557}
    Total_Loss: {'avg': -0.09162732725962996, 'std': 0.01397973380895588}
    Policy Entropy: {'avg': 0.9010559320449829, 'std': 0.5789320468902588}
    KL Divergence: {'avg': 0.024552389979362488, 'std': 0.2072957158088684}
    Policy Grad Norm: {'avg': 2.9121506474912167, 'std': 1.2515804126761048}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.43006533327059, 'std': 34.289686549596176, 'run': -16.483298561765235, 'test_avg': -76.44772246553077, 'test_std': 6.903162291444435}
    Episode Length: {'avg': 6.872393661384487, 'std': 8.090577527537869, 'run': 6.13832321179477, 'test_avg': 20.2412109375, 'test_std': 1.4722103182393373}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5301 / 10000):
    Value Loss: {'avg': 16.251509964466095, 'std': 3.7518887597893356}
    Value Grad Norm: {'avg': 352.7748155593872, 'std': 145.63997406999684}
    Policy Loss: {'avg': 0.008698007339262404, 'std': 0.019004534982277818}
    Total_Loss: {'avg': -0.0938804192119278, 'std': 0.01957212551312097}
    Policy Entropy: {'avg': 0.9105514287948608, 'std': 0.4773852229118347}
    KL Divergence: {'avg': 0.0215531587600708, 'std': 0.19428184628486633}
    Policy Grad Norm: {'avg': 3.2582470439374447, 'std': 2.213362390878655}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.558488406809154, 'std': 33.60621548532942, 'run': -17.09156545113773, 'test_avg': -76.45137827664993, 'test_std': 6.861356386467172}
    Episode Length: {'avg': 6.702746365105008, 'std': 7.886954252737923, 'run': 6.374127137052485, 'test_avg': 20.2216796875, 'test_std': 1.4586349538695083}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5401 / 10000):
    Value Loss: {'avg': 19.068301821748417, 'std': 3.784959337146257}
    Value Grad Norm: {'avg': 356.46925632158917, 'std': 138.9376013518673}
    Policy Loss: {'avg': 0.004370571667095646, 'std': 0.014159319050747432}
    Total_Loss: {'avg': -0.0921526430756785, 'std': 0.014827322285196117}
    Policy Entropy: {'avg': 1.0752124786376953, 'std': 0.5162796974182129}
    KL Divergence: {'avg': 0.030196834355592728, 'std': 0.20569361746311188}
    Policy Grad Norm: {'avg': 3.0339627116918564, 'std': 1.3670258941194755}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.038440631949577, 'std': 33.98296658067947, 'run': -22.235792891405133, 'test_avg': -76.3292833091127, 'test_std': 6.9554220647620095}
    Episode Length: {'avg': 6.814529914529914, 'std': 7.950313276171957, 'run': 7.532839179907766, 'test_avg': 20.1923828125, 'test_std': 1.4853123967551707}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5501 / 10000):
    Value Loss: {'avg': 20.924529547492664, 'std': 4.822020262101424}
    Value Grad Norm: {'avg': 350.08749953905743, 'std': 136.33667531654973}
    Policy Loss: {'avg': 0.009419238427653909, 'std': 0.01504780820193881}
    Total_Loss: {'avg': -0.09243836370296776, 'std': 0.016363622074369432}
    Policy Entropy: {'avg': 1.0498623847961426, 'std': 0.5928833484649658}
    KL Divergence: {'avg': 0.01945018209517002, 'std': 0.16064892709255219}
    Policy Grad Norm: {'avg': 3.1332737132906914, 'std': 1.8454951798491637}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.818884310955674, 'std': 33.71501972426269, 'run': -16.696421201557733, 'test_avg': -76.10748402200812, 'test_std': 6.933128943884214}
    Episode Length: {'avg': 6.493259318001586, 'std': 7.903321093155024, 'run': 6.219005601696704, 'test_avg': 20.1884765625, 'test_std': 1.4851557234472699}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5601 / 10000):
    Value Loss: {'avg': 20.20535798370838, 'std': 4.541418313035638}
    Value Grad Norm: {'avg': 382.988299369812, 'std': 186.67685623757373}
    Policy Loss: {'avg': 0.004247517557814717, 'std': 0.012902309204706136}
    Total_Loss: {'avg': -0.09458814561367035, 'std': 0.013808075896504197}
    Policy Entropy: {'avg': 1.028461217880249, 'std': 0.5553519129753113}
    KL Divergence: {'avg': 0.02129058912396431, 'std': 0.18483196198940277}
    Policy Grad Norm: {'avg': 2.961320674046874, 'std': 1.3387708366650335}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.672917635450414, 'std': 32.4936816024334, 'run': -18.780366280266076, 'test_avg': -76.10743456203043, 'test_std': 7.188200339822756}
    Episode Length: {'avg': 6.226544622425629, 'std': 7.682770020292055, 'run': 6.704850648889918, 'test_avg': 20.216796875, 'test_std': 1.553056177345248}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5701 / 10000):
    Value Loss: {'avg': 15.47188787162304, 'std': 2.9875541097815708}
    Value Grad Norm: {'avg': 341.1156422694524, 'std': 143.3511882618106}
    Policy Loss: {'avg': 0.006453072404838167, 'std': 0.01455112058300484}
    Total_Loss: {'avg': -0.09042570379097015, 'std': 0.013661498774916438}
    Policy Entropy: {'avg': 1.01953125, 'std': 0.5717793107032776}
    KL Divergence: {'avg': 0.02827715128660202, 'std': 0.20646749436855316}
    Policy Grad Norm: {'avg': 2.686137231066823, 'std': 1.1685885711356392}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -15.203815248501027, 'std': 30.77754989622615, 'run': -14.21257906732674, 'test_avg': -75.8611187039613, 'test_std': 6.669285543850735}
    Episode Length: {'avg': 5.909224011713031, 'std': 7.296218548532156, 'run': 5.65891325260556, 'test_avg': 20.1123046875, 'test_std': 1.415623261911702}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5801 / 10000):
    Value Loss: {'avg': 17.599881653984387, 'std': 3.494487147851894}
    Value Grad Norm: {'avg': 306.329013466835, 'std': 112.55842995345411}
    Policy Loss: {'avg': 0.004744233476230875, 'std': 0.012042718489793464}
    Total_Loss: {'avg': -0.09956642537144944, 'std': 0.012194486989143416}
    Policy Entropy: {'avg': 1.070605993270874, 'std': 0.5466638803482056}
    KL Divergence: {'avg': 0.020729750394821167, 'std': 0.19511455297470093}
    Policy Grad Norm: {'avg': 2.7284012865275145, 'std': 1.4671729701929885}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.81600129013119, 'std': 32.61102111131465, 'run': -17.183245927420774, 'test_avg': -75.91080526932325, 'test_std': 7.659894658980992}
    Episode Length: {'avg': 6.2810304449648715, 'std': 7.676562312023316, 'run': 6.342453862629877, 'test_avg': 20.119140625, 'test_std': 1.5529284469912352}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5901 / 10000):
    Value Loss: {'avg': 19.13620425760746, 'std': 3.7272284788943493}
    Value Grad Norm: {'avg': 374.74588410059613, 'std': 152.61158201944681}
    Policy Loss: {'avg': 0.0035525195999071, 'std': 0.02161515987953868}
    Total_Loss: {'avg': -0.09640191349899396, 'std': 0.021942303971746957}
    Policy Entropy: {'avg': 1.0525448322296143, 'std': 0.614516019821167}
    KL Divergence: {'avg': 0.019688352942466736, 'std': 0.17189520597457886}
    Policy Grad Norm: {'avg': 2.8790111802518368, 'std': 2.0938056376127525}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.59098141131688, 'std': 32.96681765238919, 'run': -19.785026663995993, 'test_avg': -75.9650364108752, 'test_std': 8.679282542619672}
    Episode Length: {'avg': 6.467417538213998, 'std': 7.750609474921407, 'run': 6.920474047493771, 'test_avg': 20.1435546875, 'test_std': 1.7258086479087933}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6001 / 10000):
    Value Loss: {'avg': 14.707014019290606, 'std': 2.898266039403582}
    Value Grad Norm: {'avg': 290.93698477745056, 'std': 117.82804469794746}
    Policy Loss: {'avg': 0.005835721596668009, 'std': 0.013273609161803585}
    Total_Loss: {'avg': -0.09307590796379372, 'std': 0.013766851441389562}
    Policy Entropy: {'avg': 1.013620138168335, 'std': 0.5315740704536438}
    KL Divergence: {'avg': 0.02190469764173031, 'std': 0.17189809679985046}
    Policy Grad Norm: {'avg': 2.944822611287236, 'std': 1.26487635807363}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.648398623787287, 'std': 33.63193120934365, 'run': -20.263936613257236, 'test_avg': -76.30430575741559, 'test_std': 8.07003450428005}
    Episode Length: {'avg': 6.693944353518821, 'std': 7.94413468739277, 'run': 6.973255821094969, 'test_avg': 20.2060546875, 'test_std': 1.6722465886523068}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6101 / 10000):
    Value Loss: {'avg': 16.753708948691685, 'std': 3.272086240100664}
    Value Grad Norm: {'avg': 301.37251102924347, 'std': 119.65326778715267}
    Policy Loss: {'avg': 0.007847084474633448, 'std': 0.015482721146537181}
    Total_Loss: {'avg': -0.08722960384329781, 'std': 0.01596642380987606}
    Policy Entropy: {'avg': 0.8916521072387695, 'std': 0.5696718096733093}
    KL Divergence: {'avg': 0.02699657902121544, 'std': 0.20616145431995392}
    Policy Grad Norm: {'avg': 2.812888879328966, 'std': 1.4783323816922427}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.669226453262645, 'std': 32.79431456273935, 'run': -14.832537363846225, 'test_avg': -75.82736281274322, 'test_std': 7.2971039177251455}
    Episode Length: {'avg': 6.481452249408051, 'std': 7.7078826864054175, 'run': 5.80195021900539, 'test_avg': 20.08203125, 'test_std': 1.5490386935204161}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6201 / 10000):
    Value Loss: {'avg': 28.372997512420017, 'std': 5.551629677497822}
    Value Grad Norm: {'avg': 427.1600911617279, 'std': 168.67405141454833}
    Policy Loss: {'avg': 0.0003528414817992598, 'std': 0.009258558804785126}
    Total_Loss: {'avg': -0.11245553370099515, 'std': 0.010125688617343954}
    Policy Entropy: {'avg': 1.1953253746032715, 'std': 0.6389247179031372}
    KL Divergence: {'avg': 0.02605733647942543, 'std': 0.22829654812812805}
    Policy Grad Norm: {'avg': 3.474605716764927, 'std': 1.5415368220640386}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.26051515930692, 'std': 35.446483948189105, 'run': -22.717920491243838, 'test_avg': -76.4253177993131, 'test_std': 7.00960764346723}
    Episode Length: {'avg': 6.838709677419355, 'std': 8.335676182843525, 'run': 7.5967669351738305, 'test_avg': 20.255859375, 'test_std': 1.5203582160874487}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6301 / 10000):
    Value Loss: {'avg': 23.164693137009937, 'std': 5.709819462549449}
    Value Grad Norm: {'avg': 357.8312877813975, 'std': 150.8932420803553}
    Policy Loss: {'avg': 0.005424444752861746, 'std': 0.017688997341200156}
    Total_Loss: {'avg': -0.10046468127984554, 'std': 0.016780736854361364}
    Policy Entropy: {'avg': 1.1112723350524902, 'std': 0.5436217188835144}
    KL Divergence: {'avg': 0.02333282306790352, 'std': 0.20138171315193176}
    Policy Grad Norm: {'avg': 3.2020582035183907, 'std': 2.120060392384715}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.51287899490323, 'std': 34.05335680808867, 'run': -18.152843274654412, 'test_avg': -75.54793301618648, 'test_std': 7.948190597065164}
    Episode Length: {'avg': 6.703612479474549, 'std': 7.957295921263923, 'run': 6.592668492143235, 'test_avg': 20.0341796875, 'test_std': 1.6165053546036903}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6401 / 10000):
    Value Loss: {'avg': 15.406297733386358, 'std': 3.3254733364980624}
    Value Grad Norm: {'avg': 301.4005832672119, 'std': 119.54748389467281}
    Policy Loss: {'avg': 0.004271465862984769, 'std': 0.012685109178810184}
    Total_Loss: {'avg': -0.08800938265630975, 'std': 0.012994445488136833}
    Policy Entropy: {'avg': 1.0267276763916016, 'std': 0.5520139336585999}
    KL Divergence: {'avg': 0.032422006130218506, 'std': 0.23986150324344635}
    Policy Grad Norm: {'avg': 2.6330896308645606, 'std': 1.0591337287317903}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.81127336500679, 'std': 32.756114286607215, 'run': -16.088884425390418, 'test_avg': -76.18386837857832, 'test_std': 6.854637805138889}
    Episode Length: {'avg': 6.5015772870662465, 'std': 7.717048440231845, 'run': 6.03283547374781, 'test_avg': 20.1689453125, 'test_std': 1.4610076724248497}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6501 / 10000):
    Value Loss: {'avg': 18.016297683119774, 'std': 3.1347137356738966}
    Value Grad Norm: {'avg': 313.83370391527814, 'std': 107.29752004252795}
    Policy Loss: {'avg': 0.006457280571339652, 'std': 0.012326810072537464}
    Total_Loss: {'avg': -0.09971033607143909, 'std': 0.012915810628953979}
    Policy Entropy: {'avg': 0.9901717901229858, 'std': 0.5579481720924377}
    KL Divergence: {'avg': 0.022128310054540634, 'std': 0.1920403242111206}
    Policy Grad Norm: {'avg': 2.8145222887396812, 'std': 1.2159496269513363}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.267168984056347, 'std': 33.78826106609212, 'run': -18.276684835644343, 'test_avg': -75.74141466201492, 'test_std': 6.775212489519372}
    Episode Length: {'avg': 6.646053702196908, 'std': 7.924020467834418, 'run': 6.589816977304896, 'test_avg': 20.0712890625, 'test_std': 1.4182804490184129}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6601 / 10000):
    Value Loss: {'avg': 19.77025145292282, 'std': 3.7972524730848627}
    Value Grad Norm: {'avg': 335.9161329269409, 'std': 130.89142205294502}
    Policy Loss: {'avg': 0.00602055924537126, 'std': 0.01209649445714926}
    Total_Loss: {'avg': -0.09916130464989692, 'std': 0.013394914965100872}
    Policy Entropy: {'avg': 1.027801752090454, 'std': 0.57835853099823}
    KL Divergence: {'avg': 0.022391822189092636, 'std': 0.19532887637615204}
    Policy Grad Norm: {'avg': 3.3344791140407324, 'std': 3.0408184586657754}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.06128960811308, 'std': 34.31029776734089, 'run': -19.39285891934334, 'test_avg': -76.54405355513917, 'test_std': 10.39393844810618}
    Episode Length: {'avg': 6.757825370675453, 'std': 8.065056762091938, 'run': 6.656046611103845, 'test_avg': 20.24609375, 'test_std': 1.9872602977996963}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (6701 / 10000):
    Value Loss: {'avg': 17.511547913153965, 'std': 3.6806144016419697}
    Value Grad Norm: {'avg': 295.80006496111554, 'std': 125.1463961623632}
    Policy Loss: {'avg': 0.0057507901365170255, 'std': 0.01610661521958786}
    Total_Loss: {'avg': -0.08679151808610186, 'std': 0.01741154162037424}
    Policy Entropy: {'avg': 0.954176664352417, 'std': 0.510197103023529}
    KL Divergence: {'avg': 0.024628739804029465, 'std': 0.22382311522960663}
    Policy Grad Norm: {'avg': 3.236377250403166, 'std': 2.3304500007585336}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.204373514343747, 'std': 33.15712877048126, 'run': -18.399997987397608, 'test_avg': -75.79369992428461, 'test_std': 8.598503439502005}
    Episode Length: {'avg': 6.602696272799365, 'std': 7.8000361348861285, 'run': 6.687798793812965, 'test_avg': 20.103515625, 'test_std': 1.6721020125521229}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6801 / 10000):
    Value Loss: {'avg': 14.883700281381607, 'std': 3.010205562680407}
    Value Grad Norm: {'avg': 264.9319996039073, 'std': 99.05575811136411}
    Policy Loss: {'avg': 0.00878618741990067, 'std': 0.01613848739552413}
    Total_Loss: {'avg': -0.08464559441199526, 'std': 0.01757402522246714}
    Policy Entropy: {'avg': 0.992457389831543, 'std': 0.5736138224601746}
    KL Divergence: {'avg': 0.02156623639166355, 'std': 0.1951708346605301}
    Policy Grad Norm: {'avg': 2.892151601612568, 'std': 2.1550680633000594}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.725834952432567, 'std': 31.923280810951017, 'run': -18.179528125102333, 'test_avg': -75.20604734082687, 'test_std': 6.827055234570268}
    Episode Length: {'avg': 6.2203519510328995, 'std': 7.519245322532734, 'run': 6.568512711009715, 'test_avg': 19.9970703125, 'test_std': 1.4357976370057002}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6901 / 10000):
    Value Loss: {'avg': 17.880348339676857, 'std': 3.753739517869749}
    Value Grad Norm: {'avg': 298.06186747550964, 'std': 117.73852329939554}
    Policy Loss: {'avg': 0.0045531092619057745, 'std': 0.014242412107667123}
    Total_Loss: {'avg': -0.0934299316140823, 'std': 0.015536498224123752}
    Policy Entropy: {'avg': 0.9318912625312805, 'std': 0.552964985370636}
    KL Divergence: {'avg': 0.021496478468179703, 'std': 0.1816631555557251}
    Policy Grad Norm: {'avg': 2.740044003352523, 'std': 0.9402686652971437}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.127329679420164, 'std': 32.277164477696964, 'run': -16.220367319995283, 'test_avg': -75.90476911915118, 'test_std': 8.116812149902042}
    Episode Length: {'avg': 6.413982717989002, 'std': 7.625608605519412, 'run': 6.199362515799969, 'test_avg': 20.1474609375, 'test_std': 1.6679227228536762}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7001 / 10000):
    Value Loss: {'avg': 17.91963594655196, 'std': 3.55965379701979}
    Value Grad Norm: {'avg': 288.8070642153422, 'std': 101.06385358380713}
    Policy Loss: {'avg': 0.010180985220358707, 'std': 0.022369574329096142}
    Total_Loss: {'avg': -0.08952485356712714, 'std': 0.022601827155539395}
    Policy Entropy: {'avg': 0.9623734951019287, 'std': 0.5723503232002258}
    KL Divergence: {'avg': 0.02948871999979019, 'std': 0.23959143459796906}
    Policy Grad Norm: {'avg': 2.753386897034943, 'std': 1.1397043947575392}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.33525463004978, 'std': 33.21291745372253, 'run': -22.19640752687846, 'test_avg': -75.83207520878364, 'test_std': 6.811271825994234}
    Episode Length: {'avg': 6.618637431480031, 'std': 7.855551654748101, 'run': 7.436057257816007, 'test_avg': 20.126953125, 'test_std': 1.4642537874469488}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7101 / 10000):
    Value Loss: {'avg': 16.512801190217335, 'std': 3.4269848927635804}
    Value Grad Norm: {'avg': 272.37527612845105, 'std': 94.54314282227516}
    Policy Loss: {'avg': 0.008100998005829751, 'std': 0.02766756947858603}
    Total_Loss: {'avg': -0.09350191068369895, 'std': 0.027223412735470243}
    Policy Entropy: {'avg': 1.030763864517212, 'std': 0.5723679065704346}
    KL Divergence: {'avg': 0.03293976932764053, 'std': 0.2472488135099411}
    Policy Grad Norm: {'avg': 3.454444309696555, 'std': 2.0708278301508356}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.97271234696057, 'std': 33.2741533547119, 'run': -19.3306980578262, 'test_avg': -75.205840097313, 'test_std': 6.726310832527958}
    Episode Length: {'avg': 6.53515625, 'std': 7.808770008015727, 'run': 6.836716688376741, 'test_avg': 19.9765625, 'test_std': 1.4098694739562774}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7201 / 10000):
    Value Loss: {'avg': 15.3760717411836, 'std': 3.25138183860902}
    Value Grad Norm: {'avg': 266.0468796491623, 'std': 106.61966082195879}
    Policy Loss: {'avg': 0.011309403213090263, 'std': 0.020817285875161396}
    Total_Loss: {'avg': -0.07983537565451115, 'std': 0.02022152874948957}
    Policy Entropy: {'avg': 1.0423130989074707, 'std': 0.6096721291542053}
    KL Divergence: {'avg': 0.021045710891485214, 'std': 0.1941259354352951}
    Policy Grad Norm: {'avg': 3.1102916076779366, 'std': 2.068782961461372}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.045538055853207, 'std': 31.94999359384711, 'run': -18.04421586474951, 'test_avg': -75.46101544738977, 'test_std': 7.629969124507938}
    Episode Length: {'avg': 6.306058221872541, 'std': 7.545401179189266, 'run': 6.529841060101363, 'test_avg': 20.0322265625, 'test_std': 1.53854655801163}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7301 / 10000):
    Value Loss: {'avg': 15.870902503530184, 'std': 3.2388697490108243}
    Value Grad Norm: {'avg': 283.22453840573627, 'std': 120.81869333832323}
    Policy Loss: {'avg': 0.00727864594955463, 'std': 0.013765767656826381}
    Total_Loss: {'avg': -0.08371297316625714, 'std': 0.015281966610748737}
    Policy Entropy: {'avg': 0.9578052163124084, 'std': 0.5868253111839294}
    KL Divergence: {'avg': 0.021410144865512848, 'std': 0.18417364358901978}
    Policy Grad Norm: {'avg': 3.5589578971266747, 'std': 2.287454561394172}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.910397262994543, 'std': 32.669924676497125, 'run': -16.59731428798052, 'test_avg': -75.36726216228371, 'test_std': 7.519741773139482}
    Episode Length: {'avg': 6.50796178343949, 'std': 7.701534319700223, 'run': 6.296182003078951, 'test_avg': 20.0078125, 'test_std': 1.5302731258973836}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7401 / 10000):
    Value Loss: {'avg': 16.426123673717182, 'std': 3.269277138212305}
    Value Grad Norm: {'avg': 279.47540334860486, 'std': 108.22555610015117}
    Policy Loss: {'avg': 0.005019543066737242, 'std': 0.011294904144213636}
    Total_Loss: {'avg': -0.09111900645075366, 'std': 0.012318057768419856}
    Policy Entropy: {'avg': 0.9283856153488159, 'std': 0.5297268629074097}
    KL Divergence: {'avg': 0.0241396501660347, 'std': 0.2076602578163147}
    Policy Grad Norm: {'avg': 3.0816469248384237, 'std': 1.2227376365717588}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.149157750083173, 'std': 33.721310795562, 'run': -16.500393721586303, 'test_avg': -74.91869689692189, 'test_std': 6.864742312415882}
    Episode Length: {'avg': 6.829840737636212, 'std': 7.948200789079292, 'run': 6.30879102384903, 'test_avg': 19.955078125, 'test_std': 1.468395433848282}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7501 / 10000):
    Value Loss: {'avg': 19.802077402671177, 'std': 4.428254538592932}
    Value Grad Norm: {'avg': 306.2503520647685, 'std': 123.09152762035201}
    Policy Loss: {'avg': 0.005388209399825428, 'std': 0.011288558079868359}
    Total_Loss: {'avg': -0.09176875546108931, 'std': 0.012831673053027595}
    Policy Entropy: {'avg': 0.957482099533081, 'std': 0.6213638186454773}
    KL Divergence: {'avg': 0.018253661692142487, 'std': 0.16621056199073792}
    Policy Grad Norm: {'avg': 3.1935505755245686, 'std': 1.2819080929440019}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.32558171837214, 'std': 34.06270898119587, 'run': -19.93742712027114, 'test_avg': -75.46422937356989, 'test_std': 7.798821345142353}
    Episode Length: {'avg': 6.88653683319221, 'std': 8.044793938546404, 'run': 7.103417835836812, 'test_avg': 20.0595703125, 'test_std': 1.6084998260393604}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7601 / 10000):
    Value Loss: {'avg': 13.78686852256457, 'std': 2.9085518287853174}
    Value Grad Norm: {'avg': 249.3425590991974, 'std': 90.03566299288822}
    Policy Loss: {'avg': 0.009057014947757125, 'std': 0.019436231877617918}
    Total_Loss: {'avg': -0.0824428426567465, 'std': 0.02081112111947488}
    Policy Entropy: {'avg': 0.9555586576461792, 'std': 0.5369461178779602}
    KL Divergence: {'avg': 0.024612005800008774, 'std': 0.17029178142547607}
    Policy Grad Norm: {'avg': 3.1463006623089314, 'std': 3.217636379539506}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.854659315289634, 'std': 31.981453032676093, 'run': -18.20717466989939, 'test_avg': -75.01611580689385, 'test_std': 7.674634674478832}
    Episode Length: {'avg': 6.557614826752618, 'std': 7.564715717320356, 'run': 6.655766475529988, 'test_avg': 19.982421875, 'test_std': 1.5517390677950609}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7701 / 10000):
    Value Loss: {'avg': 14.994959657390913, 'std': 3.2035334026985307}
    Value Grad Norm: {'avg': 238.05406606197357, 'std': 90.36937474413958}
    Policy Loss: {'avg': 0.0020553382055368274, 'std': 0.009617362496677934}
    Total_Loss: {'avg': -0.08607602887786925, 'std': 0.009515963513058699}
    Policy Entropy: {'avg': 0.8420877456665039, 'std': 0.6156955361366272}
    KL Divergence: {'avg': 0.01667349971830845, 'std': 0.17852748930454254}
    Policy Grad Norm: {'avg': 4.073284424841404, 'std': 3.0369631960158663}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.493712823712283, 'std': 32.29996442294184, 'run': -14.866931428882943, 'test_avg': -74.75027921290965, 'test_std': 7.679244221865893}
    Episode Length: {'avg': 6.427469135802469, 'std': 7.617960325484266, 'run': 5.78030628902332, 'test_avg': 19.912109375, 'test_std': 1.5461929821458604}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7801 / 10000):
    Value Loss: {'avg': 17.78764195740223, 'std': 3.9457028703155768}
    Value Grad Norm: {'avg': 248.49779538313547, 'std': 92.66901407052542}
    Policy Loss: {'avg': 0.0023810317215975374, 'std': 0.015094557617676306}
    Total_Loss: {'avg': -0.09637158876284957, 'std': 0.015700716887856667}
    Policy Entropy: {'avg': 0.9223200082778931, 'std': 0.5341848731040955}
    KL Divergence: {'avg': 0.023089051246643066, 'std': 0.24305109679698944}
    Policy Grad Norm: {'avg': 2.417795518413186, 'std': 1.2224139711362698}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.82132226375303, 'std': 32.28432480101647, 'run': -12.578629744732911, 'test_avg': -74.6237576457076, 'test_std': 6.4801289752809454}
    Episode Length: {'avg': 6.28156862745098, 'std': 7.586671328925052, 'run': 5.229420629545204, 'test_avg': 19.8818359375, 'test_std': 1.3752493198811246}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7901 / 10000):
    Value Loss: {'avg': 16.264243910710018, 'std': 3.171152086504588}
    Value Grad Norm: {'avg': 270.35196276505786, 'std': 106.14541535504881}
    Policy Loss: {'avg': 0.005137760483194143, 'std': 0.014069630115931462}
    Total_Loss: {'avg': -0.08998896990669891, 'std': 0.014071006155525772}
    Policy Entropy: {'avg': 0.9554105997085571, 'std': 0.6318007707595825}
    KL Divergence: {'avg': 0.01988949254155159, 'std': 0.18753470480442047}
    Policy Grad Norm: {'avg': 2.761668572202325, 'std': 1.4764504222993104}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.31863092805757, 'std': 32.04672467989124, 'run': -14.217953698251181, 'test_avg': -74.94989074527183, 'test_std': 6.3913107427277644}
    Episode Length: {'avg': 6.1534954407294835, 'std': 7.568782566886966, 'run': 5.608587533243859, 'test_avg': 19.951171875, 'test_std': 1.3677217148268812}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8001 / 10000):
    Value Loss: {'avg': 13.277902878820896, 'std': 3.1953207412343123}
    Value Grad Norm: {'avg': 193.53985885779062, 'std': 62.592469146730416}
    Policy Loss: {'avg': 0.007914004927442875, 'std': 0.015757706888510276}
    Total_Loss: {'avg': -0.08419602218782529, 'std': 0.016260159702841365}
    Policy Entropy: {'avg': 0.9585323333740234, 'std': 0.6058343052864075}
    KL Divergence: {'avg': 0.035878799855709076, 'std': 0.2617698907852173}
    Policy Grad Norm: {'avg': 2.804794181138277, 'std': 2.211873936385171}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -15.384281297683836, 'std': 30.460499033086066, 'run': -11.610489993739122, 'test_avg': -75.24194236437731, 'test_std': 7.375794999964403}
    Episode Length: {'avg': 5.91326164874552, 'std': 7.199587038112225, 'run': 5.090539430947813, 'test_avg': 20.0380859375, 'test_std': 1.5939076663548444}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8101 / 10000):
    Value Loss: {'avg': 16.82826275130113, 'std': 3.671669198069134}
    Value Grad Norm: {'avg': 262.84802118937176, 'std': 113.67953538734639}
    Policy Loss: {'avg': 0.0038124868951854296, 'std': 0.011894944313381159}
    Total_Loss: {'avg': -0.09465747675858438, 'std': 0.013335345245781323}
    Policy Entropy: {'avg': 1.0064034461975098, 'std': 0.5505893230438232}
    KL Divergence: {'avg': 0.0214022696018219, 'std': 0.22034981846809387}
    Policy Grad Norm: {'avg': 2.7768610138446093, 'std': 1.5376863588307395}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.738536043839503, 'std': 33.07583181877637, 'run': -16.57076220666297, 'test_avg': -74.87492963456998, 'test_std': 6.57139291412295}
    Episode Length: {'avg': 6.464006259780907, 'std': 7.7888731422621, 'run': 6.231276676669014, 'test_avg': 19.88671875, 'test_std': 1.387323811659858}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8201 / 10000):
    Value Loss: {'avg': 20.693939238786697, 'std': 5.570497667553668}
    Value Grad Norm: {'avg': 292.65734004974365, 'std': 129.3836826864984}
    Policy Loss: {'avg': 0.004187432859907858, 'std': 0.013381962503240705}
    Total_Loss: {'avg': -0.0935031957924366, 'std': 0.013258437918751882}
    Policy Entropy: {'avg': 1.070430040359497, 'std': 0.5384593605995178}
    KL Divergence: {'avg': 0.021387124434113503, 'std': 0.17428378760814667}
    Policy Grad Norm: {'avg': 2.712121618911624, 'std': 1.2823341137962454}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.761458380136645, 'std': 33.9066159436537, 'run': -22.94893129573832, 'test_avg': -75.04252542877236, 'test_std': 6.672569951721107}
    Episode Length: {'avg': 6.719412724306689, 'std': 7.931264562919075, 'run': 7.597671515057524, 'test_avg': 19.9599609375, 'test_std': 1.4119185744844216}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8301 / 10000):
    Value Loss: {'avg': 15.463764533400536, 'std': 2.8144775512699325}
    Value Grad Norm: {'avg': 256.42809804280597, 'std': 100.54754823521039}
    Policy Loss: {'avg': 0.011823785782326013, 'std': 0.015713418893968024}
    Total_Loss: {'avg': -0.07876596850110218, 'std': 0.01566292994356647}
    Policy Entropy: {'avg': 0.9179774522781372, 'std': 0.6060435175895691}
    KL Divergence: {'avg': 0.0272404532879591, 'std': 0.19417162239551544}
    Policy Grad Norm: {'avg': 2.8094089031219482, 'std': 1.8373359901693709}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -19.055718631540817, 'std': 33.45104733078503, 'run': -16.546295118620908, 'test_avg': -75.2863145766674, 'test_std': 6.623011158201822}
    Episode Length: {'avg': 6.786352558895207, 'std': 7.892803883678727, 'run': 6.236465250479581, 'test_avg': 20.056640625, 'test_std': 1.4397790506183958}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8401 / 10000):
    Value Loss: {'avg': 15.104926491777102, 'std': 3.634035475894862}
    Value Grad Norm: {'avg': 239.6269671122233, 'std': 97.00139743339808}
    Policy Loss: {'avg': 0.002711824286961928, 'std': 0.011118943832073494}
    Total_Loss: {'avg': -0.08729582093656063, 'std': 0.012758165550009321}
    Policy Entropy: {'avg': 0.899009108543396, 'std': 0.5891644954681396}
    KL Divergence: {'avg': 0.020014628767967224, 'std': 0.18020525574684143}
    Policy Grad Norm: {'avg': 3.3000000938773155, 'std': 2.0306089167475934}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.06643170104099, 'std': 32.80529188674081, 'run': -15.34177312702353, 'test_avg': -74.85126438364159, 'test_std': 6.698169308956287}
    Episode Length: {'avg': 6.584467574059247, 'std': 7.7776001303602404, 'run': 5.911752443381304, 'test_avg': 19.9404296875, 'test_std': 1.4126127620011977}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8501 / 10000):
    Value Loss: {'avg': 18.31959296266238, 'std': 4.169182352894258}
    Value Grad Norm: {'avg': 246.591765721639, 'std': 83.6772851550921}
    Policy Loss: {'avg': 0.002029839379247278, 'std': 0.014825805973212787}
    Total_Loss: {'avg': -0.09223648742772639, 'std': 0.016020251407039273}
    Policy Entropy: {'avg': 0.9542970061302185, 'std': 0.6247482299804688}
    KL Divergence: {'avg': 0.016976086422801018, 'std': 0.1611773818731308}
    Policy Grad Norm: {'avg': 3.3855607016012073, 'std': 2.1466795565114762}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.14960516057969, 'std': 31.668690986728798, 'run': -16.322657731894274, 'test_avg': -74.94419273227933, 'test_std': 6.893751847714924}
    Episode Length: {'avg': 6.086596385542169, 'std': 7.465837930585559, 'run': 6.131287297659789, 'test_avg': 19.9384765625, 'test_std': 1.4654630852185202}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8601 / 10000):
    Value Loss: {'avg': 20.07199330131213, 'std': 4.453544511330813}
    Value Grad Norm: {'avg': 279.43996187051135, 'std': 104.1979389630895}
    Policy Loss: {'avg': 0.005743424713728018, 'std': 0.011892785346966327}
    Total_Loss: {'avg': -0.09562375431414694, 'std': 0.01171990656889153}
    Policy Entropy: {'avg': 0.9309821128845215, 'std': 0.5633547902107239}
    KL Divergence: {'avg': 0.02404448762536049, 'std': 0.20940034091472626}
    Policy Grad Norm: {'avg': 3.048523610457778, 'std': 1.2899227729356373}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -18.402536127543343, 'std': 33.512963543922936, 'run': -18.33763190350895, 'test_avg': -75.22414838371245, 'test_std': 9.621328567408213}
    Episode Length: {'avg': 6.677740863787376, 'std': 7.885758403221467, 'run': 6.621969391466209, 'test_avg': 19.9658203125, 'test_std': 1.8775513139358941}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (8701 / 10000):
    Value Loss: {'avg': 15.063848162690798, 'std': 3.2979953736485283}
    Value Grad Norm: {'avg': 210.4330517053604, 'std': 82.86466931430694}
    Policy Loss: {'avg': 0.004152164212428033, 'std': 0.010195912094509901}
    Total_Loss: {'avg': -0.08396174700465053, 'std': 0.012010931719495}
    Policy Entropy: {'avg': 0.865439772605896, 'std': 0.5709975361824036}
    KL Divergence: {'avg': 0.023629089817404747, 'std': 0.19227124750614166}
    Policy Grad Norm: {'avg': 2.810283489525318, 'std': 1.174997515537356}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.073975331355474, 'std': 31.85264010539888, 'run': -16.878368148780776, 'test_avg': -74.96842283141355, 'test_std': 6.81344744374695}
    Episode Length: {'avg': 6.3469068128426, 'std': 7.522418609725581, 'run': 6.203155089799421, 'test_avg': 19.9609375, 'test_std': 1.4598926745119827}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8801 / 10000):
    Value Loss: {'avg': 15.567582870523134, 'std': 3.523043277472229}
    Value Grad Norm: {'avg': 228.96449645360312, 'std': 82.61531550880275}
    Policy Loss: {'avg': 0.006082401116145775, 'std': 0.013773109035958587}
    Total_Loss: {'avg': -0.08636538812424988, 'std': 0.014682271680173787}
    Policy Entropy: {'avg': 0.9711617231369019, 'std': 0.6149715781211853}
    KL Divergence: {'avg': 0.024507541209459305, 'std': 0.21873900294303894}
    Policy Grad Norm: {'avg': 3.0681296847760677, 'std': 1.7845141214775266}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.124906992533163, 'std': 31.251906745486366, 'run': -15.418860246736221, 'test_avg': -75.02983302399454, 'test_std': 6.8751071218122295}
    Episode Length: {'avg': 6.136674259681094, 'std': 7.387598559599463, 'run': 6.041870439403513, 'test_avg': 19.966796875, 'test_std': 1.4740168511554521}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8901 / 10000):
    Value Loss: {'avg': 14.5726521362861, 'std': 2.958326217706426}
    Value Grad Norm: {'avg': 243.48693978786469, 'std': 99.10895268685024}
    Policy Loss: {'avg': 0.0071829055159469135, 'std': 0.014783896403334038}
    Total_Loss: {'avg': -0.08448032534215599, 'std': 0.016643601966267685}
    Policy Entropy: {'avg': 0.959958553314209, 'std': 0.5533905029296875}
    KL Divergence: {'avg': 0.027033831924200058, 'std': 0.2075815498828888}
    Policy Grad Norm: {'avg': 2.7265324518084526, 'std': 1.0788713478362602}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.6757057220094, 'std': 32.65624496560208, 'run': -15.714745876440366, 'test_avg': -74.78319736762505, 'test_std': 6.406729784221203}
    Episode Length: {'avg': 6.483030781373323, 'std': 7.695999081606495, 'run': 5.915964372431522, 'test_avg': 19.9423828125, 'test_std': 1.3641620403033468}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9001 / 10000):
    Value Loss: {'avg': 17.02887037396431, 'std': 3.4367557314147295}
    Value Grad Norm: {'avg': 228.18509229024252, 'std': 74.41824070014633}
    Policy Loss: {'avg': 0.009600350211258046, 'std': 0.016022658127060968}
    Total_Loss: {'avg': -0.0863161605084315, 'std': 0.015754638113817793}
    Policy Entropy: {'avg': 1.0117075443267822, 'std': 0.5536051392555237}
    KL Divergence: {'avg': 0.017752567306160927, 'std': 0.1804255247116089}
    Policy Grad Norm: {'avg': 3.779200168326497, 'std': 3.7961385532203655}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.882578455584117, 'std': 32.07920447881044, 'run': -15.132176023560753, 'test_avg': -75.28330707336092, 'test_std': 6.884006178983538}
    Episode Length: {'avg': 6.277863777089784, 'std': 7.577220980642762, 'run': 5.887004320053165, 'test_avg': 20.00390625, 'test_std': 1.4690772158776875}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9101 / 10000):
    Value Loss: {'avg': 13.839461495478949, 'std': 3.1409607150168717}
    Value Grad Norm: {'avg': 228.04655385017395, 'std': 94.04728861251891}
    Policy Loss: {'avg': 0.007491773314541206, 'std': 0.011454966270463919}
    Total_Loss: {'avg': -0.08204214496072382, 'std': 0.012115436414486909}
    Policy Entropy: {'avg': 0.9340369701385498, 'std': 0.6010646224021912}
    KL Divergence: {'avg': 0.021601255983114243, 'std': 0.1762257069349289}
    Policy Grad Norm: {'avg': 2.775348363444209, 'std': 1.2911054979166439}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.381776752685045, 'std': 32.07292130574246, 'run': -15.770686054192828, 'test_avg': -74.21313885815465, 'test_std': 6.600366587766046}
    Episode Length: {'avg': 6.40859375, 'std': 7.574799165486893, 'run': 6.047360931819742, 'test_avg': 19.833984375, 'test_std': 1.4258280707209616}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9201 / 10000):
    Value Loss: {'avg': 16.014368494351704, 'std': 3.3915950199258926}
    Value Grad Norm: {'avg': 250.90431968371072, 'std': 106.11176187894726}
    Policy Loss: {'avg': 0.007665896417165641, 'std': 0.015032361601987457}
    Total_Loss: {'avg': -0.09264994005206972, 'std': 0.015933327064891555}
    Policy Entropy: {'avg': 1.0169997215270996, 'std': 0.5636751055717468}
    KL Divergence: {'avg': 0.020599663257598877, 'std': 0.17737777531147003}
    Policy Grad Norm: {'avg': 2.8673063665628433, 'std': 1.4029483769405036}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.64850150508579, 'std': 32.90309203931644, 'run': -15.429615120407457, 'test_avg': -74.61835150213216, 'test_std': 6.613654304255424}
    Episode Length: {'avg': 6.485062893081761, 'std': 7.764402127971573, 'run': 5.9639253570710835, 'test_avg': 19.8798828125, 'test_std': 1.4094496882709542}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9301 / 10000):
    Value Loss: {'avg': 13.901384989420572, 'std': 2.732509662570869}
    Value Grad Norm: {'avg': 223.7542757987976, 'std': 88.14627635456455}
    Policy Loss: {'avg': 0.005852092195709702, 'std': 0.014063895785581256}
    Total_Loss: {'avg': -0.08192595950094983, 'std': 0.014708166981782176}
    Policy Entropy: {'avg': 0.8483073711395264, 'std': 0.5813112854957581}
    KL Divergence: {'avg': 0.018529828637838364, 'std': 0.1709117293357849}
    Policy Grad Norm: {'avg': 3.1845026537775993, 'std': 2.078316655061675}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.13117365382655, 'std': 31.70725940111087, 'run': -13.69745745305806, 'test_avg': -74.8961273000912, 'test_std': 6.332927868831102}
    Episode Length: {'avg': 6.376779026217228, 'std': 7.480285207055005, 'run': 5.665453867543143, 'test_avg': 19.9453125, 'test_std': 1.3624919366160484}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9401 / 10000):
    Value Loss: {'avg': 14.01608337710301, 'std': 2.9772318682353442}
    Value Grad Norm: {'avg': 218.36298219362894, 'std': 77.465353666997}
    Policy Loss: {'avg': 0.004434327871422283, 'std': 0.011255465464285772}
    Total_Loss: {'avg': -0.07965444982983172, 'std': 0.0120686110152785}
    Policy Entropy: {'avg': 0.7745003700256348, 'std': 0.5775861144065857}
    KL Divergence: {'avg': 0.018894551321864128, 'std': 0.20109133422374725}
    Policy Grad Norm: {'avg': 3.5692934785038233, 'std': 2.1975301820548085}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.860662640031872, 'std': 31.63523804158053, 'run': -17.156784513713276, 'test_avg': -74.64891591825415, 'test_std': 6.566081924079819}
    Episode Length: {'avg': 6.261136712749616, 'std': 7.501418888705577, 'run': 6.2958428774545405, 'test_avg': 19.8984375, 'test_std': 1.3896371139955028}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9501 / 10000):
    Value Loss: {'avg': 15.840690337121487, 'std': 3.259380663152931}
    Value Grad Norm: {'avg': 227.03828903039297, 'std': 85.22049034194615}
    Policy Loss: {'avg': 0.004703311999037396, 'std': 0.01192164599471598}
    Total_Loss: {'avg': -0.08762039145221934, 'std': 0.011417437888946901}
    Policy Entropy: {'avg': 1.0022190809249878, 'std': 0.5940040349960327}
    KL Divergence: {'avg': 0.019362840801477432, 'std': 0.17309823632240295}
    Policy Grad Norm: {'avg': 2.915101682767272, 'std': 1.304026624663112}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.792809074502262, 'std': 31.841584629695937, 'run': -16.15690319442282, 'test_avg': -74.54550419805821, 'test_std': 6.493009107928016}
    Episode Length: {'avg': 6.245127436281859, 'std': 7.543717827233691, 'run': 6.124448749432927, 'test_avg': 19.875, 'test_std': 1.400334781400505}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9601 / 10000):
    Value Loss: {'avg': 11.945802400509516, 'std': 2.606508235106721}
    Value Grad Norm: {'avg': 190.34518003463745, 'std': 68.20746747149904}
    Policy Loss: {'avg': 0.003240425285184756, 'std': 0.011716524561622055}
    Total_Loss: {'avg': -0.0839238190674223, 'std': 0.011972191131398913}
    Policy Entropy: {'avg': 0.9466679096221924, 'std': 0.6377453207969666}
    KL Divergence: {'avg': 0.027873441576957703, 'std': 0.20404893159866333}
    Policy Grad Norm: {'avg': 2.7298539727926254, 'std': 1.2988739944628263}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -17.372949031092524, 'std': 32.31887926350809, 'run': -20.833332112934716, 'test_avg': -74.53867799397278, 'test_std': 6.348379083475572}
    Episode Length: {'avg': 6.385384615384615, 'std': 7.625762121191172, 'run': 7.243457008458176, 'test_avg': 19.8427734375, 'test_std': 1.3562955505878627}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9701 / 10000):
    Value Loss: {'avg': 13.241980319221815, 'std': 2.9225057427563255}
    Value Grad Norm: {'avg': 233.97495969136557, 'std': 94.90102121386859}
    Policy Loss: {'avg': 0.0070761411770945415, 'std': 0.017088826199438408}
    Total_Loss: {'avg': -0.08111147466115654, 'std': 0.01866699624638455}
    Policy Entropy: {'avg': 0.9210328459739685, 'std': 0.5788252353668213}
    KL Divergence: {'avg': 0.017611559480428696, 'std': 0.18288102746009827}
    Policy Grad Norm: {'avg': 2.8835613373667, 'std': 1.2510910625476337}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -15.09566491790137, 'std': 30.577243456805856, 'run': -14.374548824255015, 'test_avg': -74.95532211966363, 'test_std': 6.534876373587709}
    Episode Length: {'avg': 5.851351351351352, 'std': 7.252111696802282, 'run': 5.674779048836705, 'test_avg': 19.994140625, 'test_std': 1.3968312506257188}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9801 / 10000):
    Value Loss: {'avg': 13.03158724308014, 'std': 2.6249231177238697}
    Value Grad Norm: {'avg': 207.21994229157767, 'std': 75.70783554801308}
    Policy Loss: {'avg': 0.003182878586812876, 'std': 0.01563099814940363}
    Total_Loss: {'avg': -0.0823046601144597, 'std': 0.016529893422447945}
    Policy Entropy: {'avg': 0.9049429297447205, 'std': 0.5947535634040833}
    KL Divergence: {'avg': 0.023060457780957222, 'std': 0.26824384927749634}
    Policy Grad Norm: {'avg': 3.1690224204212427, 'std': 1.8525070272639657}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.32558334708432, 'std': 31.20995848198285, 'run': -17.294337669276818, 'test_avg': -74.41189335802447, 'test_std': 6.21586335937811}
    Episode Length: {'avg': 6.178165276724791, 'std': 7.3617215390269015, 'run': 6.416627357812923, 'test_avg': 19.8369140625, 'test_std': 1.3183517794920088}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9901 / 10000):
    Value Loss: {'avg': 14.935587291916212, 'std': 3.1614319596570364}
    Value Grad Norm: {'avg': 266.5509135723114, 'std': 116.77267193365516}
    Policy Loss: {'avg': 0.007582131096569356, 'std': 0.013765440883409745}
    Total_Loss: {'avg': -0.08162747108144686, 'std': 0.014363984685540185}
    Policy Entropy: {'avg': 0.9283195734024048, 'std': 0.5731537938117981}
    KL Divergence: {'avg': 0.031337473541498184, 'std': 0.25120940804481506}
    Policy Grad Norm: {'avg': 3.0509162992239, 'std': 2.0331662738560694}
    Num PPO updates: {'avg': 64}
    Return: {'avg': -16.859436412825357, 'std': 31.75013869724959, 'run': -16.204316188409454, 'test_avg': -75.02039496096003, 'test_std': 7.137813312676551}
    Episode Length: {'avg': 6.280542986425339, 'std': 7.548517679795109, 'run': 6.109217251003634, 'test_avg': 20.0185546875, 'test_std': 1.5501535524172363}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Training took 33753.447 seconds in total.
