
Iteration (1 / 20000):
    Value Loss: {'avg': 1216.2782836914062, 'std': 83.85474116977296}
    Value Grad Norm: {'avg': 245.59761861165364, 'std': 35.577871170620554}
    Policy Loss: {'avg': -0.003246682913353046, 'std': 0.003829687051447818}
    Total_Loss: {'avg': -0.232942899564902, 'std': 0.0038531214063665174}
    Policy Entropy: {'avg': 2.297428607940674, 'std': 0.015668269246816635}
    KL Divergence: {'avg': 0.006715087685734034, 'std': 0.08586455881595612}
    Policy Grad Norm: {'avg': 0.14438832998275758, 'std': 0.04205153331569693}
    Num PPO updates: {'avg': 30}
    Return: {'avg': -29.761692956068444, 'std': 35.19464411260007, 'run': -33.78310963631241, 'test_avg': -313.8661769963094, 'test_std': 7.947391825357928}
    Episode Length: {'avg': 12.415300546448087, 'std': 11.40233826045547, 'run': 13.471143195982165, 'test_avg': 64.0, 'test_std': 0.0}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.0}

Iteration (101 / 20000):
    Value Loss: {'avg': 473.6276112874349, 'std': 38.9199005985855}
    Value Grad Norm: {'avg': 677.9425069173177, 'std': 302.65635284125244}
    Policy Loss: {'avg': 0.008871140982955694, 'std': 0.00725669592881197}
    Total_Loss: {'avg': -0.18782612681388855, 'std': 0.00553480695416227}
    Policy Entropy: {'avg': 1.9579641819000244, 'std': 0.39510780572891235}
    KL Divergence: {'avg': 0.01840590499341488, 'std': 0.1596234291791916}
    Policy Grad Norm: {'avg': 1.0410215139389039, 'std': 0.16089133577839346}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -34.95387959662788, 'std': 59.269026245255176, 'run': -33.08096789215055, 'test_avg': -120.62712869681297, 'test_std': 18.720799120119942}
    Episode Length: {'avg': 11.216335540838852, 'std': 14.309477487093563, 'run': 10.89796056089823, 'test_avg': 30.92578125, 'test_std': 4.056047685512146}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (201 / 20000):
    Value Loss: {'avg': 251.10669504801433, 'std': 15.624777666368999}
    Value Grad Norm: {'avg': 786.2028828938802, 'std': 360.26356575061067}
    Policy Loss: {'avg': -0.0016542614903301, 'std': 0.007617093505694631}
    Total_Loss: {'avg': -0.1798962987959385, 'std': 0.007652160807155523}
    Policy Entropy: {'avg': 1.812153935432434, 'std': 0.5706750750541687}
    KL Divergence: {'avg': 0.016178280115127563, 'std': 0.18693506717681885}
    Policy Grad Norm: {'avg': 1.1386194199323654, 'std': 0.37374873002707226}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -31.86282214436811, 'std': 54.4000586257807, 'run': -30.815853936025047, 'test_avg': -119.12789790205579, 'test_std': 18.63434227754057}
    Episode Length: {'avg': 10.098989898989899, 'std': 12.710780399866696, 'run': 9.798750996590096, 'test_avg': 30.9794921875, 'test_std': 4.651588410653555}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9892578125}

Iteration (301 / 20000):
    Value Loss: {'avg': 202.03479817708333, 'std': 18.082379132366277}
    Value Grad Norm: {'avg': 1058.9323908487956, 'std': 621.0668603863801}
    Policy Loss: {'avg': -0.0070538632571697235, 'std': 0.011605113912174104}
    Total_Loss: {'avg': -0.17888894379138948, 'std': 0.011518176551784338}
    Policy Entropy: {'avg': 1.7191170454025269, 'std': 0.5663192272186279}
    KL Divergence: {'avg': 0.016957633197307587, 'std': 0.1842598021030426}
    Policy Grad Norm: {'avg': 1.1142544388771056, 'std': 0.31789492251870927}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -30.568910236522573, 'std': 50.55410207693792, 'run': -28.320811707864816, 'test_avg': -111.41702641991475, 'test_std': 16.129540444779934}
    Episode Length: {'avg': 9.906066536203522, 'std': 11.894307144743596, 'run': 9.333990179035696, 'test_avg': 28.81640625, 'test_std': 3.5739241681883707}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (401 / 20000):
    Value Loss: {'avg': 174.51117604573568, 'std': 14.77234371834728}
    Value Grad Norm: {'avg': 1308.328474934896, 'std': 617.2172989034226}
    Policy Loss: {'avg': -0.007218974130228162, 'std': 0.011894822687013187}
    Total_Loss: {'avg': -0.1817081816494465, 'std': 0.010696972373133478}
    Policy Entropy: {'avg': 1.7569595575332642, 'std': 0.45773693919181824}
    KL Divergence: {'avg': 0.023748982697725296, 'std': 0.2087685465812683}
    Policy Grad Norm: {'avg': 1.1659509360790252, 'std': 0.35736946741541203}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -32.342786531135324, 'std': 53.551217218663496, 'run': -35.507145869332156, 'test_avg': -109.17818707788798, 'test_std': 17.121103950846248}
    Episode Length: {'avg': 10.161596958174904, 'std': 12.575797887480492, 'run': 10.89860517044631, 'test_avg': 28.263671875, 'test_std': 3.8523542662031987}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (501 / 20000):
    Value Loss: {'avg': 111.77313588460287, 'std': 11.304374750763602}
    Value Grad Norm: {'avg': 1321.0878560384115, 'std': 581.1405809992111}
    Policy Loss: {'avg': -0.009543249771619836, 'std': 0.011432550386445278}
    Total_Loss: {'avg': -0.1780642529328664, 'std': 0.011390687426149624}
    Policy Entropy: {'avg': 1.7161283493041992, 'std': 0.4662420451641083}
    KL Divergence: {'avg': 0.013664049096405506, 'std': 0.17727483808994293}
    Policy Grad Norm: {'avg': 0.9364640096823375, 'std': 0.21809335331328802}
    Num PPO updates: {'avg': 30}
    Return: {'avg': -29.13402044564467, 'std': 49.27359135205137, 'run': -32.21179161987374, 'test_avg': -103.16017883686433, 'test_std': 14.855120943179408}
    Episode Length: {'avg': 9.398181818181818, 'std': 11.51140131915218, 'run': 10.098517386980651, 'test_avg': 26.748046875, 'test_std': 3.7425702562280287}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (601 / 20000):
    Value Loss: {'avg': 126.0482800801595, 'std': 8.947218127438578}
    Value Grad Norm: {'avg': 1058.5317596435548, 'std': 395.027755459687}
    Policy Loss: {'avg': -0.0077340188436210155, 'std': 0.008202435501104834}
    Total_Loss: {'avg': -0.1766096420586109, 'std': 0.008449560691025072}
    Policy Entropy: {'avg': 1.7005200386047363, 'std': 0.47982528805732727}
    KL Divergence: {'avg': 0.016444779932498932, 'std': 0.17254863679409027}
    Policy Grad Norm: {'avg': 1.227602219581604, 'std': 0.3828018141068385}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -28.153864419191457, 'std': 48.376609440521335, 'run': -32.35336922572681, 'test_avg': -99.6995554986204, 'test_std': 13.35975671888657}
    Episode Length: {'avg': 9.228260869565217, 'std': 11.399628071293867, 'run': 10.196383135486164, 'test_avg': 25.8388671875, 'test_std': 3.055542652989128}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (701 / 20000):
    Value Loss: {'avg': 104.05691833496094, 'std': 9.19732485237666}
    Value Grad Norm: {'avg': 1383.3227274576823, 'std': 703.744875764464}
    Policy Loss: {'avg': -0.005138129089027643, 'std': 0.006685948767395399}
    Total_Loss: {'avg': -0.16121011674404145, 'std': 0.009138648933754722}
    Policy Entropy: {'avg': 1.571342945098877, 'std': 0.49842995405197144}
    KL Divergence: {'avg': 0.016541898250579834, 'std': 0.1715146005153656}
    Policy Grad Norm: {'avg': 1.4525310784578322, 'std': 0.609995842016517}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -26.21746440746407, 'std': 45.608601179455135, 'run': -24.451282847945194, 'test_avg': -97.75149238806196, 'test_std': 12.855890963987198}
    Episode Length: {'avg': 8.665094339622641, 'std': 10.644902011177841, 'run': 8.226065336404337, 'test_avg': 25.2509765625, 'test_std': 2.9152245543998294}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 20000):
    Value Loss: {'avg': 91.97645263671875, 'std': 7.9932326821705075}
    Value Grad Norm: {'avg': 1299.5419901529947, 'std': 589.5358231658106}
    Policy Loss: {'avg': -0.0020867425482720137, 'std': 0.007745727536220689}
    Total_Loss: {'avg': -0.1592390716075897, 'std': 0.008538222394653553}
    Policy Entropy: {'avg': 1.5256656408309937, 'std': 0.47704604268074036}
    KL Divergence: {'avg': 0.017868081107735634, 'std': 0.1869141012430191}
    Policy Grad Norm: {'avg': 1.08931622505188, 'std': 0.20883027836809043}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -28.2819432548788, 'std': 47.19504315198436, 'run': -29.806960057760083, 'test_avg': -96.16025337057555, 'test_std': 12.791929822538364}
    Episode Length: {'avg': 9.107719928186714, 'std': 11.07891853541574, 'run': 9.465736693577325, 'test_avg': 24.98828125, 'test_std': 2.9321526087327783}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (901 / 20000):
    Value Loss: {'avg': 86.41020685831705, 'std': 7.177770964551534}
    Value Grad Norm: {'avg': 1335.6791371663412, 'std': 789.1783188520484}
    Policy Loss: {'avg': 0.0007132121827453375, 'std': 0.00429807430978498}
    Total_Loss: {'avg': -0.14881986379623413, 'std': 0.0040619204931043726}
    Policy Entropy: {'avg': 1.4709806442260742, 'std': 0.4690952003002167}
    KL Divergence: {'avg': 0.016424868255853653, 'std': 0.1722145527601242}
    Policy Grad Norm: {'avg': 1.396531528234482, 'std': 0.4294442458167484}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -23.2792395899835, 'std': 43.288297625383436, 'run': -21.167848098665303, 'test_avg': -95.97797433450177, 'test_std': 13.921882774796245}
    Episode Length: {'avg': 7.884080370942813, 'std': 10.1965465278203, 'run': 7.262671788085939, 'test_avg': 24.9892578125, 'test_std': 3.5670039834443297}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (1001 / 20000):
    Value Loss: {'avg': 76.44438222249349, 'std': 7.106769071345956}
    Value Grad Norm: {'avg': 720.6522206624348, 'std': 352.62154970726647}
    Policy Loss: {'avg': 0.0003733674995601177, 'std': 0.002616213482129988}
    Total_Loss: {'avg': -0.14546932578086852, 'std': 0.0033049727955205624}
    Policy Entropy: {'avg': 1.4409027099609375, 'std': 0.514616072177887}
    KL Divergence: {'avg': 0.019866863265633583, 'std': 0.1782134622335434}
    Policy Grad Norm: {'avg': 1.5400958716869355, 'std': 0.49869742610941625}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -23.419945438941365, 'std': 42.42857100931088, 'run': -21.204984168510126, 'test_avg': -93.17124332566647, 'test_std': 11.9094909473887}
    Episode Length: {'avg': 7.917316692667707, 'std': 9.894814805672276, 'run': 7.301507300667732, 'test_avg': 24.1357421875, 'test_std': 2.8723037349891665}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1101 / 20000):
    Value Loss: {'avg': 75.34380213419597, 'std': 6.745289064195898}
    Value Grad Norm: {'avg': 984.2617075602213, 'std': 467.9682939352105}
    Policy Loss: {'avg': 0.0076074045151472095, 'std': 0.005616136455519224}
    Total_Loss: {'avg': -0.14244371950626372, 'std': 0.007681795335318634}
    Policy Entropy: {'avg': 1.4518606662750244, 'std': 0.49331575632095337}
    KL Divergence: {'avg': 0.021511677652597427, 'std': 0.18276292085647583}
    Policy Grad Norm: {'avg': 1.6928295969963074, 'std': 0.2031838330438842}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.318379527783602, 'std': 40.65949090044279, 'run': -21.411937147732004, 'test_avg': -91.6167422747643, 'test_std': 11.193656858943044}
    Episode Length: {'avg': 7.404833836858006, 'std': 9.529688427660217, 'run': 7.474220349004958, 'test_avg': 23.8193359375, 'test_std': 2.630495948299673}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1201 / 20000):
    Value Loss: {'avg': 69.77022755940756, 'std': 7.216755484739794}
    Value Grad Norm: {'avg': 1921.4007537841796, 'std': 1094.6910824546705}
    Policy Loss: {'avg': -0.0011654001660645007, 'std': 0.004537107370605753}
    Total_Loss: {'avg': -0.14683869779109954, 'std': 0.006229488440555844}
    Policy Entropy: {'avg': 1.4348037242889404, 'std': 0.4643535017967224}
    KL Divergence: {'avg': 0.017158428207039833, 'std': 0.17480067908763885}
    Policy Grad Norm: {'avg': 1.5561965584754944, 'std': 0.26768888051380385}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.60616975076046, 'std': 40.27161942041688, 'run': -19.7257594890567, 'test_avg': -91.13108390745053, 'test_std': 10.659286192450736}
    Episode Length: {'avg': 7.485407066052227, 'std': 9.503222136659254, 'run': 7.037451096177424, 'test_avg': 23.6376953125, 'test_std': 2.42476339070754}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 20000):
    Value Loss: {'avg': 65.06380996704101, 'std': 6.868190805773774}
    Value Grad Norm: {'avg': 964.6471872965495, 'std': 426.6710520056308}
    Policy Loss: {'avg': 0.007231448916718364, 'std': 0.00807454992591603}
    Total_Loss: {'avg': -0.14051342159509658, 'std': 0.008119664974425383}
    Policy Entropy: {'avg': 1.4332575798034668, 'std': 0.4651762545108795}
    KL Divergence: {'avg': 0.01600750721991062, 'std': 0.16362027823925018}
    Policy Grad Norm: {'avg': 2.0463783502578736, 'std': 0.7269915117285444}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.868061262410627, 'std': 40.57358532232703, 'run': -24.81097294479722, 'test_avg': -88.15883353398408, 'test_std': 10.013166955553105}
    Episode Length: {'avg': 7.66060606060606, 'std': 9.573161328135482, 'run': 8.355069231043739, 'test_avg': 22.96484375, 'test_std': 2.2799085043233505}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1401 / 20000):
    Value Loss: {'avg': 51.47033958435058, 'std': 6.631053064556914}
    Value Grad Norm: {'avg': 1001.9390218098958, 'std': 597.4272213456994}
    Policy Loss: {'avg': -0.0012963297311216592, 'std': 0.0035714727065377845}
    Total_Loss: {'avg': -0.13089962899684907, 'std': 0.004274818228787875}
    Policy Entropy: {'avg': 1.3108904361724854, 'std': 0.47632360458374023}
    KL Divergence: {'avg': 0.018763436004519463, 'std': 0.2030242532491684}
    Policy Grad Norm: {'avg': 1.7464961171150208, 'std': 0.4624307540162338}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.956227532458836, 'std': 40.43420664543936, 'run': -22.79539118756407, 'test_avg': -88.07610799062782, 'test_std': 9.454128263826012}
    Episode Length: {'avg': 7.559774964838256, 'std': 9.47980380166887, 'run': 7.70843257702186, 'test_avg': 22.876953125, 'test_std': 2.1333695686759793}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 20000):
    Value Loss: {'avg': 42.483564631144205, 'std': 5.07698497938907}
    Value Grad Norm: {'avg': 644.6060470581054, 'std': 357.8586115642803}
    Policy Loss: {'avg': 0.007422472327016294, 'std': 0.009194100088772117}
    Total_Loss: {'avg': -0.11044928878545761, 'std': 0.00838783277573744}
    Policy Entropy: {'avg': 1.1943554878234863, 'std': 0.5031484365463257}
    KL Divergence: {'avg': 0.018208229914307594, 'std': 0.1704588085412979}
    Policy Grad Norm: {'avg': 2.4739813804626465, 'std': 0.7359911224234678}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.05014890901495, 'std': 37.998871229338036, 'run': -20.555109964694434, 'test_avg': -86.74842903548233, 'test_std': 10.566283923452142}
    Episode Length: {'avg': 7.311428571428571, 'std': 8.919649942797129, 'run': 7.178272301405322, 'test_avg': 22.64453125, 'test_std': 2.92293753658429}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (1601 / 20000):
    Value Loss: {'avg': 42.53897285461426, 'std': 3.482394915508491}
    Value Grad Norm: {'avg': 755.3415557861329, 'std': 290.8898350350696}
    Policy Loss: {'avg': 0.007455946505069732, 'std': 0.0073023131843710214}
    Total_Loss: {'avg': -0.12137743607163429, 'std': 0.007806127753449066}
    Policy Entropy: {'avg': 1.253196358680725, 'std': 0.5271439552307129}
    KL Divergence: {'avg': 0.023038314655423164, 'std': 0.20327341556549072}
    Policy Grad Norm: {'avg': 2.069356179237366, 'std': 0.505891400446355}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.24882269381782, 'std': 37.09582085756817, 'run': -18.930927432998566, 'test_avg': -86.30034415311289, 'test_std': 9.208038672692606}
    Episode Length: {'avg': 6.918918918918919, 'std': 8.818412973212036, 'run': 6.788308932119296, 'test_avg': 22.412109375, 'test_std': 2.035353989613873}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 20000):
    Value Loss: {'avg': 51.99486770629883, 'std': 5.917150829064009}
    Value Grad Norm: {'avg': 886.5925425211589, 'std': 478.89484241477834}
    Policy Loss: {'avg': 0.0045676831621676685, 'std': 0.004626339800340173}
    Total_Loss: {'avg': -0.12538288906216621, 'std': 0.00427724600470578}
    Policy Entropy: {'avg': 1.3320493698120117, 'std': 0.49498623609542847}
    KL Divergence: {'avg': 0.01585703156888485, 'std': 0.16173888742923737}
    Policy Grad Norm: {'avg': 1.9198235630989076, 'std': 0.331878389762543}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.434062252262784, 'std': 36.93902629138938, 'run': -17.923821220486822, 'test_avg': -85.19395083791434, 'test_std': 9.109627611119361}
    Episode Length: {'avg': 6.714859437751004, 'std': 8.796392793927607, 'run': 6.607508404918628, 'test_avg': 22.2119140625, 'test_std': 2.0350960340030015}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 20000):
    Value Loss: {'avg': 39.977278010050455, 'std': 4.669359357791912}
    Value Grad Norm: {'avg': 591.5378351847331, 'std': 261.9726585063652}
    Policy Loss: {'avg': -0.006299367779865861, 'std': 0.009086660408200633}
    Total_Loss: {'avg': -0.12890426740050315, 'std': 0.010837224380793304}
    Policy Entropy: {'avg': 1.264481782913208, 'std': 0.47690802812576294}
    KL Divergence: {'avg': 0.025626052170991898, 'std': 0.18949148058891296}
    Policy Grad Norm: {'avg': 1.986896562576294, 'std': 0.5222287751239266}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.948097087097008, 'std': 36.088724054877176, 'run': -15.951158564838353, 'test_avg': -83.05136410419685, 'test_std': 8.13734608420855}
    Episode Length: {'avg': 6.807113543091655, 'std': 8.496221338388237, 'run': 6.167632464752753, 'test_avg': 21.6220703125, 'test_std': 1.7652076970731099}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 20000):
    Value Loss: {'avg': 44.31882209777832, 'std': 5.119890447533997}
    Value Grad Norm: {'avg': 719.6558085123698, 'std': 328.04204200352956}
    Policy Loss: {'avg': 0.0022227058187127115, 'std': 0.008370415418673735}
    Total_Loss: {'avg': -0.11923883631825447, 'std': 0.00872061759088093}
    Policy Entropy: {'avg': 1.2128918170928955, 'std': 0.5002670884132385}
    KL Divergence: {'avg': 0.01779741793870926, 'std': 0.15082794427871704}
    Policy Grad Norm: {'avg': 2.086842405796051, 'std': 0.4482054064091599}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.52368034189195, 'std': 38.3644853005054, 'run': -21.369244011676894, 'test_avg': -84.05173090545583, 'test_std': 9.033853545526918}
    Episode Length: {'avg': 7.489766081871345, 'std': 8.933880609919736, 'run': 7.379933024135067, 'test_avg': 21.916015625, 'test_std': 2.0006779475357495}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 20000):
    Value Loss: {'avg': 46.42032470703125, 'std': 5.829348117734497}
    Value Grad Norm: {'avg': 579.2438481648763, 'std': 240.03626681745325}
    Policy Loss: {'avg': 0.0066180102527141575, 'std': 0.007194097802981188}
    Total_Loss: {'avg': -0.11600866913795471, 'std': 0.00789410546345423}
    Policy Entropy: {'avg': 1.179366946220398, 'std': 0.5248240232467651}
    KL Divergence: {'avg': 0.019103460013866425, 'std': 0.2304021269083023}
    Policy Grad Norm: {'avg': 3.0931309700012206, 'std': 0.5904532799603224}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.33551010703097, 'std': 37.167591007969634, 'run': -21.696105521739863, 'test_avg': -82.84790064169054, 'test_std': 7.8682021114500715}
    Episode Length: {'avg': 7.091286307053942, 'std': 8.690941779988279, 'run': 7.327314902167737, 'test_avg': 21.5625, 'test_std': 1.717897515860594}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 20000):
    Value Loss: {'avg': 44.19937807718913, 'std': 4.311062115474208}
    Value Grad Norm: {'avg': 482.923752339681, 'std': 211.65867121431137}
    Policy Loss: {'avg': 0.004074212489649653, 'std': 0.004614914799303088}
    Total_Loss: {'avg': -0.11313292980194092, 'std': 0.005097598771777029}
    Policy Entropy: {'avg': 1.1749776601791382, 'std': 0.5395901203155518}
    KL Divergence: {'avg': 0.020230207592248917, 'std': 0.19635514914989471}
    Policy Grad Norm: {'avg': 2.4935399174690245, 'std': 0.7202413093605637}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.52994016698747, 'std': 38.309574054904914, 'run': -19.545743040400684, 'test_avg': -81.68911581312128, 'test_std': 7.714767565209673}
    Episode Length: {'avg': 7.329545454545454, 'std': 9.057388484382503, 'run': 6.882434955853852, 'test_avg': 21.32421875, 'test_std': 1.6719069433280183}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 20000):
    Value Loss: {'avg': 39.69555130004883, 'std': 3.4505980636938673}
    Value Grad Norm: {'avg': 784.8454538981119, 'std': 396.97242499985657}
    Policy Loss: {'avg': 0.006239581387490034, 'std': 0.007329914659608987}
    Total_Loss: {'avg': -0.10860745012760162, 'std': 0.0077254491639077265}
    Policy Entropy: {'avg': 1.1847196817398071, 'std': 0.5389222502708435}
    KL Divergence: {'avg': 0.01740584336221218, 'std': 0.165848508477211}
    Policy Grad Norm: {'avg': 2.8121280312538146, 'std': 0.7711148236256536}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.047652328807207, 'std': 36.54836074614753, 'run': -15.081141976645533, 'test_avg': -81.63010109555316, 'test_std': 8.391760629332111}
    Episode Length: {'avg': 7.076379066478077, 'std': 8.604945416204336, 'run': 5.8780597388801406, 'test_avg': 21.2880859375, 'test_std': 1.816809168601575}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 20000):
    Value Loss: {'avg': 46.72622528076172, 'std': 5.165811637978173}
    Value Grad Norm: {'avg': 796.4315628051758, 'std': 422.6194424773534}
    Policy Loss: {'avg': -0.0016936252359300852, 'std': 0.0027849372991759253}
    Total_Loss: {'avg': -0.13740833401679992, 'std': 0.002715584600211799}
    Policy Entropy: {'avg': 1.3282049894332886, 'std': 0.5180235505104065}
    KL Divergence: {'avg': 0.02390371263027191, 'std': 0.2404879480600357}
    Policy Grad Norm: {'avg': 3.2861932277679444, 'std': 1.3224799278677883}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.149388961213187, 'std': 38.20858096031971, 'run': -18.486641728228776, 'test_avg': -83.70022424397263, 'test_std': 9.06749862259266}
    Episode Length: {'avg': 7.215942028985507, 'std': 8.96683297925186, 'run': 6.699895725894549, 'test_avg': 21.90625, 'test_std': 2.003658762738805}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2401 / 20000):
    Value Loss: {'avg': 34.76802139282226, 'std': 3.9816089946379862}
    Value Grad Norm: {'avg': 517.5710810343425, 'std': 179.62577915602}
    Policy Loss: {'avg': 0.002814040007069707, 'std': 0.005149872104381804}
    Total_Loss: {'avg': -0.1095635674893856, 'std': 0.006424402966019513}
    Policy Entropy: {'avg': 1.1378381252288818, 'std': 0.5247728824615479}
    KL Divergence: {'avg': 0.022712159901857376, 'std': 0.24060103297233582}
    Policy Grad Norm: {'avg': 2.7096227407455444, 'std': 1.354327659012298}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.93780873690479, 'std': 33.62240494472407, 'run': -13.696890945989363, 'test_avg': -82.35900277494734, 'test_std': 8.866497158405432}
    Episode Length: {'avg': 6.419597989949748, 'std': 7.996690134344306, 'run': 5.654462113307882, 'test_avg': 21.5947265625, 'test_std': 1.994330715642953}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 20000):
    Value Loss: {'avg': 32.1480105082194, 'std': 3.822016680711655}
    Value Grad Norm: {'avg': 635.7447026570638, 'std': 319.7344943940135}
    Policy Loss: {'avg': 0.006505751516669989, 'std': 0.007094831539320567}
    Total_Loss: {'avg': -0.10698670297861099, 'std': 0.007773195387210405}
    Policy Entropy: {'avg': 1.1743882894515991, 'std': 0.5262367129325867}
    KL Divergence: {'avg': 0.023748591542243958, 'std': 0.16556468605995178}
    Policy Grad Norm: {'avg': 2.4173251509666445, 'std': 0.5597872912142897}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.433258278770353, 'std': 34.71751957758986, 'run': -19.826822343703324, 'test_avg': -81.99080620524667, 'test_std': 8.117872449360158}
    Episode Length: {'avg': 6.682170542635659, 'std': 8.18233854240918, 'run': 7.0648079021045564, 'test_avg': 21.5078125, 'test_std': 1.8461154053427293}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 20000):
    Value Loss: {'avg': 37.65584767659505, 'std': 4.8272326244608745}
    Value Grad Norm: {'avg': 830.578032430013, 'std': 354.03466127468187}
    Policy Loss: {'avg': 0.0007255825214087964, 'std': 0.003792339774716977}
    Total_Loss: {'avg': -0.11409205719828605, 'std': 0.0048914909567200696}
    Policy Entropy: {'avg': 1.1677318811416626, 'std': 0.5540395975112915}
    KL Divergence: {'avg': 0.019940346479415894, 'std': 0.1773911863565445}
    Policy Grad Norm: {'avg': 2.142918360233307, 'std': 0.7334809181013716}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.951739734296943, 'std': 34.80068730318229, 'run': -17.564403266694196, 'test_avg': -81.43489070392845, 'test_std': 8.353149868624877}
    Episode Length: {'avg': 6.599465954606141, 'std': 8.166642217500042, 'run': 6.4781442964678435, 'test_avg': 21.376953125, 'test_std': 1.8324590968293766}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 20000):
    Value Loss: {'avg': 32.828492101033525, 'std': 3.3192953077993614}
    Value Grad Norm: {'avg': 434.5452524820964, 'std': 161.76598900257957}
    Policy Loss: {'avg': 0.008665672317147256, 'std': 0.0075675956091858666}
    Total_Loss: {'avg': -0.10244200751185417, 'std': 0.007243747982152161}
    Policy Entropy: {'avg': 1.1335279941558838, 'std': 0.5423603057861328}
    KL Divergence: {'avg': 0.029820216819643974, 'std': 0.20462219417095184}
    Policy Grad Norm: {'avg': 2.733353650569916, 'std': 0.5831721143915053}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.933893566392232, 'std': 36.04914928572552, 'run': -22.811055192774262, 'test_avg': -81.49746263004182, 'test_std': 7.905005127264083}
    Episode Length: {'avg': 6.981994459833795, 'std': 8.455256681568919, 'run': 7.664237643872872, 'test_avg': 21.3251953125, 'test_std': 1.704976047112694}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 20000):
    Value Loss: {'avg': 37.44760398864746, 'std': 5.209002583119378}
    Value Grad Norm: {'avg': 764.7603108723958, 'std': 379.70790112444575}
    Policy Loss: {'avg': 1.3855984434485436e-06, 'std': 0.012399563730682276}
    Total_Loss: {'avg': -0.11534813866019249, 'std': 0.012520427026289138}
    Policy Entropy: {'avg': 1.184682846069336, 'std': 0.5193139910697937}
    KL Divergence: {'avg': 0.021528497338294983, 'std': 0.20073743164539337}
    Policy Grad Norm: {'avg': 2.618015778064728, 'std': 0.9860354607223311}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.31955715198838, 'std': 35.21548716063282, 'run': -17.756124983523634, 'test_avg': -81.73134181003945, 'test_std': 8.722322592400543}
    Episode Length: {'avg': 6.634738186462324, 'std': 8.285420508518168, 'run': 6.517253156254503, 'test_avg': 21.4951171875, 'test_std': 1.9136576321646697}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 20000):
    Value Loss: {'avg': 34.04087543487549, 'std': 3.9813202878113767}
    Value Grad Norm: {'avg': 866.4448842366536, 'std': 514.0065663018623}
    Policy Loss: {'avg': 0.0040611061733216046, 'std': 0.006902440910422529}
    Total_Loss: {'avg': -0.10801334232091904, 'std': 0.008792265940947244}
    Policy Entropy: {'avg': 1.0999054908752441, 'std': 0.5188263058662415}
    KL Divergence: {'avg': 0.02829846739768982, 'std': 0.24008065462112427}
    Policy Grad Norm: {'avg': 2.9576122879981996, 'std': 1.2977273150031936}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.163561448468183, 'std': 36.439661464370324, 'run': -17.617192836640175, 'test_avg': -82.5968885915778, 'test_std': 9.03250673673674}
    Episode Length: {'avg': 7.0667593880389425, 'std': 8.577617114775931, 'run': 6.4649419752119615, 'test_avg': 21.5830078125, 'test_std': 1.9806052617985153}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 20000):
    Value Loss: {'avg': 30.743815358479818, 'std': 3.416160236378562}
    Value Grad Norm: {'avg': 468.75220896402993, 'std': 225.9775439793967}
    Policy Loss: {'avg': 0.008804269693791866, 'std': 0.008139040790127717}
    Total_Loss: {'avg': -0.10221396535634994, 'std': 0.008649539162329798}
    Policy Entropy: {'avg': 1.074334979057312, 'std': 0.5228890776634216}
    KL Divergence: {'avg': 0.018986916169524193, 'std': 0.19654378294944763}
    Policy Grad Norm: {'avg': 4.3872088432312015, 'std': 3.174205228591158}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.391966649307605, 'std': 35.27697760292773, 'run': -21.179838552928572, 'test_avg': -81.0314755282509, 'test_std': 7.864087183525039}
    Episode Length: {'avg': 6.890227576974565, 'std': 8.329155471709212, 'run': 7.2694282541034205, 'test_avg': 21.2548828125, 'test_std': 1.7310569572928818}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3101 / 20000):
    Value Loss: {'avg': 29.28822587331136, 'std': 3.0297377831318233}
    Value Grad Norm: {'avg': 452.2306193033854, 'std': 247.62881068891582}
    Policy Loss: {'avg': 0.005628102086484432, 'std': 0.0050757142178342535}
    Total_Loss: {'avg': -0.10191352739930153, 'std': 0.004047938565826637}
    Policy Entropy: {'avg': 1.0635758638381958, 'std': 0.5550776720046997}
    KL Divergence: {'avg': 0.019363341853022575, 'std': 0.22112055122852325}
    Policy Grad Norm: {'avg': 3.4338968873023985, 'std': 1.6817970372723599}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.131483709149567, 'std': 36.43204574968945, 'run': -19.95394451340686, 'test_avg': -80.59255776251683, 'test_std': 7.781025635583825}
    Episode Length: {'avg': 7.049046321525886, 'std': 8.509029851208274, 'run': 7.003982373741497, 'test_avg': 21.1552734375, 'test_std': 1.7065795021348795}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 20000):
    Value Loss: {'avg': 30.081444422403973, 'std': 3.0892701208237825}
    Value Grad Norm: {'avg': 393.2317789713542, 'std': 126.4055115761394}
    Policy Loss: {'avg': 0.007346324948593974, 'std': 0.00866236252011054}
    Total_Loss: {'avg': -0.1029415674507618, 'std': 0.008530737627597753}
    Policy Entropy: {'avg': 1.0343599319458008, 'std': 0.5457475185394287}
    KL Divergence: {'avg': 0.021895011886954308, 'std': 0.19829967617988586}
    Policy Grad Norm: {'avg': 2.576283001899719, 'std': 0.6825275197837691}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.08114988233987, 'std': 34.83128083492034, 'run': -16.128936622012134, 'test_avg': -80.85374120758144, 'test_std': 8.015758805126639}
    Episode Length: {'avg': 6.8858267716535435, 'std': 8.174528884234142, 'run': 6.124119762125373, 'test_avg': 21.3134765625, 'test_std': 1.8260201620637115}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3301 / 20000):
    Value Loss: {'avg': 36.93524996439616, 'std': 4.447786770485971}
    Value Grad Norm: {'avg': 450.94038747151694, 'std': 158.60150337211763}
    Policy Loss: {'avg': 0.004631935525685549, 'std': 0.003958597126661105}
    Total_Loss: {'avg': -0.11540863960981369, 'std': 0.0053949602453367594}
    Policy Entropy: {'avg': 1.1423468589782715, 'std': 0.5590337514877319}
    KL Divergence: {'avg': 0.029528845101594925, 'std': 0.25638261437416077}
    Policy Grad Norm: {'avg': 3.6238484978675842, 'std': 1.7757119381926705}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.7528506618019, 'std': 36.61926149553446, 'run': -21.5606115549078, 'test_avg': -79.61294323010608, 'test_std': 7.197271521894939}
    Episode Length: {'avg': 7.2625538020086085, 'std': 8.573837674798325, 'run': 7.362961699092374, 'test_avg': 20.9091796875, 'test_std': 1.5862426464250046}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 20000):
    Value Loss: {'avg': 30.46848462422689, 'std': 3.161919721431091}
    Value Grad Norm: {'avg': 418.1193868001302, 'std': 158.56836654067618}
    Policy Loss: {'avg': 0.003942802734673023, 'std': 0.004494135373407147}
    Total_Loss: {'avg': -0.10528493598103524, 'std': 0.0067815874330019585}
    Policy Entropy: {'avg': 1.018892765045166, 'std': 0.5285956263542175}
    KL Divergence: {'avg': 0.022203445434570312, 'std': 0.2091437429189682}
    Policy Grad Norm: {'avg': 3.13917475938797, 'std': 0.9823027801457561}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.275072239811713, 'std': 35.30426380979057, 'run': -23.854601724832982, 'test_avg': -80.15023430788096, 'test_std': 10.55981059877562}
    Episode Length: {'avg': 6.863395225464191, 'std': 8.280472195000645, 'run': 7.984495413975304, 'test_avg': 21.0732421875, 'test_std': 2.147288178021342}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3501 / 20000):
    Value Loss: {'avg': 30.740755081176758, 'std': 3.7647882992766646}
    Value Grad Norm: {'avg': 411.02337341308595, 'std': 173.31623648772012}
    Policy Loss: {'avg': 0.0025553204119205474, 'std': 0.00474940250852596}
    Total_Loss: {'avg': -0.10119183361530304, 'std': 0.004794122342242616}
    Policy Entropy: {'avg': 1.0265450477600098, 'std': 0.521281361579895}
    KL Divergence: {'avg': 0.019862715154886246, 'std': 0.18030831217765808}
    Policy Grad Norm: {'avg': 3.333406686782837, 'std': 1.6908832657912214}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.520766530876738, 'std': 34.181179577072655, 'run': -19.427410395226104, 'test_avg': -80.42761931965721, 'test_std': 8.331409400678048}
    Episode Length: {'avg': 6.712998712998713, 'std': 8.02690125607467, 'run': 7.025705331909842, 'test_avg': 21.1484375, 'test_std': 1.8369677960143314}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3601 / 20000):
    Value Loss: {'avg': 31.990439732869465, 'std': 3.8788342638068487}
    Value Grad Norm: {'avg': 345.975922648112, 'std': 186.5044229842667}
    Policy Loss: {'avg': 0.006348971789702773, 'std': 0.008874952011512892}
    Total_Loss: {'avg': -0.09803909137845039, 'std': 0.009639891839576633}
    Policy Entropy: {'avg': 1.0841845273971558, 'std': 0.5142080783843994}
    KL Divergence: {'avg': 0.024607984349131584, 'std': 0.20820245146751404}
    Policy Grad Norm: {'avg': 2.607299280166626, 'std': 0.8852637503872804}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.6459401260005, 'std': 34.48406758800024, 'run': -17.68552501996888, 'test_avg': -79.86666130167274, 'test_std': 10.717743000065834}
    Episode Length: {'avg': 6.7428958051420835, 'std': 8.050008632020939, 'run': 6.5275420070947865, 'test_avg': 21.0166015625, 'test_std': 2.1881065617612316}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3701 / 20000):
    Value Loss: {'avg': 25.885767936706543, 'std': 2.4900127459713386}
    Value Grad Norm: {'avg': 283.47642822265624, 'std': 94.0631863392832}
    Policy Loss: {'avg': 0.0023620125837624075, 'std': 0.005927416640316135}
    Total_Loss: {'avg': -0.09556757062673568, 'std': 0.005877999018445448}
    Policy Entropy: {'avg': 0.9831693172454834, 'std': 0.5621986389160156}
    KL Divergence: {'avg': 0.038110893219709396, 'std': 0.2611149847507477}
    Policy Grad Norm: {'avg': 2.187294673919678, 'std': 0.8177279081912617}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.997583626779793, 'std': 34.55166718560952, 'run': -15.037207746825768, 'test_avg': -78.84401973916229, 'test_std': 7.742007812679754}
    Episode Length: {'avg': 6.823451910408433, 'std': 8.072003256265635, 'run': 5.994603514641057, 'test_avg': 20.771484375, 'test_std': 1.7020573900814449}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3801 / 20000):
    Value Loss: {'avg': 22.368729909261067, 'std': 2.5492079237775336}
    Value Grad Norm: {'avg': 370.205126953125, 'std': 128.08539331912067}
    Policy Loss: {'avg': 0.00018315771594643593, 'std': 0.007694898993082129}
    Total_Loss: {'avg': -0.09725907295942307, 'std': 0.00830809770286082}
    Policy Entropy: {'avg': 0.9729966521263123, 'std': 0.5726341605186462}
    KL Divergence: {'avg': 0.030313977971673012, 'std': 0.23523157835006714}
    Policy Grad Norm: {'avg': 2.356101417541504, 'std': 0.5069965115029067}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.451146965874134, 'std': 32.17982121101137, 'run': -14.533203612912246, 'test_avg': -80.00196804958952, 'test_std': 8.017831435778575}
    Episode Length: {'avg': 6.209905660377358, 'std': 7.569850574941958, 'run': 5.691848042869032, 'test_avg': 21.0908203125, 'test_std': 1.7684721819518119}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3901 / 20000):
    Value Loss: {'avg': 29.80782349904378, 'std': 2.551577059143943}
    Value Grad Norm: {'avg': 514.4942479451497, 'std': 224.79839094420583}
    Policy Loss: {'avg': 0.0017004553694278002, 'std': 0.0016891584889621232}
    Total_Loss: {'avg': -0.10844518095254899, 'std': 0.004076815808908504}
    Policy Entropy: {'avg': 1.1095826625823975, 'std': 0.5516649484634399}
    KL Divergence: {'avg': 0.01538939494639635, 'std': 0.1676662415266037}
    Policy Grad Norm: {'avg': 2.6603715300559996, 'std': 0.9156154902489068}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.019666511341125, 'std': 35.51686017368446, 'run': -18.221485242018478, 'test_avg': -79.2372029253215, 'test_std': 7.945172855676944}
    Episode Length: {'avg': 6.831788079470199, 'std': 8.401642624482832, 'run': 6.685920989816315, 'test_avg': 20.9228515625, 'test_std': 1.764699777891783}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4001 / 20000):
    Value Loss: {'avg': 33.966485341389976, 'std': 3.476158088578626}
    Value Grad Norm: {'avg': 408.19859212239584, 'std': 155.85358889228993}
    Policy Loss: {'avg': 0.0024659288115799426, 'std': 0.004435896673914583}
    Total_Loss: {'avg': -0.11091004461050033, 'std': 0.005169238906399349}
    Policy Entropy: {'avg': 1.0994426012039185, 'std': 0.5224151015281677}
    KL Divergence: {'avg': 0.019583063200116158, 'std': 0.200319305062294}
    Policy Grad Norm: {'avg': 3.1348599791526794, 'std': 1.467901334087792}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.287792647273157, 'std': 36.17568390150832, 'run': -24.537000647461568, 'test_avg': -79.2493915407902, 'test_std': 7.4966398333099376}
    Episode Length: {'avg': 7.137931034482759, 'std': 8.487411115500393, 'run': 8.169080240544073, 'test_avg': 20.90234375, 'test_std': 1.6530731250721904}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 20000):
    Value Loss: {'avg': 26.86178684234619, 'std': 2.423498762791681}
    Value Grad Norm: {'avg': 381.64858729044596, 'std': 154.76116045622746}
    Policy Loss: {'avg': 0.00635279449634254, 'std': 0.003452610454757957}
    Total_Loss: {'avg': -0.09994872361421585, 'std': 0.004869044724270595}
    Policy Entropy: {'avg': 1.107473611831665, 'std': 0.5636020302772522}
    KL Divergence: {'avg': 0.027171751484274864, 'std': 0.21354593336582184}
    Policy Grad Norm: {'avg': 3.4101046681404115, 'std': 1.7925988006372118}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.204757148276, 'std': 34.48462662892293, 'run': -17.394791359213336, 'test_avg': -79.70510779945516, 'test_std': 8.344685306703408}
    Episode Length: {'avg': 6.572903225806452, 'std': 8.104608881350599, 'run': 6.360090998069425, 'test_avg': 21.0400390625, 'test_std': 1.827352507310541}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4201 / 20000):
    Value Loss: {'avg': 29.326729329427085, 'std': 3.2869487454793616}
    Value Grad Norm: {'avg': 476.1342137654622, 'std': 193.00396360390482}
    Policy Loss: {'avg': 0.0025616486091166735, 'std': 0.0042765077615776826}
    Total_Loss: {'avg': -0.10210371315479279, 'std': 0.004896074872575608}
    Policy Entropy: {'avg': 1.057640790939331, 'std': 0.572203516960144}
    KL Divergence: {'avg': 0.017207494005560875, 'std': 0.1921939104795456}
    Policy Grad Norm: {'avg': 3.4585976004600525, 'std': 1.2441330904560097}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.547863244444816, 'std': 33.71854859952454, 'run': -18.26076581009827, 'test_avg': -80.09722259872379, 'test_std': 11.27329333673358}
    Episode Length: {'avg': 6.419518377693283, 'std': 7.981929799042078, 'run': 6.7423073249769905, 'test_avg': 21.142578125, 'test_std': 2.354596484171223}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4301 / 20000):
    Value Loss: {'avg': 37.86144129435221, 'std': 4.588006032539645}
    Value Grad Norm: {'avg': 429.7068837483724, 'std': 201.88948610304277}
    Policy Loss: {'avg': 0.006346267275512218, 'std': 0.016575504020308066}
    Total_Loss: {'avg': -0.09880360774695873, 'std': 0.016138656513702852}
    Policy Entropy: {'avg': 1.0578339099884033, 'std': 0.5734877586364746}
    KL Divergence: {'avg': 0.023877641186118126, 'std': 0.19692283868789673}
    Policy Grad Norm: {'avg': 4.511360538005829, 'std': 3.648276346080279}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.710282069740014, 'std': 37.670490661182285, 'run': -21.229556969612513, 'test_avg': -80.62565751960506, 'test_std': 15.146849210632443}
    Episode Length: {'avg': 7.430122116689281, 'std': 8.805346476964363, 'run': 7.345746578682864, 'test_avg': 21.14453125, 'test_std': 3.0088751166795604}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (4401 / 20000):
    Value Loss: {'avg': 21.0755438486735, 'std': 2.250414330867907}
    Value Grad Norm: {'avg': 279.29720916748045, 'std': 115.42703178386063}
    Policy Loss: {'avg': 0.010391697753220797, 'std': 0.011979650153679808}
    Total_Loss: {'avg': -0.08510269559919834, 'std': 0.012198483790046772}
    Policy Entropy: {'avg': 0.939813494682312, 'std': 0.5657606720924377}
    KL Divergence: {'avg': 0.0296797938644886, 'std': 0.22942140698432922}
    Policy Grad Norm: {'avg': 4.040408480167389, 'std': 2.2970433785585813}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.701223057766455, 'std': 33.219337675663596, 'run': -19.19015609814459, 'test_avg': -79.03209624503091, 'test_std': 8.209263089051959}
    Episode Length: {'avg': 6.509702457956015, 'std': 7.817052480606777, 'run': 6.775200033384077, 'test_avg': 20.8662109375, 'test_std': 1.8062042864126335}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4501 / 20000):
    Value Loss: {'avg': 30.004335975646974, 'std': 3.2028284546030292}
    Value Grad Norm: {'avg': 306.52943725585936, 'std': 113.84385682174396}
    Policy Loss: {'avg': 0.0038855538703501226, 'std': 0.005924101884617203}
    Total_Loss: {'avg': -0.10729427337646484, 'std': 0.005295263764109924}
    Policy Entropy: {'avg': 1.095738410949707, 'std': 0.5437224507331848}
    KL Divergence: {'avg': 0.01693974807858467, 'std': 0.1687975823879242}
    Policy Grad Norm: {'avg': 2.6605936884880066, 'std': 0.7731609479634464}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -20.099905493550082, 'std': 35.8557704680115, 'run': -21.252722225611762, 'test_avg': -80.61753114534457, 'test_std': 18.406047498156674}
    Episode Length: {'avg': 7.072207084468665, 'std': 8.388000140375308, 'run': 7.356743441376895, 'test_avg': 21.1728515625, 'test_std': 3.5545972204796015}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (4601 / 20000):
    Value Loss: {'avg': 31.15434125264486, 'std': 3.762062821841663}
    Value Grad Norm: {'avg': 445.74448547363284, 'std': 164.44501139840614}
    Policy Loss: {'avg': -0.003780861082486808, 'std': 0.009550086764825983}
    Total_Loss: {'avg': -0.1157825879752636, 'std': 0.008337389516899494}
    Policy Entropy: {'avg': 1.1067129373550415, 'std': 0.58365797996521}
    KL Divergence: {'avg': 0.021178895607590675, 'std': 0.18622682988643646}
    Policy Grad Norm: {'avg': 2.901918041706085, 'std': 1.5260317752133805}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.042588222295826, 'std': 34.37116847982812, 'run': -19.16667668687154, 'test_avg': -79.03321111160022, 'test_std': 10.919835096836179}
    Episode Length: {'avg': 6.554557124518613, 'std': 8.08034361378442, 'run': 6.8070041145183815, 'test_avg': 20.8310546875, 'test_std': 2.2145145447443504}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4701 / 20000):
    Value Loss: {'avg': 27.678400166829427, 'std': 2.389937989868634}
    Value Grad Norm: {'avg': 360.96329803466796, 'std': 138.053742646962}
    Policy Loss: {'avg': 0.0007787399459630251, 'std': 0.0013146662081604712}
    Total_Loss: {'avg': -0.10632066056132317, 'std': 0.0029713888997735167}
    Policy Entropy: {'avg': 1.0771420001983643, 'std': 0.5645794868469238}
    KL Divergence: {'avg': 0.019943594932556152, 'std': 0.23554253578186035}
    Policy Grad Norm: {'avg': 2.4861390709877016, 'std': 0.864371873710265}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.338820823536814, 'std': 34.44263940906273, 'run': -16.63155451980282, 'test_avg': -78.3775612558747, 'test_std': 8.193721550890983}
    Episode Length: {'avg': 6.669301712779974, 'std': 8.108129163834768, 'run': 6.153961970123227, 'test_avg': 20.7060546875, 'test_std': 1.7827631897588858}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4801 / 20000):
    Value Loss: {'avg': 27.97113889058431, 'std': 3.145652227376981}
    Value Grad Norm: {'avg': 295.82091013590497, 'std': 130.3193597784065}
    Policy Loss: {'avg': 0.003259381651878357, 'std': 0.004586401669658586}
    Total_Loss: {'avg': -0.09820574074983597, 'std': 0.004347716557907831}
    Policy Entropy: {'avg': 0.9953963756561279, 'std': 0.5399131178855896}
    KL Divergence: {'avg': 0.023321105167269707, 'std': 0.21869078278541565}
    Policy Grad Norm: {'avg': 2.211151909828186, 'std': 0.7344497047671597}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.00774296257767, 'std': 33.740381955143214, 'run': -22.54085856949478, 'test_avg': -78.4471576667774, 'test_std': 9.350430219468462}
    Episode Length: {'avg': 6.548556430446194, 'std': 7.953168652612262, 'run': 7.779295441245728, 'test_avg': 20.681640625, 'test_std': 2.1028753668131666}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (4901 / 20000):
    Value Loss: {'avg': 24.085110155741372, 'std': 2.716805627930158}
    Value Grad Norm: {'avg': 323.49725240071615, 'std': 124.32005504434414}
    Policy Loss: {'avg': -0.0007147543132305145, 'std': 0.003907724213663755}
    Total_Loss: {'avg': -0.10953983888030053, 'std': 0.005382492964471687}
    Policy Entropy: {'avg': 1.034947395324707, 'std': 0.5487084984779358}
    KL Divergence: {'avg': 0.01875815913081169, 'std': 0.17084982991218567}
    Policy Grad Norm: {'avg': 2.44981644153595, 'std': 0.9900108942384755}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.659346588041682, 'std': 34.07294868926948, 'run': -21.02479339445375, 'test_avg': -79.87113669741011, 'test_std': 10.979301507828332}
    Episode Length: {'avg': 6.775510204081633, 'std': 8.005936078610285, 'run': 7.2320130472250455, 'test_avg': 21.1396484375, 'test_std': 2.4864928617238795}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5001 / 20000):
    Value Loss: {'avg': 22.06596285502116, 'std': 2.229128214148375}
    Value Grad Norm: {'avg': 229.7008087158203, 'std': 82.2682552835205}
    Policy Loss: {'avg': 0.002342802006751299, 'std': 0.004154304568072402}
    Total_Loss: {'avg': -0.09585309475660324, 'std': 0.005209518464011091}
    Policy Entropy: {'avg': 0.9670740962028503, 'std': 0.5548984408378601}
    KL Divergence: {'avg': 0.023622551932930946, 'std': 0.18354351818561554}
    Policy Grad Norm: {'avg': 3.6570824146270753, 'std': 1.8588834323309924}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -21.603343635479824, 'std': 35.970296602112185, 'run': -18.706519844990385, 'test_avg': -78.57010407505372, 'test_std': 11.743806925834546}
    Episode Length: {'avg': 7.407952871870398, 'std': 8.455026744639273, 'run': 6.779706809983589, 'test_avg': 20.6474609375, 'test_std': 2.473637053391548}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (5101 / 20000):
    Value Loss: {'avg': 36.78294563293457, 'std': 3.704410122769015}
    Value Grad Norm: {'avg': 616.9119725545247, 'std': 264.524597630989}
    Policy Loss: {'avg': -0.0006666248198598623, 'std': 0.004021859761226005}
    Total_Loss: {'avg': -0.1076412670314312, 'std': 0.004884358290927097}
    Policy Entropy: {'avg': 1.0365872383117676, 'std': 0.5753398537635803}
    KL Divergence: {'avg': 0.023394590243697166, 'std': 0.19779649376869202}
    Policy Grad Norm: {'avg': 2.4659785628318787, 'std': 0.4352508638282029}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.90409783045403, 'std': 34.560451943927575, 'run': -20.178494464332125, 'test_avg': -79.09016073004807, 'test_std': 9.772518761844855}
    Episode Length: {'avg': 6.525529265255293, 'std': 8.14839230757117, 'run': 7.076730718986588, 'test_avg': 20.9130859375, 'test_std': 2.2196883245716608}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5201 / 20000):
    Value Loss: {'avg': 27.14272543589274, 'std': 3.081629443361121}
    Value Grad Norm: {'avg': 330.1423080444336, 'std': 114.39534003631775}
    Policy Loss: {'avg': 0.004534203931689263, 'std': 0.003936237437172416}
    Total_Loss: {'avg': -0.10360194221138955, 'std': 0.004763162393582168}
    Policy Entropy: {'avg': 1.0508627891540527, 'std': 0.572730541229248}
    KL Divergence: {'avg': 0.02757258526980877, 'std': 0.2210381180047989}
    Policy Grad Norm: {'avg': 2.454662764072418, 'std': 0.8883703955546342}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.67817969660524, 'std': 35.13680346958219, 'run': -21.55891704494917, 'test_avg': -79.8471997268108, 'test_std': 11.374139769552137}
    Episode Length: {'avg': 6.998663101604278, 'std': 8.277522448888137, 'run': 7.450145452203129, 'test_avg': 21.158203125, 'test_std': 2.509040508090739}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5301 / 20000):
    Value Loss: {'avg': 20.92425880432129, 'std': 2.158806652986109}
    Value Grad Norm: {'avg': 234.60417683919272, 'std': 55.046820133716444}
    Policy Loss: {'avg': 0.004827569099143147, 'std': 0.009365311920916768}
    Total_Loss: {'avg': -0.09213092103600502, 'std': 0.008018758856972692}
    Policy Entropy: {'avg': 1.0092148780822754, 'std': 0.597221851348877}
    KL Divergence: {'avg': 0.036329369992017746, 'std': 0.32415518164634705}
    Policy Grad Norm: {'avg': 2.608325779438019, 'std': 0.7089026636609378}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.195333305218224, 'std': 34.00138016398111, 'run': -17.159740504690948, 'test_avg': -78.53184888203798, 'test_std': 13.17258747746809}
    Episode Length: {'avg': 6.531612903225806, 'std': 7.961761475053115, 'run': 6.289889607192039, 'test_avg': 20.615234375, 'test_std': 2.83986725725312}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (5401 / 20000):
    Value Loss: {'avg': 22.951372464497883, 'std': 2.59822746796186}
    Value Grad Norm: {'avg': 363.3863108317057, 'std': 153.57985156129266}
    Policy Loss: {'avg': 0.00623863753862679, 'std': 0.005988405676660961}
    Total_Loss: {'avg': -0.09541017934679985, 'std': 0.006972893306815182}
    Policy Entropy: {'avg': 1.0246654748916626, 'std': 0.570286750793457}
    KL Divergence: {'avg': 0.0262333694845438, 'std': 0.25894248485565186}
    Policy Grad Norm: {'avg': 2.3237075448036193, 'std': 1.0309834546060683}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.741191997859932, 'std': 33.41315090854924, 'run': -17.080392106271677, 'test_avg': -77.61455368637837, 'test_std': 7.504238113229701}
    Episode Length: {'avg': 6.507731958762887, 'std': 7.874004077774769, 'run': 6.344800095871342, 'test_avg': 20.548828125, 'test_std': 1.6570041307157277}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5501 / 20000):
    Value Loss: {'avg': 26.460652414957682, 'std': 2.9253821981518957}
    Value Grad Norm: {'avg': 379.3211430867513, 'std': 164.44054602182888}
    Policy Loss: {'avg': 0.0022119982168078423, 'std': 0.005339483543420338}
    Total_Loss: {'avg': -0.09509530290961266, 'std': 0.006476479639688428}
    Policy Entropy: {'avg': 0.960730791091919, 'std': 0.5759734511375427}
    KL Divergence: {'avg': 0.018258361145853996, 'std': 0.19278018176555634}
    Policy Grad Norm: {'avg': 3.6848418712615967, 'std': 1.4704264827131321}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.67814743406372, 'std': 34.293079747527145, 'run': -18.38964663264457, 'test_avg': -77.71930148715674, 'test_std': 7.809508726969778}
    Episode Length: {'avg': 6.72020725388601, 'std': 8.049198200248917, 'run': 6.525649189257069, 'test_avg': 20.5810546875, 'test_std': 1.7216658394224698}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5601 / 20000):
    Value Loss: {'avg': 24.662386830647787, 'std': 3.0301320583951905}
    Value Grad Norm: {'avg': 316.384486134847, 'std': 150.8122169559017}
    Policy Loss: {'avg': 0.0020928761456161737, 'std': 0.007117792500772346}
    Total_Loss: {'avg': -0.09008250609040261, 'std': 0.00900649253925696}
    Policy Entropy: {'avg': 0.9524146318435669, 'std': 0.5852821469306946}
    KL Divergence: {'avg': 0.03950362652540207, 'std': 0.3193488121032715}
    Policy Grad Norm: {'avg': 2.9384539246559145, 'std': 1.620628008323369}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.733361101909992, 'std': 32.66780481901686, 'run': -17.006596560182828, 'test_avg': -77.59845317705958, 'test_std': 7.393303372837804}
    Episode Length: {'avg': 6.477535301668806, 'std': 7.703787380891697, 'run': 6.257276742221244, 'test_avg': 20.5693359375, 'test_std': 1.6271251573775742}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5701 / 20000):
    Value Loss: {'avg': 37.92877400716146, 'std': 10.937724795400497}
    Value Grad Norm: {'avg': 263.05452194213865, 'std': 78.59768807417305}
    Policy Loss: {'avg': 0.005375719908624887, 'std': 0.004398821440372122}
    Total_Loss: {'avg': -0.0955237977206707, 'std': 0.0031982483161836226}
    Policy Entropy: {'avg': 1.0324828624725342, 'std': 0.5809175372123718}
    KL Divergence: {'avg': 0.03850593417882919, 'std': 0.3597257435321808}
    Policy Grad Norm: {'avg': 3.425040912628174, 'std': 2.361600895401277}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.833878743936456, 'std': 32.394739581264574, 'run': -13.929099136204908, 'test_avg': -77.45227248380857, 'test_std': 7.543196105658753}
    Episode Length: {'avg': 6.282527881040892, 'std': 7.614925639464631, 'run': 5.536661634884225, 'test_avg': 20.5244140625, 'test_std': 1.6510501063118121}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5801 / 20000):
    Value Loss: {'avg': 23.49634691874186, 'std': 2.3826972399878055}
    Value Grad Norm: {'avg': 252.39170888264974, 'std': 68.11989288507324}
    Policy Loss: {'avg': 0.0049677564762532714, 'std': 0.007069469889708679}
    Total_Loss: {'avg': -0.09870781749486923, 'std': 0.0074085877075882375}
    Policy Entropy: {'avg': 1.0176631212234497, 'std': 0.5337715148925781}
    KL Divergence: {'avg': 0.023529473692178726, 'std': 0.2649722397327423}
    Policy Grad Norm: {'avg': 3.0929982662200928, 'std': 1.818660823605061}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.875419383547026, 'std': 33.46846936530458, 'run': -19.547110573557056, 'test_avg': -77.91720532482466, 'test_std': 12.127607155185137}
    Episode Length: {'avg': 6.526315789473684, 'std': 7.889656259956894, 'run': 6.788458703536579, 'test_avg': 20.5048828125, 'test_std': 2.433084057968834}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5901 / 20000):
    Value Loss: {'avg': 25.748794682820638, 'std': 2.829474208487801}
    Value Grad Norm: {'avg': 279.67787653605143, 'std': 130.40111774827952}
    Policy Loss: {'avg': 0.004717119690030813, 'std': 0.008680973002972566}
    Total_Loss: {'avg': -0.09406828954815864, 'std': 0.010049802179050153}
    Policy Entropy: {'avg': 0.9873244762420654, 'std': 0.5831036567687988}
    KL Divergence: {'avg': 0.019223326817154884, 'std': 0.17100957036018372}
    Policy Grad Norm: {'avg': 3.1561329126358033, 'std': 2.6485372508992038}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.127467466416395, 'std': 33.12041643557376, 'run': -13.94987032385479, 'test_avg': -78.04493151290305, 'test_std': 8.09237915553599}
    Episode Length: {'avg': 6.371069182389937, 'std': 7.777368764214853, 'run': 5.679483573906715, 'test_avg': 20.7275390625, 'test_std': 1.80574803752811}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6001 / 20000):
    Value Loss: {'avg': 23.664203389485678, 'std': 2.838585130258848}
    Value Grad Norm: {'avg': 229.92468388875326, 'std': 64.64433813708403}
    Policy Loss: {'avg': -0.002330967434681952, 'std': 0.007923905676279843}
    Total_Loss: {'avg': -0.1020492322742939, 'std': 0.009722282341403099}
    Policy Entropy: {'avg': 1.0324862003326416, 'std': 0.535986065864563}
    KL Divergence: {'avg': 0.031345706433057785, 'std': 0.23972760140895844}
    Policy Grad Norm: {'avg': 2.8044391572475433, 'std': 1.083395145566306}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.57231020077657, 'std': 33.980436326817525, 'run': -19.412462061763115, 'test_avg': -77.27519657868824, 'test_std': 7.422294720897823}
    Episode Length: {'avg': 6.65669700910273, 'std': 8.025104304820905, 'run': 6.850687796897556, 'test_avg': 20.455078125, 'test_std': 1.6285818678060013}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6101 / 20000):
    Value Loss: {'avg': 22.559147453308107, 'std': 2.6219181024886264}
    Value Grad Norm: {'avg': 217.76135431925456, 'std': 70.89709476021409}
    Policy Loss: {'avg': 1.9833585247397424e-05, 'std': 0.0029247560798992926}
    Total_Loss: {'avg': -0.093682711571455, 'std': 0.002345405585478077}
    Policy Entropy: {'avg': 0.9296042919158936, 'std': 0.5686262845993042}
    KL Divergence: {'avg': 0.01984998770058155, 'std': 0.16515597701072693}
    Policy Grad Norm: {'avg': 2.103810179233551, 'std': 0.5970011740356733}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.348859925495617, 'std': 33.9764577396461, 'run': -14.159485990260658, 'test_avg': -77.50364985037052, 'test_std': 7.306945967975137}
    Episode Length: {'avg': 6.57994923857868, 'std': 7.970596599358641, 'run': 5.680814718095614, 'test_avg': 20.4951171875, 'test_std': 1.597109078348154}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6201 / 20000):
    Value Loss: {'avg': 20.910478146870933, 'std': 2.1673489194667077}
    Value Grad Norm: {'avg': 213.01284255981446, 'std': 68.9856035456761}
    Policy Loss: {'avg': 0.005748984962701797, 'std': 0.005921354368759241}
    Total_Loss: {'avg': -0.08726266101002693, 'std': 0.00799630572846888}
    Policy Entropy: {'avg': 0.9239027500152588, 'std': 0.5832136273384094}
    KL Divergence: {'avg': 0.021165495738387108, 'std': 0.23256024718284607}
    Policy Grad Norm: {'avg': 3.625303339958191, 'std': 1.1068380778875035}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.84740133223413, 'std': 32.304872041799, 'run': -18.751866393176275, 'test_avg': -76.56807287185347, 'test_std': 6.952750022181801}
    Episode Length: {'avg': 6.269182389937107, 'std': 7.6271935678499005, 'run': 6.6725423285471335, 'test_avg': 20.322265625, 'test_std': 1.5186510846614372}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6301 / 20000):
    Value Loss: {'avg': 20.487983353932698, 'std': 2.74499060196834}
    Value Grad Norm: {'avg': 224.42260208129883, 'std': 63.164058298796974}
    Policy Loss: {'avg': 0.0025921933352947234, 'std': 0.005475032435924273}
    Total_Loss: {'avg': -0.08578047454357147, 'std': 0.0059791782676209245}
    Policy Entropy: {'avg': 0.8593311309814453, 'std': 0.569807767868042}
    KL Divergence: {'avg': 0.027076685801148415, 'std': 0.2531373202800751}
    Policy Grad Norm: {'avg': 3.0880612969398498, 'std': 1.485655305504543}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.154536574015353, 'std': 32.44749161378934, 'run': -12.613444037127616, 'test_avg': -77.5448711218798, 'test_std': 13.972981409598335}
    Episode Length: {'avg': 6.382165605095541, 'std': 7.639601009896351, 'run': 5.282880638191199, 'test_avg': 20.4912109375, 'test_std': 2.8603432271985074}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (6401 / 20000):
    Value Loss: {'avg': 23.77150955200195, 'std': 2.6718815439718755}
    Value Grad Norm: {'avg': 298.4636260986328, 'std': 96.75555206638211}
    Policy Loss: {'avg': 0.0027810598257929087, 'std': 0.00900418029625857}
    Total_Loss: {'avg': -0.08787158615887165, 'std': 0.010691656124828032}
    Policy Entropy: {'avg': 0.8940973281860352, 'std': 0.5659787654876709}
    KL Divergence: {'avg': 0.031599611043930054, 'std': 0.23253245651721954}
    Policy Grad Norm: {'avg': 3.1142664313316346, 'std': 1.328245614688663}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.919893451868795, 'std': 32.4835636424076, 'run': -20.477521970399636, 'test_avg': -77.85337804343466, 'test_std': 10.851022442835752}
    Episode Length: {'avg': 6.279487179487179, 'std': 7.7534997718046075, 'run': 7.2010674222792845, 'test_avg': 20.6474609375, 'test_std': 2.2175906738872304}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6501 / 20000):
    Value Loss: {'avg': 18.940548515319826, 'std': 2.098778300183269}
    Value Grad Norm: {'avg': 241.5632418314616, 'std': 97.08759487225825}
    Policy Loss: {'avg': 0.004274383187294006, 'std': 0.005027147041341679}
    Total_Loss: {'avg': -0.0927454948425293, 'std': 0.005830246713227406}
    Policy Entropy: {'avg': 0.941694974899292, 'std': 0.5608664751052856}
    KL Divergence: {'avg': 0.017661137506365776, 'std': 0.2297169268131256}
    Policy Grad Norm: {'avg': 2.836287760734558, 'std': 1.0786083839082585}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.003091639909144, 'std': 33.42992754562001, 'run': -17.27267683152757, 'test_avg': -77.47137625992922, 'test_std': 7.600682920306363}
    Episode Length: {'avg': 6.588785046728972, 'std': 7.898331421563027, 'run': 6.427526639452724, 'test_avg': 20.5361328125, 'test_std': 1.6871131170910976}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6601 / 20000):
    Value Loss: {'avg': 22.414152590433755, 'std': 2.653125555765193}
    Value Grad Norm: {'avg': 241.7149543762207, 'std': 103.26577670322202}
    Policy Loss: {'avg': 0.001556954113766551, 'std': 0.005991120208619588}
    Total_Loss: {'avg': -0.09735651165246964, 'std': 0.006887130474448446}
    Policy Entropy: {'avg': 0.9512972831726074, 'std': 0.5535200238227844}
    KL Divergence: {'avg': 0.016040002927184105, 'std': 0.1823478788137436}
    Policy Grad Norm: {'avg': 2.6824860095977785, 'std': 0.8463058565169492}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.1609974931239, 'std': 32.68923226357708, 'run': -16.55700300731498, 'test_avg': -77.22312580786596, 'test_std': 7.8680979081413005}
    Episode Length: {'avg': 6.393085787451985, 'std': 7.791646817727635, 'run': 6.2983263319922775, 'test_avg': 20.513671875, 'test_std': 1.724085070358764}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6701 / 20000):
    Value Loss: {'avg': 22.195124117533364, 'std': 2.54811991481657}
    Value Grad Norm: {'avg': 248.37814865112304, 'std': 94.89873303346852}
    Policy Loss: {'avg': 0.0035610223188996316, 'std': 0.0028759811089840597}
    Total_Loss: {'avg': -0.09347861483693123, 'std': 0.0038044878311139616}
    Policy Entropy: {'avg': 0.9807044267654419, 'std': 0.5917191505432129}
    KL Divergence: {'avg': 0.023511769250035286, 'std': 0.255937397480011}
    Policy Grad Norm: {'avg': 2.8301234602928163, 'std': 1.2415576339390937}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.5650457247575, 'std': 33.26347025962232, 'run': -16.30963859904983, 'test_avg': -77.34090843229845, 'test_std': 7.43535333230057}
    Episode Length: {'avg': 6.464968152866242, 'std': 7.836326208018411, 'run': 6.228385217905606, 'test_avg': 20.482421875, 'test_std': 1.6362840170708397}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6801 / 20000):
    Value Loss: {'avg': 19.081163342793783, 'std': 2.068006040852425}
    Value Grad Norm: {'avg': 277.51703084309895, 'std': 109.26208377739215}
    Policy Loss: {'avg': 0.004021232249215245, 'std': 0.006176525737911624}
    Total_Loss: {'avg': -0.08541236221790313, 'std': 0.005964132367598527}
    Policy Entropy: {'avg': 0.9078201055526733, 'std': 0.5865036845207214}
    KL Divergence: {'avg': 0.023595083504915237, 'std': 0.19056597352027893}
    Policy Grad Norm: {'avg': 2.6788679122924806, 'std': 1.1092668181232905}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.386250450827852, 'std': 30.731394770882552, 'run': -15.195487893029366, 'test_avg': -76.5269452422374, 'test_std': 7.510710484880353}
    Episode Length: {'avg': 5.946590909090909, 'std': 7.270307747388383, 'run': 5.964365587113378, 'test_avg': 20.3154296875, 'test_std': 1.660406403487909}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6901 / 20000):
    Value Loss: {'avg': 25.511435763041177, 'std': 2.814665257935207}
    Value Grad Norm: {'avg': 393.0352513631185, 'std': 236.91124613285731}
    Policy Loss: {'avg': -0.0012035202234983444, 'std': 0.0065786802487919505}
    Total_Loss: {'avg': -0.11008623391389846, 'std': 0.007702850475427484}
    Policy Entropy: {'avg': 1.0996482372283936, 'std': 0.5666781067848206}
    KL Divergence: {'avg': 0.025374198332428932, 'std': 0.18679279088974}
    Policy Grad Norm: {'avg': 3.690115362405777, 'std': 1.8507431761032467}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.59442188712168, 'std': 34.518395224997235, 'run': -23.78757076906978, 'test_avg': -77.38338774585293, 'test_std': 8.66047748926523}
    Episode Length: {'avg': 6.6618610747051115, 'std': 8.193495498822147, 'run': 7.9519187250276815, 'test_avg': 20.59765625, 'test_std': 1.9365507692379091}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7001 / 20000):
    Value Loss: {'avg': 23.84461186726888, 'std': 2.6268168370137785}
    Value Grad Norm: {'avg': 318.5240613301595, 'std': 113.72768958373892}
    Policy Loss: {'avg': -0.0049908012617379425, 'std': 0.00838895825081792}
    Total_Loss: {'avg': -0.10159889236092567, 'std': 0.010289192329441624}
    Policy Entropy: {'avg': 0.9282652735710144, 'std': 0.5637082457542419}
    KL Divergence: {'avg': 0.028360772877931595, 'std': 0.23823800683021545}
    Policy Grad Norm: {'avg': 2.6917744398117067, 'std': 1.4661506883096231}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -19.13221307295917, 'std': 34.24392045312398, 'run': -19.800517284982053, 'test_avg': -76.69168171212416, 'test_std': 7.706769918783653}
    Episode Length: {'avg': 6.770833333333333, 'std': 8.12753699707906, 'run': 6.864253223688448, 'test_avg': 20.3212890625, 'test_std': 1.6762634863940309}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7101 / 20000):
    Value Loss: {'avg': 17.323072783152263, 'std': 1.9688779023676217}
    Value Grad Norm: {'avg': 201.1528813680013, 'std': 68.35019968263967}
    Policy Loss: {'avg': 0.002373811393044889, 'std': 0.008646871952995558}
    Total_Loss: {'avg': -0.08797391951084137, 'std': 0.009943111975468011}
    Policy Entropy: {'avg': 0.9454448223114014, 'std': 0.5692484378814697}
    KL Divergence: {'avg': 0.04320826381444931, 'std': 0.30829140543937683}
    Policy Grad Norm: {'avg': 2.8063742101192473, 'std': 1.2634971624247349}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.200837972365065, 'std': 32.06178067509971, 'run': -16.78521379449257, 'test_avg': -76.63394572977316, 'test_std': 7.53757424807465}
    Episode Length: {'avg': 6.424968474148802, 'std': 7.4819484841894885, 'run': 6.32391613617507, 'test_avg': 20.3369140625, 'test_std': 1.6425627391334998}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7201 / 20000):
    Value Loss: {'avg': 20.25384464263916, 'std': 1.6276596264544745}
    Value Grad Norm: {'avg': 287.8527414957682, 'std': 102.31513389314733}
    Policy Loss: {'avg': 0.000715571641921997, 'std': 0.003368707961176537}
    Total_Loss: {'avg': -0.09895400032401085, 'std': 0.0046721438294560205}
    Policy Entropy: {'avg': 1.014665126800537, 'std': 0.5741991400718689}
    KL Divergence: {'avg': 0.018243808299303055, 'std': 0.17299099266529083}
    Policy Grad Norm: {'avg': 3.458856153488159, 'std': 1.080966906978333}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.871404038874555, 'std': 31.70413433749757, 'run': -15.155186289274443, 'test_avg': -78.00301871706282, 'test_std': 10.088167745877051}
    Episode Length: {'avg': 6.051522248243559, 'std': 7.52697981153322, 'run': 5.915102449694849, 'test_avg': 20.701171875, 'test_std': 2.2747249562769087}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7301 / 20000):
    Value Loss: {'avg': 21.463687896728516, 'std': 2.0870421715871474}
    Value Grad Norm: {'avg': 240.67595774332682, 'std': 79.10819591695716}
    Policy Loss: {'avg': -0.00035809250548481943, 'std': 0.004437626655788831}
    Total_Loss: {'avg': -0.09372798427939415, 'std': 0.003312043312693911}
    Policy Entropy: {'avg': 0.9042397737503052, 'std': 0.5850349068641663}
    KL Divergence: {'avg': 0.022573957219719887, 'std': 0.2052348554134369}
    Policy Grad Norm: {'avg': 2.7315095901489257, 'std': 0.8865263078726928}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.339990308092943, 'std': 32.55000994617747, 'run': -18.02805670570735, 'test_avg': -75.88291810102184, 'test_std': 7.160919675183747}
    Episode Length: {'avg': 6.444587628865979, 'std': 7.6639820061619925, 'run': 6.588807418237886, 'test_avg': 20.1572265625, 'test_std': 1.56115145663207}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7401 / 20000):
    Value Loss: {'avg': 23.128220558166504, 'std': 2.6655658821355432}
    Value Grad Norm: {'avg': 267.3059122721354, 'std': 108.74409028205756}
    Policy Loss: {'avg': 0.010254470072686673, 'std': 0.009660241832865677}
    Total_Loss: {'avg': -0.08452698066830636, 'std': 0.009694398003909357}
    Policy Entropy: {'avg': 0.9684751629829407, 'std': 0.5604977607727051}
    KL Divergence: {'avg': 0.029601365327835083, 'std': 0.21436764299869537}
    Policy Grad Norm: {'avg': 2.784757339954376, 'std': 1.3034886530978531}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.13161751864855, 'std': 33.33951173435971, 'run': -16.8555589472346, 'test_avg': -76.85363879870846, 'test_std': 10.504948398565496}
    Episode Length: {'avg': 6.590268886043534, 'std': 7.905887370394275, 'run': 6.360311699294189, 'test_avg': 20.4365234375, 'test_std': 2.1281855772026046}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7501 / 20000):
    Value Loss: {'avg': 18.354818248748778, 'std': 2.1549575872202786}
    Value Grad Norm: {'avg': 213.12389907836913, 'std': 67.43709885105346}
    Policy Loss: {'avg': 0.00614719488658011, 'std': 0.00892553827993776}
    Total_Loss: {'avg': -0.07894898541271686, 'std': 0.008953610098206178}
    Policy Entropy: {'avg': 0.8944805860519409, 'std': 0.6089826226234436}
    KL Divergence: {'avg': 0.029004598036408424, 'std': 0.3006838858127594}
    Policy Grad Norm: {'avg': 2.906265211105347, 'std': 1.3068164879456516}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.927852762638288, 'std': 32.254687319811595, 'run': -17.669874058889462, 'test_avg': -76.30365288331379, 'test_std': 9.296769601945636}
    Episode Length: {'avg': 6.555123216601816, 'std': 7.651996955712881, 'run': 6.562104144451764, 'test_avg': 20.216796875, 'test_std': 2.0850732277285213}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7601 / 20000):
    Value Loss: {'avg': 27.85057938893636, 'std': 2.9921115413231205}
    Value Grad Norm: {'avg': 434.19052607218424, 'std': 282.5751077708492}
    Policy Loss: {'avg': 0.0040233873296529055, 'std': 0.008956500954520202}
    Total_Loss: {'avg': -0.09416489973664284, 'std': 0.007104911978554351}
    Policy Entropy: {'avg': 1.0175588130950928, 'std': 0.6119096279144287}
    KL Divergence: {'avg': 0.02191004529595375, 'std': 0.1889990121126175}
    Policy Grad Norm: {'avg': 2.803591084480286, 'std': 1.8041493027978655}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.46252423519989, 'std': 33.362326893302, 'run': -17.747244887906636, 'test_avg': -76.44774997781678, 'test_std': 7.319714137720421}
    Episode Length: {'avg': 6.397040690505548, 'std': 7.907304595439083, 'run': 6.454651598003659, 'test_avg': 20.328125, 'test_std': 1.633317057210571}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7701 / 20000):
    Value Loss: {'avg': 18.962810484568276, 'std': 2.2673566489627746}
    Value Grad Norm: {'avg': 241.85888163248697, 'std': 106.06039397684545}
    Policy Loss: {'avg': 0.0027917238883674146, 'std': 0.006291121192182538}
    Total_Loss: {'avg': -0.08623053804039955, 'std': 0.006349819386375549}
    Policy Entropy: {'avg': 0.938852071762085, 'std': 0.5441226363182068}
    KL Divergence: {'avg': 0.016628693789243698, 'std': 0.181551992893219}
    Policy Grad Norm: {'avg': 3.7784860014915465, 'std': 1.8503585881381182}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.325872346751986, 'std': 31.73302039019992, 'run': -15.967840536292163, 'test_avg': -76.24134920533645, 'test_std': 7.306688298960656}
    Episode Length: {'avg': 6.180048661800487, 'std': 7.544624163530052, 'run': 6.142948085209793, 'test_avg': 20.2294921875, 'test_std': 1.593771242486344}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7801 / 20000):
    Value Loss: {'avg': 17.424211184183758, 'std': 1.8320817129593074}
    Value Grad Norm: {'avg': 212.0426467895508, 'std': 66.72469906401476}
    Policy Loss: {'avg': 0.0037908500526100397, 'std': 0.00743855428405966}
    Total_Loss: {'avg': -0.08571339175105094, 'std': 0.00816130087897198}
    Policy Entropy: {'avg': 0.9523892998695374, 'std': 0.5833953022956848}
    KL Divergence: {'avg': 0.018738005310297012, 'std': 0.15812045335769653}
    Policy Grad Norm: {'avg': 2.7899643898010256, 'std': 0.8592303267158088}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.683970338243403, 'std': 31.256274833232546, 'run': -15.651020004957944, 'test_avg': -76.83538046632134, 'test_std': 7.382900398885953}
    Episode Length: {'avg': 6.052693208430913, 'std': 7.3438968276713155, 'run': 6.05685868627717, 'test_avg': 20.431640625, 'test_std': 1.6403168888509345}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7901 / 20000):
    Value Loss: {'avg': 18.363125705718993, 'std': 2.2837865872592067}
    Value Grad Norm: {'avg': 215.999720509847, 'std': 105.57122460924418}
    Policy Loss: {'avg': 0.004229987412691117, 'std': 0.009649462576045187}
    Total_Loss: {'avg': -0.07838433608412743, 'std': 0.01145926965375594}
    Policy Entropy: {'avg': 0.843757152557373, 'std': 0.614795446395874}
    KL Divergence: {'avg': 0.02259930782020092, 'std': 0.19029147922992706}
    Policy Grad Norm: {'avg': 2.968163478374481, 'std': 1.6264068785900634}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.707276169610104, 'std': 32.256662553637554, 'run': -16.319893057661243, 'test_avg': -76.33976142761111, 'test_std': 11.047341402106793}
    Episode Length: {'avg': 6.538759689922481, 'std': 7.609012846474017, 'run': 6.168974884236807, 'test_avg': 20.287109375, 'test_std': 2.5224751151968}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (8001 / 20000):
    Value Loss: {'avg': 17.77741641998291, 'std': 2.145372499647571}
    Value Grad Norm: {'avg': 183.4435702006022, 'std': 46.081465458865566}
    Policy Loss: {'avg': 0.0037751055788248777, 'std': 0.0068041897513590474}
    Total_Loss: {'avg': -0.0837474063038826, 'std': 0.007813156318976605}
    Policy Entropy: {'avg': 0.866810142993927, 'std': 0.5697514414787292}
    KL Divergence: {'avg': 0.018755575641989708, 'std': 0.18615145981311798}
    Policy Grad Norm: {'avg': 3.2083104848861694, 'std': 0.8237771784472361}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.451329567501485, 'std': 32.20021106259627, 'run': -20.014651372175113, 'test_avg': -76.30119240961352, 'test_std': 10.472037022726159}
    Episode Length: {'avg': 6.437179487179487, 'std': 7.619469141182041, 'run': 7.0442846407175, 'test_avg': 20.306640625, 'test_std': 2.138677226020703}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8101 / 20000):
    Value Loss: {'avg': 20.873570092519124, 'std': 2.3696147240089003}
    Value Grad Norm: {'avg': 257.50913289388023, 'std': 83.24035638343602}
    Policy Loss: {'avg': -0.004810583195649087, 'std': 0.00794510694135065}
    Total_Loss: {'avg': -0.10151603408157825, 'std': 0.008908239699631169}
    Policy Entropy: {'avg': 1.0333431959152222, 'std': 0.5851008296012878}
    KL Divergence: {'avg': 0.025244390591979027, 'std': 0.20149484276771545}
    Policy Grad Norm: {'avg': 1.9840607225894928, 'std': 0.7521575890886633}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.696727442471527, 'std': 32.83844515606415, 'run': -17.86438102477504, 'test_avg': -75.81436376779293, 'test_std': 6.901738827263386}
    Episode Length: {'avg': 6.464968152866242, 'std': 7.7175692209733, 'run': 6.569234482491928, 'test_avg': 20.1357421875, 'test_std': 1.5078349531804582}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8201 / 20000):
    Value Loss: {'avg': 17.208788935343424, 'std': 1.5339214021101988}
    Value Grad Norm: {'avg': 234.11713231404622, 'std': 84.98474899196229}
    Policy Loss: {'avg': 0.007175194658339023, 'std': 0.008464233236035719}
    Total_Loss: {'avg': -0.07844776660203934, 'std': 0.008335252939521193}
    Policy Entropy: {'avg': 0.8680820465087891, 'std': 0.6040369868278503}
    KL Divergence: {'avg': 0.02153480425477028, 'std': 0.22487156093120575}
    Policy Grad Norm: {'avg': 2.4030165791511537, 'std': 0.7201915339143523}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.175772307287307, 'std': 32.04484471168388, 'run': -15.963388425986407, 'test_avg': -76.32328319648315, 'test_std': 7.281718908398903}
    Episode Length: {'avg': 6.346715328467154, 'std': 7.597715924174904, 'run': 6.094885414167714, 'test_avg': 20.2998046875, 'test_std': 1.5980212254075437}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8301 / 20000):
    Value Loss: {'avg': 20.208430099487305, 'std': 2.291505842646961}
    Value Grad Norm: {'avg': 225.5315134684245, 'std': 75.71230933549988}
    Policy Loss: {'avg': -0.00018841209821403028, 'std': 0.007907085846726683}
    Total_Loss: {'avg': -0.09137017354369163, 'std': 0.009799833116422288}
    Policy Entropy: {'avg': 0.961723804473877, 'std': 0.5834806561470032}
    KL Divergence: {'avg': 0.027773309499025345, 'std': 0.20103220641613007}
    Policy Grad Norm: {'avg': 2.9708699524402618, 'std': 1.1512376741504209}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.09032347409684, 'std': 32.181716458946525, 'run': -13.017869936905218, 'test_avg': -76.62743228443424, 'test_std': 7.677176299117828}
    Episode Length: {'avg': 6.418867924528302, 'std': 7.611437684436858, 'run': 5.362909018384267, 'test_avg': 20.453125, 'test_std': 1.7121321457104297}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8401 / 20000):
    Value Loss: {'avg': 17.26360870997111, 'std': 1.6918395191952922}
    Value Grad Norm: {'avg': 208.7453582763672, 'std': 65.6065750939367}
    Policy Loss: {'avg': 0.004289216897450388, 'std': 0.004853419092606971}
    Total_Loss: {'avg': -0.08644414320588112, 'std': 0.004763492533064873}
    Policy Entropy: {'avg': 0.8937587141990662, 'std': 0.5809723734855652}
    KL Divergence: {'avg': 0.025475451722741127, 'std': 0.21190965175628662}
    Policy Grad Norm: {'avg': 2.8684610247612, 'std': 0.9247419671486238}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.08543315292261, 'std': 32.977761435544394, 'run': -19.940912546002764, 'test_avg': -75.9650081081134, 'test_std': 7.192045415427855}
    Episode Length: {'avg': 6.574120603015075, 'std': 7.792747795002106, 'run': 6.906753820754101, 'test_avg': 20.2509765625, 'test_std': 1.5837612912227914}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8501 / 20000):
    Value Loss: {'avg': 17.650763702392577, 'std': 2.1204663557406263}
    Value Grad Norm: {'avg': 246.26271591186523, 'std': 91.58025539962311}
    Policy Loss: {'avg': 0.011314691556617618, 'std': 0.01691816312421664}
    Total_Loss: {'avg': -0.07986649721860886, 'std': 0.01813369270089648}
    Policy Entropy: {'avg': 0.9893597960472107, 'std': 0.6294793486595154}
    KL Divergence: {'avg': 0.024522483348846436, 'std': 0.21021243929862976}
    Policy Grad Norm: {'avg': 4.4304720759391785, 'std': 6.140569927777365}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.639530286270034, 'std': 33.290847867713076, 'run': -18.70745371382561, 'test_avg': -76.30329573652058, 'test_std': 10.198288551991622}
    Episode Length: {'avg': 6.70694087403599, 'std': 7.886663641387973, 'run': 6.664328995490103, 'test_avg': 20.236328125, 'test_std': 2.067892711756097}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8601 / 20000):
    Value Loss: {'avg': 17.129912885030112, 'std': 1.7957761129504817}
    Value Grad Norm: {'avg': 222.4594991048177, 'std': 101.95895528807124}
    Policy Loss: {'avg': 0.0005089767277240753, 'std': 0.003714560676416874}
    Total_Loss: {'avg': -0.0860234409570694, 'std': 0.003436209369180328}
    Policy Entropy: {'avg': 0.8585556149482727, 'std': 0.5839216709136963}
    KL Divergence: {'avg': 0.024455923587083817, 'std': 0.2671648859977722}
    Policy Grad Norm: {'avg': 2.5963611006736755, 'std': 0.5859098366343016}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.449925753693556, 'std': 31.90568047730336, 'run': -15.403083661504095, 'test_avg': -77.52728690483445, 'test_std': 17.425960867220354}
    Episode Length: {'avg': 6.258104738154613, 'std': 7.592125162810676, 'run': 6.092376979457884, 'test_avg': 20.55078125, 'test_std': 3.9162820397219145}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9931640625}

Iteration (8701 / 20000):
    Value Loss: {'avg': 15.147264544169108, 'std': 1.4455120680362805}
    Value Grad Norm: {'avg': 239.0052022298177, 'std': 84.22222478301907}
    Policy Loss: {'avg': 0.0026672726962715387, 'std': 0.003777688523311399}
    Total_Loss: {'avg': -0.08389830514788628, 'std': 0.0034213741472396697}
    Policy Entropy: {'avg': 0.8961066007614136, 'std': 0.5944095849990845}
    KL Divergence: {'avg': 0.017454033717513084, 'std': 0.16313409805297852}
    Policy Grad Norm: {'avg': 2.3599316596984865, 'std': 0.7867776441116571}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.195196047284536, 'std': 31.259698483055576, 'run': -19.813608016160284, 'test_avg': -75.62453670923733, 'test_std': 6.9705740863878205}
    Episode Length: {'avg': 6.157766990291262, 'std': 7.387299706619139, 'run': 7.095066664178159, 'test_avg': 20.099609375, 'test_std': 1.5083879548750412}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8801 / 20000):
    Value Loss: {'avg': 14.63080457051595, 'std': 1.6092601493001}
    Value Grad Norm: {'avg': 295.9076105753581, 'std': 136.9218355455276}
    Policy Loss: {'avg': 0.0013409786857664584, 'std': 0.0030117420969429645}
    Total_Loss: {'avg': -0.08449415415525437, 'std': 0.00412445140754797}
    Policy Entropy: {'avg': 0.8175707459449768, 'std': 0.5599709749221802}
    KL Divergence: {'avg': 0.020061446353793144, 'std': 0.1828005313873291}
    Policy Grad Norm: {'avg': 2.8319590091705322, 'std': 0.7244424621893368}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.71153875556271, 'std': 32.511277097171266, 'run': -19.383180607876916, 'test_avg': -75.83491646544275, 'test_std': 10.077867223705692}
    Episode Length: {'avg': 6.473958333333333, 'std': 7.688218053072976, 'run': 6.908306531156529, 'test_avg': 20.1982421875, 'test_std': 2.0374321393840864}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8901 / 20000):
    Value Loss: {'avg': 20.909057998657225, 'std': 2.609133808088945}
    Value Grad Norm: {'avg': 285.3312833150228, 'std': 149.8301746127409}
    Policy Loss: {'avg': 0.00022256728261709212, 'std': 0.005612803520425578}
    Total_Loss: {'avg': -0.09036826863884925, 'std': 0.006245878667608878}
    Policy Entropy: {'avg': 0.9097118377685547, 'std': 0.5910052061080933}
    KL Divergence: {'avg': 0.024793023243546486, 'std': 0.2072708159685135}
    Policy Grad Norm: {'avg': 2.4484738230705263, 'std': 1.0621448548923567}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.712248239173476, 'std': 32.70114045070192, 'run': -19.784489838127975, 'test_avg': -76.01711665555587, 'test_std': 7.654983385091647}
    Episode Length: {'avg': 6.510773130544994, 'std': 7.703566769612554, 'run': 6.930302442448065, 'test_avg': 20.1982421875, 'test_std': 1.676688991016287}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9001 / 20000):
    Value Loss: {'avg': 15.610573959350585, 'std': 1.8625519286333618}
    Value Grad Norm: {'avg': 195.590288289388, 'std': 84.99763759717689}
    Policy Loss: {'avg': 0.005605900008231401, 'std': 0.007224737584275464}
    Total_Loss: {'avg': -0.07955591529607772, 'std': 0.0071579599548297285}
    Policy Entropy: {'avg': 0.853407621383667, 'std': 0.5923210382461548}
    KL Divergence: {'avg': 0.018401866778731346, 'std': 0.1990686058998108}
    Policy Grad Norm: {'avg': 2.8809056162834166, 'std': 1.2267851592127177}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.58811790459693, 'std': 32.69251980080664, 'run': -17.58961145657529, 'test_avg': -75.68888025778534, 'test_std': 7.079258192390725}
    Episode Length: {'avg': 6.4501891551071875, 'std': 7.74550127506615, 'run': 6.43556249030729, 'test_avg': 20.1513671875, 'test_std': 1.5692162174309632}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9101 / 20000):
    Value Loss: {'avg': 16.63765230178833, 'std': 2.009924444212212}
    Value Grad Norm: {'avg': 260.87393442789715, 'std': 100.86931557409432}
    Policy Loss: {'avg': 0.0036432464607059956, 'std': 0.007796188289124224}
    Total_Loss: {'avg': -0.08216827288269997, 'std': 0.007585942483613169}
    Policy Entropy: {'avg': 0.939016580581665, 'std': 0.6169411540031433}
    KL Divergence: {'avg': 0.019987141713500023, 'std': 0.18371957540512085}
    Policy Grad Norm: {'avg': 2.5892282009124754, 'std': 1.5513995042166788}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.761540034255596, 'std': 31.917034232260338, 'run': -18.856137726764945, 'test_avg': -75.95550282152284, 'test_std': 7.151952931158381}
    Episode Length: {'avg': 6.315217391304348, 'std': 7.535321677196534, 'run': 6.77187071980283, 'test_avg': 20.21875, 'test_std': 1.5596849641834725}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9201 / 20000):
    Value Loss: {'avg': 17.265060329437254, 'std': 1.8488186356675373}
    Value Grad Norm: {'avg': 268.3898452758789, 'std': 130.3561590737235}
    Policy Loss: {'avg': 0.0022774392273277044, 'std': 0.004048803442439885}
    Total_Loss: {'avg': -0.08031103610992432, 'std': 0.004274920479201953}
    Policy Entropy: {'avg': 0.8193314671516418, 'std': 0.5604821443557739}
    KL Divergence: {'avg': 0.015001966618001461, 'std': 0.18088452517986298}
    Policy Grad Norm: {'avg': 2.7553484201431275, 'std': 0.8836069079894131}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.784627027855754, 'std': 31.16892692656976, 'run': -15.437245911797781, 'test_avg': -75.59842238621813, 'test_std': 7.066963001382878}
    Episode Length: {'avg': 6.046228710462287, 'std': 7.370804783036788, 'run': 5.988722363567308, 'test_avg': 20.0712890625, 'test_std': 1.5467316532184472}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9301 / 20000):
    Value Loss: {'avg': 15.141858450571696, 'std': 1.8332665546473574}
    Value Grad Norm: {'avg': 193.29145024617512, 'std': 98.9365164403498}
    Policy Loss: {'avg': 0.006346197333186865, 'std': 0.00780202654231597}
    Total_Loss: {'avg': -0.0747658982872963, 'std': 0.007515865718660766}
    Policy Entropy: {'avg': 0.7852307558059692, 'std': 0.5661076307296753}
    KL Divergence: {'avg': 0.02216421440243721, 'std': 0.1831812709569931}
    Policy Grad Norm: {'avg': 3.097263240814209, 'std': 0.5424159895484896}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.770630964176306, 'std': 31.92147326563925, 'run': -16.23641984582402, 'test_avg': -75.24274518258133, 'test_std': 6.816058340038432}
    Episode Length: {'avg': 6.4940711462450595, 'std': 7.52875238079162, 'run': 6.0724280663424235, 'test_avg': 19.9716796875, 'test_std': 1.4483890266084944}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9401 / 20000):
    Value Loss: {'avg': 16.314607429504395, 'std': 1.4550653041617816}
    Value Grad Norm: {'avg': 250.90386327107748, 'std': 87.55098068891371}
    Policy Loss: {'avg': 0.0008922632783651352, 'std': 0.0029153870429080167}
    Total_Loss: {'avg': -0.07852202281355858, 'std': 0.004243613562065003}
    Policy Entropy: {'avg': 0.7602251172065735, 'std': 0.5777007937431335}
    KL Divergence: {'avg': 0.031818073242902756, 'std': 0.2586786150932312}
    Policy Grad Norm: {'avg': 2.477965474128723, 'std': 1.1980942326641395}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.95955265288757, 'std': 32.81684310538386, 'run': -17.78221520013466, 'test_avg': -75.39471341853425, 'test_std': 6.771885404521841}
    Episode Length: {'avg': 6.830287206266319, 'std': 7.683859294078336, 'run': 6.484429465388212, 'test_avg': 20.0380859375, 'test_std': 1.4748922922928123}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9501 / 20000):
    Value Loss: {'avg': 16.926149781545003, 'std': 1.5232489513585807}
    Value Grad Norm: {'avg': 261.16977767944337, 'std': 142.53287209957008}
    Policy Loss: {'avg': 0.0019585730507969855, 'std': 0.002740604594016508}
    Total_Loss: {'avg': -0.08480945751070976, 'std': 0.00365609075047283}
    Policy Entropy: {'avg': 0.8696364760398865, 'std': 0.6125063300132751}
    KL Divergence: {'avg': 0.01899023912847042, 'std': 0.20960742235183716}
    Policy Grad Norm: {'avg': 2.6511173844337463, 'std': 0.8994740107547251}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.04807729221544, 'std': 32.499907507768235, 'run': -16.074398187513488, 'test_avg': -75.39851941905134, 'test_std': 6.798870879159342}
    Episode Length: {'avg': 6.2025, 'std': 7.670657973733413, 'run': 5.93919753960954, 'test_avg': 19.9951171875, 'test_std': 1.4898666788146147}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9601 / 20000):
    Value Loss: {'avg': 14.672344175974528, 'std': 1.5972427463320613}
    Value Grad Norm: {'avg': 208.76701990763345, 'std': 111.0490875156494}
    Policy Loss: {'avg': 0.004190591350197792, 'std': 0.011734156159754284}
    Total_Loss: {'avg': -0.08156985379755496, 'std': 0.011297181168368633}
    Policy Entropy: {'avg': 0.9007721543312073, 'std': 0.5613923668861389}
    KL Divergence: {'avg': 0.028976697474718094, 'std': 0.23524437844753265}
    Policy Grad Norm: {'avg': 2.3535990118980408, 'std': 0.7940181571499062}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.664858751611522, 'std': 31.34313136085323, 'run': -13.802435608082048, 'test_avg': -75.55811509060018, 'test_std': 6.71544556067597}
    Episode Length: {'avg': 6.238038277511961, 'std': 7.4794479479564755, 'run': 5.578233723259993, 'test_avg': 20.0849609375, 'test_std': 1.4582766203979}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9701 / 20000):
    Value Loss: {'avg': 14.070010534922282, 'std': 1.3409178396612216}
    Value Grad Norm: {'avg': 177.17094828287762, 'std': 56.97355509262349}
    Policy Loss: {'avg': -0.0011071909917518496, 'std': 0.007585460601267836}
    Total_Loss: {'avg': -0.07991996556520461, 'std': 0.008532618705910516}
    Policy Entropy: {'avg': 0.88127601146698, 'std': 0.6332542300224304}
    KL Divergence: {'avg': 0.02643183432519436, 'std': 0.2176641970872879}
    Policy Grad Norm: {'avg': 3.73085018992424, 'std': 1.9708744720188252}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.81823637403952, 'std': 32.960003395322836, 'run': -19.433171687952175, 'test_avg': -76.54321470858616, 'test_std': 7.857215167510652}
    Episode Length: {'avg': 6.744487678339818, 'std': 7.777437859168044, 'run': 6.863995067067691, 'test_avg': 20.3564453125, 'test_std': 1.7232604059447247}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9801 / 20000):
    Value Loss: {'avg': 17.735917218526204, 'std': 1.825953896140276}
    Value Grad Norm: {'avg': 211.0890101114909, 'std': 72.55435094796397}
    Policy Loss: {'avg': 0.002960106544196606, 'std': 0.003170719298980321}
    Total_Loss: {'avg': -0.09286754503846169, 'std': 0.0027592602619562158}
    Policy Entropy: {'avg': 0.9888017177581787, 'std': 0.58620685338974}
    KL Divergence: {'avg': 0.019807208329439163, 'std': 0.1863793432712555}
    Policy Grad Norm: {'avg': 3.094834566116333, 'std': 1.144307134044107}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.09370699055879, 'std': 31.4337750777874, 'run': -17.43677214484351, 'test_avg': -76.04093327935074, 'test_std': 10.579232770137379}
    Episode Length: {'avg': 6.124542124542124, 'std': 7.448094437427336, 'run': 6.334143783061366, 'test_avg': 20.205078125, 'test_std': 2.145792939136133}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9901 / 20000):
    Value Loss: {'avg': 15.11441577275594, 'std': 1.579916948806388}
    Value Grad Norm: {'avg': 180.7312764485677, 'std': 61.75286645424499}
    Policy Loss: {'avg': 0.008286269381642342, 'std': 0.011161744099719893}
    Total_Loss: {'avg': -0.07125366404652596, 'std': 0.012042582990672512}
    Policy Entropy: {'avg': 0.8332014083862305, 'std': 0.594822883605957}
    KL Divergence: {'avg': 0.02094869688153267, 'std': 0.18270793557167053}
    Policy Grad Norm: {'avg': 3.232626938819885, 'std': 1.6309991177438705}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.547782965876518, 'std': 32.81427704501124, 'run': -17.88732516040484, 'test_avg': -75.4186659665306, 'test_std': 10.141253720454543}
    Episode Length: {'avg': 6.661103979460847, 'std': 7.776113936075414, 'run': 6.411183115207454, 'test_avg': 20.041015625, 'test_std': 2.0310762771264548}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (10001 / 20000):
    Value Loss: {'avg': 15.97843869527181, 'std': 1.803849217820514}
    Value Grad Norm: {'avg': 208.66997884114582, 'std': 81.52488604244294}
    Policy Loss: {'avg': 0.006158621748909354, 'std': 0.00920825569948001}
    Total_Loss: {'avg': -0.07805155664682388, 'std': 0.008563665235582258}
    Policy Entropy: {'avg': 0.8465491533279419, 'std': 0.6024006009101868}
    KL Divergence: {'avg': 0.017272615805268288, 'std': 0.17438241839408875}
    Policy Grad Norm: {'avg': 2.986938464641571, 'std': 0.8997958728380147}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.032790310509958, 'std': 30.216252657191564, 'run': -12.32352976186272, 'test_avg': -78.21531197548768, 'test_std': 24.334062939761203}
    Episode Length: {'avg': 5.927710843373494, 'std': 7.199536686114024, 'run': 5.331703775142719, 'test_avg': 20.6279296875, 'test_std': 4.61413855665997}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.990234375}

Iteration (10101 / 20000):
    Value Loss: {'avg': 13.813705984751383, 'std': 1.278632753907133}
    Value Grad Norm: {'avg': 168.07294743855795, 'std': 41.54243973175353}
    Policy Loss: {'avg': 0.0005432250909507275, 'std': 0.00455739313689343}
    Total_Loss: {'avg': -0.08306983187794685, 'std': 0.005445251553367824}
    Policy Entropy: {'avg': 0.8178671598434448, 'std': 0.5568690299987793}
    KL Divergence: {'avg': 0.015699297189712524, 'std': 0.17116783559322357}
    Policy Grad Norm: {'avg': 2.667379379272461, 'std': 1.230473558820002}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.878190223207195, 'std': 33.19420563164218, 'run': -24.543617596152075, 'test_avg': -76.32154747238368, 'test_std': 13.023961816855254}
    Episode Length: {'avg': 6.773154362416108, 'std': 7.855973923811642, 'run': 8.070520725102746, 'test_avg': 20.201171875, 'test_std': 2.7860840352920055}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (10201 / 20000):
    Value Loss: {'avg': 14.505081303914388, 'std': 1.6348859838578098}
    Value Grad Norm: {'avg': 150.73977864583333, 'std': 56.48189540903473}
    Policy Loss: {'avg': 0.0015432457439601421, 'std': 0.0024456587967050347}
    Total_Loss: {'avg': -0.07575594633817673, 'std': 0.004252548901295098}
    Policy Entropy: {'avg': 0.757527232170105, 'std': 0.6068300604820251}
    KL Divergence: {'avg': 0.024970782920718193, 'std': 0.21298572421073914}
    Policy Grad Norm: {'avg': 2.4367966771125795, 'std': 0.522395478517764}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.6781300581892, 'std': 32.089979531533515, 'run': -13.117775825842259, 'test_avg': -75.7904614722688, 'test_std': 12.71561084351846}
    Episode Length: {'avg': 6.437346437346437, 'std': 7.587192158532505, 'run': 5.368630643886001, 'test_avg': 20.0517578125, 'test_std': 2.455115998551843}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (10301 / 20000):
    Value Loss: {'avg': 14.137651824951172, 'std': 1.6534030416090504}
    Value Grad Norm: {'avg': 176.5328582763672, 'std': 57.28333232265808}
    Policy Loss: {'avg': 0.0032221163623034955, 'std': 0.004961633875106987}
    Total_Loss: {'avg': -0.07550478130578994, 'std': 0.005439933651936587}
    Policy Entropy: {'avg': 0.7873704433441162, 'std': 0.6079844832420349}
    KL Divergence: {'avg': 0.027990112081170082, 'std': 0.2844216525554657}
    Policy Grad Norm: {'avg': 2.867526686191559, 'std': 0.8565289707195293}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.76727321457829, 'std': 30.69694949202063, 'run': -16.06445144179925, 'test_avg': -75.26549511224519, 'test_std': 9.276486694323626}
    Episode Length: {'avg': 5.972445464982778, 'std': 7.323219970485588, 'run': 5.974039791221163, 'test_avg': 20.0302734375, 'test_std': 2.0757297106034622}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (10401 / 20000):
    Value Loss: {'avg': 22.524398676554362, 'std': 2.3615910684130723}
    Value Grad Norm: {'avg': 227.3604522705078, 'std': 78.59945025102962}
    Policy Loss: {'avg': 0.002160472609102726, 'std': 0.004740928986708885}
    Total_Loss: {'avg': -0.09123350530862809, 'std': 0.0056499530524416535}
    Policy Entropy: {'avg': 0.9332573413848877, 'std': 0.6191126704216003}
    KL Divergence: {'avg': 0.01745489053428173, 'std': 0.17240794003009796}
    Policy Grad Norm: {'avg': 2.3785736560821533, 'std': 0.9276513918816705}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.424393659823243, 'std': 31.139923468135184, 'run': -15.551447134863583, 'test_avg': -75.28632759818477, 'test_std': 7.50314422968495}
    Episode Length: {'avg': 5.923708920187793, 'std': 7.34543717397235, 'run': 5.9784129253794696, 'test_avg': 20.0224609375, 'test_std': 1.631143255139358}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (10501 / 20000):
    Value Loss: {'avg': 14.07602138519287, 'std': 1.5882077182630268}
    Value Grad Norm: {'avg': 198.6913724263509, 'std': 82.32391733128412}
    Policy Loss: {'avg': 0.0059838127344846725, 'std': 0.006524042140097076}
    Total_Loss: {'avg': -0.07906225472688674, 'std': 0.006270598755603997}
    Policy Entropy: {'avg': 0.82527095079422, 'std': 0.580406129360199}
    KL Divergence: {'avg': 0.020771309733390808, 'std': 0.17463386058807373}
    Policy Grad Norm: {'avg': 3.396371042728424, 'std': 0.8469147680892446}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.073048876920392, 'std': 32.46935146565333, 'run': -16.007487252387158, 'test_avg': -75.5210973823204, 'test_std': 6.717466649252639}
    Episode Length: {'avg': 6.555142503097893, 'std': 7.705330245941683, 'run': 6.084400907839242, 'test_avg': 20.0537109375, 'test_std': 1.4469951011295343}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (10601 / 20000):
    Value Loss: {'avg': 13.515941015879314, 'std': 1.509958321890308}
    Value Grad Norm: {'avg': 155.7707176208496, 'std': 66.75905686554039}
    Policy Loss: {'avg': 0.003564780903980136, 'std': 0.004453061049997092}
    Total_Loss: {'avg': -0.08378870785236359, 'std': 0.004127915846525711}
    Policy Entropy: {'avg': 0.8539108037948608, 'std': 0.6232606768608093}
    KL Divergence: {'avg': 0.015619195066392422, 'std': 0.17174145579338074}
    Policy Grad Norm: {'avg': 2.8604498386383055, 'std': 1.065870870814712}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.51566051188208, 'std': 30.851620768644263, 'run': -18.30125358322763, 'test_avg': -75.10926201874759, 'test_std': 6.525516082485885}
    Episode Length: {'avg': 6.25207100591716, 'std': 7.290855817472403, 'run': 6.735302120916482, 'test_avg': 19.947265625, 'test_std': 1.4049133730210412}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (10701 / 20000):
    Value Loss: {'avg': 16.132207584381103, 'std': 1.9447832535575875}
    Value Grad Norm: {'avg': 231.55482533772786, 'std': 135.45958990303484}
    Policy Loss: {'avg': 0.006792460707947612, 'std': 0.009360875047946046}
    Total_Loss: {'avg': -0.08039357736706734, 'std': 0.007438353926019707}
    Policy Entropy: {'avg': 0.9079464077949524, 'std': 0.6297747492790222}
    KL Divergence: {'avg': 0.03685743734240532, 'std': 0.22741259634494781}
    Policy Grad Norm: {'avg': 2.887929451465607, 'std': 1.4540080321617297}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.715499468855562, 'std': 31.86502863131219, 'run': -15.83462102507525, 'test_avg': -75.18995957592836, 'test_std': 9.007270883338672}
    Episode Length: {'avg': 6.240566037735849, 'std': 7.571119135413215, 'run': 5.993422713082242, 'test_avg': 19.96484375, 'test_std': 2.015742335489816}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (10801 / 20000):
    Value Loss: {'avg': 21.73239606221517, 'std': 2.593793638193949}
    Value Grad Norm: {'avg': 197.2613644917806, 'std': 58.139300097983835}
    Policy Loss: {'avg': 0.0013890191912651062, 'std': 0.003382481778516699}
    Total_Loss: {'avg': -0.09196056202054023, 'std': 0.004163188318776815}
    Policy Entropy: {'avg': 0.9037569761276245, 'std': 0.5872437357902527}
    KL Divergence: {'avg': 0.015977459028363228, 'std': 0.1567380577325821}
    Policy Grad Norm: {'avg': 3.1144472479820253, 'std': 1.2686091227285665}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.205068756539085, 'std': 33.49613795318024, 'run': -19.913451190313445, 'test_avg': -75.31323120026101, 'test_std': 7.486351367353664}
    Episode Length: {'avg': 6.575875486381323, 'std': 7.892789341228814, 'run': 6.957071863628131, 'test_avg': 20.0810546875, 'test_std': 1.664270808833189}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (10901 / 20000):
    Value Loss: {'avg': 15.24096425374349, 'std': 1.649112143120177}
    Value Grad Norm: {'avg': 222.28187637329103, 'std': 86.17331688718}
    Policy Loss: {'avg': -0.008368785283528269, 'std': 0.0080230404925993}
    Total_Loss: {'avg': -0.1044249277561903, 'std': 0.00854734070410453}
    Policy Entropy: {'avg': 0.9929653406143188, 'std': 0.5815906524658203}
    KL Divergence: {'avg': 0.03466402366757393, 'std': 0.27743199467658997}
    Policy Grad Norm: {'avg': 1.9782134950160981, 'std': 0.5664905270531579}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.261036670259738, 'std': 33.15491236831494, 'run': -16.123554499534436, 'test_avg': -75.60561836319492, 'test_std': 6.966355919786353}
    Episode Length: {'avg': 6.598997493734336, 'std': 7.881140777029816, 'run': 6.026215465503231, 'test_avg': 20.126953125, 'test_std': 1.5635921476052297}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (11001 / 20000):
    Value Loss: {'avg': 16.948615010579427, 'std': 1.7121626887704757}
    Value Grad Norm: {'avg': 266.2297416687012, 'std': 132.63417969260868}
    Policy Loss: {'avg': 0.00048497938551008703, 'std': 0.00461503029930103}
    Total_Loss: {'avg': -0.08398689851164817, 'std': 0.005776565026617687}
    Policy Entropy: {'avg': 0.8297569751739502, 'std': 0.6009626984596252}
    KL Divergence: {'avg': 0.015565347857773304, 'std': 0.16673962771892548}
    Policy Grad Norm: {'avg': 2.6941911816596984, 'std': 0.595289603418833}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.960425432324211, 'std': 31.003451079985858, 'run': -16.4421241906315, 'test_avg': -76.49176216816112, 'test_std': 15.021780657777096}
    Episode Length: {'avg': 6.117718446601942, 'std': 7.413381802252627, 'run': 6.220707388240695, 'test_avg': 20.2998046875, 'test_std': 3.1416680421160073}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (11101 / 20000):
    Value Loss: {'avg': 14.010554917653401, 'std': 1.798612773812882}
    Value Grad Norm: {'avg': 170.82005182902017, 'std': 60.108274309529676}
    Policy Loss: {'avg': -0.0014504324644804, 'std': 0.010696371338400226}
    Total_Loss: {'avg': -0.08164198081940413, 'std': 0.010767127425747708}
    Policy Entropy: {'avg': 0.7726765871047974, 'std': 0.5761027336120605}
    KL Divergence: {'avg': 0.02264210395514965, 'std': 0.1969939023256302}
    Policy Grad Norm: {'avg': 3.6320029497146606, 'std': 2.008737709240777}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -14.892343199828945, 'std': 29.56535558391099, 'run': -17.592849874217897, 'test_avg': -75.26459804600387, 'test_std': 8.939698961670276}
    Episode Length: {'avg': 5.853717026378897, 'std': 7.00754590516334, 'run': 6.45043331855493, 'test_avg': 20.0087890625, 'test_std': 2.00461403763427}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (11201 / 20000):
    Value Loss: {'avg': 16.880830478668212, 'std': 2.2450429897277484}
    Value Grad Norm: {'avg': 247.75812555948895, 'std': 87.31534950893746}
    Policy Loss: {'avg': 0.0024082692340016364, 'std': 0.003728245227096404}
    Total_Loss: {'avg': -0.08354562073946, 'std': 0.004923880378127517}
    Policy Entropy: {'avg': 0.9026561975479126, 'std': 0.5851049423217773}
    KL Divergence: {'avg': 0.02014409750699997, 'std': 0.17517051100730896}
    Policy Grad Norm: {'avg': 3.0869707226753236, 'std': 0.9921628891066557}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -14.811004109670051, 'std': 29.740334959939023, 'run': -18.077397378085237, 'test_avg': -75.02412045450991, 'test_std': 6.998952865132286}
    Episode Length: {'avg': 5.819612590799031, 'std': 7.0556523694403115, 'run': 6.612646579339105, 'test_avg': 19.9755859375, 'test_std': 1.522740913961481}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (11301 / 20000):
    Value Loss: {'avg': 11.302333354949951, 'std': 1.3924971949360072}
    Value Grad Norm: {'avg': 142.18025232950848, 'std': 47.18134403232372}
    Policy Loss: {'avg': 0.003853298258036375, 'std': 0.004582961664665437}
    Total_Loss: {'avg': -0.07960297837853432, 'std': 0.005084856613755249}
    Policy Entropy: {'avg': 0.8687011003494263, 'std': 0.6034587621688843}
    KL Divergence: {'avg': 0.020123440772294998, 'std': 0.1803852617740631}
    Policy Grad Norm: {'avg': 3.1459460139274595, 'std': 1.1983823752396054}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.206286656107611, 'std': 30.0715858107489, 'run': -18.71747625816938, 'test_avg': -75.37065254692052, 'test_std': 6.728709554851529}
    Episode Length: {'avg': 5.949579831932773, 'std': 7.136962471307815, 'run': 6.802909082290743, 'test_avg': 20.01171875, 'test_std': 1.4563503771065662}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (11401 / 20000):
    Value Loss: {'avg': 15.574441878000895, 'std': 1.7208868358258196}
    Value Grad Norm: {'avg': 189.34496612548827, 'std': 73.64579963121152}
    Policy Loss: {'avg': 0.02273559421300888, 'std': 0.052411928813677754}
    Total_Loss: {'avg': -0.05969036780297756, 'std': 0.05111379094853792}
    Policy Entropy: {'avg': 0.8774979114532471, 'std': 0.5907192230224609}
    KL Divergence: {'avg': 0.020428074523806572, 'std': 0.2089267522096634}
    Policy Grad Norm: {'avg': 8.756015145778656, 'std': 16.038715629014234}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.520666682798506, 'std': 32.80739814235903, 'run': -19.131962710841808, 'test_avg': -76.21540948026473, 'test_std': 7.394119695726497}
    Episode Length: {'avg': 6.6424010217113665, 'std': 7.80574110735776, 'run': 6.787460217818816, 'test_avg': 20.2763671875, 'test_std': 1.635419744338847}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (11501 / 20000):
    Value Loss: {'avg': 15.363317966461182, 'std': 1.3730413860862627}
    Value Grad Norm: {'avg': 165.11310780843098, 'std': 54.20504506596346}
    Policy Loss: {'avg': 0.01036356296390295, 'std': 0.0076442333054176385}
    Total_Loss: {'avg': -0.08190126270055771, 'std': 0.0074185844886808985}
    Policy Entropy: {'avg': 0.9047949910163879, 'std': 0.6375935673713684}
    KL Divergence: {'avg': 0.0292352382093668, 'std': 0.19804660975933075}
    Policy Grad Norm: {'avg': 2.6183435201644896, 'std': 0.6210006877174696}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.293398910906994, 'std': 31.89401327578025, 'run': -13.177226265832955, 'test_avg': -75.9855419747347, 'test_std': 10.983392367280471}
    Episode Length: {'avg': 6.376884422110553, 'std': 7.52758200192379, 'run': 5.428450062542786, 'test_avg': 20.2255859375, 'test_std': 2.4966558978566202}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (11601 / 20000):
    Value Loss: {'avg': 14.33977123896281, 'std': 1.778842201697948}
    Value Grad Norm: {'avg': 236.12232996622723, 'std': 105.67063581759226}
    Policy Loss: {'avg': 0.004399380646646023, 'std': 0.007349565896769692}
    Total_Loss: {'avg': -0.07967072948813439, 'std': 0.008315815210572503}
    Policy Entropy: {'avg': 0.8758561611175537, 'std': 0.5840904712677002}
    KL Divergence: {'avg': 0.01868128776550293, 'std': 0.17905642092227936}
    Policy Grad Norm: {'avg': 2.720731222629547, 'std': 1.3976543899856981}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.294205379911922, 'std': 32.02981356623738, 'run': -19.898585090681955, 'test_avg': -75.26028439369273, 'test_std': 9.229371447801825}
    Episode Length: {'avg': 6.3760479041916165, 'std': 7.568127380376825, 'run': 7.041574600239747, 'test_avg': 19.986328125, 'test_std': 2.0624546855225656}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (11701 / 20000):
    Value Loss: {'avg': 14.185729948679606, 'std': 1.4349182884039844}
    Value Grad Norm: {'avg': 178.94508158365886, 'std': 58.621336655114526}
    Policy Loss: {'avg': 0.0017800034023821355, 'std': 0.005345141214110029}
    Total_Loss: {'avg': -0.08011543825268745, 'std': 0.006366172087997821}
    Policy Entropy: {'avg': 0.8182195425033569, 'std': 0.5835395455360413}
    KL Divergence: {'avg': 0.02418753318488598, 'std': 0.2383294701576233}
    Policy Grad Norm: {'avg': 3.4398828625679014, 'std': 1.3725267559519074}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.246856292147335, 'std': 32.23200970230429, 'run': -13.888277282639097, 'test_avg': -75.47969115222584, 'test_std': 9.93161639694819}
    Episode Length: {'avg': 6.646983311938382, 'std': 7.61087665139847, 'run': 5.524772781614114, 'test_avg': 20.0810546875, 'test_std': 1.9937089682634919}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (11801 / 20000):
    Value Loss: {'avg': 16.217821089426675, 'std': 1.5136625303899913}
    Value Grad Norm: {'avg': 260.11341018676757, 'std': 120.41961568930617}
    Policy Loss: {'avg': 0.0018612444400787354, 'std': 0.003984172105587908}
    Total_Loss: {'avg': -0.0859534926712513, 'std': 0.003987158377191437}
    Policy Entropy: {'avg': 0.8872280716896057, 'std': 0.6019901037216187}
    KL Divergence: {'avg': 0.030594049021601677, 'std': 0.18211346864700317}
    Policy Grad Norm: {'avg': 2.7746628880500794, 'std': 1.4206596747588498}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.722837764364463, 'std': 31.750006975230704, 'run': -18.609807101395134, 'test_avg': -76.31232414270423, 'test_std': 15.40810461958278}
    Episode Length: {'avg': 6.244416873449132, 'std': 7.511021667935176, 'run': 6.645808448678358, 'test_avg': 20.2734375, 'test_std': 3.4108967015425358}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (11901 / 20000):
    Value Loss: {'avg': 12.671843115488688, 'std': 1.3456875934634833}
    Value Grad Norm: {'avg': 145.7762451171875, 'std': 42.62363868887771}
    Policy Loss: {'avg': 0.003424045909196138, 'std': 0.004174530655187265}
    Total_Loss: {'avg': -0.07870861664414405, 'std': 0.00411188620782094}
    Policy Entropy: {'avg': 0.7874011993408203, 'std': 0.5940641164779663}
    KL Divergence: {'avg': 0.017712051048874855, 'std': 0.17100149393081665}
    Policy Grad Norm: {'avg': 2.620796966552734, 'std': 1.3850235073750434}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.658217040486804, 'std': 31.995472481252374, 'run': -16.098422991649564, 'test_avg': -75.36668189694493, 'test_std': 6.576830120954045}
    Episode Length: {'avg': 6.4324324324324325, 'std': 7.563797762329118, 'run': 5.964659473302681, 'test_avg': 20.0078125, 'test_std': 1.423826785407463}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (12001 / 20000):
    Value Loss: {'avg': 15.507929579416912, 'std': 2.032312171878656}
    Value Grad Norm: {'avg': 227.5243342081706, 'std': 111.0311349775672}
    Policy Loss: {'avg': 0.0001723273191601038, 'std': 0.004175187260994881}
    Total_Loss: {'avg': -0.08152124285697937, 'std': 0.0042359418293617}
    Policy Entropy: {'avg': 0.784521222114563, 'std': 0.6165807247161865}
    KL Divergence: {'avg': 0.02481260895729065, 'std': 0.24434445798397064}
    Policy Grad Norm: {'avg': 2.319764196872711, 'std': 0.7879623492762776}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.764827287569645, 'std': 31.44579591478766, 'run': -16.198592979304607, 'test_avg': -75.86240220222027, 'test_std': 12.395667438929182}
    Episode Length: {'avg': 6.276885043263288, 'std': 7.448710306426165, 'run': 6.156140095884681, 'test_avg': 20.197265625, 'test_std': 2.865158485702555}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (12101 / 20000):
    Value Loss: {'avg': 16.643664582570395, 'std': 2.0208993337029595}
    Value Grad Norm: {'avg': 236.88449376424154, 'std': 100.25362688584521}
    Policy Loss: {'avg': 0.0009161252062767744, 'std': 0.0026116567933958178}
    Total_Loss: {'avg': -0.08596825003623962, 'std': 0.002858785788015157}
    Policy Entropy: {'avg': 0.8994101285934448, 'std': 0.6169820427894592}
    KL Divergence: {'avg': 0.020215781405568123, 'std': 0.18766982853412628}
    Policy Grad Norm: {'avg': 2.0766394972801208, 'std': 0.3692337069603473}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.146420848632793, 'std': 32.03403669058089, 'run': -17.295469076233033, 'test_avg': -75.7535475890754, 'test_std': 10.752364878960451}
    Episode Length: {'avg': 6.397260273972603, 'std': 7.565757720064018, 'run': 6.385340280519472, 'test_avg': 20.11328125, 'test_std': 2.4428745584655873}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (12201 / 20000):
    Value Loss: {'avg': 17.17611001332601, 'std': 2.2132916958946933}
    Value Grad Norm: {'avg': 227.6998140970866, 'std': 89.717560806815}
    Policy Loss: {'avg': 0.002136675454676151, 'std': 0.0021881834415732647}
    Total_Loss: {'avg': -0.08395018577575683, 'std': 0.0026342566515137173}
    Policy Entropy: {'avg': 0.8368825912475586, 'std': 0.6129305362701416}
    KL Divergence: {'avg': 0.018219979479908943, 'std': 0.15643475949764252}
    Policy Grad Norm: {'avg': 2.4537082433700563, 'std': 0.6265097013339455}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.481496327414394, 'std': 32.28684973773266, 'run': -17.913503958688633, 'test_avg': -75.43365228891521, 'test_std': 12.56243188013846}
    Episode Length: {'avg': 6.425879396984925, 'std': 7.648252245945849, 'run': 6.571501460169991, 'test_avg': 20.0673828125, 'test_std': 2.447166446950348}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (12301 / 20000):
    Value Loss: {'avg': 13.871862602233886, 'std': 1.8299021207831165}
    Value Grad Norm: {'avg': 184.62944564819335, 'std': 53.945874425252455}
    Policy Loss: {'avg': 0.002554035559296608, 'std': 0.005577102503273639}
    Total_Loss: {'avg': -0.08359042033553124, 'std': 0.006516357492471398}
    Policy Entropy: {'avg': 0.8449360132217407, 'std': 0.5910001397132874}
    KL Divergence: {'avg': 0.015929728746414185, 'std': 0.17428064346313477}
    Policy Grad Norm: {'avg': 2.286561644077301, 'std': 0.7834269504753474}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.386805561818946, 'std': 31.34237099453888, 'run': -16.560972730451798, 'test_avg': -75.2671664704969, 'test_std': 6.981548463419707}
    Episode Length: {'avg': 6.161781946072685, 'std': 7.432200314442551, 'run': 6.192563978992673, 'test_avg': 20.0107421875, 'test_std': 1.518403328469651}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (12401 / 20000):
    Value Loss: {'avg': 13.244815127054851, 'std': 1.472322044578415}
    Value Grad Norm: {'avg': 181.25099283854166, 'std': 69.3707792969122}
    Policy Loss: {'avg': 0.004326578741893172, 'std': 0.004241301859924754}
    Total_Loss: {'avg': -0.07334815040230751, 'std': 0.005950408820005576}
    Policy Entropy: {'avg': 0.7478983998298645, 'std': 0.5889566540718079}
    KL Divergence: {'avg': 0.018391888588666916, 'std': 0.17795494198799133}
    Policy Grad Norm: {'avg': 2.3968798995018004, 'std': 0.9008180370849262}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.276493373711133, 'std': 30.631986094340398, 'run': -15.601237230833355, 'test_avg': -75.02458731869584, 'test_std': 6.628769004966471}
    Episode Length: {'avg': 6.193853427895981, 'std': 7.228637561140893, 'run': 6.0716665127649225, 'test_avg': 19.9306640625, 'test_std': 1.428667548896872}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (12501 / 20000):
    Value Loss: {'avg': 15.79650945663452, 'std': 1.9889645937777154}
    Value Grad Norm: {'avg': 188.775900777181, 'std': 68.88164494507438}
    Policy Loss: {'avg': -0.003231118363328278, 'std': 0.009651711019899496}
    Total_Loss: {'avg': -0.08874189779162407, 'std': 0.009868887797838713}
    Policy Entropy: {'avg': 0.8270578980445862, 'std': 0.5893813371658325}
    KL Divergence: {'avg': 0.025713354349136353, 'std': 0.21549928188323975}
    Policy Grad Norm: {'avg': 3.3407771944999696, 'std': 1.2027199905554833}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -16.23588580474946, 'std': 31.19514488821787, 'run': -13.07542495505515, 'test_avg': -74.56720648607543, 'test_std': 7.105055490508687}
    Episode Length: {'avg': 6.1516245487364625, 'std': 7.445986433464649, 'run': 5.341012714718991, 'test_avg': 19.90234375, 'test_std': 1.5519123708624587}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (12601 / 20000):
    Value Loss: {'avg': 15.084182421366373, 'std': 2.1361216500341906}
    Value Grad Norm: {'avg': 162.96931482950848, 'std': 47.996521814230285}
    Policy Loss: {'avg': -0.003920741146430373, 'std': 0.008333293315801113}
    Total_Loss: {'avg': -0.08606203012168408, 'std': 0.00869205203752616}
    Policy Entropy: {'avg': 0.8360742330551147, 'std': 0.6036379337310791}
    KL Divergence: {'avg': 0.035292427986860275, 'std': 0.25473877787590027}
    Policy Grad Norm: {'avg': 2.39715570807457, 'std': 0.7945713285588402}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -15.835956201930472, 'std': 31.05101205021725, 'run': -14.688262773624084, 'test_avg': -75.82200781042039, 'test_std': 13.934869402131437}
    Episode Length: {'avg': 6.019836639439907, 'std': 7.3424854049546076, 'run': 5.777686013494673, 'test_avg': 20.1748046875, 'test_std': 2.8466177094453737}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (12701 / 20000):
    Value Loss: {'avg': 18.367373180389404, 'std': 1.6820859983528402}
    Value Grad Norm: {'avg': 250.27677205403646, 'std': 99.49668554399945}
    Policy Loss: {'avg': 0.0027933679055422546, 'std': 0.004518553116625188}
    Total_Loss: {'avg': -0.0902865469455719, 'std': 0.006769224861944215}
    Policy Entropy: {'avg': 0.8734508752822876, 'std': 0.5737611651420593}
    KL Divergence: {'avg': 0.03689911961555481, 'std': 0.3291294276714325}
    Policy Grad Norm: {'avg': 3.164050245285034, 'std': 0.9764615750751411}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.601586628759595, 'std': 33.670463209855136, 'run': -21.680435873738578, 'test_avg': -74.64124850055337, 'test_std': 6.908939997577055}
    Episode Length: {'avg': 6.977622377622378, 'std': 7.9749294192498486, 'run': 7.531891477330965, 'test_avg': 19.9169921875, 'test_std': 1.4869038773787513}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (12801 / 20000):
    Value Loss: {'avg': 18.52707446416219, 'std': 3.103755754083548}
    Value Grad Norm: {'avg': 218.5024617513021, 'std': 97.53313498178207}
    Policy Loss: {'avg': -0.005228806450031698, 'std': 0.0075880206104201224}
    Total_Loss: {'avg': -0.09209014140069485, 'std': 0.007163113979077099}
    Policy Entropy: {'avg': 0.8881774544715881, 'std': 0.5760173797607422}
    KL Divergence: {'avg': 0.021082842722535133, 'std': 0.17766183614730835}
    Policy Grad Norm: {'avg': 3.56561883687973, 'std': 1.902146381047954}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.3351702148724, 'std': 32.25810686296362, 'run': -19.537176188234294, 'test_avg': -75.23995403442305, 'test_std': 6.446853492596452}
    Episode Length: {'avg': 6.41442542787286, 'std': 7.643853482603517, 'run': 6.966772656150579, 'test_avg': 19.9794921875, 'test_std': 1.3787482065723475}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (12901 / 20000):
    Value Loss: {'avg': 13.010980796813964, 'std': 1.7708832352426118}
    Value Grad Norm: {'avg': 182.17729746500652, 'std': 80.85192748378762}
    Policy Loss: {'avg': 0.003358174953609705, 'std': 0.006122266956042024}
    Total_Loss: {'avg': -0.08099788799881935, 'std': 0.0063792102213526295}
    Policy Entropy: {'avg': 0.850322425365448, 'std': 0.5694563388824463}
    KL Divergence: {'avg': 0.017299847677350044, 'std': 0.17459020018577576}
    Policy Grad Norm: {'avg': 3.0380009174346925, 'std': 1.2622742339334891}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.68750297878602, 'std': 31.1993745025229, 'run': -13.513169070568148, 'test_avg': -74.81519860111841, 'test_std': 6.702029153362782}
    Episode Length: {'avg': 6.244471744471745, 'std': 7.393332387177325, 'run': 5.442325748659526, 'test_avg': 19.9208984375, 'test_std': 1.4485286087302724}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13001 / 20000):
    Value Loss: {'avg': 14.08459021250407, 'std': 1.5508808251927868}
    Value Grad Norm: {'avg': 198.43816070556642, 'std': 69.53367472953828}
    Policy Loss: {'avg': 0.003913219459354878, 'std': 0.006670628301729335}
    Total_Loss: {'avg': -0.07229163870215416, 'std': 0.007038372139967479}
    Policy Entropy: {'avg': 0.8096169233322144, 'std': 0.6002238988876343}
    KL Divergence: {'avg': 0.022211069241166115, 'std': 0.183577299118042}
    Policy Grad Norm: {'avg': 2.7412235617637633, 'std': 0.8664765334733222}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.425930444361793, 'std': 31.24274159226584, 'run': -19.04069866514417, 'test_avg': -75.83817091584352, 'test_std': 7.120677630304916}
    Episode Length: {'avg': 6.20918984280532, 'std': 7.44563611567901, 'run': 6.837845284388712, 'test_avg': 20.1513671875, 'test_std': 1.579142025610217}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13101 / 20000):
    Value Loss: {'avg': 15.112144470214844, 'std': 1.6762437975507811}
    Value Grad Norm: {'avg': 185.30918350219727, 'std': 74.25156593154887}
    Policy Loss: {'avg': 0.003078398201614618, 'std': 0.004288201160256226}
    Total_Loss: {'avg': -0.07669898867607117, 'std': 0.005320939341858245}
    Policy Entropy: {'avg': 0.7534788250923157, 'std': 0.5940855145454407}
    KL Divergence: {'avg': 0.026550689712166786, 'std': 0.27487316727638245}
    Policy Grad Norm: {'avg': 4.185771536827088, 'std': 1.441863406425266}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.78031514068882, 'std': 31.835514827097615, 'run': -14.843097443061293, 'test_avg': -74.89189739662879, 'test_std': 6.543024889766457}
    Episode Length: {'avg': 6.284301606922126, 'std': 7.527502982402038, 'run': 5.921866591328171, 'test_avg': 19.90234375, 'test_std': 1.4025069542914708}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13201 / 20000):
    Value Loss: {'avg': 13.024822934468586, 'std': 1.337045284498816}
    Value Grad Norm: {'avg': 154.22350209554037, 'std': 47.07456077903954}
    Policy Loss: {'avg': 0.0046340438537299635, 'std': 0.004040200560026679}
    Total_Loss: {'avg': -0.07035237774252892, 'std': 0.0038616244491079623}
    Policy Entropy: {'avg': 0.7248642444610596, 'std': 0.5633552670478821}
    KL Divergence: {'avg': 0.015112544409930706, 'std': 0.1581043004989624}
    Policy Grad Norm: {'avg': 2.3439857244491575, 'std': 0.4428129341755843}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.335897753582532, 'std': 30.749501856746736, 'run': -15.390375799780546, 'test_avg': -75.51158106683758, 'test_std': 13.695410572094362}
    Episode Length: {'avg': 6.170580964153276, 'std': 7.245173136556054, 'run': 5.900962048935902, 'test_avg': 20.064453125, 'test_std': 2.787343411687504}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (13301 / 20000):
    Value Loss: {'avg': 18.941619809468587, 'std': 1.95663343545218}
    Value Grad Norm: {'avg': 181.73676401774088, 'std': 61.62466883166176}
    Policy Loss: {'avg': 0.010348410438746214, 'std': 0.011086994668790023}
    Total_Loss: {'avg': -0.0785052701830864, 'std': 0.011358618846318135}
    Policy Entropy: {'avg': 0.8811087608337402, 'std': 0.6191970109939575}
    KL Divergence: {'avg': 0.01789853721857071, 'std': 0.1515188068151474}
    Policy Grad Norm: {'avg': 2.92311635017395, 'std': 1.1377223384184858}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.628649060320488, 'std': 32.27666938336368, 'run': -18.964690977975366, 'test_avg': -75.05594418875685, 'test_std': 6.7815647114254505}
    Episode Length: {'avg': 6.503937007874016, 'std': 7.660486627239209, 'run': 6.909134015117986, 'test_avg': 19.9892578125, 'test_std': 1.4713679580267183}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13401 / 20000):
    Value Loss: {'avg': 12.532737668355306, 'std': 1.4625595988308335}
    Value Grad Norm: {'avg': 175.99522590637207, 'std': 63.79840783446546}
    Policy Loss: {'avg': 0.0040718444623053076, 'std': 0.002571869346369866}
    Total_Loss: {'avg': -0.07506001442670822, 'std': 0.0033269736521182062}
    Policy Entropy: {'avg': 0.7758780717849731, 'std': 0.5815033316612244}
    KL Divergence: {'avg': 0.019807154312729836, 'std': 0.17067334055900574}
    Policy Grad Norm: {'avg': 2.6572344422340395, 'std': 0.6514320888193308}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.01937878261039, 'std': 31.645387221181746, 'run': -17.222355563046914, 'test_avg': -75.18484419910405, 'test_std': 6.995658952875209}
    Episode Length: {'avg': 6.309226932668329, 'std': 7.49773961953647, 'run': 6.32982764753689, 'test_avg': 20.017578125, 'test_std': 1.5180179542816628}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13501 / 20000):
    Value Loss: {'avg': 17.938962364196776, 'std': 1.754719124959386}
    Value Grad Norm: {'avg': 209.16777547200522, 'std': 81.16023511685322}
    Policy Loss: {'avg': 0.003519912250339985, 'std': 0.004169451368899391}
    Total_Loss: {'avg': -0.08106595054268836, 'std': 0.0067363033723632304}
    Policy Entropy: {'avg': 0.8496890664100647, 'std': 0.6064935326576233}
    KL Divergence: {'avg': 0.01576702669262886, 'std': 0.15404006838798523}
    Policy Grad Norm: {'avg': 3.5204357147216796, 'std': 1.2078866927046175}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.44678124486637, 'std': 33.14317740991385, 'run': -23.71745813909601, 'test_avg': -74.963010278508, 'test_std': 6.973358576124482}
    Episode Length: {'avg': 6.6200495049504955, 'std': 7.895696534184018, 'run': 7.812216167396589, 'test_avg': 19.9951171875, 'test_std': 1.5312422148837492}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13601 / 20000):
    Value Loss: {'avg': 14.76100565592448, 'std': 1.6373641885949586}
    Value Grad Norm: {'avg': 230.09034678141276, 'std': 88.25734718299931}
    Policy Loss: {'avg': 0.005860829353332519, 'std': 0.005855302014315539}
    Total_Loss: {'avg': -0.0849651612341404, 'std': 0.005206377206275073}
    Policy Entropy: {'avg': 0.8982832431793213, 'std': 0.5962908864021301}
    KL Divergence: {'avg': 0.018764181062579155, 'std': 0.16008806228637695}
    Policy Grad Norm: {'avg': 2.7363323092460634, 'std': 0.7057600042106706}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.2650216557227, 'std': 32.09828407217302, 'run': -19.071632484034023, 'test_avg': -75.31914911152433, 'test_std': 6.547573482917238}
    Episode Length: {'avg': 6.420724094881399, 'std': 7.5510097199178166, 'run': 6.843883685892712, 'test_avg': 20.0478515625, 'test_std': 1.4404369703205722}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13701 / 20000):
    Value Loss: {'avg': 14.04050137201945, 'std': 1.7211869067009629}
    Value Grad Norm: {'avg': 181.02126592000326, 'std': 71.60775426456307}
    Policy Loss: {'avg': 0.009454099414870142, 'std': 0.009712600132707526}
    Total_Loss: {'avg': -0.07200845852494239, 'std': 0.0094508050851295}
    Policy Entropy: {'avg': 0.834883451461792, 'std': 0.5882851481437683}
    KL Divergence: {'avg': 0.025934899225831032, 'std': 0.19644954800605774}
    Policy Grad Norm: {'avg': 3.0289278507232664, 'std': 1.1050244625972991}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.767763300971712, 'std': 31.108774315771353, 'run': -16.367413000162905, 'test_avg': -75.78483283915894, 'test_std': 10.573068386974981}
    Episode Length: {'avg': 6.2768292682926825, 'std': 7.352796029991282, 'run': 6.174764355159413, 'test_avg': 20.19140625, 'test_std': 2.180005997115819}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (13801 / 20000):
    Value Loss: {'avg': 11.41354061762492, 'std': 1.4504904654079676}
    Value Grad Norm: {'avg': 144.969593556722, 'std': 40.01785611686588}
    Policy Loss: {'avg': 0.00531725799664855, 'std': 0.00820649248426019}
    Total_Loss: {'avg': -0.07473382502794265, 'std': 0.00708129403443273}
    Policy Entropy: {'avg': 0.7845973968505859, 'std': 0.5897858142852783}
    KL Divergence: {'avg': 0.015928631648421288, 'std': 0.29800158739089966}
    Policy Grad Norm: {'avg': 4.1758012771606445, 'std': 4.636064937732737}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.630015266848785, 'std': 29.86965101690815, 'run': -13.620034116348684, 'test_avg': -75.26979641207717, 'test_std': 6.8928228263253395}
    Episode Length: {'avg': 6.052631578947368, 'std': 7.084670179643115, 'run': 5.500763523972062, 'test_avg': 20.056640625, 'test_std': 1.5164188783445058}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (13901 / 20000):
    Value Loss: {'avg': 14.84641335805257, 'std': 1.7910378987799107}
    Value Grad Norm: {'avg': 141.97232844034832, 'std': 38.38655480926744}
    Policy Loss: {'avg': -0.0013363970909267664, 'std': 0.00576494767123735}
    Total_Loss: {'avg': -0.09208348095417022, 'std': 0.004961296304956606}
    Policy Entropy: {'avg': 0.8963565826416016, 'std': 0.5875258445739746}
    KL Divergence: {'avg': 0.017466826364398003, 'std': 0.17401917278766632}
    Policy Grad Norm: {'avg': 2.719933843612671, 'std': 0.912960284825221}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.293391302157428, 'std': 32.75914512130662, 'run': -20.511436574833997, 'test_avg': -74.73229718158265, 'test_std': 6.6132190221744604}
    Episode Length: {'avg': 6.685676392572944, 'std': 7.713925650774455, 'run': 7.103907486113559, 'test_avg': 19.9345703125, 'test_std': 1.445161718803004}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (14001 / 20000):
    Value Loss: {'avg': 15.590325101216633, 'std': 2.1442538002430944}
    Value Grad Norm: {'avg': 173.9100540161133, 'std': 49.24186137579393}
    Policy Loss: {'avg': 0.008260924415662885, 'std': 0.0056035386462653155}
    Total_Loss: {'avg': -0.06991005390882492, 'std': 0.0062786184325249565}
    Policy Entropy: {'avg': 0.7769170999526978, 'std': 0.5883432030677795}
    KL Divergence: {'avg': 0.01774710975587368, 'std': 0.16756945848464966}
    Policy Grad Norm: {'avg': 2.9046357393264772, 'std': 1.2173864704101687}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.465179115462295, 'std': 31.113544413083922, 'run': -15.158747371468015, 'test_avg': -75.30329412035951, 'test_std': 8.882376029226808}
    Episode Length: {'avg': 6.168674698795181, 'std': 7.388886602968578, 'run': 5.815191060923732, 'test_avg': 20.0078125, 'test_std': 2.0024246776954557}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (14101 / 20000):
    Value Loss: {'avg': 14.236707019805909, 'std': 1.4533142076154162}
    Value Grad Norm: {'avg': 160.67286580403646, 'std': 42.44083170891207}
    Policy Loss: {'avg': 4.7617219388484953e-05, 'std': 0.004589445361560596}
    Total_Loss: {'avg': -0.082869141548872, 'std': 0.006356412750624993}
    Policy Entropy: {'avg': 0.8249805569648743, 'std': 0.5939314961433411}
    KL Divergence: {'avg': 0.021051369607448578, 'std': 0.16668012738227844}
    Policy Grad Norm: {'avg': 2.8615707874298097, 'std': 0.8846426567458735}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.36476931498075, 'std': 32.01014561927897, 'run': -19.558962702789216, 'test_avg': -75.45988235167347, 'test_std': 13.840303476667021}
    Episode Length: {'avg': 6.406991260923845, 'std': 7.577919897551465, 'run': 6.9001895781390195, 'test_avg': 20.0341796875, 'test_std': 2.807600543428926}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (14201 / 20000):
    Value Loss: {'avg': 16.063239765167236, 'std': 1.7326415835672229}
    Value Grad Norm: {'avg': 173.53084259033204, 'std': 59.09241165439595}
    Policy Loss: {'avg': -0.00647492641583085, 'std': 0.008920308043641818}
    Total_Loss: {'avg': -0.09067240059375763, 'std': 0.009242837929752045}
    Policy Entropy: {'avg': 0.8491634130477905, 'std': 0.5510916113853455}
    KL Divergence: {'avg': 0.024454576894640923, 'std': 0.19482053816318512}
    Policy Grad Norm: {'avg': 2.693728631734848, 'std': 0.9226895195716066}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.95983472203643, 'std': 32.15386982469841, 'run': -17.870350372607692, 'test_avg': -75.62170552478614, 'test_std': 10.325955773756915}
    Episode Length: {'avg': 6.615089514066496, 'std': 7.62878700924311, 'run': 6.578867575901751, 'test_avg': 20.16796875, 'test_std': 2.096572112764891}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (14301 / 20000):
    Value Loss: {'avg': 16.497221215566, 'std': 2.189992515976948}
    Value Grad Norm: {'avg': 189.8059969584147, 'std': 81.85893453592429}
    Policy Loss: {'avg': 5.639428272843361e-05, 'std': 0.004432827737921836}
    Total_Loss: {'avg': -0.08218817338347435, 'std': 0.005969062737025394}
    Policy Entropy: {'avg': 0.7770329713821411, 'std': 0.6042834520339966}
    KL Divergence: {'avg': 0.02595619671046734, 'std': 0.23554681241512299}
    Policy Grad Norm: {'avg': 3.0163545846939086, 'std': 1.0690635878165056}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.687521653385055, 'std': 32.43668708088691, 'run': -17.719540426098234, 'test_avg': -74.82730441155346, 'test_std': 8.947469383029496}
    Episode Length: {'avg': 6.457433290978399, 'std': 7.666104210600469, 'run': 6.427717178769538, 'test_avg': 19.9462890625, 'test_std': 2.013636591516173}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (14401 / 20000):
    Value Loss: {'avg': 12.29560120900472, 'std': 1.6008302433402117}
    Value Grad Norm: {'avg': 153.32426783243815, 'std': 53.29354168872234}
    Policy Loss: {'avg': 0.004942837450653314, 'std': 0.006163081806282587}
    Total_Loss: {'avg': -0.07484169453382492, 'std': 0.007531258543328219}
    Policy Entropy: {'avg': 0.7405643463134766, 'std': 0.5591033101081848}
    KL Divergence: {'avg': 0.02558574452996254, 'std': 0.20778334140777588}
    Policy Grad Norm: {'avg': 3.349862539768219, 'std': 1.2521500927822016}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.487613898674486, 'std': 31.899445036765044, 'run': -21.636570735209794, 'test_avg': -74.99544044248123, 'test_std': 6.735957264395521}
    Episode Length: {'avg': 6.481796116504855, 'std': 7.5657094763651624, 'run': 7.386292852912583, 'test_avg': 20.0361328125, 'test_std': 1.4868115154117014}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (14501 / 20000):
    Value Loss: {'avg': 14.024750995635987, 'std': 2.3308094595351014}
    Value Grad Norm: {'avg': 160.5948143005371, 'std': 51.62775658429022}
    Policy Loss: {'avg': -0.0045434023486450315, 'std': 0.007986112865424935}
    Total_Loss: {'avg': -0.08183402083814144, 'std': 0.008109436886476928}
    Policy Entropy: {'avg': 0.7965055704116821, 'std': 0.5897576212882996}
    KL Divergence: {'avg': 0.027823908254504204, 'std': 0.20731790363788605}
    Policy Grad Norm: {'avg': 2.3138749599456787, 'std': 0.8544730866596886}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -16.887078031008453, 'std': 31.55869266117559, 'run': -16.429269196777973, 'test_avg': -74.96805045066202, 'test_std': 8.918346674681487}
    Episode Length: {'avg': 6.257756563245823, 'std': 7.44208542948708, 'run': 6.249877449506413, 'test_avg': 19.9169921875, 'test_std': 1.9960763113077529}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (14601 / 20000):
    Value Loss: {'avg': 12.61537996927897, 'std': 1.5658947681354132}
    Value Grad Norm: {'avg': 181.23265864054363, 'std': 76.91085865959526}
    Policy Loss: {'avg': 0.0019044960383325816, 'std': 0.00673438242853592}
    Total_Loss: {'avg': -0.07856066152453423, 'std': 0.006419666482816021}
    Policy Entropy: {'avg': 0.8672025203704834, 'std': 0.6480423808097839}
    KL Divergence: {'avg': 0.016693400219082832, 'std': 0.19984650611877441}
    Policy Grad Norm: {'avg': 2.281003999710083, 'std': 0.6018057288149218}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.483705256176432, 'std': 30.593681384752866, 'run': -15.886750180332237, 'test_avg': -74.57930859390012, 'test_std': 7.005130207304769}
    Episode Length: {'avg': 5.957345971563981, 'std': 7.267442203339624, 'run': 6.000063301719063, 'test_avg': 19.9580078125, 'test_std': 1.5541006542978368}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (14701 / 20000):
    Value Loss: {'avg': 14.487971782684326, 'std': 1.7821211849633092}
    Value Grad Norm: {'avg': 165.9376190185547, 'std': 51.61877426629293}
    Policy Loss: {'avg': -0.0049344351515173916, 'std': 0.008869166269188768}
    Total_Loss: {'avg': -0.08707207962870597, 'std': 0.009671443523305701}
    Policy Entropy: {'avg': 0.8323453068733215, 'std': 0.5963708162307739}
    KL Divergence: {'avg': 0.0236335601657629, 'std': 0.2001623958349228}
    Policy Grad Norm: {'avg': 2.484746551513672, 'std': 0.9823727718231252}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -15.345701185840847, 'std': 30.55558965301905, 'run': -13.908472028928387, 'test_avg': -75.02463830995647, 'test_std': 9.969438325702672}
    Episode Length: {'avg': 5.933333333333334, 'std': 7.26967586172196, 'run': 5.575259443575967, 'test_avg': 19.9677734375, 'test_std': 1.9980304079691664}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (14801 / 20000):
    Value Loss: {'avg': 11.54107453028361, 'std': 1.3939675763273545}
    Value Grad Norm: {'avg': 186.6099594116211, 'std': 92.71744576715854}
    Policy Loss: {'avg': -0.0029257247457280754, 'std': 0.009591030329950895}
    Total_Loss: {'avg': -0.07616971880197525, 'std': 0.009801669924172005}
    Policy Entropy: {'avg': 0.7144045829772949, 'std': 0.5636881589889526}
    KL Divergence: {'avg': 0.027057772502303123, 'std': 0.2529052495956421}
    Policy Grad Norm: {'avg': 3.1142401933670043, 'std': 1.6253781544983148}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -16.11320798523587, 'std': 30.455733333172635, 'run': -18.379976659988703, 'test_avg': -74.79657650780783, 'test_std': 6.892470077348313}
    Episode Length: {'avg': 6.158227848101266, 'std': 7.218578484749632, 'run': 6.63477412226721, 'test_avg': 19.9189453125, 'test_std': 1.4731557793167285}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (14901 / 20000):
    Value Loss: {'avg': 13.130959447224935, 'std': 1.6626379004573852}
    Value Grad Norm: {'avg': 142.25085906982423, 'std': 40.93879441611696}
    Policy Loss: {'avg': -0.00342031994368881, 'std': 0.007630347333532932}
    Total_Loss: {'avg': -0.08151370361447334, 'std': 0.00879933947388929}
    Policy Entropy: {'avg': 0.766750693321228, 'std': 0.5666441321372986}
    KL Divergence: {'avg': 0.022229567170143127, 'std': 0.16501206159591675}
    Policy Grad Norm: {'avg': 3.2002255260944366, 'std': 2.102013542492061}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.241302298566055, 'std': 31.711347613739797, 'run': -14.800150380602728, 'test_avg': -74.8553532483022, 'test_std': 6.714643069357402}
    Episode Length: {'avg': 6.359394703656998, 'std': 7.478811811733956, 'run': 5.755122572257694, 'test_avg': 19.9150390625, 'test_std': 1.445496913382772}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15001 / 20000):
    Value Loss: {'avg': 15.773171774546306, 'std': 2.083162797823945}
    Value Grad Norm: {'avg': 197.08770090738932, 'std': 62.02586235251999}
    Policy Loss: {'avg': 0.003933201963081956, 'std': 0.006071309571144718}
    Total_Loss: {'avg': -0.087514216452837, 'std': 0.006988263851001745}
    Policy Entropy: {'avg': 0.9391646981239319, 'std': 0.5946990251541138}
    KL Divergence: {'avg': 0.016594624146819115, 'std': 0.1534453183412552}
    Policy Grad Norm: {'avg': 3.4575486540794373, 'std': 1.4066672049761784}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.537947044040063, 'std': 31.558816234927217, 'run': -20.186482474443252, 'test_avg': -75.44688275472656, 'test_std': 8.892277137064202}
    Episode Length: {'avg': 6.189655172413793, 'std': 7.4641007086241205, 'run': 6.869762790847429, 'test_avg': 20.01953125, 'test_std': 1.9920764368551318}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (15101 / 20000):
    Value Loss: {'avg': 12.412940470377604, 'std': 1.5733738057164326}
    Value Grad Norm: {'avg': 144.85203196207684, 'std': 54.97879789928074}
    Policy Loss: {'avg': 0.0041272747330367565, 'std': 0.004488610111402315}
    Total_Loss: {'avg': -0.0772680900990963, 'std': 0.005528047424153329}
    Policy Entropy: {'avg': 0.7828302383422852, 'std': 0.6146851778030396}
    KL Divergence: {'avg': 0.018003160133957863, 'std': 0.18719640374183655}
    Policy Grad Norm: {'avg': 2.2266255378723145, 'std': 0.7806398612067507}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.704751650616592, 'std': 30.374535458228404, 'run': -17.9883517207004, 'test_avg': -74.46961714019591, 'test_std': 6.664213439663391}
    Episode Length: {'avg': 6.002336448598131, 'std': 7.190335814163842, 'run': 6.6179679803653775, 'test_avg': 19.8203125, 'test_std': 1.4357793710538365}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15201 / 20000):
    Value Loss: {'avg': 13.889312680562337, 'std': 1.2874442587777986}
    Value Grad Norm: {'avg': 157.90071131388348, 'std': 51.280491999612735}
    Policy Loss: {'avg': 0.0023986180778592823, 'std': 0.003889773784014112}
    Total_Loss: {'avg': -0.07712122425436974, 'std': 0.003801737971899473}
    Policy Entropy: {'avg': 0.755089521408081, 'std': 0.5680472254753113}
    KL Divergence: {'avg': 0.020186055451631546, 'std': 0.17699842154979706}
    Policy Grad Norm: {'avg': 2.2647274017333983, 'std': 0.42522467845832435}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.581518562298974, 'std': 31.24899574348472, 'run': -15.370003919957544, 'test_avg': -75.07287673257198, 'test_std': 10.212440624745101}
    Episode Length: {'avg': 6.215311004784689, 'std': 7.434663094848215, 'run': 5.893748891840593, 'test_avg': 19.951171875, 'test_std': 2.0265711964322852}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (15301 / 20000):
    Value Loss: {'avg': 12.009036127726237, 'std': 1.4460749776519815}
    Value Grad Norm: {'avg': 195.6522415161133, 'std': 90.87076177647175}
    Policy Loss: {'avg': -0.0032371597830206157, 'std': 0.009351798393337512}
    Total_Loss: {'avg': -0.08653828389942646, 'std': 0.009390697094263175}
    Policy Entropy: {'avg': 0.8283931016921997, 'std': 0.6258204579353333}
    KL Divergence: {'avg': 0.023634031414985657, 'std': 0.18424318730831146}
    Policy Grad Norm: {'avg': 2.789665824174881, 'std': 1.0217615580813089}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -14.516618342660328, 'std': 29.430979210068653, 'run': -17.570312935056535, 'test_avg': -74.35056706650818, 'test_std': 6.801937691556647}
    Episode Length: {'avg': 5.76045197740113, 'std': 7.027726832232795, 'run': 6.520207933113992, 'test_avg': 19.8955078125, 'test_std': 1.5327860076512523}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15401 / 20000):
    Value Loss: {'avg': 12.00573304494222, 'std': 1.8128709449357576}
    Value Grad Norm: {'avg': 162.15768076578777, 'std': 86.74935126405877}
    Policy Loss: {'avg': -0.005696859722957015, 'std': 0.008414132241489729}
    Total_Loss: {'avg': -0.09501263350248337, 'std': 0.008836207447199354}
    Policy Entropy: {'avg': 0.9097142219543457, 'std': 0.5933106541633606}
    KL Divergence: {'avg': 0.0240210872143507, 'std': 0.1672409325838089}
    Policy Grad Norm: {'avg': 2.9832786321640015, 'std': 1.5219481886128245}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -16.216959304562035, 'std': 31.035305152221802, 'run': -15.036579100163488, 'test_avg': -74.36941524689287, 'test_std': 6.500212116273421}
    Episode Length: {'avg': 6.135198135198135, 'std': 7.366078382805075, 'run': 5.81451406277689, 'test_avg': 19.7958984375, 'test_std': 1.3800839158127518}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15501 / 20000):
    Value Loss: {'avg': 12.197740427652995, 'std': 1.3566010892398808}
    Value Grad Norm: {'avg': 140.75487899780273, 'std': 44.73607183991256}
    Policy Loss: {'avg': 0.0012647895142436027, 'std': 0.004096273517851904}
    Total_Loss: {'avg': -0.0798490896821022, 'std': 0.004418987086244655}
    Policy Entropy: {'avg': 0.7925264835357666, 'std': 0.5639363527297974}
    KL Divergence: {'avg': 0.02077152580022812, 'std': 0.19317297637462616}
    Policy Grad Norm: {'avg': 2.322675716876984, 'std': 0.49086102572249046}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.06306546761643, 'std': 31.522154008062177, 'run': -17.243552199531162, 'test_avg': -74.50206713060774, 'test_std': 6.670153920193254}
    Episode Length: {'avg': 6.3447432762836184, 'std': 7.466206048459539, 'run': 6.4413066823406275, 'test_avg': 19.837890625, 'test_std': 1.4296968386819318}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15601 / 20000):
    Value Loss: {'avg': 14.05206371943156, 'std': 1.4613529873135567}
    Value Grad Norm: {'avg': 146.65778198242188, 'std': 53.171924436641724}
    Policy Loss: {'avg': -0.000402235658839345, 'std': 0.0027610607974876246}
    Total_Loss: {'avg': -0.08860490545630455, 'std': 0.004331752947730233}
    Policy Entropy: {'avg': 0.8660000562667847, 'std': 0.5975576639175415}
    KL Divergence: {'avg': 0.018214453011751175, 'std': 0.1788358986377716}
    Policy Grad Norm: {'avg': 3.2309367299079894, 'std': 1.3523305603047278}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.827223927568832, 'std': 30.980728131305792, 'run': -16.69889591427875, 'test_avg': -74.98024089956529, 'test_std': 9.922089376784012}
    Episode Length: {'avg': 6.028605482717521, 'std': 7.345655674785517, 'run': 6.308789226686477, 'test_avg': 19.94140625, 'test_std': 1.9431581632643642}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (15701 / 20000):
    Value Loss: {'avg': 11.943658796946208, 'std': 1.5499294681865}
    Value Grad Norm: {'avg': 132.08820343017578, 'std': 46.95143347466611}
    Policy Loss: {'avg': 0.0011865973938256502, 'std': 0.006637526284825816}
    Total_Loss: {'avg': -0.0791844218969345, 'std': 0.006069537214876772}
    Policy Entropy: {'avg': 0.819740355014801, 'std': 0.6091978549957275}
    KL Divergence: {'avg': 0.02788003347814083, 'std': 0.25316914916038513}
    Policy Grad Norm: {'avg': 1.9671672463417054, 'std': 0.627169140695473}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.112926017549924, 'std': 30.83238491820809, 'run': -16.00451921296938, 'test_avg': -74.4313410938079, 'test_std': 6.4438621337722255}
    Episode Length: {'avg': 6.1028708133971294, 'std': 7.305791200127872, 'run': 6.09798538448966, 'test_avg': 19.826171875, 'test_std': 1.3902066062132579}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15801 / 20000):
    Value Loss: {'avg': 14.18286231358846, 'std': 1.749773611250482}
    Value Grad Norm: {'avg': 182.81762975056967, 'std': 66.35085365848343}
    Policy Loss: {'avg': 0.0008709958754479885, 'std': 0.0064702176079835735}
    Total_Loss: {'avg': -0.07885657027363777, 'std': 0.007092425915689055}
    Policy Entropy: {'avg': 0.8289597630500793, 'std': 0.6153159141540527}
    KL Divergence: {'avg': 0.01775013469159603, 'std': 0.1669943630695343}
    Policy Grad Norm: {'avg': 2.9746222853660584, 'std': 0.891603212534384}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.987188967261552, 'std': 32.49331413932063, 'run': -15.465754908887542, 'test_avg': -74.77433253816122, 'test_std': 6.5095786275996}
    Episode Length: {'avg': 6.534105534105534, 'std': 7.660874052789134, 'run': 5.913399857172479, 'test_avg': 19.892578125, 'test_std': 1.386381726210889}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (15901 / 20000):
    Value Loss: {'avg': 12.908600838979085, 'std': 1.4697697828648644}
    Value Grad Norm: {'avg': 159.8834083557129, 'std': 55.229168414438455}
    Policy Loss: {'avg': -0.0007600215263664723, 'std': 0.003189397805323315}
    Total_Loss: {'avg': -0.07919653132557869, 'std': 0.004574294517676935}
    Policy Entropy: {'avg': 0.781602680683136, 'std': 0.5983487963676453}
    KL Divergence: {'avg': 0.015709007158875465, 'std': 0.17556370794773102}
    Policy Grad Norm: {'avg': 2.807614541053772, 'std': 0.7949278986699084}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.152539898226074, 'std': 31.502631438698423, 'run': -16.021117039229807, 'test_avg': -74.43065453796652, 'test_std': 6.470076294514556}
    Episode Length: {'avg': 6.366004962779156, 'std': 7.458655981615223, 'run': 6.1275322986684015, 'test_avg': 19.8330078125, 'test_std': 1.3906932342590743}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (16001 / 20000):
    Value Loss: {'avg': 16.649907271067303, 'std': 1.5331803867665763}
    Value Grad Norm: {'avg': 162.14564247131347, 'std': 51.72597457267257}
    Policy Loss: {'avg': 0.0012134096585214138, 'std': 0.0057529173863893465}
    Total_Loss: {'avg': -0.08696479722857475, 'std': 0.006299111774306574}
    Policy Entropy: {'avg': 0.8713088035583496, 'std': 0.588808536529541}
    KL Divergence: {'avg': 0.01745360903441906, 'std': 0.1722986251115799}
    Policy Grad Norm: {'avg': 2.748041331768036, 'std': 1.0916454790640084}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.356351327966811, 'std': 30.391008909056737, 'run': -14.73438173712509, 'test_avg': -74.79778276856852, 'test_std': 11.634772871740973}
    Episode Length: {'avg': 5.9766355140186915, 'std': 7.20668925295418, 'run': 5.893860174019686, 'test_avg': 19.9169921875, 'test_std': 2.427049781229047}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (16101 / 20000):
    Value Loss: {'avg': 13.988185405731201, 'std': 1.7501822755877965}
    Value Grad Norm: {'avg': 146.60266825358073, 'std': 58.320479559012796}
    Policy Loss: {'avg': 0.006543769547715783, 'std': 0.0065406057146438846}
    Total_Loss: {'avg': -0.07509278208017349, 'std': 0.007765482320112951}
    Policy Entropy: {'avg': 0.7619244456291199, 'std': 0.5747123956680298}
    KL Divergence: {'avg': 0.016763968393206596, 'std': 0.17650450766086578}
    Policy Grad Norm: {'avg': 3.3778909921646116, 'std': 1.2919167365824635}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.875857520279283, 'std': 32.84071237411074, 'run': -16.737011123191202, 'test_avg': -74.8748215823382, 'test_std': 8.920448393012203}
    Episode Length: {'avg': 6.715608465608466, 'std': 7.797185747572682, 'run': 6.127978256590844, 'test_avg': 19.9755859375, 'test_std': 2.0098365645127085}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (16201 / 20000):
    Value Loss: {'avg': 10.699493217468262, 'std': 1.063293843895792}
    Value Grad Norm: {'avg': 125.07681808471679, 'std': 39.33795054476975}
    Policy Loss: {'avg': -0.0031144968466833233, 'std': 0.009278698267949689}
    Total_Loss: {'avg': -0.08023631796240807, 'std': 0.010278675607520226}
    Policy Entropy: {'avg': 0.8341614007949829, 'std': 0.597622275352478}
    KL Divergence: {'avg': 0.025091324001550674, 'std': 0.18767806887626648}
    Policy Grad Norm: {'avg': 2.8950707256793975, 'std': 1.3491905338065078}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -18.183509765180798, 'std': 32.09501520617793, 'run': -17.35535770788647, 'test_avg': -74.70503586346258, 'test_std': 6.748472445273957}
    Episode Length: {'avg': 6.613722998729352, 'std': 7.563418597353819, 'run': 6.5237884124989165, 'test_avg': 19.8740234375, 'test_std': 1.4599968641064553}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (16301 / 20000):
    Value Loss: {'avg': 12.28797467549642, 'std': 1.473219335320901}
    Value Grad Norm: {'avg': 161.18922576904296, 'std': 53.86426984389291}
    Policy Loss: {'avg': 0.0016453127842396497, 'std': 0.00323532368208135}
    Total_Loss: {'avg': -0.07246989011764526, 'std': 0.004109346744626904}
    Policy Entropy: {'avg': 0.7507665753364563, 'std': 0.5863779783248901}
    KL Divergence: {'avg': 0.01811877451837063, 'std': 0.1880561262369156}
    Policy Grad Norm: {'avg': 2.590265679359436, 'std': 0.36221758080018357}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.945019665611674, 'std': 30.979901607774632, 'run': -18.170630269182176, 'test_avg': -74.46384308488044, 'test_std': 6.762095413792611}
    Episode Length: {'avg': 6.359259259259259, 'std': 7.364953341529605, 'run': 6.648922764227339, 'test_avg': 19.8671875, 'test_std': 1.4367992517550077}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (16401 / 20000):
    Value Loss: {'avg': 12.182821400960286, 'std': 1.4236869029595862}
    Value Grad Norm: {'avg': 131.1300193786621, 'std': 47.57291013139335}
    Policy Loss: {'avg': 0.002518366277217865, 'std': 0.0050278064797436095}
    Total_Loss: {'avg': -0.07312044613063336, 'std': 0.006294783182095536}
    Policy Entropy: {'avg': 0.7330093383789062, 'std': 0.5929624438285828}
    KL Divergence: {'avg': 0.025766495615243912, 'std': 0.24986232817173004}
    Policy Grad Norm: {'avg': 2.836526095867157, 'std': 0.7854283025903611}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.47632857510116, 'std': 30.815516837426816, 'run': -16.638590621029447, 'test_avg': -75.65746606886572, 'test_std': 17.413967233517536}
    Episode Length: {'avg': 6.185592185592186, 'std': 7.332316778342362, 'run': 6.236043696555958, 'test_avg': 20.083984375, 'test_std': 3.428222899660385}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (16501 / 20000):
    Value Loss: {'avg': 14.137403583526611, 'std': 1.5256617422287528}
    Value Grad Norm: {'avg': 191.84751841227214, 'std': 69.74511021646882}
    Policy Loss: {'avg': 0.0036448815837502478, 'std': 0.005004692753860361}
    Total_Loss: {'avg': -0.07905571833252907, 'std': 0.006440527564631864}
    Policy Entropy: {'avg': 0.8172520399093628, 'std': 0.6052289009094238}
    KL Divergence: {'avg': 0.015048505738377571, 'std': 0.1708524525165558}
    Policy Grad Norm: {'avg': 3.0570603251457213, 'std': 1.219895608146046}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -19.131566361366602, 'std': 32.7407329003985, 'run': -17.665888171079548, 'test_avg': -74.47483954715635, 'test_std': 7.043886773408251}
    Episode Length: {'avg': 6.821768707482994, 'std': 7.7851814322402495, 'run': 6.49769809798254, 'test_avg': 19.8896484375, 'test_std': 1.5105521656512921}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (16601 / 20000):
    Value Loss: {'avg': 14.100209204355876, 'std': 1.4748013234451602}
    Value Grad Norm: {'avg': 179.4699457804362, 'std': 67.56007438939375}
    Policy Loss: {'avg': 0.005132704274728894, 'std': 0.007032269355723326}
    Total_Loss: {'avg': -0.07404750138521195, 'std': 0.00731774911965003}
    Policy Entropy: {'avg': 0.824049711227417, 'std': 0.5970025658607483}
    KL Divergence: {'avg': 0.019838375970721245, 'std': 0.17887704074382782}
    Policy Grad Norm: {'avg': 3.198231315612793, 'std': 1.4473306126741823}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.41209848620672, 'std': 31.988337402853848, 'run': -15.69986370549459, 'test_avg': -74.46292007012937, 'test_std': 6.822682717812045}
    Episode Length: {'avg': 6.404411764705882, 'std': 7.566579001849788, 'run': 6.072612762688296, 'test_avg': 19.85546875, 'test_std': 1.4586117433276882}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (16701 / 20000):
    Value Loss: {'avg': 10.108873844146729, 'std': 1.12022321575385}
    Value Grad Norm: {'avg': 112.00456886291504, 'std': 48.685026688333465}
    Policy Loss: {'avg': 0.0035372393205761908, 'std': 0.005408067210264715}
    Total_Loss: {'avg': -0.07268256321549416, 'std': 0.005957392777317365}
    Policy Entropy: {'avg': 0.7271687984466553, 'std': 0.5904523134231567}
    KL Divergence: {'avg': 0.023941924795508385, 'std': 0.19555741548538208}
    Policy Grad Norm: {'avg': 3.116370987892151, 'std': 0.9003369494284982}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.055803085598065, 'std': 30.419931870086717, 'run': -16.791776830742688, 'test_avg': -74.48759144086185, 'test_std': 9.977123493471295}
    Episode Length: {'avg': 6.075151515151515, 'std': 7.223643050181612, 'run': 6.265905353633857, 'test_avg': 19.802734375, 'test_std': 1.9595898864796581}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (16801 / 20000):
    Value Loss: {'avg': 12.771940390268961, 'std': 1.538626029718046}
    Value Grad Norm: {'avg': 130.6610341389974, 'std': 42.0708926938621}
    Policy Loss: {'avg': 0.00017764989752322435, 'std': 0.00262972635151885}
    Total_Loss: {'avg': -0.08513303846120834, 'std': 0.003224673474855848}
    Policy Entropy: {'avg': 0.8495546579360962, 'std': 0.6438825726509094}
    KL Divergence: {'avg': 0.015545270405709743, 'std': 0.1771601140499115}
    Policy Grad Norm: {'avg': 3.0023173093795776, 'std': 1.3115893886601957}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.822462696360574, 'std': 30.598473940472445, 'run': -14.18564428016723, 'test_avg': -75.16047463588126, 'test_std': 10.555017694590436}
    Episode Length: {'avg': 6.034278959810875, 'std': 7.228784554470231, 'run': 5.569170631874037, 'test_avg': 19.984375, 'test_std': 2.405996334031912}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (16901 / 20000):
    Value Loss: {'avg': 16.323056920369467, 'std': 1.894520740376284}
    Value Grad Norm: {'avg': 178.33813298543294, 'std': 62.327921821715414}
    Policy Loss: {'avg': 0.002413586154580116, 'std': 0.004069283920699251}
    Total_Loss: {'avg': -0.07948121801018715, 'std': 0.0045888502475066205}
    Policy Entropy: {'avg': 0.8228939771652222, 'std': 0.5795087218284607}
    KL Divergence: {'avg': 0.020252374932169914, 'std': 0.16424815356731415}
    Policy Grad Norm: {'avg': 3.0459550261497497, 'std': 0.9420060658775427}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.70743288049549, 'std': 31.950740168525396, 'run': -18.31750594582928, 'test_avg': -74.59636666427303, 'test_std': 6.9856615937739965}
    Episode Length: {'avg': 6.484237074401009, 'std': 7.563606111280203, 'run': 6.644077216988002, 'test_avg': 19.9033203125, 'test_std': 1.4893596276671737}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (17001 / 20000):
    Value Loss: {'avg': 14.910018380482992, 'std': 1.9674931339119137}
    Value Grad Norm: {'avg': 226.03221638997397, 'std': 96.15504249985425}
    Policy Loss: {'avg': -0.006493980810046196, 'std': 0.009716374470986253}
    Total_Loss: {'avg': -0.08763031214475632, 'std': 0.009730159758013395}
    Policy Entropy: {'avg': 0.8112044334411621, 'std': 0.585720956325531}
    KL Divergence: {'avg': 0.02122381143271923, 'std': 0.1789744347333908}
    Policy Grad Norm: {'avg': 2.407761037349701, 'std': 1.0264988681861944}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -19.14300507168427, 'std': 32.926438478297214, 'run': -20.304478065653242, 'test_avg': -74.43072659597775, 'test_std': 6.50304461263468}
    Episode Length: {'avg': 6.871287128712871, 'std': 7.7916002289842075, 'run': 7.101917297067153, 'test_avg': 19.873046875, 'test_std': 1.4001590638397963}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (17101 / 20000):
    Value Loss: {'avg': 11.974286874135336, 'std': 1.4283058308443737}
    Value Grad Norm: {'avg': 130.53225758870443, 'std': 35.09978692099997}
    Policy Loss: {'avg': -0.00019086324609816075, 'std': 0.003267358348441009}
    Total_Loss: {'avg': -0.07756308764219284, 'std': 0.0030640124683405253}
    Policy Entropy: {'avg': 0.7464479804039001, 'std': 0.6005816459655762}
    KL Divergence: {'avg': 0.01901048980653286, 'std': 0.1677297204732895}
    Policy Grad Norm: {'avg': 2.943018341064453, 'std': 0.9849819176666628}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -14.723683776912749, 'std': 29.496292674348478, 'run': -15.434621244185303, 'test_avg': -74.54326831618576, 'test_std': 6.440655135841122}
    Episode Length: {'avg': 5.770396270396271, 'std': 7.003309912207203, 'run': 5.793129420841816, 'test_avg': 19.865234375, 'test_std': 1.3811659843474133}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (17201 / 20000):
    Value Loss: {'avg': 13.120913823445639, 'std': 1.3799114228671407}
    Value Grad Norm: {'avg': 157.63825276692708, 'std': 59.013524026962756}
    Policy Loss: {'avg': 0.001761488290503621, 'std': 0.0018823766465757093}
    Total_Loss: {'avg': -0.0809924528002739, 'std': 0.0037983271448370367}
    Policy Entropy: {'avg': 0.7930509448051453, 'std': 0.5739530920982361}
    KL Divergence: {'avg': 0.01645529642701149, 'std': 0.18127873539924622}
    Policy Grad Norm: {'avg': 3.287257742881775, 'std': 1.1316486033217954}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.293093864970746, 'std': 32.849797525646586, 'run': -19.111996003277945, 'test_avg': -75.38452637451982, 'test_std': 14.794133585065156}
    Episode Length: {'avg': 6.623724489795919, 'std': 7.80109871942514, 'run': 6.82785775730518, 'test_avg': 20.0478515625, 'test_std': 3.397013749672837}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (17301 / 20000):
    Value Loss: {'avg': 14.850392150878907, 'std': 1.3713804123058702}
    Value Grad Norm: {'avg': 264.5550381978353, 'std': 159.08139510601364}
    Policy Loss: {'avg': 0.007137216627597809, 'std': 0.007992886509923837}
    Total_Loss: {'avg': -0.07673931121826172, 'std': 0.00906838932383682}
    Policy Entropy: {'avg': 0.7969105243682861, 'std': 0.6036743521690369}
    KL Divergence: {'avg': 0.01579112559556961, 'std': 0.1933518648147583}
    Policy Grad Norm: {'avg': 2.9613361835479735, 'std': 1.373975846642221}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.516455461960803, 'std': 31.895068523492384, 'run': -14.539140827705964, 'test_avg': -74.82800435931506, 'test_std': 13.871165025325114}
    Episode Length: {'avg': 6.425316455696202, 'std': 7.54288109939449, 'run': 5.681365983310295, 'test_avg': 19.9306640625, 'test_std': 2.804167717928262}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (17401 / 20000):
    Value Loss: {'avg': 11.910821215311687, 'std': 1.2099290171659534}
    Value Grad Norm: {'avg': 136.97417424519855, 'std': 27.06409880254828}
    Policy Loss: {'avg': 0.006972886901348829, 'std': 0.007768152161684698}
    Total_Loss: {'avg': -0.06975533105432988, 'std': 0.007707889141039428}
    Policy Entropy: {'avg': 0.7757419347763062, 'std': 0.6403011083602905}
    KL Divergence: {'avg': 0.021262599155306816, 'std': 0.21795348823070526}
    Policy Grad Norm: {'avg': 3.8209999322891237, 'std': 1.6616691369613392}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -14.625158191678771, 'std': 29.248441650576734, 'run': -11.582120791206966, 'test_avg': -74.23763797818063, 'test_std': 6.562642860145235}
    Episode Length: {'avg': 5.726757369614512, 'std': 6.982903362640035, 'run': 5.043742427399948, 'test_avg': 19.798828125, 'test_std': 1.4281484522657244}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (17501 / 20000):
    Value Loss: {'avg': 13.133839480082194, 'std': 1.5810434620137805}
    Value Grad Norm: {'avg': 162.95868301391602, 'std': 65.3532617821444}
    Policy Loss: {'avg': -0.005733557976782322, 'std': 0.0061215272304419865}
    Total_Loss: {'avg': -0.08568331710994244, 'std': 0.007912768178814852}
    Policy Entropy: {'avg': 0.8201608061790466, 'std': 0.5624571442604065}
    KL Divergence: {'avg': 0.028984850272536278, 'std': 0.28263142704963684}
    Policy Grad Norm: {'avg': 2.975097280740738, 'std': 1.4711736305725247}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.738072654900147, 'std': 31.733056083212926, 'run': -16.907459112116424, 'test_avg': -74.31274021087569, 'test_std': 9.685806678016316}
    Episode Length: {'avg': 6.5559796437659035, 'std': 7.527053572991211, 'run': 6.373304033340415, 'test_avg': 19.796875, 'test_std': 1.9247945304304561}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (17601 / 20000):
    Value Loss: {'avg': 12.372089544932047, 'std': 1.3343576080445476}
    Value Grad Norm: {'avg': 141.05171915690104, 'std': 52.201750312664885}
    Policy Loss: {'avg': 0.0018263028003275394, 'std': 0.0032346877514251708}
    Total_Loss: {'avg': -0.07310772985219956, 'std': 0.0025409213380790385}
    Policy Entropy: {'avg': 0.7650848627090454, 'std': 0.6101303696632385}
    KL Divergence: {'avg': 0.021263692528009415, 'std': 0.23393794894218445}
    Policy Grad Norm: {'avg': 3.0751696109771727, 'std': 0.8934979467907699}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.140086494532866, 'std': 31.634202189450495, 'run': -14.548934300150895, 'test_avg': -74.90207799339069, 'test_std': 11.571373628555607}
    Episode Length: {'avg': 6.375308641975309, 'std': 7.4925400078303, 'run': 5.82613889073883, 'test_avg': 19.9462890625, 'test_std': 2.4278748058112205}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (17701 / 20000):
    Value Loss: {'avg': 11.626311874389648, 'std': 1.2674759300300613}
    Value Grad Norm: {'avg': 121.36530647277831, 'std': 37.87973245464344}
    Policy Loss: {'avg': 0.0018887394573539496, 'std': 0.006602568369868658}
    Total_Loss: {'avg': -0.07418557107448578, 'std': 0.006268144750385186}
    Policy Entropy: {'avg': 0.722712516784668, 'std': 0.5895155072212219}
    KL Divergence: {'avg': 0.02070612832903862, 'std': 0.2114757001399994}
    Policy Grad Norm: {'avg': 2.613626945018768, 'std': 0.9007575305683607}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.063108338343296, 'std': 29.819280275796213, 'run': -14.384789499597698, 'test_avg': -74.72979883526132, 'test_std': 6.856478626878674}
    Episode Length: {'avg': 5.863898500576702, 'std': 7.089633742373523, 'run': 5.620699558354757, 'test_avg': 19.90625, 'test_std': 1.4740595518838444}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (17801 / 20000):
    Value Loss: {'avg': 12.360963122049968, 'std': 1.1488437186552918}
    Value Grad Norm: {'avg': 163.92176971435546, 'std': 69.33623578725567}
    Policy Loss: {'avg': 0.0015349527820944786, 'std': 0.005317445200267404}
    Total_Loss: {'avg': -0.0719671942293644, 'std': 0.004717378283638219}
    Policy Entropy: {'avg': 0.7337727546691895, 'std': 0.6064862608909607}
    KL Divergence: {'avg': 0.019414452835917473, 'std': 0.18503476679325104}
    Policy Grad Norm: {'avg': 3.21071343421936, 'std': 1.1744695177187479}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.369631269238642, 'std': 31.304848847799285, 'run': -15.812345824942906, 'test_avg': -74.68816619242259, 'test_std': 9.922904534777727}
    Episode Length: {'avg': 6.3906056860321385, 'std': 7.4054876090858235, 'run': 6.1296196998981, 'test_avg': 19.927734375, 'test_std': 1.9825046164998859}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (17901 / 20000):
    Value Loss: {'avg': 11.235862541198731, 'std': 1.2492294927952303}
    Value Grad Norm: {'avg': 130.36919123331705, 'std': 33.846659979969026}
    Policy Loss: {'avg': 0.005966972839087248, 'std': 0.007753421853024996}
    Total_Loss: {'avg': -0.08068509623408318, 'std': 0.00654874449098777}
    Policy Entropy: {'avg': 0.8934125900268555, 'std': 0.6212167143821716}
    KL Divergence: {'avg': 0.02003810554742813, 'std': 0.17733719944953918}
    Policy Grad Norm: {'avg': 2.8153677582740784, 'std': 1.7122260956552195}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -14.641120882896624, 'std': 29.625324873474973, 'run': -16.16798535034929, 'test_avg': -74.39819079199036, 'test_std': 9.812811458608676}
    Episode Length: {'avg': 5.763529411764706, 'std': 7.070025327499746, 'run': 6.1045381837227914, 'test_avg': 19.8388671875, 'test_std': 1.9691004365536664}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (18001 / 20000):
    Value Loss: {'avg': 13.872181065877278, 'std': 1.6256559882563064}
    Value Grad Norm: {'avg': 149.36676635742188, 'std': 42.64644816908213}
    Policy Loss: {'avg': 0.0011703482829034328, 'std': 0.0036199967042821056}
    Total_Loss: {'avg': -0.07872624173760415, 'std': 0.004174329241294483}
    Policy Entropy: {'avg': 0.8049516677856445, 'std': 0.6032548546791077}
    KL Divergence: {'avg': 0.018742209300398827, 'std': 0.18998438119888306}
    Policy Grad Norm: {'avg': 3.0971763253211977, 'std': 1.1162186489607986}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.285624341727104, 'std': 31.2518201187381, 'run': -17.530555409441362, 'test_avg': -74.44497036589115, 'test_std': 8.80043528905676}
    Episode Length: {'avg': 6.426952141057934, 'std': 7.414352548135067, 'run': 6.501512505938472, 'test_avg': 19.8359375, 'test_std': 1.9656318312679386}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (18101 / 20000):
    Value Loss: {'avg': 12.222960726420085, 'std': 1.2963806620591443}
    Value Grad Norm: {'avg': 169.05144170125325, 'std': 71.15484592856187}
    Policy Loss: {'avg': 0.004150628298521042, 'std': 0.0079433311981152}
    Total_Loss: {'avg': -0.0744236283004284, 'std': 0.00824509227707564}
    Policy Entropy: {'avg': 0.7870713472366333, 'std': 0.6044095754623413}
    KL Divergence: {'avg': 0.017391880974173546, 'std': 0.16168172657489777}
    Policy Grad Norm: {'avg': 2.8019232511520387, 'std': 0.9611991575056927}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.204818091229583, 'std': 30.63364602611737, 'run': -15.47571771498815, 'test_avg': -75.21159632338527, 'test_std': 12.04741959947897}
    Episode Length: {'avg': 6.095238095238095, 'std': 7.280958609732925, 'run': 5.938642717665004, 'test_avg': 20.0048828125, 'test_std': 2.775622042109136}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (18201 / 20000):
    Value Loss: {'avg': 13.007428391774495, 'std': 1.8222178577821642}
    Value Grad Norm: {'avg': 155.50371246337892, 'std': 61.83428735904146}
    Policy Loss: {'avg': -0.006380780506879092, 'std': 0.00809488912880669}
    Total_Loss: {'avg': -0.0835706852376461, 'std': 0.008882855678175393}
    Policy Entropy: {'avg': 0.8337692618370056, 'std': 0.6022284626960754}
    KL Divergence: {'avg': 0.02138923481106758, 'std': 0.19791173934936523}
    Policy Grad Norm: {'avg': 2.488635164499283, 'std': 0.8857782145989697}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -16.85674438390692, 'std': 30.862635878813844, 'run': -17.216055452614743, 'test_avg': -74.73551113128727, 'test_std': 13.775870497308572}
    Episode Length: {'avg': 6.313180169286578, 'std': 7.348953510391101, 'run': 6.482776051490839, 'test_avg': 19.9287109375, 'test_std': 2.7995877030498386}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (18301 / 20000):
    Value Loss: {'avg': 14.541687933603923, 'std': 1.8360726223617245}
    Value Grad Norm: {'avg': 157.98967208862305, 'std': 53.35076863775959}
    Policy Loss: {'avg': 0.0065298969857394695, 'std': 0.006663762662823706}
    Total_Loss: {'avg': -0.07499735578894615, 'std': 0.006410916191690668}
    Policy Entropy: {'avg': 0.8225035071372986, 'std': 0.6043080687522888}
    KL Divergence: {'avg': 0.024155227467417717, 'std': 0.19987866282463074}
    Policy Grad Norm: {'avg': 3.4811573028564453, 'std': 1.8632420837048809}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.35409034062583, 'std': 31.488736775385423, 'run': -14.8383834998, 'test_avg': -75.08631115760116, 'test_std': 12.524818239106605}
    Episode Length: {'avg': 6.442748091603053, 'std': 7.4423931539298405, 'run': 5.793233346866153, 'test_avg': 19.9794921875, 'test_std': 2.409407290626984}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (18401 / 20000):
    Value Loss: {'avg': 11.301202170054118, 'std': 1.293439254279812}
    Value Grad Norm: {'avg': 124.3922238667806, 'std': 31.734129795521206}
    Policy Loss: {'avg': 0.0006245537661015987, 'std': 0.004380334679646058}
    Total_Loss: {'avg': -0.0762989416718483, 'std': 0.005139169675265923}
    Policy Entropy: {'avg': 0.758114218711853, 'std': 0.5691810250282288}
    KL Divergence: {'avg': 0.021961936727166176, 'std': 0.1956469565629959}
    Policy Grad Norm: {'avg': 2.7059149503707887, 'std': 0.7150279844071817}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.0078614201361, 'std': 30.569930036821006, 'run': -15.214251431377711, 'test_avg': -74.90470741611007, 'test_std': 12.363541239926358}
    Episode Length: {'avg': 6.101057579318449, 'std': 7.235935671285905, 'run': 5.92430707237951, 'test_avg': 19.93359375, 'test_std': 2.814840063833279}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (18501 / 20000):
    Value Loss: {'avg': 12.839396699269612, 'std': 2.014714761824782}
    Value Grad Norm: {'avg': 132.9462750752767, 'std': 46.505651079995545}
    Policy Loss: {'avg': 0.001405636966228485, 'std': 0.004847575208017882}
    Total_Loss: {'avg': -0.07584343552589416, 'std': 0.004793592526476762}
    Policy Entropy: {'avg': 0.7464536428451538, 'std': 0.6058981418609619}
    KL Divergence: {'avg': 0.01535661518573761, 'std': 0.15583717823028564}
    Policy Grad Norm: {'avg': 3.2579696655273436, 'std': 1.8742114604498459}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.724263357625333, 'std': 30.777571902632367, 'run': -18.24977219626456, 'test_avg': -74.13034073019782, 'test_std': 8.951189024542801}
    Episode Length: {'avg': 6.221411192214112, 'std': 7.355229131403488, 'run': 6.587092950076056, 'test_avg': 19.8095703125, 'test_std': 2.0019195404957344}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (18601 / 20000):
    Value Loss: {'avg': 12.506729030609131, 'std': 1.372893664755947}
    Value Grad Norm: {'avg': 132.9318728129069, 'std': 51.524778126360935}
    Policy Loss: {'avg': 0.003311468195170164, 'std': 0.0067812422976124605}
    Total_Loss: {'avg': -0.07937928065657615, 'std': 0.006986310353468636}
    Policy Entropy: {'avg': 0.8442910313606262, 'std': 0.6034420132637024}
    KL Divergence: {'avg': 0.023844558745622635, 'std': 0.21231810748577118}
    Policy Grad Norm: {'avg': 2.8709985256195067, 'std': 1.60671479221027}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.11491899201364, 'std': 31.36774316944289, 'run': -17.375488954387723, 'test_avg': -74.67262789455893, 'test_std': 6.836611878177151}
    Episode Length: {'avg': 6.3868520859671305, 'std': 7.418296925948357, 'run': 6.509862436900276, 'test_avg': 19.927734375, 'test_std': 1.4633051815815317}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (18701 / 20000):
    Value Loss: {'avg': 14.406326548258464, 'std': 2.50210242513197}
    Value Grad Norm: {'avg': 165.06427281697592, 'std': 54.66998723254268}
    Policy Loss: {'avg': -0.0008574257604777813, 'std': 0.0017146090328864492}
    Total_Loss: {'avg': -0.07961653247475624, 'std': 0.00277927886529616}
    Policy Entropy: {'avg': 0.75975501537323, 'std': 0.5945706367492676}
    KL Divergence: {'avg': 0.01679202727973461, 'std': 0.16250164806842804}
    Policy Grad Norm: {'avg': 2.41120388507843, 'std': 0.4158991719417856}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.652420433887848, 'std': 31.098413150861802, 'run': -14.914133355292876, 'test_avg': -74.90317422036829, 'test_std': 12.250932938007912}
    Episode Length: {'avg': 6.2639593908629445, 'std': 7.345800316695733, 'run': 5.8078212880541455, 'test_avg': 19.966796875, 'test_std': 2.8116094238870084}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (18801 / 20000):
    Value Loss: {'avg': 11.82975508371989, 'std': 1.6722818073210044}
    Value Grad Norm: {'avg': 156.91117731730142, 'std': 55.13288313845977}
    Policy Loss: {'avg': 0.0015856072306632996, 'std': 0.003963227188562829}
    Total_Loss: {'avg': -0.07822527512907981, 'std': 0.005782950991834085}
    Policy Entropy: {'avg': 0.7972180247306824, 'std': 0.5963665843009949}
    KL Divergence: {'avg': 0.019097069278359413, 'std': 0.20378519594669342}
    Policy Grad Norm: {'avg': 2.458367371559143, 'std': 0.7702621648828724}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -14.989576748001227, 'std': 29.96463294487744, 'run': -13.833148333091998, 'test_avg': -74.29658766522775, 'test_std': 6.339532003547548}
    Episode Length: {'avg': 5.8422247446084, 'std': 7.112288069850405, 'run': 5.492810644200043, 'test_avg': 19.82421875, 'test_std': 1.3665791057046195}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (18901 / 20000):
    Value Loss: {'avg': 15.072442944844564, 'std': 1.7361934245098065}
    Value Grad Norm: {'avg': 139.77545267740885, 'std': 29.524724432189533}
    Policy Loss: {'avg': 0.002204014174640179, 'std': 0.0032305065707791654}
    Total_Loss: {'avg': -0.0799670621752739, 'std': 0.0037284624570811404}
    Policy Entropy: {'avg': 0.8599570989608765, 'std': 0.5640991926193237}
    KL Divergence: {'avg': 0.015810532495379448, 'std': 0.15425024926662445}
    Policy Grad Norm: {'avg': 2.7258002400398254, 'std': 0.8561601592784222}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.29605713042282, 'std': 31.024665753174503, 'run': -18.244133015976367, 'test_avg': -74.77384429786227, 'test_std': 6.415703751456962}
    Episode Length: {'avg': 6.137135922330097, 'std': 7.3746403269853715, 'run': 6.681370840971553, 'test_avg': 19.9345703125, 'test_std': 1.3773475028088054}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (19001 / 20000):
    Value Loss: {'avg': 14.787267430623372, 'std': 1.8971036802277894}
    Value Grad Norm: {'avg': 165.77360153198242, 'std': 72.23582382627997}
    Policy Loss: {'avg': -0.0061014633858576415, 'std': 0.009608716699525469}
    Total_Loss: {'avg': -0.09523862227797508, 'std': 0.009491953590903044}
    Policy Entropy: {'avg': 0.8665498495101929, 'std': 0.6025941371917725}
    KL Divergence: {'avg': 0.02423870377242565, 'std': 0.17059628665447235}
    Policy Grad Norm: {'avg': 3.013660800457001, 'std': 1.3531580812379767}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -17.985403595938905, 'std': 32.84810197986869, 'run': -19.946072903238562, 'test_avg': -74.66844848094642, 'test_std': 10.047827266219313}
    Episode Length: {'avg': 6.458974358974359, 'std': 7.799382551127347, 'run': 6.91001126047354, 'test_avg': 19.9228515625, 'test_std': 2.0002210018123767}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (19101 / 20000):
    Value Loss: {'avg': 10.876252047220866, 'std': 1.0640495069807516}
    Value Grad Norm: {'avg': 136.85569279988607, 'std': 46.403216992851675}
    Policy Loss: {'avg': 0.003454288374632597, 'std': 0.006139658371553933}
    Total_Loss: {'avg': -0.07773735374212265, 'std': 0.007534543824739727}
    Policy Entropy: {'avg': 0.8246577382087708, 'std': 0.6146311163902283}
    KL Divergence: {'avg': 0.01818893663585186, 'std': 0.17222808301448822}
    Policy Grad Norm: {'avg': 2.200916278362274, 'std': 0.7933000353609637}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -15.441488864800876, 'std': 30.085421437726797, 'run': -15.69660438996509, 'test_avg': -75.44244318391213, 'test_std': 14.781564755135335}
    Episode Length: {'avg': 5.958382877526754, 'std': 7.17104955532914, 'run': 5.94701493343663, 'test_avg': 20.072265625, 'test_std': 2.7857499312471248}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (19201 / 20000):
    Value Loss: {'avg': 12.716484196980794, 'std': 1.2838984488028535}
    Value Grad Norm: {'avg': 126.81524073282877, 'std': 31.709365748258186}
    Policy Loss: {'avg': 0.002022992633283138, 'std': 0.006074863786864433}
    Total_Loss: {'avg': -0.08030940741300582, 'std': 0.0064427936303446}
    Policy Entropy: {'avg': 0.8410407304763794, 'std': 0.6025341153144836}
    KL Divergence: {'avg': 0.018387392163276672, 'std': 0.1819153130054474}
    Policy Grad Norm: {'avg': 2.606267440319061, 'std': 0.7115676465500615}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -16.733672735624147, 'std': 31.498361850600965, 'run': -13.659911604536314, 'test_avg': -74.44600578625057, 'test_std': 11.577744796768837}
    Episode Length: {'avg': 6.268998793727382, 'std': 7.447201631885465, 'run': 5.637891854314945, 'test_avg': 19.841796875, 'test_std': 2.400433532976957}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (19301 / 20000):
    Value Loss: {'avg': 13.449614556630452, 'std': 1.569440321260362}
    Value Grad Norm: {'avg': 146.0509910583496, 'std': 51.153126000872746}
    Policy Loss: {'avg': 0.0003237188793718815, 'std': 0.003951888272058588}
    Total_Loss: {'avg': -0.08792806789278984, 'std': 0.004580728377434221}
    Policy Entropy: {'avg': 0.8154561519622803, 'std': 0.5802246332168579}
    KL Divergence: {'avg': 0.01814708486199379, 'std': 0.1671590805053711}
    Policy Grad Norm: {'avg': 2.5612982511520386, 'std': 0.38856363268188654}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.44472237172398, 'std': 31.837749954969922, 'run': -17.322393952167115, 'test_avg': -74.71018825029428, 'test_std': 11.671558053489616}
    Episode Length: {'avg': 6.435, 'std': 7.593798456635519, 'run': 6.433703621970425, 'test_avg': 19.9404296875, 'test_std': 2.444574311688776}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (19401 / 20000):
    Value Loss: {'avg': 11.595612716674804, 'std': 1.1585068601612591}
    Value Grad Norm: {'avg': 150.74749094645182, 'std': 61.94871113336913}
    Policy Loss: {'avg': -0.00606677271425724, 'std': 0.010013404845440351}
    Total_Loss: {'avg': -0.08099346533417702, 'std': 0.010012700867612216}
    Policy Entropy: {'avg': 0.7393753528594971, 'std': 0.5839958190917969}
    KL Divergence: {'avg': 0.025926610454916954, 'std': 0.2067723125219345}
    Policy Grad Norm: {'avg': 2.6561208069324493, 'std': 1.0519244133354826}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -15.795098991197802, 'std': 30.210135153453074, 'run': -14.70503830077147, 'test_avg': -74.27970522693997, 'test_std': 6.749259175600716}
    Episode Length: {'avg': 6.008403361344538, 'std': 7.174295618303739, 'run': 5.766418343091826, 'test_avg': 19.8681640625, 'test_std': 1.467486873223572}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (19501 / 20000):
    Value Loss: {'avg': 12.66651102701823, 'std': 1.5217328714153284}
    Value Grad Norm: {'avg': 145.65728912353515, 'std': 42.60647747022338}
    Policy Loss: {'avg': 0.0029761893674731255, 'std': 0.0033556624614393235}
    Total_Loss: {'avg': -0.07778804451227188, 'std': 0.0031463749026924845}
    Policy Entropy: {'avg': 0.8357316851615906, 'std': 0.5828102827072144}
    KL Divergence: {'avg': 0.020403798669576645, 'std': 0.196149080991745}
    Policy Grad Norm: {'avg': 2.729949450492859, 'std': 0.6208855938321066}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.714619052498616, 'std': 31.9317737335051, 'run': -17.85335531673715, 'test_avg': -74.51690990244668, 'test_std': 11.642530991616447}
    Episode Length: {'avg': 6.4613434727503165, 'std': 7.6423600174386985, 'run': 6.539984138433348, 'test_avg': 19.87890625, 'test_std': 2.4228293230665128}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (19601 / 20000):
    Value Loss: {'avg': 12.618264770507812, 'std': 1.8411500446796065}
    Value Grad Norm: {'avg': 133.49491907755535, 'std': 46.41937057325514}
    Policy Loss: {'avg': -0.0019032973796129227, 'std': 0.011229576436561464}
    Total_Loss: {'avg': -0.07927093915641308, 'std': 0.011543553358680264}
    Policy Entropy: {'avg': 0.7162704467773438, 'std': 0.586513876914978}
    KL Divergence: {'avg': 0.025265324860811234, 'std': 0.17921467125415802}
    Policy Grad Norm: {'avg': 3.5707783639431, 'std': 1.9624815913392062}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -14.879296675265463, 'std': 29.84579131930293, 'run': -13.475857471989649, 'test_avg': -75.3123272691019, 'test_std': 12.871629241084133}
    Episode Length: {'avg': 5.763187429854097, 'std': 7.09649955186877, 'run': 5.490497344046641, 'test_avg': 20.0478515625, 'test_std': 2.7720450330877218}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (19701 / 20000):
    Value Loss: {'avg': 14.1148193359375, 'std': 1.4987621262680055}
    Value Grad Norm: {'avg': 137.07460174560546, 'std': 46.512751686005146}
    Policy Loss: {'avg': 0.002805333910509944, 'std': 0.0047421157377947835}
    Total_Loss: {'avg': -0.08492526710033417, 'std': 0.004969342603286844}
    Policy Entropy: {'avg': 0.8641961812973022, 'std': 0.5919644236564636}
    KL Divergence: {'avg': 0.018443582579493523, 'std': 0.1971726417541504}
    Policy Grad Norm: {'avg': 2.640760862827301, 'std': 0.6720445530528875}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -18.48174101236913, 'std': 32.50687723965233, 'run': -20.16872053534289, 'test_avg': -74.98380475955538, 'test_std': 14.637272405386355}
    Episode Length: {'avg': 6.667103538663172, 'std': 7.729659333965618, 'run': 7.096716548164544, 'test_avg': 20.0234375, 'test_std': 2.82452939595143}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (19801 / 20000):
    Value Loss: {'avg': 14.459769948323567, 'std': 1.4825892956679667}
    Value Grad Norm: {'avg': 202.78099899291993, 'std': 71.83050651323983}
    Policy Loss: {'avg': 0.0037460530176758764, 'std': 0.004837085983686141}
    Total_Loss: {'avg': -0.07423904240131378, 'std': 0.005577037416755963}
    Policy Entropy: {'avg': 0.776370644569397, 'std': 0.6053298711776733}
    KL Divergence: {'avg': 0.019608024507761, 'std': 0.16562718152999878}
    Policy Grad Norm: {'avg': 2.7707306146621704, 'std': 0.8972580533702975}
    Num PPO updates: {'avg': 10}
    Return: {'avg': -17.386013923302063, 'std': 31.769363306660896, 'run': -13.838592411446877, 'test_avg': -74.3368393151049, 'test_std': 6.88090811370477}
    Episode Length: {'avg': 6.413151364764268, 'std': 7.581928085468612, 'run': 5.532322838961681, 'test_avg': 19.8212890625, 'test_std': 1.4658534931287885}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (19901 / 20000):
    Value Loss: {'avg': 11.13697551091512, 'std': 1.3621051357523075}
    Value Grad Norm: {'avg': 101.69561195373535, 'std': 31.237761804321206}
    Policy Loss: {'avg': -0.0058159886859357355, 'std': 0.010235015728831832}
    Total_Loss: {'avg': -0.07996212672442198, 'std': 0.010097219644961705}
    Policy Entropy: {'avg': 0.7834986448287964, 'std': 0.6065499186515808}
    KL Divergence: {'avg': 0.02350502274930477, 'std': 0.19231462478637695}
    Policy Grad Norm: {'avg': 2.8210921764373778, 'std': 1.2855314364101609}
    Num PPO updates: {'avg': 20}
    Return: {'avg': -15.019257054323559, 'std': 29.936065546365477, 'run': -15.063603951307112, 'test_avg': -74.67683269994261, 'test_std': 12.618322830832616}
    Episode Length: {'avg': 5.896708286038592, 'std': 7.085308011558051, 'run': 5.997602147523148, 'test_avg': 19.8828125, 'test_std': 2.428657337881108}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Training took 34574.297 seconds in total.
