
Iteration (1 / 10001):
    Value Loss: {'avg': 2258.3287404378257, 'std': 201.23349541535217}
    Value Grad Norm: {'avg': 516.2360064188639, 'std': 139.81422010226666}
    Policy Loss: {'avg': -0.0005026674965241303, 'std': 0.003641683098510879}
    Total_Loss: {'avg': -0.2303504211207231, 'std': 0.003686909643425048}
    Policy Entropy: {'avg': 2.299025297164917, 'std': 0.006033681333065033}
    KL Divergence: {'avg': 0.0048833005130290985, 'std': 0.06767003238201141}
    Policy Grad Norm: {'avg': 0.14013780979439616, 'std': 0.04877691956559308}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -160.05966897025087, 'std': 44.835947994389045, 'run': -123.94416905038838, 'test_avg': -149.58898504803844, 'test_std': 31.326843888196198}
    Episode Length: {'avg': 37.16197183098591, 'std': 7.776487968611992, 'run': 29.578798867785977, 'test_avg': 36.0185546875, 'test_std': 4.389779440481239}
    Ratio Terminated: {'avg': 0.2323943661971831, 'test_avg': 0.5859375}

Iteration (101 / 10001):
    Value Loss: {'avg': 217.41979249318442, 'std': 24.143292328916278}
    Value Grad Norm: {'avg': 946.6495717366537, 'std': 512.914192832878}
    Policy Loss: {'avg': -0.006188484151304389, 'std': 0.008860104733787292}
    Total_Loss: {'avg': -0.19591643630216518, 'std': 0.008617758944301203}
    Policy Entropy: {'avg': 1.8960952758789062, 'std': 0.33454015851020813}
    KL Divergence: {'avg': 0.009985394775867462, 'std': 0.17176496982574463}
    Policy Grad Norm: {'avg': 1.6634324006736279, 'std': 0.6500643361126003}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -127.80493408067304, 'std': 41.965026087528074, 'run': -129.42729369814478, 'test_avg': -117.18977893070453, 'test_std': 13.829383230913285}
    Episode Length: {'avg': 32.86530612244898, 'std': 9.17729120633539, 'run': 33.083389731424205, 'test_avg': 30.5654296875, 'test_std': 3.072308306630969}
    Ratio Terminated: {'avg': 0.8244897959183674, 'test_avg': 0.998046875}

Iteration (201 / 10001):
    Value Loss: {'avg': 148.22632185618082, 'std': 14.360702664556312}
    Value Grad Norm: {'avg': 1268.3729972839355, 'std': 668.6665169323318}
    Policy Loss: {'avg': 0.006734111928381026, 'std': 0.006526986828631339}
    Total_Loss: {'avg': -0.1781545551493764, 'std': 0.006185200144729236}
    Policy Entropy: {'avg': 1.7968977689743042, 'std': 0.3482707440853119}
    KL Divergence: {'avg': 0.016199033707380295, 'std': 0.20128242671489716}
    Policy Grad Norm: {'avg': 1.7301995530724525, 'std': 0.3669141961636966}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -119.23741001082331, 'std': 38.82630552568928, 'run': -120.01602321423965, 'test_avg': -114.94679415190069, 'test_std': 13.800919816554188}
    Episode Length: {'avg': 30.87593984962406, 'std': 8.524821347330438, 'run': 31.184534650529493, 'test_avg': 29.8779296875, 'test_std': 3.0339455171947556}
    Ratio Terminated: {'avg': 0.9323308270676691, 'test_avg': 1.0}

Iteration (301 / 10001):
    Value Loss: {'avg': 155.080455938975, 'std': 15.54426178342368}
    Value Grad Norm: {'avg': 1942.5185438791912, 'std': 1290.6378010414874}
    Policy Loss: {'avg': 0.003103603783529252, 'std': 0.005033002421688949}
    Total_Loss: {'avg': -0.17424546740949154, 'std': 0.005951556246020937}
    Policy Entropy: {'avg': 1.8127449750900269, 'std': 0.2945876717567444}
    KL Divergence: {'avg': 0.01775658130645752, 'std': 0.17955800890922546}
    Policy Grad Norm: {'avg': 1.8284265100955963, 'std': 0.4275137356230355}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -111.19506870924675, 'std': 39.17662298847953, 'run': -113.0714599499775, 'test_avg': -108.24982594170379, 'test_std': 13.975802286509056}
    Episode Length: {'avg': 28.76206896551724, 'std': 8.63325222585578, 'run': 29.183226995517163, 'test_avg': 28.103515625, 'test_std': 3.059792703825025}
    Ratio Terminated: {'avg': 0.9862068965517241, 'test_avg': 0.998046875}

Iteration (401 / 10001):
    Value Loss: {'avg': 136.88574425379434, 'std': 13.981207287156119}
    Value Grad Norm: {'avg': 2039.7101949055989, 'std': 897.7960526815615}
    Policy Loss: {'avg': -0.005982100289353791, 'std': 0.010868455988721182}
    Total_Loss: {'avg': -0.1803925825903813, 'std': 0.010171449930063243}
    Policy Entropy: {'avg': 1.7468652725219727, 'std': 0.34879639744758606}
    KL Divergence: {'avg': 0.015100793913006783, 'std': 0.17086315155029297}
    Policy Grad Norm: {'avg': 1.8500691056251526, 'std': 0.6728512148558112}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -109.51047446500246, 'std': 36.38258813533811, 'run': -109.1991097391132, 'test_avg': -103.54830590310752, 'test_std': 13.781166455060799}
    Episode Length: {'avg': 28.5, 'std': 7.998780935486401, 'run': 28.401934944329362, 'test_avg': 26.9541015625, 'test_std': 3.0934095098992405}
    Ratio Terminated: {'avg': 0.9680851063829787, 'test_avg': 1.0}

Iteration (501 / 10001):
    Value Loss: {'avg': 138.6839254697164, 'std': 14.462298709141205}
    Value Grad Norm: {'avg': 2200.489723841349, 'std': 1174.6828921582744}
    Policy Loss: {'avg': 0.008131438924465328, 'std': 0.0069668085792387755}
    Total_Loss: {'avg': -0.16169348638504744, 'std': 0.00809619585398652}
    Policy Entropy: {'avg': 1.6314384937286377, 'std': 0.4757287800312042}
    KL Divergence: {'avg': 0.02565727010369301, 'std': 0.2470221221446991}
    Policy Grad Norm: {'avg': 2.2993918545544147, 'std': 0.7641729208926512}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -106.91477050861492, 'std': 34.192903545689184, 'run': -106.39306222426805, 'test_avg': -97.7320692587931, 'test_std': 12.454164687161022}
    Episode Length: {'avg': 27.6722972972973, 'std': 7.663799785671436, 'run': 27.62960160554991, 'test_avg': 25.3974609375, 'test_std': 2.8147965273997375}
    Ratio Terminated: {'avg': 0.9864864864864865, 'test_avg': 1.0}

Iteration (601 / 10001):
    Value Loss: {'avg': 110.07807270685832, 'std': 8.92822513221932}
    Value Grad Norm: {'avg': 1606.2368927001953, 'std': 672.4957230648093}
    Policy Loss: {'avg': 0.00027450546622276306, 'std': 0.005343576827517845}
    Total_Loss: {'avg': -0.16884488984942436, 'std': 0.004034192478761565}
    Policy Entropy: {'avg': 1.741006851196289, 'std': 0.32518014311790466}
    KL Divergence: {'avg': 0.01821739226579666, 'std': 0.21337202191352844}
    Policy Grad Norm: {'avg': 1.8447183221578598, 'std': 0.4386217588263069}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -106.92023605823086, 'std': 29.567489944610703, 'run': -107.25962793244646, 'test_avg': -95.37182659949724, 'test_std': 12.030455804175025}
    Episode Length: {'avg': 27.681355932203388, 'std': 6.709479117327562, 'run': 27.723767383689285, 'test_avg': 24.7509765625, 'test_std': 2.7403058935227804}
    Ratio Terminated: {'avg': 0.9966101694915255, 'test_avg': 1.0}

Iteration (701 / 10001):
    Value Loss: {'avg': 105.55337142944336, 'std': 6.921961575174985}
    Value Grad Norm: {'avg': 2075.247039159139, 'std': 1134.267111775029}
    Policy Loss: {'avg': -0.006826461845776066, 'std': 0.009706232585351351}
    Total_Loss: {'avg': -0.16690898997088274, 'std': 0.009932436641757423}
    Policy Entropy: {'avg': 1.6062053442001343, 'std': 0.42744696140289307}
    KL Divergence: {'avg': 0.01670755259692669, 'std': 0.1938992291688919}
    Policy Grad Norm: {'avg': 2.3207196295261383, 'std': 0.6707774528655837}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -99.05141119264016, 'std': 30.36629549955702, 'run': -99.21790240312689, 'test_avg': -91.35992938919574, 'test_std': 10.52754325656379}
    Episode Length: {'avg': 25.650943396226417, 'std': 6.618597467994023, 'run': 25.62365768405776, 'test_avg': 23.6435546875, 'test_std': 2.374362056784259}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (801 / 10001):
    Value Loss: {'avg': 101.55525461832683, 'std': 8.534099042049975}
    Value Grad Norm: {'avg': 2899.5253149668374, 'std': 1178.392857108128}
    Policy Loss: {'avg': 0.0009482176101300865, 'std': 0.004639277445660717}
    Total_Loss: {'avg': -0.15479941945523024, 'std': 0.0052550748565331614}
    Policy Entropy: {'avg': 1.5845673084259033, 'std': 0.3982628881931305}
    KL Divergence: {'avg': 0.01566823571920395, 'std': 0.17021071910858154}
    Policy Grad Norm: {'avg': 1.9992854185402393, 'std': 0.652179330428074}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -99.16231000089654, 'std': 29.724911663054346, 'run': -97.13490792289855, 'test_avg': -88.00100055960004, 'test_std': 9.604763962599261}
    Episode Length: {'avg': 25.761467889908257, 'std': 6.602611496918788, 'run': 25.337658212938546, 'test_avg': 22.8798828125, 'test_std': 2.186657334555895}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (901 / 10001):
    Value Loss: {'avg': 100.93711868921916, 'std': 7.844170767088818}
    Value Grad Norm: {'avg': 1190.820805867513, 'std': 734.3052367627613}
    Policy Loss: {'avg': 0.0011997399269603193, 'std': 0.01032579156846186}
    Total_Loss: {'avg': -0.1490400331094861, 'std': 0.011120055928879186}
    Policy Entropy: {'avg': 1.5078232288360596, 'std': 0.4603561758995056}
    KL Divergence: {'avg': 0.018802879378199577, 'std': 0.189838707447052}
    Policy Grad Norm: {'avg': 2.1054467633366585, 'std': 0.7449134988881262}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -94.24797374203592, 'std': 28.478493684097128, 'run': -92.58860023352827, 'test_avg': -88.10686492988106, 'test_std': 10.603189490176897}
    Episode Length: {'avg': 24.411594202898552, 'std': 6.220012960326776, 'run': 24.102751289015583, 'test_avg': 22.8896484375, 'test_std': 2.3457346333619684}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1001 / 10001):
    Value Loss: {'avg': 91.91474914550781, 'std': 9.057666047743853}
    Value Grad Norm: {'avg': 1471.1650327046711, 'std': 863.792228416898}
    Policy Loss: {'avg': 0.0024418715911451727, 'std': 0.007732171555088876}
    Total_Loss: {'avg': -0.13315855944529176, 'std': 0.008558116710901453}
    Policy Entropy: {'avg': 1.3520557880401611, 'std': 0.517996072769165}
    KL Divergence: {'avg': 0.01593353971838951, 'std': 0.21961218118667603}
    Policy Grad Norm: {'avg': 2.6992922611534595, 'std': 0.9099344846135371}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -87.83702560139281, 'std': 30.29122028882334, 'run': -85.43309126064898, 'test_avg': -87.08088562888042, 'test_std': 9.523163039680046}
    Episode Length: {'avg': 22.946175637393768, 'std': 6.619564387709551, 'run': 22.47718131795124, 'test_avg': 22.6416015625, 'test_std': 2.1486432341125314}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1101 / 10001):
    Value Loss: {'avg': 92.06009833017985, 'std': 6.09336576585614}
    Value Grad Norm: {'avg': 1012.6121114095052, 'std': 573.1222544017895}
    Policy Loss: {'avg': -0.007730408794789885, 'std': 0.01321614219824492}
    Total_Loss: {'avg': -0.16529018804430962, 'std': 0.012341090440883376}
    Policy Entropy: {'avg': 1.4947192668914795, 'std': 0.47868090867996216}
    KL Divergence: {'avg': 0.02375713363289833, 'std': 0.23308616876602173}
    Policy Grad Norm: {'avg': 2.2613977963725724, 'std': 0.5499748582832527}
    Num PPO updates: {'avg': 48}
    Return: {'avg': -95.75661033434977, 'std': 28.20896800019036, 'run': -94.46641264414926, 'test_avg': -85.07292491121532, 'test_std': 8.633305908491467}
    Episode Length: {'avg': 24.72106824925816, 'std': 6.218041238287132, 'run': 24.429633166707184, 'test_avg': 22.07421875, 'test_std': 1.9193604930154309}
    Ratio Terminated: {'avg': 0.9970326409495549, 'test_avg': 1.0}

Iteration (1201 / 10001):
    Value Loss: {'avg': 95.37579409281413, 'std': 6.54718319545636}
    Value Grad Norm: {'avg': 1077.6120688120525, 'std': 456.9947193088107}
    Policy Loss: {'avg': -0.0016705838061170653, 'std': 0.0069398557295508945}
    Total_Loss: {'avg': -0.15881760884076357, 'std': 0.0067337622521016225}
    Policy Entropy: {'avg': 1.6306830644607544, 'std': 0.3636968731880188}
    KL Divergence: {'avg': 0.01898270845413208, 'std': 0.194278284907341}
    Policy Grad Norm: {'avg': 2.3938215412199497, 'std': 0.9648156345785822}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -93.96061179757024, 'std': 31.4680905814985, 'run': -94.60879606943055, 'test_avg': -88.03730118476508, 'test_std': 10.911874782561412}
    Episode Length: {'avg': 24.477341389728096, 'std': 6.911302547391479, 'run': 24.641232825499117, 'test_avg': 22.955078125, 'test_std': 2.4689346437576036}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1301 / 10001):
    Value Loss: {'avg': 70.83100684483846, 'std': 5.4329262885567475}
    Value Grad Norm: {'avg': 835.666665395101, 'std': 402.81895216186}
    Policy Loss: {'avg': 0.007341344840824604, 'std': 0.005165270003404794}
    Total_Loss: {'avg': -0.13393752463161945, 'std': 0.00779417477255222}
    Policy Entropy: {'avg': 1.3519375324249268, 'std': 0.4981802701950073}
    KL Divergence: {'avg': 0.01694152131676674, 'std': 0.17204983532428741}
    Policy Grad Norm: {'avg': 3.4321713596582413, 'std': 1.644441761961256}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -89.08907110011636, 'std': 28.275285429275648, 'run': -89.89975888906966, 'test_avg': -83.88958396334054, 'test_std': 9.291601875491674}
    Episode Length: {'avg': 23.21590909090909, 'std': 6.129194043926099, 'run': 23.318729549056595, 'test_avg': 21.8642578125, 'test_std': 2.015111813531129}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (1401 / 10001):
    Value Loss: {'avg': 81.65075874328613, 'std': 8.63417124813332}
    Value Grad Norm: {'avg': 901.313814163208, 'std': 430.07606138146326}
    Policy Loss: {'avg': 0.009482978901360184, 'std': 0.00787265263447183}
    Total_Loss: {'avg': -0.12618538783863187, 'std': 0.008033922461658084}
    Policy Entropy: {'avg': 1.3492062091827393, 'std': 0.5190786123275757}
    KL Divergence: {'avg': 0.018297463655471802, 'std': 0.20501109957695007}
    Policy Grad Norm: {'avg': 2.6906612142920494, 'std': 0.8582326325218993}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -85.63686167264058, 'std': 30.211951215938477, 'run': -87.13426187682339, 'test_avg': -83.47922103134393, 'test_std': 8.745918091655309}
    Episode Length: {'avg': 22.445682451253482, 'std': 6.613628793302307, 'run': 22.745168849856462, 'test_avg': 21.7109375, 'test_std': 1.9280104048198885}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1501 / 10001):
    Value Loss: {'avg': 85.52556117375691, 'std': 6.112808145625232}
    Value Grad Norm: {'avg': 860.3115838368734, 'std': 463.5485176879208}
    Policy Loss: {'avg': 0.0065350684453733265, 'std': 0.007840759430694759}
    Total_Loss: {'avg': -0.13815447874367237, 'std': 0.008018137352946656}
    Policy Entropy: {'avg': 1.4723560810089111, 'std': 0.41416075825691223}
    KL Divergence: {'avg': 0.017608100548386574, 'std': 0.17323695123195648}
    Policy Grad Norm: {'avg': 2.08771151304245, 'std': 0.6279343609494624}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -89.36807797500691, 'std': 31.0225821711657, 'run': -86.2530877279282, 'test_avg': -82.5320267438234, 'test_std': 8.548177628926508}
    Episode Length: {'avg': 23.322946175637394, 'std': 6.892781488327347, 'run': 22.622432491139048, 'test_avg': 21.4912109375, 'test_std': 1.928892396527181}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1601 / 10001):
    Value Loss: {'avg': 79.6650726000468, 'std': 5.701794562530164}
    Value Grad Norm: {'avg': 762.7873557408651, 'std': 341.1672436915383}
    Policy Loss: {'avg': -0.0021389755129348487, 'std': 0.00931389919876633}
    Total_Loss: {'avg': -0.14667068514972925, 'std': 0.007895709035550334}
    Policy Entropy: {'avg': 1.486166000366211, 'std': 0.47865232825279236}
    KL Divergence: {'avg': 0.02133363112807274, 'std': 0.21058183908462524}
    Policy Grad Norm: {'avg': 2.2954977676272392, 'std': 0.6910939667833649}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -87.28962702075202, 'std': 28.599933811676024, 'run': -86.72309553660634, 'test_avg': -82.75031782695925, 'test_std': 8.014678120791416}
    Episode Length: {'avg': 22.73756906077348, 'std': 6.214416730957467, 'run': 22.61006675613861, 'test_avg': 21.5283203125, 'test_std': 1.7503288505020713}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1701 / 10001):
    Value Loss: {'avg': 68.39059281349182, 'std': 4.618605861098546}
    Value Grad Norm: {'avg': 928.0717436472574, 'std': 514.3575591669929}
    Policy Loss: {'avg': -0.000718731782399118, 'std': 0.009637796045747802}
    Total_Loss: {'avg': -0.13674105890095234, 'std': 0.010125548106408994}
    Policy Entropy: {'avg': 1.316449761390686, 'std': 0.5201849937438965}
    KL Divergence: {'avg': 0.015752937644720078, 'std': 0.16863687336444855}
    Policy Grad Norm: {'avg': 2.254559811204672, 'std': 0.783993511196465}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -86.44997246054797, 'std': 26.69943539733737, 'run': -84.93274600631473, 'test_avg': -81.08608087904054, 'test_std': 7.819057327806032}
    Episode Length: {'avg': 22.580381471389646, 'std': 5.8513322609279825, 'run': 22.231918067621617, 'test_avg': 21.2353515625, 'test_std': 1.7122833671821989}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1801 / 10001):
    Value Loss: {'avg': 69.6918957233429, 'std': 5.244001033617334}
    Value Grad Norm: {'avg': 761.0094788869222, 'std': 404.2299280236249}
    Policy Loss: {'avg': -0.0006589528202312067, 'std': 0.009670155894771134}
    Total_Loss: {'avg': -0.1415964961051941, 'std': 0.010002419191567219}
    Policy Entropy: {'avg': 1.4538300037384033, 'std': 0.5057240724563599}
    KL Divergence: {'avg': 0.01852286234498024, 'std': 0.18037532269954681}
    Policy Grad Norm: {'avg': 2.4774396177381277, 'std': 1.1077465658526506}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -86.12569521551038, 'std': 28.62223456291734, 'run': -84.99634144811823, 'test_avg': -81.15545783259986, 'test_std': 8.014513616809493}
    Episode Length: {'avg': 22.637393767705383, 'std': 6.314152098286919, 'run': 22.41364556138291, 'test_avg': 21.275390625, 'test_std': 1.7843558021488062}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (1901 / 10001):
    Value Loss: {'avg': 69.42511709531148, 'std': 5.645481256998706}
    Value Grad Norm: {'avg': 830.6941897074381, 'std': 381.61091474117455}
    Policy Loss: {'avg': 0.0067808655148837715, 'std': 0.005003255539571431}
    Total_Loss: {'avg': -0.13002998987212777, 'std': 0.005468508385162137}
    Policy Entropy: {'avg': 1.3450493812561035, 'std': 0.48969200253486633}
    KL Divergence: {'avg': 0.01944301463663578, 'std': 0.19290247559547424}
    Policy Grad Norm: {'avg': 2.8080970719456673, 'std': 1.114501157782154}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.22394157312843, 'std': 26.062605154507278, 'run': -82.24961629938991, 'test_avg': -80.60001837184424, 'test_std': 7.78332013360719}
    Episode Length: {'avg': 22.116531165311653, 'std': 5.698853866582311, 'run': 21.67998448827613, 'test_avg': 21.1484375, 'test_std': 1.7222797561934444}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2001 / 10001):
    Value Loss: {'avg': 86.19298140207927, 'std': 6.96066738206512}
    Value Grad Norm: {'avg': 1063.5842564900715, 'std': 489.2091152874331}
    Policy Loss: {'avg': -0.0054676649160683155, 'std': 0.009469830741809555}
    Total_Loss: {'avg': -0.14908675383776426, 'std': 0.009914764461198664}
    Policy Entropy: {'avg': 1.4635252952575684, 'std': 0.4793945848941803}
    KL Divergence: {'avg': 0.018979893997311592, 'std': 0.18329080939292908}
    Policy Grad Norm: {'avg': 2.2427005618810654, 'std': 1.1274803196728083}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -86.56262154181758, 'std': 28.680873794480867, 'run': -85.76777301939732, 'test_avg': -80.99789699488406, 'test_std': 8.015155439043621}
    Episode Length: {'avg': 22.66846361185984, 'std': 6.330566124039163, 'run': 22.47204568056194, 'test_avg': 21.232421875, 'test_std': 1.776221958827636}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2101 / 10001):
    Value Loss: {'avg': 56.558551708857216, 'std': 5.527021450876369}
    Value Grad Norm: {'avg': 567.1568864186605, 'std': 262.81125083677927}
    Policy Loss: {'avg': 0.007919959491118789, 'std': 0.008599896914618719}
    Total_Loss: {'avg': -0.12151256669312716, 'std': 0.0064482170959389495}
    Policy Entropy: {'avg': 1.3554348945617676, 'std': 0.48527076840400696}
    KL Divergence: {'avg': 0.018699347972869873, 'std': 0.1774141490459442}
    Policy Grad Norm: {'avg': 2.924559563398361, 'std': 0.9197205172454227}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.80603327941111, 'std': 24.262502788206536, 'run': -83.09838590659868, 'test_avg': -80.3278571953312, 'test_std': 7.537257581825046}
    Episode Length: {'avg': 22.138381201044385, 'std': 5.382416444216087, 'run': 21.750648289692325, 'test_avg': 21.0263671875, 'test_std': 1.651907067278102}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2201 / 10001):
    Value Loss: {'avg': 64.0178644657135, 'std': 5.628413031727683}
    Value Grad Norm: {'avg': 930.8229354222616, 'std': 423.5781580066976}
    Policy Loss: {'avg': 0.0016503292717970908, 'std': 0.003849849609583969}
    Total_Loss: {'avg': -0.12721498822793365, 'std': 0.004074946380949979}
    Policy Entropy: {'avg': 1.2606534957885742, 'std': 0.5284087061882019}
    KL Divergence: {'avg': 0.015679514035582542, 'std': 0.17225518822669983}
    Policy Grad Norm: {'avg': 2.6598053127527237, 'std': 1.0397220187321643}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -83.57021926128252, 'std': 27.78018453196524, 'run': -83.26341263107456, 'test_avg': -79.83718530150713, 'test_std': 7.746740568222851}
    Episode Length: {'avg': 21.91374663072776, 'std': 6.122126344354164, 'run': 21.817762806811682, 'test_avg': 20.96875, 'test_std': 1.7107769616463744}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2301 / 10001):
    Value Loss: {'avg': 67.06309405962627, 'std': 6.643878764879333}
    Value Grad Norm: {'avg': 795.6537504196167, 'std': 363.921672787257}
    Policy Loss: {'avg': 0.005776193807832897, 'std': 0.005323908824451715}
    Total_Loss: {'avg': -0.1223309226334095, 'std': 0.00586443425999734}
    Policy Entropy: {'avg': 1.2668182849884033, 'std': 0.5174940824508667}
    KL Divergence: {'avg': 0.022062741219997406, 'std': 0.18091708421707153}
    Policy Grad Norm: {'avg': 2.8379936143755913, 'std': 1.9553763839584926}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -83.36185045153313, 'std': 27.2747035316243, 'run': -85.53266520291358, 'test_avg': -80.20083658943085, 'test_std': 7.926118011137253}
    Episode Length: {'avg': 21.87037037037037, 'std': 6.079423215677007, 'run': 22.332243036435976, 'test_avg': 21.025390625, 'test_std': 1.7397410917036218}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2401 / 10001):
    Value Loss: {'avg': 60.34795022010803, 'std': 4.9510935814574575}
    Value Grad Norm: {'avg': 903.1737750371298, 'std': 506.74942516214884}
    Policy Loss: {'avg': 0.0035761227773036808, 'std': 0.008674599814853575}
    Total_Loss: {'avg': -0.12543087964877486, 'std': 0.008597694181635116}
    Policy Entropy: {'avg': 1.2930984497070312, 'std': 0.4792384207248688}
    KL Divergence: {'avg': 0.016557183116674423, 'std': 0.18073883652687073}
    Policy Grad Norm: {'avg': 2.710066184401512, 'std': 1.2515042730524546}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.5091319028685, 'std': 24.001095752681664, 'run': -85.01972690039514, 'test_avg': -79.61447301250143, 'test_std': 7.994703379731092}
    Episode Length: {'avg': 22.137466307277627, 'std': 5.274152304322302, 'run': 22.329492754607216, 'test_avg': 20.9326171875, 'test_std': 1.7495397234928933}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2501 / 10001):
    Value Loss: {'avg': 68.2198080221812, 'std': 7.073291961309048}
    Value Grad Norm: {'avg': 815.7699890136719, 'std': 425.48373241246003}
    Policy Loss: {'avg': 0.006387581233866513, 'std': 0.007172927555564896}
    Total_Loss: {'avg': -0.12928558606654406, 'std': 0.00622944514937857}
    Policy Entropy: {'avg': 1.3731637001037598, 'std': 0.4918056130409241}
    KL Divergence: {'avg': 0.01666240766644478, 'std': 0.18916240334510803}
    Policy Grad Norm: {'avg': 2.877896763384342, 'std': 1.4604918530587225}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -85.66785606579647, 'std': 24.83398437381412, 'run': -86.84189901137576, 'test_avg': -79.56014485764453, 'test_std': 7.217037234795771}
    Episode Length: {'avg': 22.44077134986226, 'std': 5.4508766914410085, 'run': 22.680804664599926, 'test_avg': 20.8837890625, 'test_std': 1.57096795973227}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2601 / 10001):
    Value Loss: {'avg': 62.35629423459371, 'std': 6.059488112916218}
    Value Grad Norm: {'avg': 1031.242825826009, 'std': 602.9722161147977}
    Policy Loss: {'avg': -0.0013157702633179724, 'std': 0.006317955055166828}
    Total_Loss: {'avg': -0.13560715899802744, 'std': 0.007358858525681947}
    Policy Entropy: {'avg': 1.3134602308273315, 'std': 0.4765594005584717}
    KL Divergence: {'avg': 0.018130658194422722, 'std': 0.21075068414211273}
    Policy Grad Norm: {'avg': 2.847696006298065, 'std': 1.0546151250705587}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -84.07151233347507, 'std': 25.283281057672223, 'run': -82.27705619612316, 'test_avg': -79.49800540105511, 'test_std': 7.6178365130972825}
    Episode Length: {'avg': 22.046070460704605, 'std': 5.5962184294827555, 'run': 21.646542134153695, 'test_avg': 20.9326171875, 'test_std': 1.6899145301107952}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2701 / 10001):
    Value Loss: {'avg': 63.09491777420044, 'std': 4.894073242531301}
    Value Grad Norm: {'avg': 797.737398147583, 'std': 416.3503248523997}
    Policy Loss: {'avg': 0.00461333230487071, 'std': 0.004472134150080353}
    Total_Loss: {'avg': -0.1293575605377555, 'std': 0.0039170380006565255}
    Policy Entropy: {'avg': 1.3494532108306885, 'std': 0.5022545456886292}
    KL Divergence: {'avg': 0.02404705062508583, 'std': 0.2096739560365677}
    Policy Grad Norm: {'avg': 2.696620598435402, 'std': 0.8821817015173464}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -84.14409185469766, 'std': 26.22873955149654, 'run': -84.64364044577114, 'test_avg': -79.05606662693708, 'test_std': 7.558234869587169}
    Episode Length: {'avg': 22.018567639257295, 'std': 5.759750129629736, 'run': 22.124043684772193, 'test_avg': 20.771484375, 'test_std': 1.6519777871178714}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2801 / 10001):
    Value Loss: {'avg': 58.71293123563131, 'std': 5.0664052076761905}
    Value Grad Norm: {'avg': 588.27086353302, 'std': 332.26407456658376}
    Policy Loss: {'avg': 0.003272184025263414, 'std': 0.004633870402191581}
    Total_Loss: {'avg': -0.12215731618925929, 'std': 0.005087238709309402}
    Policy Entropy: {'avg': 1.2979907989501953, 'std': 0.5099292397499084}
    KL Divergence: {'avg': 0.017499012872576714, 'std': 0.173114612698555}
    Policy Grad Norm: {'avg': 3.294971242547035, 'std': 1.5788604234813097}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -81.63684635710578, 'std': 25.136692950714732, 'run': -81.81737156165305, 'test_avg': -78.60679560541706, 'test_std': 7.625644122076779}
    Episode Length: {'avg': 21.515706806282722, 'std': 5.531775360275446, 'run': 21.553447762294805, 'test_avg': 20.7021484375, 'test_std': 1.6683389221666887}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (2901 / 10001):
    Value Loss: {'avg': 54.876943508783974, 'std': 6.062414137136183}
    Value Grad Norm: {'avg': 754.6074911753336, 'std': 410.5257293810871}
    Policy Loss: {'avg': -0.0023255979758687317, 'std': 0.008585721359540626}
    Total_Loss: {'avg': -0.13439035904593766, 'std': 0.00895824158187801}
    Policy Entropy: {'avg': 1.3727898597717285, 'std': 0.480783075094223}
    KL Divergence: {'avg': 0.01913977600634098, 'std': 0.18958210945129395}
    Policy Grad Norm: {'avg': 2.8937256447970867, 'std': 1.3626574883035372}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -82.58529862509201, 'std': 26.88694416129897, 'run': -84.75855274582786, 'test_avg': -78.64769334225707, 'test_std': 7.802163738770055}
    Episode Length: {'avg': 21.78342245989305, 'std': 5.919571729714817, 'run': 22.250890661056598, 'test_avg': 20.76953125, 'test_std': 1.7341946344840988}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3001 / 10001):
    Value Loss: {'avg': 63.38497519493103, 'std': 4.7777480866329505}
    Value Grad Norm: {'avg': 717.5189463297526, 'std': 327.2413481225733}
    Policy Loss: {'avg': -0.0021424642618512735, 'std': 0.008448466550034185}
    Total_Loss: {'avg': -0.14241909934207797, 'std': 0.00920555364964021}
    Policy Entropy: {'avg': 1.380023717880249, 'std': 0.5004969239234924}
    KL Divergence: {'avg': 0.01904897764325142, 'std': 0.19406111538410187}
    Policy Grad Norm: {'avg': 2.490677073597908, 'std': 1.24408425179473}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -83.22734911688731, 'std': 28.512619844505437, 'run': -85.52417944647576, 'test_avg': -78.87538265184034, 'test_std': 8.046661325101605}
    Episode Length: {'avg': 21.80965147453083, 'std': 6.2866054583950115, 'run': 22.36154344672352, 'test_avg': 20.8037109375, 'test_std': 1.7808513529890335}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3101 / 10001):
    Value Loss: {'avg': 43.730704387029014, 'std': 4.29477755084384}
    Value Grad Norm: {'avg': 514.5983400344849, 'std': 212.19139189908043}
    Policy Loss: {'avg': 0.0027656449237838387, 'std': 0.004108915551806882}
    Total_Loss: {'avg': -0.11402646685019135, 'std': 0.0038333949997058484}
    Policy Entropy: {'avg': 1.2085685729980469, 'std': 0.5135329365730286}
    KL Divergence: {'avg': 0.021513324230909348, 'std': 0.1987813413143158}
    Policy Grad Norm: {'avg': 2.183357670903206, 'std': 0.4793038907005088}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.64606296570469, 'std': 26.025244838652885, 'run': -73.88193745394048, 'test_avg': -78.37844101332047, 'test_std': 7.309970657571085}
    Episode Length: {'avg': 20.556962025316455, 'std': 5.684860719808464, 'run': 19.72786708028766, 'test_avg': 20.6240234375, 'test_std': 1.603904240268316}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3201 / 10001):
    Value Loss: {'avg': 45.37033327420553, 'std': 5.370955619159875}
    Value Grad Norm: {'avg': 649.0233062108358, 'std': 267.5521966520652}
    Policy Loss: {'avg': 0.006626615766435862, 'std': 0.006107464125035746}
    Total_Loss: {'avg': -0.11446453491225839, 'std': 0.005882528898459296}
    Policy Entropy: {'avg': 1.225886344909668, 'std': 0.5046890377998352}
    KL Divergence: {'avg': 0.0211089625954628, 'std': 0.20040185749530792}
    Policy Grad Norm: {'avg': 2.6693627163767815, 'std': 0.6065156019590767}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.5673898486578, 'std': 24.891628763169283, 'run': -80.94064786941769, 'test_avg': -78.11581017272007, 'test_std': 8.046349519533294}
    Episode Length: {'avg': 21.033678756476682, 'std': 5.4626765100341865, 'run': 21.313828627753935, 'test_avg': 20.6494140625, 'test_std': 1.6976372736622056}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3301 / 10001):
    Value Loss: {'avg': 53.36324214935303, 'std': 4.022254455808663}
    Value Grad Norm: {'avg': 574.1652692159017, 'std': 236.41135751328994}
    Policy Loss: {'avg': 0.004233640822349116, 'std': 0.004731831480033232}
    Total_Loss: {'avg': -0.121789684984833, 'std': 0.006677829972205107}
    Policy Entropy: {'avg': 1.2449674606323242, 'std': 0.5213915705680847}
    KL Divergence: {'avg': 0.021890491247177124, 'std': 0.21319696307182312}
    Policy Grad Norm: {'avg': 2.59214748442173, 'std': 0.794848374933958}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -81.48574226361333, 'std': 25.39317614706467, 'run': -83.48561156051359, 'test_avg': -78.18499846745556, 'test_std': 7.54324536991426}
    Episode Length: {'avg': 21.410666666666668, 'std': 5.584444426758632, 'run': 21.897474795258933, 'test_avg': 20.681640625, 'test_std': 1.7008197827370215}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3401 / 10001):
    Value Loss: {'avg': 46.96433973312378, 'std': 3.848499800585037}
    Value Grad Norm: {'avg': 540.7421906789144, 'std': 271.03732137701866}
    Policy Loss: {'avg': 0.0014381235523615032, 'std': 0.004685822982971295}
    Total_Loss: {'avg': -0.11924371588975191, 'std': 0.005018013640917554}
    Policy Entropy: {'avg': 1.2542176246643066, 'std': 0.5098012685775757}
    KL Divergence: {'avg': 0.020400503650307655, 'std': 0.17995665967464447}
    Policy Grad Norm: {'avg': 2.4120621979236603, 'std': 0.7038464765778795}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.5002373220583, 'std': 25.7200485361249, 'run': -79.05492494770428, 'test_avg': -77.9517683453285, 'test_std': 7.086995961588112}
    Episode Length: {'avg': 20.948586118251928, 'std': 5.6169436388088645, 'run': 20.86658249691435, 'test_avg': 20.533203125, 'test_std': 1.5407457780212264}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3501 / 10001):
    Value Loss: {'avg': 55.987964471181236, 'std': 5.058958867467761}
    Value Grad Norm: {'avg': 832.196310043335, 'std': 420.74012529257595}
    Policy Loss: {'avg': -0.004491873405640945, 'std': 0.007148595784975256}
    Total_Loss: {'avg': -0.12734522856771946, 'std': 0.008341341990133772}
    Policy Entropy: {'avg': 1.229931116104126, 'std': 0.5290381908416748}
    KL Divergence: {'avg': 0.015145636163651943, 'std': 0.17760248482227325}
    Policy Grad Norm: {'avg': 2.909873351454735, 'std': 1.063439800337931}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -79.85396638318065, 'std': 27.817128201504243, 'run': -81.72289147059315, 'test_avg': -78.04720959279985, 'test_std': 7.910791003957005}
    Episode Length: {'avg': 21.091836734693878, 'std': 6.103840769270587, 'run': 21.49619321624911, 'test_avg': 20.6416015625, 'test_std': 1.7476177349459345}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3601 / 10001):
    Value Loss: {'avg': 43.60971641540527, 'std': 3.6559693193545906}
    Value Grad Norm: {'avg': 602.528244972229, 'std': 276.08220879774274}
    Policy Loss: {'avg': -0.002043027285253629, 'std': 0.010055793129758298}
    Total_Loss: {'avg': -0.12014636513777077, 'std': 0.010549972989076868}
    Policy Entropy: {'avg': 1.1944595575332642, 'std': 0.5119794607162476}
    KL Divergence: {'avg': 0.017123093828558922, 'std': 0.15814492106437683}
    Policy Grad Norm: {'avg': 2.780603565275669, 'std': 0.8240989461841565}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -80.17503511473055, 'std': 24.09648487060313, 'run': -80.23211061575465, 'test_avg': -78.66072417993848, 'test_std': 10.688788747908605}
    Episode Length: {'avg': 21.189873417721518, 'std': 5.328395273110711, 'run': 21.1997740199328, 'test_avg': 20.7412109375, 'test_std': 2.1933895934444414}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (3701 / 10001):
    Value Loss: {'avg': 41.881577253341675, 'std': 3.921614726078688}
    Value Grad Norm: {'avg': 517.1081581115723, 'std': 240.71652863742983}
    Policy Loss: {'avg': 0.000466743964352645, 'std': 0.009861739249625578}
    Total_Loss: {'avg': -0.11842586356215179, 'std': 0.00920585946875493}
    Policy Entropy: {'avg': 1.2000162601470947, 'std': 0.5413578748703003}
    KL Divergence: {'avg': 0.01662546396255493, 'std': 0.19341424107551575}
    Policy Grad Norm: {'avg': 2.8341500274837017, 'std': 1.3568930303996736}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -77.96488167880187, 'std': 25.419691831713532, 'run': -78.03666760501024, 'test_avg': -77.11996344440786, 'test_std': 7.209072560763437}
    Episode Length: {'avg': 20.678048780487806, 'std': 5.557570630652717, 'run': 20.699269113737962, 'test_avg': 20.4248046875, 'test_std': 1.5781126116275819}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (3801 / 10001):
    Value Loss: {'avg': 40.157043854395546, 'std': 3.21378598482716}
    Value Grad Norm: {'avg': 394.2624273300171, 'std': 159.67600512205672}
    Policy Loss: {'avg': 0.0036073753726668656, 'std': 0.0040572310037637945}
    Total_Loss: {'avg': -0.11394756799563766, 'std': 0.006023438335415479}
    Policy Entropy: {'avg': 1.2202715873718262, 'std': 0.5118916630744934}
    KL Divergence: {'avg': 0.02065330743789673, 'std': 0.19608601927757263}
    Policy Grad Norm: {'avg': 2.1519276201725006, 'std': 0.4101573046038244}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.81478469979021, 'std': 24.52774272979815, 'run': -80.6624945418217, 'test_avg': -77.17307183724361, 'test_std': 7.502958722025595}
    Episode Length: {'avg': 21.0671834625323, 'std': 5.364312457292931, 'run': 21.243287544972443, 'test_avg': 20.361328125, 'test_std': 1.626894506747129}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (3901 / 10001):
    Value Loss: {'avg': 49.53648932774862, 'std': 5.724881718094425}
    Value Grad Norm: {'avg': 626.2942047119141, 'std': 281.38844539602974}
    Policy Loss: {'avg': -0.002475615168805234, 'std': 0.009988343467839424}
    Total_Loss: {'avg': -0.125282027060166, 'std': 0.009954438982631698}
    Policy Entropy: {'avg': 1.3062257766723633, 'std': 0.5146737098693848}
    KL Divergence: {'avg': 0.015492424368858337, 'std': 0.173442542552948}
    Policy Grad Norm: {'avg': 3.1043791510164738, 'std': 2.4491163575130863}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -80.39582680219131, 'std': 26.021777286101507, 'run': -80.02357071624441, 'test_avg': -77.3429138007213, 'test_std': 9.520934806164826}
    Episode Length: {'avg': 21.289817232375977, 'std': 5.798809251858691, 'run': 21.20496233118295, 'test_avg': 20.513671875, 'test_std': 1.9926154181963927}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (4001 / 10001):
    Value Loss: {'avg': 45.56658069292704, 'std': 4.20560735185097}
    Value Grad Norm: {'avg': 646.5212640762329, 'std': 354.7126355761959}
    Policy Loss: {'avg': 0.0027590961544774473, 'std': 0.006036073698114322}
    Total_Loss: {'avg': -0.11597565282136202, 'std': 0.005004808432659448}
    Policy Entropy: {'avg': 1.1159882545471191, 'std': 0.5072548389434814}
    KL Divergence: {'avg': 0.02439575269818306, 'std': 0.2283330112695694}
    Policy Grad Norm: {'avg': 4.00934362411499, 'std': 1.7395669426435083}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.95353065103501, 'std': 25.243750189766555, 'run': -79.0520376661664, 'test_avg': -77.12187939218103, 'test_std': 7.191253663440069}
    Episode Length: {'avg': 21.106598984771573, 'std': 5.579040463557252, 'run': 20.88913625562935, 'test_avg': 20.4609375, 'test_std': 1.5996940320241713}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4101 / 10001):
    Value Loss: {'avg': 41.99593138694763, 'std': 4.101398654036956}
    Value Grad Norm: {'avg': 664.4777517318726, 'std': 342.9957596326642}
    Policy Loss: {'avg': 0.0006789323379052803, 'std': 0.0035223274947550082}
    Total_Loss: {'avg': -0.11400842294096947, 'std': 0.00417854028772765}
    Policy Entropy: {'avg': 1.190687894821167, 'std': 0.5624493956565857}
    KL Divergence: {'avg': 0.015735846012830734, 'std': 0.16686882078647614}
    Policy Grad Norm: {'avg': 3.3885456398129463, 'std': 1.4152057253455461}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.14756912683734, 'std': 25.25630752681859, 'run': -78.16970598180662, 'test_avg': -77.41157774515128, 'test_std': 7.013841350016014}
    Episode Length: {'avg': 20.83291770573566, 'std': 5.47308205199238, 'run': 20.64109048179986, 'test_avg': 20.4208984375, 'test_std': 1.5250489148909483}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4201 / 10001):
    Value Loss: {'avg': 38.730280001958214, 'std': 4.3169930573504045}
    Value Grad Norm: {'avg': 535.2134176890055, 'std': 334.55000008755655}
    Policy Loss: {'avg': 0.008599467546446249, 'std': 0.006695979478982913}
    Total_Loss: {'avg': -0.10689722094684839, 'std': 0.005889127345327337}
    Policy Entropy: {'avg': 1.1164530515670776, 'std': 0.5194509625434875}
    KL Divergence: {'avg': 0.03193299099802971, 'std': 0.2342613935470581}
    Policy Grad Norm: {'avg': 2.489684537053108, 'std': 0.7522062522343036}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.26768624546966, 'std': 21.472267246468434, 'run': -79.92097441664515, 'test_avg': -77.35620436538122, 'test_std': 7.606115853128201}
    Episode Length: {'avg': 20.864935064935064, 'std': 4.669596779882877, 'run': 21.032193133878074, 'test_avg': 20.509765625, 'test_std': 1.6641622164225336}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4301 / 10001):
    Value Loss: {'avg': 45.54561630884806, 'std': 4.076633194206911}
    Value Grad Norm: {'avg': 605.4029569625854, 'std': 222.5627252822569}
    Policy Loss: {'avg': -0.0011642636090982705, 'std': 0.008905302414911017}
    Total_Loss: {'avg': -0.1252807832788676, 'std': 0.009078533669101703}
    Policy Entropy: {'avg': 1.2911725044250488, 'std': 0.5305769443511963}
    KL Divergence: {'avg': 0.020696621388196945, 'std': 0.18688693642616272}
    Policy Grad Norm: {'avg': 2.8294440917670727, 'std': 1.5263644272149826}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -78.29655547740397, 'std': 27.49624302335172, 'run': -78.93030913991322, 'test_avg': -77.24014022617058, 'test_std': 7.2085847290221965}
    Episode Length: {'avg': 20.681818181818183, 'std': 6.043593546627795, 'run': 20.798430036568817, 'test_avg': 20.443359375, 'test_std': 1.5924366045779057}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4401 / 10001):
    Value Loss: {'avg': 42.40048933029175, 'std': 4.119090148258557}
    Value Grad Norm: {'avg': 460.9358050028483, 'std': 182.3806044574027}
    Policy Loss: {'avg': 0.0056500553619116545, 'std': 0.005343375123985601}
    Total_Loss: {'avg': -0.11210121447220445, 'std': 0.006628411315471118}
    Policy Entropy: {'avg': 1.1348021030426025, 'std': 0.5362842679023743}
    KL Divergence: {'avg': 0.01823827065527439, 'std': 0.17312389612197876}
    Policy Grad Norm: {'avg': 2.6592221707105637, 'std': 0.8483219263351232}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -78.02377263710048, 'std': 26.61972236689114, 'run': -78.30611681853173, 'test_avg': -76.7941434831631, 'test_std': 7.154783111035543}
    Episode Length: {'avg': 20.5725, 'std': 5.796528594771185, 'run': 20.627630935345742, 'test_avg': 20.3544921875, 'test_std': 1.5638492099628611}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4501 / 10001):
    Value Loss: {'avg': 38.75771097342173, 'std': 3.1258626871217263}
    Value Grad Norm: {'avg': 402.40654309590656, 'std': 181.5127846773911}
    Policy Loss: {'avg': 0.004759519710205495, 'std': 0.006858986283833599}
    Total_Loss: {'avg': -0.11824563657864928, 'std': 0.006591247177598503}
    Policy Entropy: {'avg': 1.2671951055526733, 'std': 0.534108579158783}
    KL Divergence: {'avg': 0.024275438860058784, 'std': 0.19712784886360168}
    Policy Grad Norm: {'avg': 2.412989266216755, 'std': 0.9377433074316174}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.15150774167483, 'std': 26.80667738872887, 'run': -75.92050553883652, 'test_avg': -77.15542747700444, 'test_std': 8.6284528884935}
    Episode Length: {'avg': 20.54901960784314, 'std': 5.880972060141466, 'run': 20.230190086578652, 'test_avg': 20.3994140625, 'test_std': 1.8199307937878424}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (4601 / 10001):
    Value Loss: {'avg': 45.895456314086914, 'std': 4.630648879545374}
    Value Grad Norm: {'avg': 458.3180799484253, 'std': 158.1909734296847}
    Policy Loss: {'avg': 0.004286062467144802, 'std': 0.00709608543210335}
    Total_Loss: {'avg': -0.12104355776682496, 'std': 0.006689657929742775}
    Policy Entropy: {'avg': 1.2642160654067993, 'std': 0.495650053024292}
    KL Divergence: {'avg': 0.017521027475595474, 'std': 0.17031972110271454}
    Policy Grad Norm: {'avg': 2.4598912745714188, 'std': 0.9102714388762531}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -82.35415109223167, 'std': 22.02366602224419, 'run': -82.61832393921509, 'test_avg': -77.11280595837243, 'test_std': 6.9240783530260535}
    Episode Length: {'avg': 21.62532981530343, 'std': 4.884631229959886, 'run': 21.66201561529562, 'test_avg': 20.3720703125, 'test_std': 1.4977982574619828}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4701 / 10001):
    Value Loss: {'avg': 35.429970463116966, 'std': 3.778725766304214}
    Value Grad Norm: {'avg': 494.64294179280597, 'std': 259.0968719329237}
    Policy Loss: {'avg': 0.002534967294195667, 'std': 0.005489820603476127}
    Total_Loss: {'avg': -0.11254134681075811, 'std': 0.004504780289728214}
    Policy Entropy: {'avg': 1.1591756343841553, 'std': 0.5285623669624329}
    KL Divergence: {'avg': 0.027344003319740295, 'std': 0.21066492795944214}
    Policy Grad Norm: {'avg': 3.317591093480587, 'std': 1.9855410494570438}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.84230154697336, 'std': 24.235227087594627, 'run': -78.00290732577645, 'test_avg': -76.59038432334631, 'test_std': 8.271882317530443}
    Episode Length: {'avg': 20.391414141414142, 'std': 5.313488365119911, 'run': 20.646052374424368, 'test_avg': 20.27734375, 'test_std': 1.7284483126017791}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (4801 / 10001):
    Value Loss: {'avg': 50.74107964833578, 'std': 4.20176876339575}
    Value Grad Norm: {'avg': 627.9863074620565, 'std': 333.31703618614176}
    Policy Loss: {'avg': 0.0008345599635504186, 'std': 0.001839147519749251}
    Total_Loss: {'avg': -0.12293985346332192, 'std': 0.003072880279073063}
    Policy Entropy: {'avg': 1.1738989353179932, 'std': 0.5221656560897827}
    KL Divergence: {'avg': 0.017282908782362938, 'std': 0.1802089512348175}
    Policy Grad Norm: {'avg': 2.474838227033615, 'std': 0.553579121207377}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -79.17384901178892, 'std': 25.24639036064858, 'run': -78.93765962415351, 'test_avg': -77.24955446135391, 'test_std': 7.206746930862232}
    Episode Length: {'avg': 20.861460957178842, 'std': 5.51329520904492, 'run': 20.796480858546968, 'test_avg': 20.4677734375, 'test_std': 1.5863604803667524}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (4901 / 10001):
    Value Loss: {'avg': 43.20736034711202, 'std': 7.7991907217355045}
    Value Grad Norm: {'avg': 477.96743965148926, 'std': 185.21832438445068}
    Policy Loss: {'avg': 0.007327130879275501, 'std': 0.008675177475784753}
    Total_Loss: {'avg': -0.0983429392799735, 'std': 0.008136769548746965}
    Policy Entropy: {'avg': 1.1280885934829712, 'std': 0.5241440534591675}
    KL Divergence: {'avg': 0.03567509725689888, 'std': 0.23772235214710236}
    Policy Grad Norm: {'avg': 2.382197380065918, 'std': 1.26467554854633}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.05372413922147, 'std': 23.95910081536551, 'run': -75.65898080091985, 'test_avg': -76.24170473604524, 'test_std': 8.978383651803577}
    Episode Length: {'avg': 19.978155339805824, 'std': 5.291228177498583, 'run': 20.133369695077494, 'test_avg': 20.2099609375, 'test_std': 1.8360161947063869}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (5001 / 10001):
    Value Loss: {'avg': 50.52958130836487, 'std': 5.330076348131042}
    Value Grad Norm: {'avg': 753.051487604777, 'std': 343.90253306798104}
    Policy Loss: {'avg': -0.0032402722572442144, 'std': 0.008824949337881673}
    Total_Loss: {'avg': -0.12853908445686102, 'std': 0.009676822815420582}
    Policy Entropy: {'avg': 1.247002124786377, 'std': 0.5044880509376526}
    KL Divergence: {'avg': 0.015773586928844452, 'std': 0.17300572991371155}
    Policy Grad Norm: {'avg': 3.0857503041625023, 'std': 1.5600342742830784}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -78.8408036866129, 'std': 26.25586346432191, 'run': -78.0797252195393, 'test_avg': -76.59755007593638, 'test_std': 7.907466015763482}
    Episode Length: {'avg': 20.806701030927837, 'std': 5.767064007025842, 'run': 20.66322607867822, 'test_avg': 20.255859375, 'test_std': 1.662712875160534}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5101 / 10001):
    Value Loss: {'avg': 40.015711625417076, 'std': 3.467895081066953}
    Value Grad Norm: {'avg': 468.3267895380656, 'std': 220.32094956118422}
    Policy Loss: {'avg': 0.00574236802640371, 'std': 0.007604556889516418}
    Total_Loss: {'avg': -0.1115807881578803, 'std': 0.008668857633489426}
    Policy Entropy: {'avg': 1.2163095474243164, 'std': 0.5539438724517822}
    KL Divergence: {'avg': 0.018069084733724594, 'std': 0.17635861039161682}
    Policy Grad Norm: {'avg': 2.635483533143997, 'std': 0.9211222722301577}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.43956136553334, 'std': 25.40779367574957, 'run': -76.32854586539663, 'test_avg': -76.4547706460638, 'test_std': 7.78149820030502}
    Episode Length: {'avg': 20.305084745762713, 'std': 5.491697303979202, 'run': 20.275740561738377, 'test_avg': 20.28515625, 'test_std': 1.6940654615704605}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5201 / 10001):
    Value Loss: {'avg': 39.974823792775474, 'std': 4.772289548497456}
    Value Grad Norm: {'avg': 410.6440073649089, 'std': 152.52980777607164}
    Policy Loss: {'avg': -0.0054161362058948725, 'std': 0.008153373358030926}
    Total_Loss: {'avg': -0.12137211230583489, 'std': 0.009482429577961823}
    Policy Entropy: {'avg': 1.1412029266357422, 'std': 0.5441660284996033}
    KL Divergence: {'avg': 0.023799898102879524, 'std': 0.19343724846839905}
    Policy Grad Norm: {'avg': 2.520726013928652, 'std': 0.9090951899073865}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -77.29503392989227, 'std': 24.74253008307548, 'run': -77.99434024564438, 'test_avg': -76.5248649542438, 'test_std': 7.402493234291443}
    Episode Length: {'avg': 20.44221105527638, 'std': 5.465324877421028, 'run': 20.609780220435894, 'test_avg': 20.263671875, 'test_std': 1.604074582846441}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5301 / 10001):
    Value Loss: {'avg': 34.68529466787974, 'std': 3.9485828745670544}
    Value Grad Norm: {'avg': 396.3453776041667, 'std': 177.13938932334804}
    Policy Loss: {'avg': 0.004164786165347323, 'std': 0.004623136814178665}
    Total_Loss: {'avg': -0.10860408050939441, 'std': 0.004858383791018056}
    Policy Entropy: {'avg': 1.1319557428359985, 'std': 0.5256375074386597}
    KL Divergence: {'avg': 0.019076723605394363, 'std': 0.1755029261112213}
    Policy Grad Norm: {'avg': 2.081023618578911, 'std': 0.5119557159722311}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.63937249195257, 'std': 26.790331627011206, 'run': -74.51658988211426, 'test_avg': -77.51372783554535, 'test_std': 10.250116582743592}
    Episode Length: {'avg': 19.913875598086126, 'std': 5.858151708437536, 'run': 19.920102180550536, 'test_avg': 20.529296875, 'test_std': 2.0736255551847433}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (5401 / 10001):
    Value Loss: {'avg': 36.5120937426885, 'std': 2.8484939316047355}
    Value Grad Norm: {'avg': 483.5067071914673, 'std': 219.21138580775576}
    Policy Loss: {'avg': -0.0009088511869776994, 'std': 0.006665651820850961}
    Total_Loss: {'avg': -0.11586731811985373, 'std': 0.008338860187552121}
    Policy Entropy: {'avg': 1.173468828201294, 'std': 0.5312859416007996}
    KL Divergence: {'avg': 0.026512455195188522, 'std': 0.19317439198493958}
    Policy Grad Norm: {'avg': 2.715604957193136, 'std': 1.0683901478785576}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -77.12239819811876, 'std': 23.570161960344297, 'run': -75.83797032367374, 'test_avg': -76.71888289699422, 'test_std': 7.550473719846265}
    Episode Length: {'avg': 20.41147132169576, 'std': 5.172608469992765, 'run': 20.13998439628178, 'test_avg': 20.390625, 'test_std': 1.6499733662623164}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5501 / 10001):
    Value Loss: {'avg': 35.89798525969187, 'std': 2.5415003636343285}
    Value Grad Norm: {'avg': 388.36710357666016, 'std': 142.04078030832352}
    Policy Loss: {'avg': -0.003923601019778289, 'std': 0.008018490462445009}
    Total_Loss: {'avg': -0.11733247805386782, 'std': 0.008592863735711113}
    Policy Entropy: {'avg': 1.145611047744751, 'std': 0.5064274072647095}
    KL Divergence: {'avg': 0.025138970464468002, 'std': 0.19592703878879547}
    Policy Grad Norm: {'avg': 3.0602876730263233, 'std': 1.8369638243230595}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -75.61921740301533, 'std': 24.84891406582726, 'run': -74.69838682634678, 'test_avg': -76.70074478176072, 'test_std': 9.021512696943143}
    Episode Length: {'avg': 20.08068459657702, 'std': 5.453142789208236, 'run': 19.9133086864115, 'test_avg': 20.3525390625, 'test_std': 1.8523985186540237}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (5601 / 10001):
    Value Loss: {'avg': 35.59030902385712, 'std': 4.215183628382565}
    Value Grad Norm: {'avg': 543.72514184316, 'std': 204.86926023641345}
    Policy Loss: {'avg': 0.0027113759133499116, 'std': 0.004931532837968268}
    Total_Loss: {'avg': -0.10386399598792195, 'std': 0.005316059439061976}
    Policy Entropy: {'avg': 1.134012222290039, 'std': 0.5223092436790466}
    KL Divergence: {'avg': 0.021770674735307693, 'std': 0.20357447862625122}
    Policy Grad Norm: {'avg': 2.6477429419755936, 'std': 0.8398187191450562}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.32898967827875, 'std': 26.569166709591343, 'run': -73.02674293283523, 'test_avg': -76.3718935997999, 'test_std': 7.847193026262434}
    Episode Length: {'avg': 19.657004830917874, 'std': 5.835774786389943, 'run': 19.58830977901928, 'test_avg': 20.2763671875, 'test_std': 1.7350894040865272}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (5701 / 10001):
    Value Loss: {'avg': 37.06982572873434, 'std': 3.630627203515265}
    Value Grad Norm: {'avg': 489.4932435353597, 'std': 198.50491192181872}
    Policy Loss: {'avg': 0.0028566899127326906, 'std': 0.004289314034347249}
    Total_Loss: {'avg': -0.10905024688690901, 'std': 0.004970234327223195}
    Policy Entropy: {'avg': 1.0999852418899536, 'std': 0.5075509548187256}
    KL Divergence: {'avg': 0.020230069756507874, 'std': 0.17994950711727142}
    Policy Grad Norm: {'avg': 2.367341071367264, 'std': 0.43594791434350894}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.90163064503592, 'std': 24.389868136832188, 'run': -74.99647909182372, 'test_avg': -75.7952026269187, 'test_std': 7.035757988436306}
    Episode Length: {'avg': 20.214463840399002, 'std': 5.402399972295883, 'run': 20.02548395608642, 'test_avg': 20.15625, 'test_std': 1.5490042164242162}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5801 / 10001):
    Value Loss: {'avg': 37.52961234251658, 'std': 3.705726448219974}
    Value Grad Norm: {'avg': 565.0856768290201, 'std': 233.08827626708225}
    Policy Loss: {'avg': 0.003316376532893628, 'std': 0.006086503308079444}
    Total_Loss: {'avg': -0.11118812346830964, 'std': 0.006761434167598679}
    Policy Entropy: {'avg': 1.1660175323486328, 'std': 0.5369007587432861}
    KL Divergence: {'avg': 0.01748347282409668, 'std': 0.1627020388841629}
    Policy Grad Norm: {'avg': 2.8619773238897324, 'std': 1.4128578843187034}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.36049280978304, 'std': 23.690908995430505, 'run': -75.95994496566385, 'test_avg': -76.05545058941374, 'test_std': 6.658409568454644}
    Episode Length: {'avg': 20.25862068965517, 'std': 5.188051075266312, 'run': 20.11409906705272, 'test_avg': 20.1640625, 'test_std': 1.450497456424433}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (5901 / 10001):
    Value Loss: {'avg': 30.43357479572296, 'std': 3.1926437168157435}
    Value Grad Norm: {'avg': 425.17176183064777, 'std': 125.98247668853054}
    Policy Loss: {'avg': 0.005431737285107374, 'std': 0.008225161117076827}
    Total_Loss: {'avg': -0.10162997804582119, 'std': 0.008449256995784834}
    Policy Entropy: {'avg': 1.0762653350830078, 'std': 0.5148829221725464}
    KL Divergence: {'avg': 0.021962743252515793, 'std': 0.18926405906677246}
    Policy Grad Norm: {'avg': 3.004773646593094, 'std': 1.1551209157277864}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.47085317215556, 'std': 23.299659916797985, 'run': -76.32782300780656, 'test_avg': -76.2219425256772, 'test_std': 7.546332736590762}
    Episode Length: {'avg': 20.088669950738915, 'std': 5.168302377231431, 'run': 20.308164610124898, 'test_avg': 20.201171875, 'test_std': 1.5614241901895156}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6001 / 10001):
    Value Loss: {'avg': 35.76587931315104, 'std': 4.466335429289607}
    Value Grad Norm: {'avg': 414.81274032592773, 'std': 199.38300256134121}
    Policy Loss: {'avg': 0.008897979685571045, 'std': 0.005597459948046191}
    Total_Loss: {'avg': -0.10436504520475864, 'std': 0.005663550752538886}
    Policy Entropy: {'avg': 1.1479058265686035, 'std': 0.5326447486877441}
    KL Divergence: {'avg': 0.024912020191550255, 'std': 0.21782521903514862}
    Policy Grad Norm: {'avg': 3.932604618370533, 'std': 2.5771956549812556}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.28458431001124, 'std': 24.907466868005066, 'run': -75.05283382522651, 'test_avg': -76.47403578878115, 'test_std': 7.232190213563102}
    Episode Length: {'avg': 20.312655086848636, 'std': 5.515285652522971, 'run': 20.0132393277489, 'test_avg': 20.3046875, 'test_std': 1.5527626274945407}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6101 / 10001):
    Value Loss: {'avg': 39.05833729108175, 'std': 2.9905486275397126}
    Value Grad Norm: {'avg': 600.423875172933, 'std': 267.50948008122714}
    Policy Loss: {'avg': -0.000769516991567798, 'std': 0.00908045762414577}
    Total_Loss: {'avg': -0.1124811745248735, 'std': 0.00956688895746522}
    Policy Entropy: {'avg': 1.1291508674621582, 'std': 0.5075183510780334}
    KL Divergence: {'avg': 0.021517744287848473, 'std': 0.18199335038661957}
    Policy Grad Norm: {'avg': 2.526974603533745, 'std': 0.7470172504621359}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -75.37854385133689, 'std': 24.058760978551767, 'run': -75.97333356005745, 'test_avg': -76.22547292751602, 'test_std': 8.157319224592399}
    Episode Length: {'avg': 20.07766990291262, 'std': 5.232347707464845, 'run': 20.24459970684037, 'test_avg': 20.2705078125, 'test_std': 1.7190537617760722}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6201 / 10001):
    Value Loss: {'avg': 26.641222318013508, 'std': 2.107310980146024}
    Value Grad Norm: {'avg': 324.2719306945801, 'std': 116.73327001717506}
    Policy Loss: {'avg': 0.0015746780845802277, 'std': 0.004361176811367864}
    Total_Loss: {'avg': -0.10261694807559252, 'std': 0.004778028828299842}
    Policy Entropy: {'avg': 1.0280157327651978, 'std': 0.5339018702507019}
    KL Divergence: {'avg': 0.021658573299646378, 'std': 0.19407585263252258}
    Policy Grad Norm: {'avg': 2.539476804435253, 'std': 0.8154154020814051}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.37272938976693, 'std': 21.42348261797185, 'run': -76.0064457865176, 'test_avg': -75.54205637876446, 'test_std': 7.950045472152079}
    Episode Length: {'avg': 20.27493917274939, 'std': 4.711101935215222, 'run': 20.13468242978842, 'test_avg': 20.08203125, 'test_std': 1.7317997138882537}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6301 / 10001):
    Value Loss: {'avg': 31.515617688496906, 'std': 3.1311169533893395}
    Value Grad Norm: {'avg': 641.1034520467123, 'std': 302.5411666278504}
    Policy Loss: {'avg': 0.004298877087421715, 'std': 0.007944003342993647}
    Total_Loss: {'avg': -0.10188803402706981, 'std': 0.009070622560985757}
    Policy Entropy: {'avg': 1.136301875114441, 'std': 0.5324432849884033}
    KL Divergence: {'avg': 0.01596587523818016, 'std': 0.15206293761730194}
    Policy Grad Norm: {'avg': 2.553064852952957, 'std': 0.6675493095105486}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.22876562851013, 'std': 22.675552201724937, 'run': -75.1876272125042, 'test_avg': -76.28332877802758, 'test_std': 10.39786427444971}
    Episode Length: {'avg': 20.036585365853657, 'std': 4.9854547507705815, 'run': 20.06284183286609, 'test_avg': 20.2021484375, 'test_std': 2.148572217012104}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (6401 / 10001):
    Value Loss: {'avg': 46.459768215815224, 'std': 5.421046615946908}
    Value Grad Norm: {'avg': 643.2913668950399, 'std': 330.612913370078}
    Policy Loss: {'avg': -0.0007790403760736808, 'std': 0.006735195486294236}
    Total_Loss: {'avg': -0.12674065213650465, 'std': 0.009027397135952884}
    Policy Entropy: {'avg': 1.2473881244659424, 'std': 0.5356674194335938}
    KL Divergence: {'avg': 0.020945768803358078, 'std': 0.18595199286937714}
    Policy Grad Norm: {'avg': 2.57429751008749, 'std': 0.9173659556652561}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -78.43945278748852, 'std': 26.584756347675278, 'run': -77.87069170258874, 'test_avg': -76.07991077759459, 'test_std': 8.692113387390219}
    Episode Length: {'avg': 20.803108808290155, 'std': 5.929428728835259, 'run': 20.642113959989274, 'test_avg': 20.1826171875, 'test_std': 1.9522749615076227}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (6501 / 10001):
    Value Loss: {'avg': 30.151159803072613, 'std': 3.00377140296654}
    Value Grad Norm: {'avg': 427.7318871815999, 'std': 198.64451802513744}
    Policy Loss: {'avg': 0.0043023701291531324, 'std': 0.005475546200925019}
    Total_Loss: {'avg': -0.09908074513077736, 'std': 0.005199446395164867}
    Policy Entropy: {'avg': 1.0627657175064087, 'std': 0.5353161096572876}
    KL Divergence: {'avg': 0.022385936230421066, 'std': 0.19423070549964905}
    Policy Grad Norm: {'avg': 3.0853026136755943, 'std': 1.130878942632337}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.8986568556357, 'std': 25.27176085314581, 'run': -74.15416068116609, 'test_avg': -75.72018388351592, 'test_std': 6.8552124912423205}
    Episode Length: {'avg': 19.707434052757794, 'std': 5.587393088143195, 'run': 19.789872270675836, 'test_avg': 20.16015625, 'test_std': 1.510294872065034}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6601 / 10001):
    Value Loss: {'avg': 32.08883122603098, 'std': 2.708860594885593}
    Value Grad Norm: {'avg': 384.41741911570233, 'std': 153.93499583274226}
    Policy Loss: {'avg': 0.007433506980305538, 'std': 0.005499474270498696}
    Total_Loss: {'avg': -0.10084192175418139, 'std': 0.006070560604078771}
    Policy Entropy: {'avg': 1.0709466934204102, 'std': 0.5384193062782288}
    KL Divergence: {'avg': 0.01982053555548191, 'std': 0.21429534256458282}
    Policy Grad Norm: {'avg': 3.581259548664093, 'std': 2.5832294966526113}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.24783099326903, 'std': 23.694187624806855, 'run': -74.44688601250363, 'test_avg': -75.82029853140207, 'test_std': 7.114566956955054}
    Episode Length: {'avg': 20.009779951100246, 'std': 5.190258149473872, 'run': 19.83991473180239, 'test_avg': 20.1220703125, 'test_std': 1.53911919658815}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (6701 / 10001):
    Value Loss: {'avg': 28.308898250261944, 'std': 3.532690134625987}
    Value Grad Norm: {'avg': 405.84127648671466, 'std': 152.84835614738674}
    Policy Loss: {'avg': 0.00278276510653086, 'std': 0.007644016072896334}
    Total_Loss: {'avg': -0.10017122374847531, 'std': 0.006577817715188453}
    Policy Entropy: {'avg': 0.9925264120101929, 'std': 0.5306238532066345}
    KL Divergence: {'avg': 0.01978086680173874, 'std': 0.17758262157440186}
    Policy Grad Norm: {'avg': 2.662615768611431, 'std': 1.2387568583553206}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.86102877542531, 'std': 23.86949733248115, 'run': -74.96884028864514, 'test_avg': -75.2890566207248, 'test_std': 7.863260003249311}
    Episode Length: {'avg': 19.53771289537713, 'std': 5.242574507804574, 'run': 20.01735562465117, 'test_avg': 20.060546875, 'test_std': 1.6316708310586834}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6801 / 10001):
    Value Loss: {'avg': 31.68232758839925, 'std': 2.8785963153739083}
    Value Grad Norm: {'avg': 446.09760570526123, 'std': 196.90056754920016}
    Policy Loss: {'avg': 0.00402188251609914, 'std': 0.005835566904343364}
    Total_Loss: {'avg': -0.1070662597194314, 'std': 0.004382536435794102}
    Policy Entropy: {'avg': 1.0307294130325317, 'std': 0.5091948509216309}
    KL Divergence: {'avg': 0.022998668253421783, 'std': 0.1891741305589676}
    Policy Grad Norm: {'avg': 2.3729095831513405, 'std': 0.6249148547657971}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -77.73373753208146, 'std': 22.093130427002052, 'run': -77.56230517608455, 'test_avg': -75.61581945729475, 'test_std': 8.00836902443043}
    Episode Length: {'avg': 20.533834586466167, 'std': 4.839606135997611, 'run': 20.527710550344512, 'test_avg': 20.080078125, 'test_std': 1.6628505251213905}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (6901 / 10001):
    Value Loss: {'avg': 32.75342265764872, 'std': 4.721165132335668}
    Value Grad Norm: {'avg': 366.63771597544354, 'std': 141.8874772243849}
    Policy Loss: {'avg': 0.003938830690458417, 'std': 0.005814824065268097}
    Total_Loss: {'avg': -0.1055383225902915, 'std': 0.00594240913119839}
    Policy Entropy: {'avg': 1.0877313613891602, 'std': 0.5500965714454651}
    KL Divergence: {'avg': 0.020169991999864578, 'std': 0.17794524133205414}
    Policy Grad Norm: {'avg': 2.341445967555046, 'std': 0.7964555137607328}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.17552610648853, 'std': 25.996378377135734, 'run': -73.03694950221309, 'test_avg': -75.80823529084424, 'test_std': 7.232683717953594}
    Episode Length: {'avg': 19.62864077669903, 'std': 5.78460084105862, 'run': 19.541302393820065, 'test_avg': 20.1982421875, 'test_std': 1.5906086799069137}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7001 / 10001):
    Value Loss: {'avg': 30.49064787228902, 'std': 2.8419040506503994}
    Value Grad Norm: {'avg': 439.238733291626, 'std': 238.33572141222663}
    Policy Loss: {'avg': 0.0034741992567433044, 'std': 0.005187277659124201}
    Total_Loss: {'avg': -0.0977477771230042, 'std': 0.006921158307231274}
    Policy Entropy: {'avg': 0.955926775932312, 'std': 0.5260562300682068}
    KL Divergence: {'avg': 0.01962694153189659, 'std': 0.18338711559772491}
    Policy Grad Norm: {'avg': 2.625218130648136, 'std': 1.0018650104277749}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.56087376776378, 'std': 24.72908780633446, 'run': -74.35721878355045, 'test_avg': -75.01153926692211, 'test_std': 6.5541132437049}
    Episode Length: {'avg': 19.71325301204819, 'std': 5.439896594612924, 'run': 19.89719136117325, 'test_avg': 19.9521484375, 'test_std': 1.4089055736515164}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7101 / 10001):
    Value Loss: {'avg': 35.02529033025106, 'std': 3.7896611877060815}
    Value Grad Norm: {'avg': 437.1515235900879, 'std': 164.36053267309038}
    Policy Loss: {'avg': -0.002591688171378337, 'std': 0.009488173887624725}
    Total_Loss: {'avg': -0.11315359617583454, 'std': 0.010310194240970249}
    Policy Entropy: {'avg': 1.126905918121338, 'std': 0.5263419151306152}
    KL Divergence: {'avg': 0.01941981539130211, 'std': 0.1613650918006897}
    Policy Grad Norm: {'avg': 3.0423569343984127, 'std': 1.3583858273814944}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -74.11645443023802, 'std': 26.209804067155282, 'run': -74.08723865320906, 'test_avg': -75.88789410240554, 'test_std': 7.717105046812745}
    Episode Length: {'avg': 19.789598108747043, 'std': 5.756746321254546, 'run': 19.781734474620787, 'test_avg': 20.15234375, 'test_std': 1.608156205670313}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7201 / 10001):
    Value Loss: {'avg': 31.30036497116089, 'std': 2.762939213082761}
    Value Grad Norm: {'avg': 425.76823329925537, 'std': 143.15706809420612}
    Policy Loss: {'avg': 0.002614676719531417, 'std': 0.004811446059142021}
    Total_Loss: {'avg': -0.10194346774369478, 'std': 0.005496354746000074}
    Policy Entropy: {'avg': 1.1589691638946533, 'std': 0.513603687286377}
    KL Divergence: {'avg': 0.018358170986175537, 'std': 0.2006850391626358}
    Policy Grad Norm: {'avg': 2.971268817782402, 'std': 1.4332424568704476}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.82505702086014, 'std': 23.983564799448427, 'run': -70.98829542840483, 'test_avg': -75.39988761958742, 'test_std': 6.5233348238565885}
    Episode Length: {'avg': 19.702179176755447, 'std': 5.192742196794975, 'run': 19.109031315890952, 'test_avg': 20.03125, 'test_std': 1.3992883235773819}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7301 / 10001):
    Value Loss: {'avg': 30.712221185366314, 'std': 4.022493071491301}
    Value Grad Norm: {'avg': 707.1376708348593, 'std': 380.225707961665}
    Policy Loss: {'avg': 0.0033471936476416886, 'std': 0.007608014245766303}
    Total_Loss: {'avg': -0.10763715207576752, 'std': 0.008366739948199987}
    Policy Entropy: {'avg': 1.1173958778381348, 'std': 0.5119832754135132}
    KL Divergence: {'avg': 0.027442708611488342, 'std': 0.20120041072368622}
    Policy Grad Norm: {'avg': 2.6469677537679672, 'std': 0.9728792729648912}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.21484122855387, 'std': 21.816991073739587, 'run': -76.77233374277172, 'test_avg': -75.46778642642764, 'test_std': 6.902012373530912}
    Episode Length: {'avg': 20.242053789731052, 'std': 4.8014455532193265, 'run': 20.371171600776933, 'test_avg': 20.078125, 'test_std': 1.504469253383066}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7401 / 10001):
    Value Loss: {'avg': 26.416372299194336, 'std': 2.9079600168424165}
    Value Grad Norm: {'avg': 371.5953149795532, 'std': 161.10254244526723}
    Policy Loss: {'avg': 0.007273276511114091, 'std': 0.011756944447705807}
    Total_Loss: {'avg': -0.09206814458593726, 'std': 0.01035556515577073}
    Policy Entropy: {'avg': 1.0143706798553467, 'std': 0.569704532623291}
    KL Divergence: {'avg': 0.026357753202319145, 'std': 0.21115551888942719}
    Policy Grad Norm: {'avg': 4.3418454229831696, 'std': 4.122798477129285}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.1554015754154, 'std': 24.400078356138046, 'run': -73.02597170051999, 'test_avg': -75.56738190166016, 'test_std': 8.315979772312934}
    Episode Length: {'avg': 19.524940617577197, 'std': 5.340427119021087, 'run': 19.515002735137827, 'test_avg': 20.083984375, 'test_std': 1.6614826961951363}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7501 / 10001):
    Value Loss: {'avg': 27.772565921147663, 'std': 3.03476612408095}
    Value Grad Norm: {'avg': 381.2933174769084, 'std': 150.07641737498042}
    Policy Loss: {'avg': 0.0033967437921091914, 'std': 0.004718351041576313}
    Total_Loss: {'avg': -0.09675415605306625, 'std': 0.006231722431198755}
    Policy Entropy: {'avg': 1.0026013851165771, 'std': 0.535078763961792}
    KL Divergence: {'avg': 0.021453583613038063, 'std': 0.17354023456573486}
    Policy Grad Norm: {'avg': 3.1968278884887695, 'std': 1.5087028070948818}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.45634079569506, 'std': 23.55262483578351, 'run': -73.61376836182333, 'test_avg': -75.09800801899297, 'test_std': 6.556445100893637}
    Episode Length: {'avg': 19.90864197530864, 'std': 5.236533523329544, 'run': 19.73459854501122, 'test_avg': 19.99609375, 'test_std': 1.4368151816468733}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (7601 / 10001):
    Value Loss: {'avg': 30.05968713760376, 'std': 3.9603126002484754}
    Value Grad Norm: {'avg': 454.7026192347209, 'std': 208.37169863984084}
    Policy Loss: {'avg': 0.005575756629696116, 'std': 0.005831539265179791}
    Total_Loss: {'avg': -0.09700878337025642, 'std': 0.007243631861123541}
    Policy Entropy: {'avg': 0.9975506067276001, 'std': 0.5530583262443542}
    KL Divergence: {'avg': 0.021510522812604904, 'std': 0.21119432151317596}
    Policy Grad Norm: {'avg': 3.3023899495601654, 'std': 1.1371154505395986}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.89806108756677, 'std': 22.458221800380258, 'run': -75.01007555738526, 'test_avg': -75.25698781439083, 'test_std': 8.441966912951553}
    Episode Length: {'avg': 20.004866180048662, 'std': 4.96851161890088, 'run': 20.05493014611141, 'test_avg': 19.9990234375, 'test_std': 1.6889458572807132}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (7701 / 10001):
    Value Loss: {'avg': 30.109197815259297, 'std': 2.696790361085141}
    Value Grad Norm: {'avg': 365.24477132161456, 'std': 146.53817577138946}
    Policy Loss: {'avg': 0.005377254623454064, 'std': 0.0064906453342751325}
    Total_Loss: {'avg': -0.10186386341229081, 'std': 0.007392735013766633}
    Policy Entropy: {'avg': 1.1134872436523438, 'std': 0.5143386125564575}
    KL Divergence: {'avg': 0.023135319352149963, 'std': 0.22093290090560913}
    Policy Grad Norm: {'avg': 2.7343402057886124, 'std': 0.8328380924805986}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.05398220969744, 'std': 26.460412621497394, 'run': -74.34290964642986, 'test_avg': -75.50926482847284, 'test_std': 8.602353504581659}
    Episode Length: {'avg': 19.49056603773585, 'std': 5.781795247444765, 'run': 19.76692942160764, 'test_avg': 20.0595703125, 'test_std': 1.8036871445371707}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (7801 / 10001):
    Value Loss: {'avg': 34.19684052467346, 'std': 3.8133047534390365}
    Value Grad Norm: {'avg': 458.0883836746216, 'std': 183.22133586209426}
    Policy Loss: {'avg': -0.0017546000017318875, 'std': 0.00316136829314224}
    Total_Loss: {'avg': -0.11237901356071234, 'std': 0.0036438350980655065}
    Policy Entropy: {'avg': 1.1039506196975708, 'std': 0.507613480091095}
    KL Divergence: {'avg': 0.020571758970618248, 'std': 0.1813034564256668}
    Policy Grad Norm: {'avg': 2.4430645257234573, 'std': 0.49756019435498566}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.87012381139377, 'std': 23.78445478846768, 'run': -78.30860697045985, 'test_avg': -75.40213925099191, 'test_std': 7.030779614464348}
    Episode Length: {'avg': 20.313725490196077, 'std': 5.219177292535566, 'run': 20.65413629374161, 'test_avg': 19.99609375, 'test_std': 1.5213276656299055}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (7901 / 10001):
    Value Loss: {'avg': 27.388875365257263, 'std': 2.6493766793655524}
    Value Grad Norm: {'avg': 353.9685068130493, 'std': 171.58080397874085}
    Policy Loss: {'avg': 0.006439198114094324, 'std': 0.01042009523463296}
    Total_Loss: {'avg': -0.09375266218557954, 'std': 0.010039519648052745}
    Policy Entropy: {'avg': 1.0726981163024902, 'std': 0.5241848826408386}
    KL Divergence: {'avg': 0.019922463223338127, 'std': 0.22605258226394653}
    Policy Grad Norm: {'avg': 3.1513054594397545, 'std': 1.6729868758163275}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.01102008316128, 'std': 23.276150052488987, 'run': -72.43966050025061, 'test_avg': -75.14062410421542, 'test_std': 6.746308304399459}
    Episode Length: {'avg': 19.507142857142856, 'std': 5.0969128311325145, 'run': 19.35570903099592, 'test_avg': 19.990234375, 'test_std': 1.4776665329391334}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8001 / 10001):
    Value Loss: {'avg': 24.40512728691101, 'std': 2.118620040034313}
    Value Grad Norm: {'avg': 427.6452833811442, 'std': 178.02261490886872}
    Policy Loss: {'avg': 0.002319129300303757, 'std': 0.003964194908305445}
    Total_Loss: {'avg': -0.0956183304078877, 'std': 0.005178149678127524}
    Policy Entropy: {'avg': 0.9744156002998352, 'std': 0.5378833413124084}
    KL Divergence: {'avg': 0.017374299466609955, 'std': 0.15820586681365967}
    Policy Grad Norm: {'avg': 2.885041296482086, 'std': 1.037078205088777}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.83126492253395, 'std': 21.940873798518933, 'run': -72.59701712898101, 'test_avg': -74.8053148654038, 'test_std': 6.848209142805654}
    Episode Length: {'avg': 19.77912621359223, 'std': 4.895733352802216, 'run': 19.5041020989312, 'test_avg': 19.8798828125, 'test_std': 1.4790944184760788}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8101 / 10001):
    Value Loss: {'avg': 26.402618050575256, 'std': 3.1415337276170265}
    Value Grad Norm: {'avg': 402.95146656036377, 'std': 186.19627340318863}
    Policy Loss: {'avg': 0.0013397415750660002, 'std': 0.004114969743024677}
    Total_Loss: {'avg': -0.10062490962445736, 'std': 0.005772262609417504}
    Policy Entropy: {'avg': 0.9606031179428101, 'std': 0.5291098952293396}
    KL Divergence: {'avg': 0.02761724777519703, 'std': 0.2378576695919037}
    Policy Grad Norm: {'avg': 3.4699719175696373, 'std': 1.3446422646011575}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.9238676890051, 'std': 22.8027177054207, 'run': -73.21783692904323, 'test_avg': -74.93233358236424, 'test_std': 11.768688549812595}
    Episode Length: {'avg': 19.72596153846154, 'std': 4.981880537591041, 'run': 19.54296911968125, 'test_avg': 19.9375, 'test_std': 2.424645592658853}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.990234375}

Iteration (8201 / 10001):
    Value Loss: {'avg': 28.91345949967702, 'std': 3.5428713616882446}
    Value Grad Norm: {'avg': 391.496470451355, 'std': 162.15552469762278}
    Policy Loss: {'avg': 0.005165506634511985, 'std': 0.005821225155832885}
    Total_Loss: {'avg': -0.09788193041458726, 'std': 0.006544874932255842}
    Policy Entropy: {'avg': 1.007380485534668, 'std': 0.5534920692443848}
    KL Divergence: {'avg': 0.020943358540534973, 'std': 0.18488414585590363}
    Policy Grad Norm: {'avg': 3.0908934473991394, 'std': 1.0421700605790196}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.37196387969952, 'std': 25.518089577030864, 'run': -71.51217088917828, 'test_avg': -75.39906466632178, 'test_std': 9.576885471935068}
    Episode Length: {'avg': 19.408450704225352, 'std': 5.5637427825086725, 'run': 19.216325752910375, 'test_avg': 20.041015625, 'test_std': 1.952631773659811}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9951171875}

Iteration (8301 / 10001):
    Value Loss: {'avg': 25.91590742270152, 'std': 2.0605308426447717}
    Value Grad Norm: {'avg': 378.2658580144246, 'std': 140.0475080621446}
    Policy Loss: {'avg': 0.0005203982873354107, 'std': 0.0036697883906587924}
    Total_Loss: {'avg': -0.09735125489532948, 'std': 0.004783565175978657}
    Policy Entropy: {'avg': 0.9932458400726318, 'std': 0.4977276027202606}
    KL Divergence: {'avg': 0.016072476282715797, 'std': 0.17173254489898682}
    Policy Grad Norm: {'avg': 2.861567437648773, 'std': 0.8129399283255233}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -70.81782684759457, 'std': 25.61571514045084, 'run': -71.69592131250116, 'test_avg': -75.10479251353274, 'test_std': 7.9941835584603265}
    Episode Length: {'avg': 19.07565011820331, 'std': 5.649238781377966, 'run': 19.234947146505228, 'test_avg': 19.990234375, 'test_std': 1.6735249871359434}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (8401 / 10001):
    Value Loss: {'avg': 27.36359214782715, 'std': 2.683703399482607}
    Value Grad Norm: {'avg': 403.6403474807739, 'std': 119.23552397390151}
    Policy Loss: {'avg': 0.004178198898443952, 'std': 0.007493461184478731}
    Total_Loss: {'avg': -0.1054144543595612, 'std': 0.0073770916921562495}
    Policy Entropy: {'avg': 1.0983316898345947, 'std': 0.5119749903678894}
    KL Divergence: {'avg': 0.024249380454421043, 'std': 0.2672681510448456}
    Policy Grad Norm: {'avg': 2.6355943828821182, 'std': 0.8529492309347966}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -76.61094823531127, 'std': 21.79125189713387, 'run': -79.27469852003767, 'test_avg': -74.74317217641533, 'test_std': 6.2832701961449375}
    Episode Length: {'avg': 20.383458646616543, 'std': 4.812871950165608, 'run': 20.97620964621255, 'test_avg': 19.9111328125, 'test_std': 1.3802856807508508}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (8501 / 10001):
    Value Loss: {'avg': 28.36727797985077, 'std': 3.1954329115961664}
    Value Grad Norm: {'avg': 461.9403009414673, 'std': 192.8305930071122}
    Policy Loss: {'avg': 0.006011814024532214, 'std': 0.004705718138246229}
    Total_Loss: {'avg': -0.09729349706321955, 'std': 0.0048790397093054225}
    Policy Entropy: {'avg': 1.0511841773986816, 'std': 0.5309340357780457}
    KL Divergence: {'avg': 0.015774497762322426, 'std': 0.169215127825737}
    Policy Grad Norm: {'avg': 2.7258609756827354, 'std': 0.7474420861459768}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.69224236670875, 'std': 24.30355286686424, 'run': -73.06977625372006, 'test_avg': -74.99814196537008, 'test_std': 7.099663226673229}
    Episode Length: {'avg': 19.474178403755868, 'std': 5.337047407434654, 'run': 19.616902172120763, 'test_avg': 19.92578125, 'test_std': 1.5284922152724356}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8601 / 10001):
    Value Loss: {'avg': 28.573694070180256, 'std': 2.999548051093668}
    Value Grad Norm: {'avg': 360.48014704386395, 'std': 106.48903432671078}
    Policy Loss: {'avg': 0.0026825902750715613, 'std': 0.0061364597870483695}
    Total_Loss: {'avg': -0.09696100372821093, 'std': 0.0066114559069368915}
    Policy Entropy: {'avg': 0.9933515191078186, 'std': 0.524142861366272}
    KL Divergence: {'avg': 0.023251667618751526, 'std': 0.19254423677921295}
    Policy Grad Norm: {'avg': 2.123746246099472, 'std': 0.42652486249561145}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.93106488640939, 'std': 23.690538833790097, 'run': -73.9806875181047, 'test_avg': -75.33940995615768, 'test_std': 7.932950242093728}
    Episode Length: {'avg': 19.750599520383695, 'std': 5.239140269898644, 'run': 19.758030407444842, 'test_avg': 20.0380859375, 'test_std': 1.622448311615734}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8701 / 10001):
    Value Loss: {'avg': 24.20620055993398, 'std': 2.4189985904467175}
    Value Grad Norm: {'avg': 363.4647267659505, 'std': 127.47537569637483}
    Policy Loss: {'avg': 0.00044560115202330053, 'std': 0.016182977821218397}
    Total_Loss: {'avg': -0.10492210136726499, 'std': 0.015403992528100029}
    Policy Entropy: {'avg': 1.0668773651123047, 'std': 0.514795184135437}
    KL Divergence: {'avg': 0.02312837727367878, 'std': 0.17777258157730103}
    Policy Grad Norm: {'avg': 2.8093119338154793, 'std': 2.632135048455347}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -72.92857256356747, 'std': 23.924546468595597, 'run': -74.27584045209372, 'test_avg': -74.74706115535946, 'test_std': 7.344541487937265}
    Episode Length: {'avg': 19.509345794392523, 'std': 5.249157167954126, 'run': 19.813105541604624, 'test_avg': 19.93359375, 'test_std': 1.5981814540160755}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8801 / 10001):
    Value Loss: {'avg': 24.379122257232666, 'std': 3.6791547683175096}
    Value Grad Norm: {'avg': 370.84742164611816, 'std': 152.25760445474927}
    Policy Loss: {'avg': 0.006648506358033046, 'std': 0.005549664334397559}
    Total_Loss: {'avg': -0.08931384002789855, 'std': 0.006065060093301413}
    Policy Entropy: {'avg': 0.9153507947921753, 'std': 0.5448833703994751}
    KL Divergence: {'avg': 0.017005417495965958, 'std': 0.17597341537475586}
    Policy Grad Norm: {'avg': 3.251508951187134, 'std': 1.108820345494565}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.96984491946637, 'std': 22.34185515723909, 'run': -73.08697818385997, 'test_avg': -74.8719381977406, 'test_std': 7.593387145684167}
    Episode Length: {'avg': 19.602905569007262, 'std': 4.969855014989614, 'run': 19.656126128263153, 'test_avg': 20.0224609375, 'test_std': 1.6672639094596335}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (8901 / 10001):
    Value Loss: {'avg': 24.46300522486369, 'std': 2.1463285648750388}
    Value Grad Norm: {'avg': 338.0085636774699, 'std': 140.35698291888758}
    Policy Loss: {'avg': 0.005992333346512169, 'std': 0.004973665962635061}
    Total_Loss: {'avg': -0.09909325232729316, 'std': 0.0053481559180058}
    Policy Entropy: {'avg': 1.0588395595550537, 'std': 0.5292775630950928}
    KL Divergence: {'avg': 0.02627328410744667, 'std': 0.22417975962162018}
    Policy Grad Norm: {'avg': 2.487114131450653, 'std': 0.850841510813583}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.65459892360713, 'std': 24.762743637991065, 'run': -71.09812452854845, 'test_avg': -74.2432517121667, 'test_std': 7.203297259722502}
    Episode Length: {'avg': 19.210401891252957, 'std': 5.3647730749596505, 'run': 19.130116226421304, 'test_avg': 19.7490234375, 'test_std': 1.5355485021892612}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9001 / 10001):
    Value Loss: {'avg': 24.88115127881368, 'std': 3.1661242029842254}
    Value Grad Norm: {'avg': 377.9043159484863, 'std': 173.0798212138562}
    Policy Loss: {'avg': 0.0029532246699091047, 'std': 0.004687230744243981}
    Total_Loss: {'avg': -0.0921104559674859, 'std': 0.005357250376324567}
    Policy Entropy: {'avg': 0.9047411680221558, 'std': 0.5128961801528931}
    KL Divergence: {'avg': 0.01502095628529787, 'std': 0.17289921641349792}
    Policy Grad Norm: {'avg': 3.671543464064598, 'std': 1.6149370526784872}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.54775494374348, 'std': 21.19547978195689, 'run': -75.19241781963314, 'test_avg': -74.79776000160915, 'test_std': 7.933090436260676}
    Episode Length: {'avg': 19.891625615763548, 'std': 4.7289152275436885, 'run': 19.98018966312185, 'test_avg': 19.9150390625, 'test_std': 1.6428135398148875}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Iteration (9101 / 10001):
    Value Loss: {'avg': 26.8500763575236, 'std': 2.7026728803575604}
    Value Grad Norm: {'avg': 446.5086326599121, 'std': 213.8043204987434}
    Policy Loss: {'avg': -0.004489769053179771, 'std': 0.010954330280130209}
    Total_Loss: {'avg': -0.10753568517975509, 'std': 0.011087667515062937}
    Policy Entropy: {'avg': 1.0603262186050415, 'std': 0.5091516375541687}
    KL Divergence: {'avg': 0.022265100851655006, 'std': 0.1609562486410141}
    Policy Grad Norm: {'avg': 2.9796192497015, 'std': 1.2320302558793699}
    Num PPO updates: {'avg': 32}
    Return: {'avg': -72.90763183465641, 'std': 24.71848781889164, 'run': -72.10968672706292, 'test_avg': -74.85001525324321, 'test_std': 6.710500329109295}
    Episode Length: {'avg': 19.47906976744186, 'std': 5.388038351218583, 'run': 19.3121383886812, 'test_avg': 19.9560546875, 'test_std': 1.4547277656005873}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9201 / 10001):
    Value Loss: {'avg': 30.82840605576833, 'std': 3.018688757243727}
    Value Grad Norm: {'avg': 445.8726625442505, 'std': 174.21226182288285}
    Policy Loss: {'avg': 0.006062396219931543, 'std': 0.007490082256734335}
    Total_Loss: {'avg': -0.10256413975730538, 'std': 0.006225735816702367}
    Policy Entropy: {'avg': 1.1133623123168945, 'std': 0.5279898047447205}
    KL Divergence: {'avg': 0.019867410883307457, 'std': 0.1836463361978531}
    Policy Grad Norm: {'avg': 2.5161445811390877, 'std': 0.7188669878577038}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -75.8688838376836, 'std': 21.29615426532512, 'run': -75.8079358126191, 'test_avg': -74.45160800025043, 'test_std': 7.531350101949826}
    Episode Length: {'avg': 20.14987714987715, 'std': 4.695090617473082, 'run': 20.10861052199027, 'test_avg': 19.83984375, 'test_std': 1.5051131520872234}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9990234375}

Iteration (9301 / 10001):
    Value Loss: {'avg': 22.895113825798035, 'std': 2.209306425910663}
    Value Grad Norm: {'avg': 319.1887969970703, 'std': 162.91929118166877}
    Policy Loss: {'avg': 0.0042788303981069475, 'std': 0.0045799322255973005}
    Total_Loss: {'avg': -0.0888930968940258, 'std': 0.005310589892239201}
    Policy Entropy: {'avg': 0.9575837850570679, 'std': 0.5276735424995422}
    KL Divergence: {'avg': 0.02329390123486519, 'std': 0.19530083239078522}
    Policy Grad Norm: {'avg': 2.8996465131640434, 'std': 0.748655889839178}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.52314639283377, 'std': 21.803877181183655, 'run': -75.19334537828756, 'test_avg': -74.84328266198514, 'test_std': 6.832327434741867}
    Episode Length: {'avg': 19.700239808153476, 'std': 4.790961207838156, 'run': 20.062757908518748, 'test_avg': 19.9560546875, 'test_std': 1.4773757551852804}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9401 / 10001):
    Value Loss: {'avg': 24.634273409843445, 'std': 2.4568185009990504}
    Value Grad Norm: {'avg': 363.033639272054, 'std': 133.12857761184438}
    Policy Loss: {'avg': 0.0026842894149012864, 'std': 0.005546951717216591}
    Total_Loss: {'avg': -0.0970036331564188, 'std': 0.0048436771221667145}
    Policy Entropy: {'avg': 1.0563255548477173, 'std': 0.5140106081962585}
    KL Divergence: {'avg': 0.024053437635302544, 'std': 0.20589877665042877}
    Policy Grad Norm: {'avg': 2.462229698896408, 'std': 0.8185964866525849}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.8353711969903, 'std': 23.944208420669202, 'run': -70.18745299436134, 'test_avg': -74.74410741091789, 'test_std': 8.338785830152188}
    Episode Length: {'avg': 19.24532710280374, 'std': 5.216177355249242, 'run': 18.894785325854436, 'test_avg': 19.890625, 'test_std': 1.798368944175527}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.9970703125}

Iteration (9501 / 10001):
    Value Loss: {'avg': 24.538896203041077, 'std': 2.3133528581799556}
    Value Grad Norm: {'avg': 339.39211050669354, 'std': 141.95843663225446}
    Policy Loss: {'avg': 0.003797337500145659, 'std': 0.005426430667494766}
    Total_Loss: {'avg': -0.098532909527421, 'std': 0.007036778677645734}
    Policy Entropy: {'avg': 0.9940474033355713, 'std': 0.5218680500984192}
    KL Divergence: {'avg': 0.017357440665364265, 'std': 0.15752726793289185}
    Policy Grad Norm: {'avg': 2.2578631192445755, 'std': 0.612625932842413}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.20120574252977, 'std': 23.84099251382789, 'run': -72.76538561528051, 'test_avg': -74.627770252425, 'test_std': 9.496264100913498}
    Episode Length: {'avg': 19.523114355231144, 'std': 5.225925083388636, 'run': 19.425972705585966, 'test_avg': 19.8974609375, 'test_std': 2.065394133854752}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.994140625}

Iteration (9601 / 10001):
    Value Loss: {'avg': 23.756110072135925, 'std': 2.7018860540408443}
    Value Grad Norm: {'avg': 406.9622046152751, 'std': 176.78814454616065}
    Policy Loss: {'avg': 0.0033312524901703, 'std': 0.006200940843432474}
    Total_Loss: {'avg': -0.09223084151744843, 'std': 0.007102978160227882}
    Policy Entropy: {'avg': 0.9565210342407227, 'std': 0.5371671915054321}
    KL Divergence: {'avg': 0.01910434663295746, 'std': 0.18481722474098206}
    Policy Grad Norm: {'avg': 2.6994880586862564, 'std': 1.469686168828582}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -72.3339024352804, 'std': 22.906528136120173, 'run': -70.8760153175752, 'test_avg': -74.32935230822504, 'test_std': 6.511683891636096}
    Episode Length: {'avg': 19.387173396674584, 'std': 5.016336905881275, 'run': 19.058851174396754, 'test_avg': 19.828125, 'test_std': 1.417575918381446}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9701 / 10001):
    Value Loss: {'avg': 26.09965380032857, 'std': 2.5146662121639767}
    Value Grad Norm: {'avg': 382.30463790893555, 'std': 134.09943543875855}
    Policy Loss: {'avg': 0.002496140659786761, 'std': 0.004203729203571964}
    Total_Loss: {'avg': -0.08736937958747149, 'std': 0.00521903100934613}
    Policy Entropy: {'avg': 0.9061743021011353, 'std': 0.5346067547798157}
    KL Divergence: {'avg': 0.01801496185362339, 'std': 0.17737822234630585}
    Policy Grad Norm: {'avg': 3.7066272497177124, 'std': 1.3811106366822388}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -71.446025004312, 'std': 24.64642397244561, 'run': -71.46383656686642, 'test_avg': -74.51769673452833, 'test_std': 6.36925410425458}
    Episode Length: {'avg': 19.1371158392435, 'std': 5.375288717590523, 'run': 19.129216199956584, 'test_avg': 19.841796875, 'test_std': 1.3529377373849227}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (9801 / 10001):
    Value Loss: {'avg': 23.85648250579834, 'std': 2.112481228155209}
    Value Grad Norm: {'avg': 389.93424224853516, 'std': 150.22994476356834}
    Policy Loss: {'avg': 0.0032206996402237564, 'std': 0.0072336296448356555}
    Total_Loss: {'avg': -0.09693805826827884, 'std': 0.008252501694088196}
    Policy Entropy: {'avg': 0.9857977628707886, 'std': 0.5763490200042725}
    KL Divergence: {'avg': 0.01924559846520424, 'std': 0.17543920874595642}
    Policy Grad Norm: {'avg': 3.25851684063673, 'std': 2.1823902663149695}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.16672127901653, 'std': 23.078806265687472, 'run': -72.17166334661135, 'test_avg': -74.82296651470506, 'test_std': 9.137439523208702}
    Episode Length: {'avg': 19.62142857142857, 'std': 5.121106451980569, 'run': 19.38148437021864, 'test_avg': 19.916015625, 'test_std': 1.8500362495788722}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.99609375}

Iteration (9901 / 10001):
    Value Loss: {'avg': 23.536354899406433, 'std': 1.7938302760760405}
    Value Grad Norm: {'avg': 356.13163471221924, 'std': 161.18823577968098}
    Policy Loss: {'avg': 0.004456874507013708, 'std': 0.005382639638640725}
    Total_Loss: {'avg': -0.0927880541421473, 'std': 0.006632433466961155}
    Policy Entropy: {'avg': 1.0099984407424927, 'std': 0.5259254574775696}
    KL Divergence: {'avg': 0.027742568403482437, 'std': 0.22296860814094543}
    Policy Grad Norm: {'avg': 2.9896168783307076, 'std': 1.6754208499388679}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -73.29796458506644, 'std': 22.099045073290718, 'run': -73.56001544037214, 'test_avg': -74.55032948501417, 'test_std': 6.641194159260245}
    Episode Length: {'avg': 19.6, 'std': 4.870763528380083, 'run': 19.667143802901265, 'test_avg': 19.8720703125, 'test_std': 1.4253019180356674}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 1.0}

Iteration (10001 / 10001):
    Value Loss: {'avg': 23.902182698249817, 'std': 2.317486464151064}
    Value Grad Norm: {'avg': 433.5575234095256, 'std': 180.25808541340908}
    Policy Loss: {'avg': 0.002324852568563074, 'std': 0.0023869854017282838}
    Total_Loss: {'avg': -0.09788518724963069, 'std': 0.003456982987927772}
    Policy Entropy: {'avg': 1.0482254028320312, 'std': 0.5141806602478027}
    KL Divergence: {'avg': 0.01675957441329956, 'std': 0.14722144603729248}
    Policy Grad Norm: {'avg': 2.6247511580586433, 'std': 0.718965760671397}
    Num PPO updates: {'avg': 16}
    Return: {'avg': -74.85513300174665, 'std': 20.185947946191476, 'run': -75.67037896122244, 'test_avg': -74.40271745918392, 'test_std': 7.663257937547743}
    Episode Length: {'avg': 19.943488943488944, 'std': 4.4704050698126885, 'run': 20.118487834726473, 'test_avg': 19.845703125, 'test_std': 1.662318215434468}
    Ratio Terminated: {'avg': 1.0, 'test_avg': 0.998046875}

Training took 31782.420 seconds in total.
